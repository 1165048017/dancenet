{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import model\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mdn\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20210, 1, 128)\n"
     ]
    }
   ],
   "source": [
    "data = np.load('./lv.npy')\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data).reshape(-1,128)\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler = scaler.fit(data)\n",
    "data =  scaler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "numComponents = 24\n",
    "outputDim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 1, 512)            1312768   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 512)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 1, 512)            2099200   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1, 512)            0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 512)               2099200   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1000)              513000    \n",
      "_________________________________________________________________\n",
      "mdn_1 (MDN)                  (None, 128)               6174168   \n",
      "=================================================================\n",
      "Total params: 12,198,336\n",
      "Trainable params: 12,198,336\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(128,))\n",
    "x = Reshape((1,128))(inputs)\n",
    "x = LSTM(512, return_sequences=True,input_shape=(1,128))(x)\n",
    "x = Dropout(0.40)(x)\n",
    "x = LSTM(512, return_sequences=True)(x)\n",
    "x = Dropout(0.40)(x)\n",
    "x = LSTM(512)(x)\n",
    "x = Dropout(0.40)(x)\n",
    "x = Dense(1000,activation='relu')(x)\n",
    "outputs = mdn.MDN(outputDim, numComponents)(x)\n",
    "model = Model(inputs=inputs,outputs=outputs)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.adam(lr=0.0005)\n",
    "model.compile(loss=mdn.get_mixture_loss_func(outputDim,numComponents),optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_grad.py:249: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Train on 16167 samples, validate on 4042 samples\n",
      "Epoch 1/10000\n",
      "16167/16167 [==============================] - 9s 556us/step - loss: 103.2711 - val_loss: 19.1214\n",
      "\n",
      "Epoch 00001: loss improved from inf to 103.27111, saving model to gendance.h5\n",
      "Epoch 2/10000\n",
      "16167/16167 [==============================] - 1s 31us/step - loss: -36.3775 - val_loss: -62.2189\n",
      "\n",
      "Epoch 00002: loss improved from 103.27111 to -36.37748, saving model to gendance.h5\n",
      "Epoch 3/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -63.8749 - val_loss: -73.9898\n",
      "\n",
      "Epoch 00003: loss improved from -36.37748 to -63.87492, saving model to gendance.h5\n",
      "Epoch 4/10000\n",
      "16167/16167 [==============================] - 1s 32us/step - loss: -70.3210 - val_loss: -77.9045\n",
      "\n",
      "Epoch 00004: loss improved from -63.87492 to -70.32097, saving model to gendance.h5\n",
      "Epoch 5/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -74.0362 - val_loss: -79.7741\n",
      "\n",
      "Epoch 00005: loss improved from -70.32097 to -74.03622, saving model to gendance.h5\n",
      "Epoch 6/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -75.3527 - val_loss: -80.1460\n",
      "\n",
      "Epoch 00006: loss improved from -74.03622 to -75.35267, saving model to gendance.h5\n",
      "Epoch 7/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -76.4034 - val_loss: -80.6827\n",
      "\n",
      "Epoch 00007: loss improved from -75.35267 to -76.40343, saving model to gendance.h5\n",
      "Epoch 8/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -77.2424 - val_loss: -81.1322\n",
      "\n",
      "Epoch 00008: loss improved from -76.40343 to -77.24239, saving model to gendance.h5\n",
      "Epoch 9/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -77.3406 - val_loss: -81.1952\n",
      "\n",
      "Epoch 00009: loss improved from -77.24239 to -77.34062, saving model to gendance.h5\n",
      "Epoch 10/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -77.9183 - val_loss: -81.3516\n",
      "\n",
      "Epoch 00010: loss improved from -77.34062 to -77.91833, saving model to gendance.h5\n",
      "Epoch 11/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -78.1988 - val_loss: -81.6052\n",
      "\n",
      "Epoch 00011: loss improved from -77.91833 to -78.19882, saving model to gendance.h5\n",
      "Epoch 12/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -78.2368 - val_loss: -81.6390\n",
      "\n",
      "Epoch 00012: loss improved from -78.19882 to -78.23685, saving model to gendance.h5\n",
      "Epoch 13/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -78.2653 - val_loss: -81.8124\n",
      "\n",
      "Epoch 00013: loss improved from -78.23685 to -78.26527, saving model to gendance.h5\n",
      "Epoch 14/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -78.6887 - val_loss: -81.8245\n",
      "\n",
      "Epoch 00014: loss improved from -78.26527 to -78.68867, saving model to gendance.h5\n",
      "Epoch 15/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -78.8461 - val_loss: -81.8292\n",
      "\n",
      "Epoch 00015: loss improved from -78.68867 to -78.84612, saving model to gendance.h5\n",
      "Epoch 16/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -78.8511 - val_loss: -82.0889\n",
      "\n",
      "Epoch 00016: loss improved from -78.84612 to -78.85114, saving model to gendance.h5\n",
      "Epoch 17/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -79.2734 - val_loss: -82.3543\n",
      "\n",
      "Epoch 00017: loss improved from -78.85114 to -79.27342, saving model to gendance.h5\n",
      "Epoch 18/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -79.5739 - val_loss: -82.3533\n",
      "\n",
      "Epoch 00018: loss improved from -79.27342 to -79.57386, saving model to gendance.h5\n",
      "Epoch 19/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -79.6654 - val_loss: -82.2611\n",
      "\n",
      "Epoch 00019: loss improved from -79.57386 to -79.66545, saving model to gendance.h5\n",
      "Epoch 20/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -79.9151 - val_loss: -82.2257\n",
      "\n",
      "Epoch 00020: loss improved from -79.66545 to -79.91505, saving model to gendance.h5\n",
      "Epoch 21/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -80.1321 - val_loss: -82.2325\n",
      "\n",
      "Epoch 00021: loss improved from -79.91505 to -80.13212, saving model to gendance.h5\n",
      "Epoch 22/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -80.1265 - val_loss: -82.3653\n",
      "\n",
      "Epoch 00022: loss did not improve from -80.13212\n",
      "Epoch 23/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -80.1713 - val_loss: -82.4121\n",
      "\n",
      "Epoch 00023: loss improved from -80.13212 to -80.17128, saving model to gendance.h5\n",
      "Epoch 24/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -80.4069 - val_loss: -82.7159\n",
      "\n",
      "Epoch 00024: loss improved from -80.17128 to -80.40695, saving model to gendance.h5\n",
      "Epoch 25/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -80.5975 - val_loss: -82.6755\n",
      "\n",
      "Epoch 00025: loss improved from -80.40695 to -80.59751, saving model to gendance.h5\n",
      "Epoch 26/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -80.6548 - val_loss: -82.5736\n",
      "\n",
      "Epoch 00026: loss improved from -80.59751 to -80.65481, saving model to gendance.h5\n",
      "Epoch 27/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -80.7986 - val_loss: -82.7351\n",
      "\n",
      "Epoch 00027: loss improved from -80.65481 to -80.79862, saving model to gendance.h5\n",
      "Epoch 28/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -80.9357 - val_loss: -82.7143\n",
      "\n",
      "Epoch 00028: loss improved from -80.79862 to -80.93573, saving model to gendance.h5\n",
      "Epoch 29/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -81.0250 - val_loss: -82.7888\n",
      "\n",
      "Epoch 00029: loss improved from -80.93573 to -81.02496, saving model to gendance.h5\n",
      "Epoch 30/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -81.0909 - val_loss: -82.8941\n",
      "\n",
      "Epoch 00030: loss improved from -81.02496 to -81.09093, saving model to gendance.h5\n",
      "Epoch 31/10000\n",
      "16167/16167 [==============================] - 1s 33us/step - loss: -81.2226 - val_loss: -83.0329\n",
      "\n",
      "Epoch 00031: loss improved from -81.09093 to -81.22263, saving model to gendance.h5\n",
      "Epoch 32/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -81.3597 - val_loss: -83.0708\n",
      "\n",
      "Epoch 00032: loss improved from -81.22263 to -81.35972, saving model to gendance.h5\n",
      "Epoch 33/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -81.4054 - val_loss: -83.1322\n",
      "\n",
      "Epoch 00033: loss improved from -81.35972 to -81.40538, saving model to gendance.h5\n",
      "Epoch 34/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -81.4907 - val_loss: -83.0753\n",
      "\n",
      "Epoch 00034: loss improved from -81.40538 to -81.49066, saving model to gendance.h5\n",
      "Epoch 35/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -81.5593 - val_loss: -83.1720\n",
      "\n",
      "Epoch 00035: loss improved from -81.49066 to -81.55927, saving model to gendance.h5\n",
      "Epoch 36/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -81.6267 - val_loss: -83.0428\n",
      "\n",
      "Epoch 00036: loss improved from -81.55927 to -81.62672, saving model to gendance.h5\n",
      "Epoch 37/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -81.7367 - val_loss: -83.2344\n",
      "\n",
      "Epoch 00037: loss improved from -81.62672 to -81.73669, saving model to gendance.h5\n",
      "Epoch 38/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -81.8642 - val_loss: -83.2979\n",
      "\n",
      "Epoch 00038: loss improved from -81.73669 to -81.86421, saving model to gendance.h5\n",
      "Epoch 39/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -81.8807 - val_loss: -83.3071\n",
      "\n",
      "Epoch 00039: loss improved from -81.86421 to -81.88066, saving model to gendance.h5\n",
      "Epoch 40/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -81.9638 - val_loss: -83.3007\n",
      "\n",
      "Epoch 00040: loss improved from -81.88066 to -81.96380, saving model to gendance.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -82.0382 - val_loss: -83.3253\n",
      "\n",
      "Epoch 00041: loss improved from -81.96380 to -82.03817, saving model to gendance.h5\n",
      "Epoch 42/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -82.1335 - val_loss: -83.4306\n",
      "\n",
      "Epoch 00042: loss improved from -82.03817 to -82.13348, saving model to gendance.h5\n",
      "Epoch 43/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -82.1964 - val_loss: -83.4607\n",
      "\n",
      "Epoch 00043: loss improved from -82.13348 to -82.19639, saving model to gendance.h5\n",
      "Epoch 44/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -82.3019 - val_loss: -83.5194\n",
      "\n",
      "Epoch 00044: loss improved from -82.19639 to -82.30194, saving model to gendance.h5\n",
      "Epoch 45/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -82.3410 - val_loss: -83.4501\n",
      "\n",
      "Epoch 00045: loss improved from -82.30194 to -82.34100, saving model to gendance.h5\n",
      "Epoch 46/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -82.4427 - val_loss: -83.5316\n",
      "\n",
      "Epoch 00046: loss improved from -82.34100 to -82.44271, saving model to gendance.h5\n",
      "Epoch 47/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -82.4794 - val_loss: -83.6135\n",
      "\n",
      "Epoch 00047: loss improved from -82.44271 to -82.47940, saving model to gendance.h5\n",
      "Epoch 48/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -82.5623 - val_loss: -83.5163\n",
      "\n",
      "Epoch 00048: loss improved from -82.47940 to -82.56230, saving model to gendance.h5\n",
      "Epoch 49/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -82.6056 - val_loss: -83.5406\n",
      "\n",
      "Epoch 00049: loss improved from -82.56230 to -82.60561, saving model to gendance.h5\n",
      "Epoch 50/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -82.7032 - val_loss: -83.5719\n",
      "\n",
      "Epoch 00050: loss improved from -82.60561 to -82.70315, saving model to gendance.h5\n",
      "Epoch 51/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -82.7564 - val_loss: -83.5929\n",
      "\n",
      "Epoch 00051: loss improved from -82.70315 to -82.75643, saving model to gendance.h5\n",
      "Epoch 52/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -82.8311 - val_loss: -83.6769\n",
      "\n",
      "Epoch 00052: loss improved from -82.75643 to -82.83108, saving model to gendance.h5\n",
      "Epoch 53/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -82.9209 - val_loss: -83.7204\n",
      "\n",
      "Epoch 00053: loss improved from -82.83108 to -82.92090, saving model to gendance.h5\n",
      "Epoch 54/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -82.9664 - val_loss: -83.6511\n",
      "\n",
      "Epoch 00054: loss improved from -82.92090 to -82.96640, saving model to gendance.h5\n",
      "Epoch 55/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -83.0577 - val_loss: -83.6479\n",
      "\n",
      "Epoch 00055: loss improved from -82.96640 to -83.05774, saving model to gendance.h5\n",
      "Epoch 56/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -83.1496 - val_loss: -83.7292\n",
      "\n",
      "Epoch 00056: loss improved from -83.05774 to -83.14960, saving model to gendance.h5\n",
      "Epoch 57/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -83.2871 - val_loss: -83.9204\n",
      "\n",
      "Epoch 00057: loss improved from -83.14960 to -83.28713, saving model to gendance.h5\n",
      "Epoch 58/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -83.4688 - val_loss: -84.0792\n",
      "\n",
      "Epoch 00058: loss improved from -83.28713 to -83.46875, saving model to gendance.h5\n",
      "Epoch 59/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -83.7548 - val_loss: -84.3259\n",
      "\n",
      "Epoch 00059: loss improved from -83.46875 to -83.75478, saving model to gendance.h5\n",
      "Epoch 60/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -84.1920 - val_loss: -84.5502\n",
      "\n",
      "Epoch 00060: loss improved from -83.75478 to -84.19199, saving model to gendance.h5\n",
      "Epoch 61/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -84.5459 - val_loss: -84.5628\n",
      "\n",
      "Epoch 00061: loss improved from -84.19199 to -84.54591, saving model to gendance.h5\n",
      "Epoch 62/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -84.7262 - val_loss: -84.9310\n",
      "\n",
      "Epoch 00062: loss improved from -84.54591 to -84.72620, saving model to gendance.h5\n",
      "Epoch 63/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -84.9147 - val_loss: -85.0158\n",
      "\n",
      "Epoch 00063: loss improved from -84.72620 to -84.91470, saving model to gendance.h5\n",
      "Epoch 64/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -85.1184 - val_loss: -85.0442\n",
      "\n",
      "Epoch 00064: loss improved from -84.91470 to -85.11837, saving model to gendance.h5\n",
      "Epoch 65/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -85.1807 - val_loss: -85.1065\n",
      "\n",
      "Epoch 00065: loss improved from -85.11837 to -85.18067, saving model to gendance.h5\n",
      "Epoch 66/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -85.2598 - val_loss: -85.1710\n",
      "\n",
      "Epoch 00066: loss improved from -85.18067 to -85.25978, saving model to gendance.h5\n",
      "Epoch 67/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -85.1852 - val_loss: -84.9047\n",
      "\n",
      "Epoch 00067: loss did not improve from -85.25978\n",
      "Epoch 68/10000\n",
      "16167/16167 [==============================] - 1s 33us/step - loss: -84.5200 - val_loss: -81.7607\n",
      "\n",
      "Epoch 00068: loss did not improve from -85.25978\n",
      "Epoch 69/10000\n",
      "16167/16167 [==============================] - 1s 31us/step - loss: -83.9645 - val_loss: -84.9215\n",
      "\n",
      "Epoch 00069: loss did not improve from -85.25978\n",
      "Epoch 70/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -85.4013 - val_loss: -85.1951\n",
      "\n",
      "Epoch 00070: loss improved from -85.25978 to -85.40128, saving model to gendance.h5\n",
      "Epoch 71/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -85.6299 - val_loss: -85.4161\n",
      "\n",
      "Epoch 00071: loss improved from -85.40128 to -85.62994, saving model to gendance.h5\n",
      "Epoch 72/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -85.8612 - val_loss: -85.2080\n",
      "\n",
      "Epoch 00072: loss improved from -85.62994 to -85.86123, saving model to gendance.h5\n",
      "Epoch 73/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -85.8904 - val_loss: -85.2027\n",
      "\n",
      "Epoch 00073: loss improved from -85.86123 to -85.89036, saving model to gendance.h5\n",
      "Epoch 74/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -86.2197 - val_loss: -86.0798\n",
      "\n",
      "Epoch 00074: loss improved from -85.89036 to -86.21968, saving model to gendance.h5\n",
      "Epoch 75/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -86.8058 - val_loss: -86.2073\n",
      "\n",
      "Epoch 00075: loss improved from -86.21968 to -86.80581, saving model to gendance.h5\n",
      "Epoch 76/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -87.0495 - val_loss: -85.9759\n",
      "\n",
      "Epoch 00076: loss improved from -86.80581 to -87.04948, saving model to gendance.h5\n",
      "Epoch 77/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -87.2309 - val_loss: -86.0793\n",
      "\n",
      "Epoch 00077: loss improved from -87.04948 to -87.23095, saving model to gendance.h5\n",
      "Epoch 78/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -87.5912 - val_loss: -86.9218\n",
      "\n",
      "Epoch 00078: loss improved from -87.23095 to -87.59124, saving model to gendance.h5\n",
      "Epoch 79/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -88.3442 - val_loss: -87.5468\n",
      "\n",
      "Epoch 00079: loss improved from -87.59124 to -88.34420, saving model to gendance.h5\n",
      "Epoch 80/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -89.0086 - val_loss: -87.6696\n",
      "\n",
      "Epoch 00080: loss improved from -88.34420 to -89.00859, saving model to gendance.h5\n",
      "Epoch 81/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -89.3505 - val_loss: -87.6728\n",
      "\n",
      "Epoch 00081: loss improved from -89.00859 to -89.35052, saving model to gendance.h5\n",
      "Epoch 82/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -89.5955 - val_loss: -87.8955\n",
      "\n",
      "Epoch 00082: loss improved from -89.35052 to -89.59547, saving model to gendance.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -89.8824 - val_loss: -88.3440\n",
      "\n",
      "Epoch 00083: loss improved from -89.59547 to -89.88243, saving model to gendance.h5\n",
      "Epoch 84/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -90.2011 - val_loss: -88.6669\n",
      "\n",
      "Epoch 00084: loss improved from -89.88243 to -90.20110, saving model to gendance.h5\n",
      "Epoch 85/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -90.5244 - val_loss: -88.8211\n",
      "\n",
      "Epoch 00085: loss improved from -90.20110 to -90.52443, saving model to gendance.h5\n",
      "Epoch 86/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -90.7672 - val_loss: -88.4284\n",
      "\n",
      "Epoch 00086: loss improved from -90.52443 to -90.76718, saving model to gendance.h5\n",
      "Epoch 87/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -90.5478 - val_loss: -87.3215\n",
      "\n",
      "Epoch 00087: loss did not improve from -90.76718\n",
      "Epoch 88/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -90.6957 - val_loss: -87.8141\n",
      "\n",
      "Epoch 00088: loss did not improve from -90.76718\n",
      "Epoch 89/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -90.8058 - val_loss: -88.7849\n",
      "\n",
      "Epoch 00089: loss improved from -90.76718 to -90.80583, saving model to gendance.h5\n",
      "Epoch 90/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -91.8195 - val_loss: -89.6534\n",
      "\n",
      "Epoch 00090: loss improved from -90.80583 to -91.81949, saving model to gendance.h5\n",
      "Epoch 91/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -92.2508 - val_loss: -89.6269\n",
      "\n",
      "Epoch 00091: loss improved from -91.81949 to -92.25078, saving model to gendance.h5\n",
      "Epoch 92/10000\n",
      "16167/16167 [==============================] - 1s 34us/step - loss: -92.2021 - val_loss: -87.8564\n",
      "\n",
      "Epoch 00092: loss did not improve from -92.25078\n",
      "Epoch 93/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -91.6211 - val_loss: -88.5844\n",
      "\n",
      "Epoch 00093: loss did not improve from -92.25078\n",
      "Epoch 94/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -92.6708 - val_loss: -90.1589\n",
      "\n",
      "Epoch 00094: loss improved from -92.25078 to -92.67083, saving model to gendance.h5\n",
      "Epoch 95/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -93.7643 - val_loss: -90.4787\n",
      "\n",
      "Epoch 00095: loss improved from -92.67083 to -93.76426, saving model to gendance.h5\n",
      "Epoch 96/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -93.9178 - val_loss: -89.7699\n",
      "\n",
      "Epoch 00096: loss improved from -93.76426 to -93.91783, saving model to gendance.h5\n",
      "Epoch 97/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -93.6503 - val_loss: -91.8277\n",
      "\n",
      "Epoch 00097: loss did not improve from -93.91783\n",
      "Epoch 98/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -95.2439 - val_loss: -92.5306\n",
      "\n",
      "Epoch 00098: loss improved from -93.91783 to -95.24391, saving model to gendance.h5\n",
      "Epoch 99/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -96.2857 - val_loss: -93.1523\n",
      "\n",
      "Epoch 00099: loss improved from -95.24391 to -96.28572, saving model to gendance.h5\n",
      "Epoch 100/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -97.0651 - val_loss: -93.5752\n",
      "\n",
      "Epoch 00100: loss improved from -96.28572 to -97.06508, saving model to gendance.h5\n",
      "Epoch 101/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -97.3789 - val_loss: -93.3356\n",
      "\n",
      "Epoch 00101: loss improved from -97.06508 to -97.37893, saving model to gendance.h5\n",
      "Epoch 102/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -97.1678 - val_loss: -94.5179\n",
      "\n",
      "Epoch 00102: loss did not improve from -97.37893\n",
      "Epoch 103/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -98.7637 - val_loss: -95.7795\n",
      "\n",
      "Epoch 00103: loss improved from -97.37893 to -98.76368, saving model to gendance.h5\n",
      "Epoch 104/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -99.7636 - val_loss: -96.7950\n",
      "\n",
      "Epoch 00104: loss improved from -98.76368 to -99.76358, saving model to gendance.h5\n",
      "Epoch 105/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -100.2289 - val_loss: -96.7469\n",
      "\n",
      "Epoch 00105: loss improved from -99.76358 to -100.22892, saving model to gendance.h5\n",
      "Epoch 106/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -100.9252 - val_loss: -97.6318\n",
      "\n",
      "Epoch 00106: loss improved from -100.22892 to -100.92518, saving model to gendance.h5\n",
      "Epoch 107/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -101.6485 - val_loss: -98.6206\n",
      "\n",
      "Epoch 00107: loss improved from -100.92518 to -101.64848, saving model to gendance.h5\n",
      "Epoch 108/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -102.2547 - val_loss: -98.7618\n",
      "\n",
      "Epoch 00108: loss improved from -101.64848 to -102.25466, saving model to gendance.h5\n",
      "Epoch 109/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -102.8169 - val_loss: -99.7984\n",
      "\n",
      "Epoch 00109: loss improved from -102.25466 to -102.81688, saving model to gendance.h5\n",
      "Epoch 110/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -103.1939 - val_loss: -100.0318\n",
      "\n",
      "Epoch 00110: loss improved from -102.81688 to -103.19392, saving model to gendance.h5\n",
      "Epoch 111/10000\n",
      "16167/16167 [==============================] - 1s 32us/step - loss: -103.7182 - val_loss: -100.4607\n",
      "\n",
      "Epoch 00111: loss improved from -103.19392 to -103.71820, saving model to gendance.h5\n",
      "Epoch 112/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -104.0067 - val_loss: -100.8563\n",
      "\n",
      "Epoch 00112: loss improved from -103.71820 to -104.00674, saving model to gendance.h5\n",
      "Epoch 113/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -104.5795 - val_loss: -101.3859\n",
      "\n",
      "Epoch 00113: loss improved from -104.00674 to -104.57954, saving model to gendance.h5\n",
      "Epoch 114/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -105.0839 - val_loss: -102.3976\n",
      "\n",
      "Epoch 00114: loss improved from -104.57954 to -105.08391, saving model to gendance.h5\n",
      "Epoch 115/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -105.9325 - val_loss: -103.0789\n",
      "\n",
      "Epoch 00115: loss improved from -105.08391 to -105.93252, saving model to gendance.h5\n",
      "Epoch 116/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -106.4068 - val_loss: -103.6948\n",
      "\n",
      "Epoch 00116: loss improved from -105.93252 to -106.40682, saving model to gendance.h5\n",
      "Epoch 117/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -106.8331 - val_loss: -103.6423\n",
      "\n",
      "Epoch 00117: loss improved from -106.40682 to -106.83305, saving model to gendance.h5\n",
      "Epoch 118/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -107.3315 - val_loss: -104.8670\n",
      "\n",
      "Epoch 00118: loss improved from -106.83305 to -107.33155, saving model to gendance.h5\n",
      "Epoch 119/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -107.9307 - val_loss: -105.2792\n",
      "\n",
      "Epoch 00119: loss improved from -107.33155 to -107.93070, saving model to gendance.h5\n",
      "Epoch 120/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -108.6209 - val_loss: -105.9427\n",
      "\n",
      "Epoch 00120: loss improved from -107.93070 to -108.62089, saving model to gendance.h5\n",
      "Epoch 121/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -109.0019 - val_loss: -106.5874\n",
      "\n",
      "Epoch 00121: loss improved from -108.62089 to -109.00187, saving model to gendance.h5\n",
      "Epoch 122/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -109.4889 - val_loss: -107.0599\n",
      "\n",
      "Epoch 00122: loss improved from -109.00187 to -109.48890, saving model to gendance.h5\n",
      "Epoch 123/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -110.0816 - val_loss: -107.7571\n",
      "\n",
      "Epoch 00123: loss improved from -109.48890 to -110.08164, saving model to gendance.h5\n",
      "Epoch 124/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -110.5191 - val_loss: -108.1961\n",
      "\n",
      "Epoch 00124: loss improved from -110.08164 to -110.51908, saving model to gendance.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -110.8600 - val_loss: -108.6816\n",
      "\n",
      "Epoch 00125: loss improved from -110.51908 to -110.85999, saving model to gendance.h5\n",
      "Epoch 126/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -111.1282 - val_loss: -109.3457\n",
      "\n",
      "Epoch 00126: loss improved from -110.85999 to -111.12820, saving model to gendance.h5\n",
      "Epoch 127/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -111.3911 - val_loss: -109.6694\n",
      "\n",
      "Epoch 00127: loss improved from -111.12820 to -111.39113, saving model to gendance.h5\n",
      "Epoch 128/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -111.8902 - val_loss: -109.9589\n",
      "\n",
      "Epoch 00128: loss improved from -111.39113 to -111.89023, saving model to gendance.h5\n",
      "Epoch 129/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -112.5213 - val_loss: -110.8599\n",
      "\n",
      "Epoch 00129: loss improved from -111.89023 to -112.52132, saving model to gendance.h5\n",
      "Epoch 130/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -112.7454 - val_loss: -111.2642\n",
      "\n",
      "Epoch 00130: loss improved from -112.52132 to -112.74543, saving model to gendance.h5\n",
      "Epoch 131/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -113.3228 - val_loss: -111.8730\n",
      "\n",
      "Epoch 00131: loss improved from -112.74543 to -113.32281, saving model to gendance.h5\n",
      "Epoch 132/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -113.4870 - val_loss: -111.9341\n",
      "\n",
      "Epoch 00132: loss improved from -113.32281 to -113.48701, saving model to gendance.h5\n",
      "Epoch 133/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -113.7845 - val_loss: -112.0217\n",
      "\n",
      "Epoch 00133: loss improved from -113.48701 to -113.78451, saving model to gendance.h5\n",
      "Epoch 134/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -113.9857 - val_loss: -112.6580\n",
      "\n",
      "Epoch 00134: loss improved from -113.78451 to -113.98569, saving model to gendance.h5\n",
      "Epoch 135/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -114.2875 - val_loss: -112.7349\n",
      "\n",
      "Epoch 00135: loss improved from -113.98569 to -114.28752, saving model to gendance.h5\n",
      "Epoch 136/10000\n",
      "16167/16167 [==============================] - 1s 31us/step - loss: -114.6749 - val_loss: -113.2692\n",
      "\n",
      "Epoch 00136: loss improved from -114.28752 to -114.67490, saving model to gendance.h5\n",
      "Epoch 137/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -114.8635 - val_loss: -113.4355\n",
      "\n",
      "Epoch 00137: loss improved from -114.67490 to -114.86350, saving model to gendance.h5\n",
      "Epoch 138/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -115.2824 - val_loss: -113.3843\n",
      "\n",
      "Epoch 00138: loss improved from -114.86350 to -115.28240, saving model to gendance.h5\n",
      "Epoch 139/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -115.2854 - val_loss: -114.1878\n",
      "\n",
      "Epoch 00139: loss improved from -115.28240 to -115.28540, saving model to gendance.h5\n",
      "Epoch 140/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -115.6517 - val_loss: -114.6180\n",
      "\n",
      "Epoch 00140: loss improved from -115.28540 to -115.65168, saving model to gendance.h5\n",
      "Epoch 141/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -115.9693 - val_loss: -114.9416\n",
      "\n",
      "Epoch 00141: loss improved from -115.65168 to -115.96934, saving model to gendance.h5\n",
      "Epoch 142/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -116.0020 - val_loss: -115.7363\n",
      "\n",
      "Epoch 00142: loss improved from -115.96934 to -116.00199, saving model to gendance.h5\n",
      "Epoch 143/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -116.3881 - val_loss: -115.8978\n",
      "\n",
      "Epoch 00143: loss improved from -116.00199 to -116.38810, saving model to gendance.h5\n",
      "Epoch 144/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -116.6490 - val_loss: -115.9353\n",
      "\n",
      "Epoch 00144: loss improved from -116.38810 to -116.64898, saving model to gendance.h5\n",
      "Epoch 145/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -117.0211 - val_loss: -115.9788\n",
      "\n",
      "Epoch 00145: loss improved from -116.64898 to -117.02108, saving model to gendance.h5\n",
      "Epoch 146/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -117.3112 - val_loss: -116.2744\n",
      "\n",
      "Epoch 00146: loss improved from -117.02108 to -117.31120, saving model to gendance.h5\n",
      "Epoch 147/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -117.3436 - val_loss: -116.6869\n",
      "\n",
      "Epoch 00147: loss improved from -117.31120 to -117.34364, saving model to gendance.h5\n",
      "Epoch 148/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -117.6465 - val_loss: -116.4659\n",
      "\n",
      "Epoch 00148: loss improved from -117.34364 to -117.64647, saving model to gendance.h5\n",
      "Epoch 149/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -117.7054 - val_loss: -116.8503\n",
      "\n",
      "Epoch 00149: loss improved from -117.64647 to -117.70535, saving model to gendance.h5\n",
      "Epoch 150/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -117.7715 - val_loss: -116.8547\n",
      "\n",
      "Epoch 00150: loss improved from -117.70535 to -117.77154, saving model to gendance.h5\n",
      "Epoch 151/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -118.0324 - val_loss: -117.5441\n",
      "\n",
      "Epoch 00151: loss improved from -117.77154 to -118.03236, saving model to gendance.h5\n",
      "Epoch 152/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -118.3350 - val_loss: -117.4818\n",
      "\n",
      "Epoch 00152: loss improved from -118.03236 to -118.33503, saving model to gendance.h5\n",
      "Epoch 153/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -118.2791 - val_loss: -117.9359\n",
      "\n",
      "Epoch 00153: loss did not improve from -118.33503\n",
      "Epoch 154/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -118.7197 - val_loss: -117.4724\n",
      "\n",
      "Epoch 00154: loss improved from -118.33503 to -118.71967, saving model to gendance.h5\n",
      "Epoch 155/10000\n",
      "16167/16167 [==============================] - 1s 32us/step - loss: -118.9580 - val_loss: -118.2891\n",
      "\n",
      "Epoch 00155: loss improved from -118.71967 to -118.95802, saving model to gendance.h5\n",
      "Epoch 156/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -119.3760 - val_loss: -118.7835\n",
      "\n",
      "Epoch 00156: loss improved from -118.95802 to -119.37595, saving model to gendance.h5\n",
      "Epoch 157/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -119.4166 - val_loss: -118.7502\n",
      "\n",
      "Epoch 00157: loss improved from -119.37595 to -119.41662, saving model to gendance.h5\n",
      "Epoch 158/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -119.5976 - val_loss: -118.9316\n",
      "\n",
      "Epoch 00158: loss improved from -119.41662 to -119.59756, saving model to gendance.h5\n",
      "Epoch 159/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -119.7350 - val_loss: -118.9993\n",
      "\n",
      "Epoch 00159: loss improved from -119.59756 to -119.73504, saving model to gendance.h5\n",
      "Epoch 160/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -119.9553 - val_loss: -119.3787\n",
      "\n",
      "Epoch 00160: loss improved from -119.73504 to -119.95527, saving model to gendance.h5\n",
      "Epoch 161/10000\n",
      "16167/16167 [==============================] - 1s 32us/step - loss: -119.9671 - val_loss: -118.8446\n",
      "\n",
      "Epoch 00161: loss improved from -119.95527 to -119.96710, saving model to gendance.h5\n",
      "Epoch 162/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -119.7417 - val_loss: -119.0137\n",
      "\n",
      "Epoch 00162: loss did not improve from -119.96710\n",
      "Epoch 163/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -119.9772 - val_loss: -119.7287\n",
      "\n",
      "Epoch 00163: loss improved from -119.96710 to -119.97716, saving model to gendance.h5\n",
      "Epoch 164/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -120.1182 - val_loss: -119.5941\n",
      "\n",
      "Epoch 00164: loss improved from -119.97716 to -120.11822, saving model to gendance.h5\n",
      "Epoch 165/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -120.1601 - val_loss: -119.9104\n",
      "\n",
      "Epoch 00165: loss improved from -120.11822 to -120.16011, saving model to gendance.h5\n",
      "Epoch 166/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -120.0694 - val_loss: -120.3157\n",
      "\n",
      "Epoch 00166: loss did not improve from -120.16011\n",
      "Epoch 167/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -120.3040 - val_loss: -119.7045\n",
      "\n",
      "Epoch 00167: loss improved from -120.16011 to -120.30400, saving model to gendance.h5\n",
      "Epoch 168/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -120.4288 - val_loss: -120.6852\n",
      "\n",
      "Epoch 00168: loss improved from -120.30400 to -120.42885, saving model to gendance.h5\n",
      "Epoch 169/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -120.9602 - val_loss: -120.9224\n",
      "\n",
      "Epoch 00169: loss improved from -120.42885 to -120.96020, saving model to gendance.h5\n",
      "Epoch 170/10000\n",
      "16167/16167 [==============================] - 1s 38us/step - loss: -121.2360 - val_loss: -120.8251\n",
      "\n",
      "Epoch 00170: loss improved from -120.96020 to -121.23597, saving model to gendance.h5\n",
      "Epoch 171/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -121.1191 - val_loss: -120.9276\n",
      "\n",
      "Epoch 00171: loss did not improve from -121.23597\n",
      "Epoch 172/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -121.2599 - val_loss: -121.3072\n",
      "\n",
      "Epoch 00172: loss improved from -121.23597 to -121.25990, saving model to gendance.h5\n",
      "Epoch 173/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -121.5840 - val_loss: -121.4436\n",
      "\n",
      "Epoch 00173: loss improved from -121.25990 to -121.58404, saving model to gendance.h5\n",
      "Epoch 174/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -121.5077 - val_loss: -121.0104\n",
      "\n",
      "Epoch 00174: loss did not improve from -121.58404\n",
      "Epoch 175/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -121.7705 - val_loss: -121.5387\n",
      "\n",
      "Epoch 00175: loss improved from -121.58404 to -121.77050, saving model to gendance.h5\n",
      "Epoch 176/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -121.8897 - val_loss: -121.4246\n",
      "\n",
      "Epoch 00176: loss improved from -121.77050 to -121.88970, saving model to gendance.h5\n",
      "Epoch 177/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -121.8888 - val_loss: -122.0100\n",
      "\n",
      "Epoch 00177: loss did not improve from -121.88970\n",
      "Epoch 178/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -122.0631 - val_loss: -122.2123\n",
      "\n",
      "Epoch 00178: loss improved from -121.88970 to -122.06305, saving model to gendance.h5\n",
      "Epoch 179/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -122.4293 - val_loss: -122.4574\n",
      "\n",
      "Epoch 00179: loss improved from -122.06305 to -122.42927, saving model to gendance.h5\n",
      "Epoch 180/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -122.4334 - val_loss: -122.1101\n",
      "\n",
      "Epoch 00180: loss improved from -122.42927 to -122.43343, saving model to gendance.h5\n",
      "Epoch 181/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -122.5510 - val_loss: -122.8095\n",
      "\n",
      "Epoch 00181: loss improved from -122.43343 to -122.55099, saving model to gendance.h5\n",
      "Epoch 182/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -122.7297 - val_loss: -122.6459\n",
      "\n",
      "Epoch 00182: loss improved from -122.55099 to -122.72974, saving model to gendance.h5\n",
      "Epoch 183/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -122.6588 - val_loss: -121.9055\n",
      "\n",
      "Epoch 00183: loss did not improve from -122.72974\n",
      "Epoch 184/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -122.7559 - val_loss: -123.0727\n",
      "\n",
      "Epoch 00184: loss improved from -122.72974 to -122.75591, saving model to gendance.h5\n",
      "Epoch 185/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -122.9549 - val_loss: -122.7490\n",
      "\n",
      "Epoch 00185: loss improved from -122.75591 to -122.95491, saving model to gendance.h5\n",
      "Epoch 186/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -123.0549 - val_loss: -123.1228\n",
      "\n",
      "Epoch 00186: loss improved from -122.95491 to -123.05488, saving model to gendance.h5\n",
      "Epoch 187/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -123.0322 - val_loss: -122.5661\n",
      "\n",
      "Epoch 00187: loss did not improve from -123.05488\n",
      "Epoch 188/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -123.2263 - val_loss: -123.4270\n",
      "\n",
      "Epoch 00188: loss improved from -123.05488 to -123.22627, saving model to gendance.h5\n",
      "Epoch 189/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -123.2796 - val_loss: -123.0986\n",
      "\n",
      "Epoch 00189: loss improved from -123.22627 to -123.27956, saving model to gendance.h5\n",
      "Epoch 190/10000\n",
      "16167/16167 [==============================] - 1s 32us/step - loss: -123.2679 - val_loss: -123.5484\n",
      "\n",
      "Epoch 00190: loss did not improve from -123.27956\n",
      "Epoch 191/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -123.1671 - val_loss: -123.2432\n",
      "\n",
      "Epoch 00191: loss did not improve from -123.27956\n",
      "Epoch 192/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -123.2891 - val_loss: -123.6240\n",
      "\n",
      "Epoch 00192: loss improved from -123.27956 to -123.28910, saving model to gendance.h5\n",
      "Epoch 193/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -123.6069 - val_loss: -124.0255\n",
      "\n",
      "Epoch 00193: loss improved from -123.28910 to -123.60689, saving model to gendance.h5\n",
      "Epoch 194/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -123.7692 - val_loss: -124.2989\n",
      "\n",
      "Epoch 00194: loss improved from -123.60689 to -123.76916, saving model to gendance.h5\n",
      "Epoch 195/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -124.2461 - val_loss: -124.0420\n",
      "\n",
      "Epoch 00195: loss improved from -123.76916 to -124.24613, saving model to gendance.h5\n",
      "Epoch 196/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -124.0956 - val_loss: -124.2862\n",
      "\n",
      "Epoch 00196: loss did not improve from -124.24613\n",
      "Epoch 197/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -124.0524 - val_loss: -124.6053\n",
      "\n",
      "Epoch 00197: loss did not improve from -124.24613\n",
      "Epoch 198/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -123.9985 - val_loss: -124.5681\n",
      "\n",
      "Epoch 00198: loss did not improve from -124.24613\n",
      "Epoch 199/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -124.0231 - val_loss: -124.6595\n",
      "\n",
      "Epoch 00199: loss did not improve from -124.24613\n",
      "Epoch 200/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -124.1279 - val_loss: -124.3130\n",
      "\n",
      "Epoch 00200: loss did not improve from -124.24613\n",
      "Epoch 201/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -123.9991 - val_loss: -125.1455\n",
      "\n",
      "Epoch 00201: loss did not improve from -124.24613\n",
      "Epoch 202/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -124.4380 - val_loss: -125.6968\n",
      "\n",
      "Epoch 00202: loss improved from -124.24613 to -124.43797, saving model to gendance.h5\n",
      "Epoch 203/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -124.6000 - val_loss: -124.9846\n",
      "\n",
      "Epoch 00203: loss improved from -124.43797 to -124.60005, saving model to gendance.h5\n",
      "Epoch 204/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -124.6494 - val_loss: -125.0933\n",
      "\n",
      "Epoch 00204: loss improved from -124.60005 to -124.64937, saving model to gendance.h5\n",
      "Epoch 205/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -124.6411 - val_loss: -125.6539\n",
      "\n",
      "Epoch 00205: loss did not improve from -124.64937\n",
      "Epoch 206/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -124.8906 - val_loss: -125.6111\n",
      "\n",
      "Epoch 00206: loss improved from -124.64937 to -124.89061, saving model to gendance.h5\n",
      "Epoch 207/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -125.1638 - val_loss: -126.0284\n",
      "\n",
      "Epoch 00207: loss improved from -124.89061 to -125.16379, saving model to gendance.h5\n",
      "Epoch 208/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -125.2281 - val_loss: -125.5289\n",
      "\n",
      "Epoch 00208: loss improved from -125.16379 to -125.22811, saving model to gendance.h5\n",
      "Epoch 209/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -125.2614 - val_loss: -126.1257\n",
      "\n",
      "Epoch 00209: loss improved from -125.22811 to -125.26137, saving model to gendance.h5\n",
      "Epoch 210/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -125.3434 - val_loss: -125.7854\n",
      "\n",
      "Epoch 00210: loss improved from -125.26137 to -125.34342, saving model to gendance.h5\n",
      "Epoch 211/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -125.1539 - val_loss: -126.1185\n",
      "\n",
      "Epoch 00211: loss did not improve from -125.34342\n",
      "Epoch 212/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -125.3347 - val_loss: -126.3566\n",
      "\n",
      "Epoch 00212: loss did not improve from -125.34342\n",
      "Epoch 213/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -125.5573 - val_loss: -126.6609\n",
      "\n",
      "Epoch 00213: loss improved from -125.34342 to -125.55726, saving model to gendance.h5\n",
      "Epoch 214/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -125.7729 - val_loss: -126.1781\n",
      "\n",
      "Epoch 00214: loss improved from -125.55726 to -125.77294, saving model to gendance.h5\n",
      "Epoch 215/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -125.9884 - val_loss: -126.7760\n",
      "\n",
      "Epoch 00215: loss improved from -125.77294 to -125.98839, saving model to gendance.h5\n",
      "Epoch 216/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -125.9574 - val_loss: -126.9739\n",
      "\n",
      "Epoch 00216: loss did not improve from -125.98839\n",
      "Epoch 217/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -125.9769 - val_loss: -126.8599\n",
      "\n",
      "Epoch 00217: loss did not improve from -125.98839\n",
      "Epoch 218/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -126.1881 - val_loss: -126.6073\n",
      "\n",
      "Epoch 00218: loss improved from -125.98839 to -126.18814, saving model to gendance.h5\n",
      "Epoch 219/10000\n",
      "16167/16167 [==============================] - 1s 32us/step - loss: -125.8309 - val_loss: -126.7386\n",
      "\n",
      "Epoch 00219: loss did not improve from -126.18814\n",
      "Epoch 220/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -125.9035 - val_loss: -127.4598\n",
      "\n",
      "Epoch 00220: loss did not improve from -126.18814\n",
      "Epoch 221/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -126.2364 - val_loss: -127.2619\n",
      "\n",
      "Epoch 00221: loss improved from -126.18814 to -126.23638, saving model to gendance.h5\n",
      "Epoch 222/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -126.2580 - val_loss: -126.7216\n",
      "\n",
      "Epoch 00222: loss improved from -126.23638 to -126.25799, saving model to gendance.h5\n",
      "Epoch 223/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -125.9851 - val_loss: -126.8589\n",
      "\n",
      "Epoch 00223: loss did not improve from -126.25799\n",
      "Epoch 224/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -126.6284 - val_loss: -127.6109\n",
      "\n",
      "Epoch 00224: loss improved from -126.25799 to -126.62842, saving model to gendance.h5\n",
      "Epoch 225/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -126.7728 - val_loss: -127.5164\n",
      "\n",
      "Epoch 00225: loss improved from -126.62842 to -126.77282, saving model to gendance.h5\n",
      "Epoch 226/10000\n",
      "16167/16167 [==============================] - 1s 31us/step - loss: -127.0462 - val_loss: -127.8062\n",
      "\n",
      "Epoch 00226: loss improved from -126.77282 to -127.04624, saving model to gendance.h5\n",
      "Epoch 227/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -126.8414 - val_loss: -126.6343\n",
      "\n",
      "Epoch 00227: loss did not improve from -127.04624\n",
      "Epoch 228/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -126.8866 - val_loss: -128.0283\n",
      "\n",
      "Epoch 00228: loss did not improve from -127.04624\n",
      "Epoch 229/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -127.2110 - val_loss: -127.7028\n",
      "\n",
      "Epoch 00229: loss improved from -127.04624 to -127.21103, saving model to gendance.h5\n",
      "Epoch 230/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -127.4505 - val_loss: -127.8600\n",
      "\n",
      "Epoch 00230: loss improved from -127.21103 to -127.45051, saving model to gendance.h5\n",
      "Epoch 231/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -127.4443 - val_loss: -127.7526\n",
      "\n",
      "Epoch 00231: loss did not improve from -127.45051\n",
      "Epoch 232/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -127.3893 - val_loss: -128.0101\n",
      "\n",
      "Epoch 00232: loss did not improve from -127.45051\n",
      "Epoch 233/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -127.5722 - val_loss: -128.3458\n",
      "\n",
      "Epoch 00233: loss improved from -127.45051 to -127.57216, saving model to gendance.h5\n",
      "Epoch 234/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -127.6435 - val_loss: -127.9392\n",
      "\n",
      "Epoch 00234: loss improved from -127.57216 to -127.64349, saving model to gendance.h5\n",
      "Epoch 235/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -127.8795 - val_loss: -128.2197\n",
      "\n",
      "Epoch 00235: loss improved from -127.64349 to -127.87953, saving model to gendance.h5\n",
      "Epoch 236/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -127.8925 - val_loss: -128.9749\n",
      "\n",
      "Epoch 00236: loss improved from -127.87953 to -127.89250, saving model to gendance.h5\n",
      "Epoch 237/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -128.1154 - val_loss: -128.8131\n",
      "\n",
      "Epoch 00237: loss improved from -127.89250 to -128.11541, saving model to gendance.h5\n",
      "Epoch 238/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -128.3255 - val_loss: -128.8189\n",
      "\n",
      "Epoch 00238: loss improved from -128.11541 to -128.32554, saving model to gendance.h5\n",
      "Epoch 239/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -128.2040 - val_loss: -128.8941\n",
      "\n",
      "Epoch 00239: loss did not improve from -128.32554\n",
      "Epoch 240/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -128.2677 - val_loss: -129.6165\n",
      "\n",
      "Epoch 00240: loss did not improve from -128.32554\n",
      "Epoch 241/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -128.2536 - val_loss: -129.3954\n",
      "\n",
      "Epoch 00241: loss did not improve from -128.32554\n",
      "Epoch 242/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -128.1435 - val_loss: -128.8123\n",
      "\n",
      "Epoch 00242: loss did not improve from -128.32554\n",
      "Epoch 243/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -128.2387 - val_loss: -129.2148\n",
      "\n",
      "Epoch 00243: loss did not improve from -128.32554\n",
      "Epoch 244/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -128.9904 - val_loss: -129.5037\n",
      "\n",
      "Epoch 00244: loss improved from -128.32554 to -128.99039, saving model to gendance.h5\n",
      "Epoch 245/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -128.9517 - val_loss: -129.5815\n",
      "\n",
      "Epoch 00245: loss did not improve from -128.99039\n",
      "Epoch 246/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -128.7645 - val_loss: -130.3104\n",
      "\n",
      "Epoch 00246: loss did not improve from -128.99039\n",
      "Epoch 247/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -128.7443 - val_loss: -129.5070\n",
      "\n",
      "Epoch 00247: loss did not improve from -128.99039\n",
      "Epoch 248/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -128.8226 - val_loss: -129.1546\n",
      "\n",
      "Epoch 00248: loss did not improve from -128.99039\n",
      "Epoch 249/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -128.7221 - val_loss: -129.4878\n",
      "\n",
      "Epoch 00249: loss did not improve from -128.99039\n",
      "Epoch 250/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -128.9937 - val_loss: -129.6575\n",
      "\n",
      "Epoch 00250: loss improved from -128.99039 to -128.99374, saving model to gendance.h5\n",
      "Epoch 251/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -129.0620 - val_loss: -130.3720\n",
      "\n",
      "Epoch 00251: loss improved from -128.99374 to -129.06197, saving model to gendance.h5\n",
      "Epoch 252/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -129.2864 - val_loss: -130.0280\n",
      "\n",
      "Epoch 00252: loss improved from -129.06197 to -129.28641, saving model to gendance.h5\n",
      "Epoch 253/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -129.3230 - val_loss: -130.2423\n",
      "\n",
      "Epoch 00253: loss improved from -129.28641 to -129.32296, saving model to gendance.h5\n",
      "Epoch 254/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -129.5459 - val_loss: -130.3357\n",
      "\n",
      "Epoch 00254: loss improved from -129.32296 to -129.54592, saving model to gendance.h5\n",
      "Epoch 255/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -129.5853 - val_loss: -130.9015\n",
      "\n",
      "Epoch 00255: loss improved from -129.54592 to -129.58534, saving model to gendance.h5\n",
      "Epoch 256/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -129.4644 - val_loss: -130.2105\n",
      "\n",
      "Epoch 00256: loss did not improve from -129.58534\n",
      "Epoch 257/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -129.5091 - val_loss: -129.5009\n",
      "\n",
      "Epoch 00257: loss did not improve from -129.58534\n",
      "Epoch 258/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -129.6409 - val_loss: -130.3334\n",
      "\n",
      "Epoch 00258: loss improved from -129.58534 to -129.64088, saving model to gendance.h5\n",
      "Epoch 259/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -129.7607 - val_loss: -130.9344\n",
      "\n",
      "Epoch 00259: loss improved from -129.64088 to -129.76070, saving model to gendance.h5\n",
      "Epoch 260/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -129.9091 - val_loss: -130.7099\n",
      "\n",
      "Epoch 00260: loss improved from -129.76070 to -129.90907, saving model to gendance.h5\n",
      "Epoch 261/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -129.8171 - val_loss: -130.0682\n",
      "\n",
      "Epoch 00261: loss did not improve from -129.90907\n",
      "Epoch 262/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -129.6317 - val_loss: -130.3805\n",
      "\n",
      "Epoch 00262: loss did not improve from -129.90907\n",
      "Epoch 263/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -129.7568 - val_loss: -130.9891\n",
      "\n",
      "Epoch 00263: loss did not improve from -129.90907\n",
      "Epoch 264/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -129.9863 - val_loss: -131.2938\n",
      "\n",
      "Epoch 00264: loss improved from -129.90907 to -129.98628, saving model to gendance.h5\n",
      "Epoch 265/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -130.2942 - val_loss: -130.9462\n",
      "\n",
      "Epoch 00265: loss improved from -129.98628 to -130.29416, saving model to gendance.h5\n",
      "Epoch 266/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -130.4849 - val_loss: -131.4056\n",
      "\n",
      "Epoch 00266: loss improved from -130.29416 to -130.48494, saving model to gendance.h5\n",
      "Epoch 267/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -130.8365 - val_loss: -131.5394\n",
      "\n",
      "Epoch 00267: loss improved from -130.48494 to -130.83653, saving model to gendance.h5\n",
      "Epoch 268/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -130.9126 - val_loss: -131.8089\n",
      "\n",
      "Epoch 00268: loss improved from -130.83653 to -130.91257, saving model to gendance.h5\n",
      "Epoch 269/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -130.9880 - val_loss: -131.8820\n",
      "\n",
      "Epoch 00269: loss improved from -130.91257 to -130.98796, saving model to gendance.h5\n",
      "Epoch 270/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -131.0572 - val_loss: -131.8495\n",
      "\n",
      "Epoch 00270: loss improved from -130.98796 to -131.05715, saving model to gendance.h5\n",
      "Epoch 271/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -130.9856 - val_loss: -131.7957\n",
      "\n",
      "Epoch 00271: loss did not improve from -131.05715\n",
      "Epoch 272/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -131.0428 - val_loss: -132.3139\n",
      "\n",
      "Epoch 00272: loss did not improve from -131.05715\n",
      "Epoch 273/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -131.2138 - val_loss: -131.7458\n",
      "\n",
      "Epoch 00273: loss improved from -131.05715 to -131.21383, saving model to gendance.h5\n",
      "Epoch 274/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -131.1969 - val_loss: -131.7151\n",
      "\n",
      "Epoch 00274: loss did not improve from -131.21383\n",
      "Epoch 275/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -131.4394 - val_loss: -132.0613\n",
      "\n",
      "Epoch 00275: loss improved from -131.21383 to -131.43944, saving model to gendance.h5\n",
      "Epoch 276/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -131.5087 - val_loss: -132.3571\n",
      "\n",
      "Epoch 00276: loss improved from -131.43944 to -131.50875, saving model to gendance.h5\n",
      "Epoch 277/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -131.4822 - val_loss: -132.3914\n",
      "\n",
      "Epoch 00277: loss did not improve from -131.50875\n",
      "Epoch 278/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -131.5129 - val_loss: -131.5523\n",
      "\n",
      "Epoch 00278: loss improved from -131.50875 to -131.51293, saving model to gendance.h5\n",
      "Epoch 279/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -131.7964 - val_loss: -132.7551\n",
      "\n",
      "Epoch 00279: loss improved from -131.51293 to -131.79641, saving model to gendance.h5\n",
      "Epoch 280/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -131.6835 - val_loss: -132.6044\n",
      "\n",
      "Epoch 00280: loss did not improve from -131.79641\n",
      "Epoch 281/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -131.5046 - val_loss: -132.0407\n",
      "\n",
      "Epoch 00281: loss did not improve from -131.79641\n",
      "Epoch 282/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -131.8545 - val_loss: -132.3357\n",
      "\n",
      "Epoch 00282: loss improved from -131.79641 to -131.85448, saving model to gendance.h5\n",
      "Epoch 283/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -131.9824 - val_loss: -132.8575\n",
      "\n",
      "Epoch 00283: loss improved from -131.85448 to -131.98244, saving model to gendance.h5\n",
      "Epoch 284/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -131.9367 - val_loss: -132.7703\n",
      "\n",
      "Epoch 00284: loss did not improve from -131.98244\n",
      "Epoch 285/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -131.9494 - val_loss: -131.7526\n",
      "\n",
      "Epoch 00285: loss did not improve from -131.98244\n",
      "Epoch 286/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -132.2734 - val_loss: -132.9253\n",
      "\n",
      "Epoch 00286: loss improved from -131.98244 to -132.27341, saving model to gendance.h5\n",
      "Epoch 287/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -132.3229 - val_loss: -132.2965\n",
      "\n",
      "Epoch 00287: loss improved from -132.27341 to -132.32289, saving model to gendance.h5\n",
      "Epoch 288/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -132.4650 - val_loss: -131.9461\n",
      "\n",
      "Epoch 00288: loss improved from -132.32289 to -132.46498, saving model to gendance.h5\n",
      "Epoch 289/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -132.1128 - val_loss: -132.6105\n",
      "\n",
      "Epoch 00289: loss did not improve from -132.46498\n",
      "Epoch 290/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -132.3679 - val_loss: -132.6634\n",
      "\n",
      "Epoch 00290: loss did not improve from -132.46498\n",
      "Epoch 291/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -132.8037 - val_loss: -133.1589\n",
      "\n",
      "Epoch 00291: loss improved from -132.46498 to -132.80369, saving model to gendance.h5\n",
      "Epoch 292/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -132.7562 - val_loss: -132.3422\n",
      "\n",
      "Epoch 00292: loss did not improve from -132.80369\n",
      "Epoch 293/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -132.6970 - val_loss: -132.8497\n",
      "\n",
      "Epoch 00293: loss did not improve from -132.80369\n",
      "Epoch 294/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -132.6443 - val_loss: -132.8633\n",
      "\n",
      "Epoch 00294: loss did not improve from -132.80369\n",
      "Epoch 295/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -132.9160 - val_loss: -133.7156\n",
      "\n",
      "Epoch 00295: loss improved from -132.80369 to -132.91601, saving model to gendance.h5\n",
      "Epoch 296/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -132.9424 - val_loss: -132.7784\n",
      "\n",
      "Epoch 00296: loss improved from -132.91601 to -132.94236, saving model to gendance.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 297/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -133.2981 - val_loss: -133.0834\n",
      "\n",
      "Epoch 00297: loss improved from -132.94236 to -133.29814, saving model to gendance.h5\n",
      "Epoch 298/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -133.2849 - val_loss: -133.4381\n",
      "\n",
      "Epoch 00298: loss did not improve from -133.29814\n",
      "Epoch 299/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -133.2413 - val_loss: -133.9542\n",
      "\n",
      "Epoch 00299: loss did not improve from -133.29814\n",
      "Epoch 300/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -133.2431 - val_loss: -132.4270\n",
      "\n",
      "Epoch 00300: loss did not improve from -133.29814\n",
      "Epoch 301/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -133.3164 - val_loss: -133.2385\n",
      "\n",
      "Epoch 00301: loss improved from -133.29814 to -133.31638, saving model to gendance.h5\n",
      "Epoch 302/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -133.6565 - val_loss: -134.0589\n",
      "\n",
      "Epoch 00302: loss improved from -133.31638 to -133.65654, saving model to gendance.h5\n",
      "Epoch 303/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -133.5254 - val_loss: -134.3651\n",
      "\n",
      "Epoch 00303: loss did not improve from -133.65654\n",
      "Epoch 304/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -133.6754 - val_loss: -133.6191\n",
      "\n",
      "Epoch 00304: loss improved from -133.65654 to -133.67536, saving model to gendance.h5\n",
      "Epoch 305/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -133.6169 - val_loss: -133.9570\n",
      "\n",
      "Epoch 00305: loss did not improve from -133.67536\n",
      "Epoch 306/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -133.9806 - val_loss: -133.9044\n",
      "\n",
      "Epoch 00306: loss improved from -133.67536 to -133.98059, saving model to gendance.h5\n",
      "Epoch 307/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -133.9077 - val_loss: -134.8627\n",
      "\n",
      "Epoch 00307: loss did not improve from -133.98059\n",
      "Epoch 308/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -133.8418 - val_loss: -134.8860\n",
      "\n",
      "Epoch 00308: loss did not improve from -133.98059\n",
      "Epoch 309/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -134.0902 - val_loss: -135.4773\n",
      "\n",
      "Epoch 00309: loss improved from -133.98059 to -134.09022, saving model to gendance.h5\n",
      "Epoch 310/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -134.0736 - val_loss: -134.6187\n",
      "\n",
      "Epoch 00310: loss did not improve from -134.09022\n",
      "Epoch 311/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -134.3339 - val_loss: -134.6934\n",
      "\n",
      "Epoch 00311: loss improved from -134.09022 to -134.33389, saving model to gendance.h5\n",
      "Epoch 312/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -134.3883 - val_loss: -135.3342\n",
      "\n",
      "Epoch 00312: loss improved from -134.33389 to -134.38826, saving model to gendance.h5\n",
      "Epoch 313/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -134.4600 - val_loss: -135.5089\n",
      "\n",
      "Epoch 00313: loss improved from -134.38826 to -134.46003, saving model to gendance.h5\n",
      "Epoch 314/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -134.4832 - val_loss: -135.7295\n",
      "\n",
      "Epoch 00314: loss improved from -134.46003 to -134.48324, saving model to gendance.h5\n",
      "Epoch 315/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -134.7954 - val_loss: -136.2872\n",
      "\n",
      "Epoch 00315: loss improved from -134.48324 to -134.79544, saving model to gendance.h5\n",
      "Epoch 316/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -134.8029 - val_loss: -135.5142\n",
      "\n",
      "Epoch 00316: loss improved from -134.79544 to -134.80289, saving model to gendance.h5\n",
      "Epoch 317/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -134.0564 - val_loss: -135.3519\n",
      "\n",
      "Epoch 00317: loss did not improve from -134.80289\n",
      "Epoch 318/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -134.4069 - val_loss: -135.9238\n",
      "\n",
      "Epoch 00318: loss did not improve from -134.80289\n",
      "Epoch 319/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -134.4967 - val_loss: -134.7209\n",
      "\n",
      "Epoch 00319: loss did not improve from -134.80289\n",
      "Epoch 320/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -134.4971 - val_loss: -134.8985\n",
      "\n",
      "Epoch 00320: loss did not improve from -134.80289\n",
      "Epoch 321/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -134.5819 - val_loss: -135.9593\n",
      "\n",
      "Epoch 00321: loss did not improve from -134.80289\n",
      "Epoch 322/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -134.8856 - val_loss: -135.3020\n",
      "\n",
      "Epoch 00322: loss improved from -134.80289 to -134.88557, saving model to gendance.h5\n",
      "Epoch 323/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -134.9191 - val_loss: -135.4601\n",
      "\n",
      "Epoch 00323: loss improved from -134.88557 to -134.91915, saving model to gendance.h5\n",
      "Epoch 324/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -135.0658 - val_loss: -135.3499\n",
      "\n",
      "Epoch 00324: loss improved from -134.91915 to -135.06578, saving model to gendance.h5\n",
      "Epoch 325/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -135.5053 - val_loss: -135.4248\n",
      "\n",
      "Epoch 00325: loss improved from -135.06578 to -135.50534, saving model to gendance.h5\n",
      "Epoch 326/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -135.7913 - val_loss: -136.1237\n",
      "\n",
      "Epoch 00326: loss improved from -135.50534 to -135.79133, saving model to gendance.h5\n",
      "Epoch 327/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -135.7821 - val_loss: -136.9646\n",
      "\n",
      "Epoch 00327: loss did not improve from -135.79133\n",
      "Epoch 328/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -135.8198 - val_loss: -136.2648\n",
      "\n",
      "Epoch 00328: loss improved from -135.79133 to -135.81980, saving model to gendance.h5\n",
      "Epoch 329/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -135.6098 - val_loss: -135.8739\n",
      "\n",
      "Epoch 00329: loss did not improve from -135.81980\n",
      "Epoch 330/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -135.5649 - val_loss: -135.6723\n",
      "\n",
      "Epoch 00330: loss did not improve from -135.81980\n",
      "Epoch 331/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -135.9298 - val_loss: -136.5502\n",
      "\n",
      "Epoch 00331: loss improved from -135.81980 to -135.92977, saving model to gendance.h5\n",
      "Epoch 332/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -136.0030 - val_loss: -136.6749\n",
      "\n",
      "Epoch 00332: loss improved from -135.92977 to -136.00303, saving model to gendance.h5\n",
      "Epoch 333/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -136.2154 - val_loss: -136.0755\n",
      "\n",
      "Epoch 00333: loss improved from -136.00303 to -136.21535, saving model to gendance.h5\n",
      "Epoch 334/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -136.1853 - val_loss: -135.6981\n",
      "\n",
      "Epoch 00334: loss did not improve from -136.21535\n",
      "Epoch 335/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -135.8263 - val_loss: -136.4364\n",
      "\n",
      "Epoch 00335: loss did not improve from -136.21535\n",
      "Epoch 336/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -135.7545 - val_loss: -136.3339\n",
      "\n",
      "Epoch 00336: loss did not improve from -136.21535\n",
      "Epoch 337/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -135.7198 - val_loss: -136.3694\n",
      "\n",
      "Epoch 00337: loss did not improve from -136.21535\n",
      "Epoch 338/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -136.3970 - val_loss: -137.3642\n",
      "\n",
      "Epoch 00338: loss improved from -136.21535 to -136.39704, saving model to gendance.h5\n",
      "Epoch 339/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -136.3062 - val_loss: -137.0207\n",
      "\n",
      "Epoch 00339: loss did not improve from -136.39704\n",
      "Epoch 340/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -136.1960 - val_loss: -135.9875\n",
      "\n",
      "Epoch 00340: loss did not improve from -136.39704\n",
      "Epoch 341/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -135.9537 - val_loss: -137.2979\n",
      "\n",
      "Epoch 00341: loss did not improve from -136.39704\n",
      "Epoch 342/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -136.2957 - val_loss: -137.9629\n",
      "\n",
      "Epoch 00342: loss did not improve from -136.39704\n",
      "Epoch 343/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -136.7536 - val_loss: -137.5490\n",
      "\n",
      "Epoch 00343: loss improved from -136.39704 to -136.75358, saving model to gendance.h5\n",
      "Epoch 344/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -136.7570 - val_loss: -137.1203\n",
      "\n",
      "Epoch 00344: loss improved from -136.75358 to -136.75699, saving model to gendance.h5\n",
      "Epoch 345/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -136.7303 - val_loss: -137.9283\n",
      "\n",
      "Epoch 00345: loss did not improve from -136.75699\n",
      "Epoch 346/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -136.4454 - val_loss: -136.4124\n",
      "\n",
      "Epoch 00346: loss did not improve from -136.75699\n",
      "Epoch 347/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -136.6850 - val_loss: -137.6160\n",
      "\n",
      "Epoch 00347: loss did not improve from -136.75699\n",
      "Epoch 348/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -136.9577 - val_loss: -138.1581\n",
      "\n",
      "Epoch 00348: loss improved from -136.75699 to -136.95771, saving model to gendance.h5\n",
      "Epoch 349/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -137.2438 - val_loss: -137.5382\n",
      "\n",
      "Epoch 00349: loss improved from -136.95771 to -137.24381, saving model to gendance.h5\n",
      "Epoch 350/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -137.0499 - val_loss: -136.2285\n",
      "\n",
      "Epoch 00350: loss did not improve from -137.24381\n",
      "Epoch 351/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -137.0147 - val_loss: -137.8246\n",
      "\n",
      "Epoch 00351: loss did not improve from -137.24381\n",
      "Epoch 352/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -137.0802 - val_loss: -138.3059\n",
      "\n",
      "Epoch 00352: loss did not improve from -137.24381\n",
      "Epoch 353/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -137.2841 - val_loss: -136.7173\n",
      "\n",
      "Epoch 00353: loss improved from -137.24381 to -137.28410, saving model to gendance.h5\n",
      "Epoch 354/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -137.5155 - val_loss: -137.9027\n",
      "\n",
      "Epoch 00354: loss improved from -137.28410 to -137.51554, saving model to gendance.h5\n",
      "Epoch 355/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -137.5810 - val_loss: -138.1773\n",
      "\n",
      "Epoch 00355: loss improved from -137.51554 to -137.58104, saving model to gendance.h5\n",
      "Epoch 356/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -137.5494 - val_loss: -138.0699\n",
      "\n",
      "Epoch 00356: loss did not improve from -137.58104\n",
      "Epoch 357/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -137.6178 - val_loss: -138.5906\n",
      "\n",
      "Epoch 00357: loss improved from -137.58104 to -137.61782, saving model to gendance.h5\n",
      "Epoch 358/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -137.4292 - val_loss: -137.7462\n",
      "\n",
      "Epoch 00358: loss did not improve from -137.61782\n",
      "Epoch 359/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -137.6165 - val_loss: -136.8535\n",
      "\n",
      "Epoch 00359: loss did not improve from -137.61782\n",
      "Epoch 360/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -137.6554 - val_loss: -138.2930\n",
      "\n",
      "Epoch 00360: loss improved from -137.61782 to -137.65545, saving model to gendance.h5\n",
      "Epoch 361/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -137.5146 - val_loss: -138.0083\n",
      "\n",
      "Epoch 00361: loss did not improve from -137.65545\n",
      "Epoch 362/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -137.7522 - val_loss: -138.4754\n",
      "\n",
      "Epoch 00362: loss improved from -137.65545 to -137.75216, saving model to gendance.h5\n",
      "Epoch 363/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -138.2140 - val_loss: -139.3861\n",
      "\n",
      "Epoch 00363: loss improved from -137.75216 to -138.21405, saving model to gendance.h5\n",
      "Epoch 364/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -138.0495 - val_loss: -137.8856\n",
      "\n",
      "Epoch 00364: loss did not improve from -138.21405\n",
      "Epoch 365/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -138.1206 - val_loss: -138.2701\n",
      "\n",
      "Epoch 00365: loss did not improve from -138.21405\n",
      "Epoch 366/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -138.0328 - val_loss: -138.4922\n",
      "\n",
      "Epoch 00366: loss did not improve from -138.21405\n",
      "Epoch 367/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -137.9663 - val_loss: -137.9554\n",
      "\n",
      "Epoch 00367: loss did not improve from -138.21405\n",
      "Epoch 368/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -138.1391 - val_loss: -138.8610\n",
      "\n",
      "Epoch 00368: loss did not improve from -138.21405\n",
      "Epoch 369/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -138.6815 - val_loss: -140.1812\n",
      "\n",
      "Epoch 00369: loss improved from -138.21405 to -138.68146, saving model to gendance.h5\n",
      "Epoch 370/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -138.3490 - val_loss: -139.1462\n",
      "\n",
      "Epoch 00370: loss did not improve from -138.68146\n",
      "Epoch 371/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -138.3816 - val_loss: -138.6935\n",
      "\n",
      "Epoch 00371: loss did not improve from -138.68146\n",
      "Epoch 372/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -138.3475 - val_loss: -139.3730\n",
      "\n",
      "Epoch 00372: loss did not improve from -138.68146\n",
      "Epoch 373/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -138.1519 - val_loss: -139.1233\n",
      "\n",
      "Epoch 00373: loss did not improve from -138.68146\n",
      "Epoch 374/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -138.5736 - val_loss: -139.8964\n",
      "\n",
      "Epoch 00374: loss did not improve from -138.68146\n",
      "Epoch 375/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -138.5298 - val_loss: -139.5423\n",
      "\n",
      "Epoch 00375: loss did not improve from -138.68146\n",
      "Epoch 376/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -138.4424 - val_loss: -139.1549\n",
      "\n",
      "Epoch 00376: loss did not improve from -138.68146\n",
      "Epoch 377/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -138.5751 - val_loss: -139.6762\n",
      "\n",
      "Epoch 00377: loss did not improve from -138.68146\n",
      "Epoch 378/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -138.6825 - val_loss: -139.4997\n",
      "\n",
      "Epoch 00378: loss improved from -138.68146 to -138.68251, saving model to gendance.h5\n",
      "Epoch 379/10000\n",
      "16167/16167 [==============================] - 1s 33us/step - loss: -138.7916 - val_loss: -139.2339\n",
      "\n",
      "Epoch 00379: loss improved from -138.68251 to -138.79159, saving model to gendance.h5\n",
      "Epoch 380/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -138.7064 - val_loss: -139.3031\n",
      "\n",
      "Epoch 00380: loss did not improve from -138.79159\n",
      "Epoch 381/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -138.8258 - val_loss: -138.9698\n",
      "\n",
      "Epoch 00381: loss improved from -138.79159 to -138.82580, saving model to gendance.h5\n",
      "Epoch 382/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -138.9222 - val_loss: -138.9317\n",
      "\n",
      "Epoch 00382: loss improved from -138.82580 to -138.92223, saving model to gendance.h5\n",
      "Epoch 383/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -139.0542 - val_loss: -138.9208\n",
      "\n",
      "Epoch 00383: loss improved from -138.92223 to -139.05418, saving model to gendance.h5\n",
      "Epoch 384/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -139.0559 - val_loss: -139.4582\n",
      "\n",
      "Epoch 00384: loss improved from -139.05418 to -139.05595, saving model to gendance.h5\n",
      "Epoch 385/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -139.5287 - val_loss: -139.7463\n",
      "\n",
      "Epoch 00385: loss improved from -139.05595 to -139.52874, saving model to gendance.h5\n",
      "Epoch 386/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -139.5779 - val_loss: -139.7331\n",
      "\n",
      "Epoch 00386: loss improved from -139.52874 to -139.57790, saving model to gendance.h5\n",
      "Epoch 387/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -139.5895 - val_loss: -140.1001\n",
      "\n",
      "Epoch 00387: loss improved from -139.57790 to -139.58949, saving model to gendance.h5\n",
      "Epoch 388/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -139.4247 - val_loss: -140.3147\n",
      "\n",
      "Epoch 00388: loss did not improve from -139.58949\n",
      "Epoch 389/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -139.7676 - val_loss: -140.1350\n",
      "\n",
      "Epoch 00389: loss improved from -139.58949 to -139.76758, saving model to gendance.h5\n",
      "Epoch 390/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -139.4941 - val_loss: -140.3188\n",
      "\n",
      "Epoch 00390: loss did not improve from -139.76758\n",
      "Epoch 391/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -139.8001 - val_loss: -140.3709\n",
      "\n",
      "Epoch 00391: loss improved from -139.76758 to -139.80006, saving model to gendance.h5\n",
      "Epoch 392/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -139.7834 - val_loss: -140.7653\n",
      "\n",
      "Epoch 00392: loss did not improve from -139.80006\n",
      "Epoch 393/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -139.6268 - val_loss: -140.1820\n",
      "\n",
      "Epoch 00393: loss did not improve from -139.80006\n",
      "Epoch 394/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -139.9107 - val_loss: -139.0237\n",
      "\n",
      "Epoch 00394: loss improved from -139.80006 to -139.91071, saving model to gendance.h5\n",
      "Epoch 395/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -139.6769 - val_loss: -139.8821\n",
      "\n",
      "Epoch 00395: loss did not improve from -139.91071\n",
      "Epoch 396/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -139.9196 - val_loss: -141.1260\n",
      "\n",
      "Epoch 00396: loss improved from -139.91071 to -139.91956, saving model to gendance.h5\n",
      "Epoch 397/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -139.5121 - val_loss: -139.0559\n",
      "\n",
      "Epoch 00397: loss did not improve from -139.91956\n",
      "Epoch 398/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -139.6255 - val_loss: -139.0136\n",
      "\n",
      "Epoch 00398: loss did not improve from -139.91956\n",
      "Epoch 399/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -139.7628 - val_loss: -140.5260\n",
      "\n",
      "Epoch 00399: loss did not improve from -139.91956\n",
      "Epoch 400/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -139.8117 - val_loss: -139.9629\n",
      "\n",
      "Epoch 00400: loss did not improve from -139.91956\n",
      "Epoch 401/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -139.8586 - val_loss: -139.8991\n",
      "\n",
      "Epoch 00401: loss did not improve from -139.91956\n",
      "Epoch 402/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -140.2865 - val_loss: -141.5973\n",
      "\n",
      "Epoch 00402: loss improved from -139.91956 to -140.28645, saving model to gendance.h5\n",
      "Epoch 403/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -140.2536 - val_loss: -141.2663\n",
      "\n",
      "Epoch 00403: loss did not improve from -140.28645\n",
      "Epoch 404/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -140.2492 - val_loss: -140.4299\n",
      "\n",
      "Epoch 00404: loss did not improve from -140.28645\n",
      "Epoch 405/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -140.0918 - val_loss: -140.2590\n",
      "\n",
      "Epoch 00405: loss did not improve from -140.28645\n",
      "Epoch 406/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -139.7986 - val_loss: -141.0965\n",
      "\n",
      "Epoch 00406: loss did not improve from -140.28645\n",
      "Epoch 407/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -140.2231 - val_loss: -139.1349\n",
      "\n",
      "Epoch 00407: loss did not improve from -140.28645\n",
      "Epoch 408/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -140.5351 - val_loss: -140.8472\n",
      "\n",
      "Epoch 00408: loss improved from -140.28645 to -140.53511, saving model to gendance.h5\n",
      "Epoch 409/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -140.5883 - val_loss: -141.9806\n",
      "\n",
      "Epoch 00409: loss improved from -140.53511 to -140.58835, saving model to gendance.h5\n",
      "Epoch 410/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -140.4131 - val_loss: -140.8993\n",
      "\n",
      "Epoch 00410: loss did not improve from -140.58835\n",
      "Epoch 411/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -140.5263 - val_loss: -140.2588\n",
      "\n",
      "Epoch 00411: loss did not improve from -140.58835\n",
      "Epoch 412/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -140.5292 - val_loss: -141.1943\n",
      "\n",
      "Epoch 00412: loss did not improve from -140.58835\n",
      "Epoch 413/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -140.4798 - val_loss: -140.4266\n",
      "\n",
      "Epoch 00413: loss did not improve from -140.58835\n",
      "Epoch 414/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -140.6953 - val_loss: -140.4192\n",
      "\n",
      "Epoch 00414: loss improved from -140.58835 to -140.69533, saving model to gendance.h5\n",
      "Epoch 415/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -141.0958 - val_loss: -141.5499\n",
      "\n",
      "Epoch 00415: loss improved from -140.69533 to -141.09583, saving model to gendance.h5\n",
      "Epoch 416/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -141.1995 - val_loss: -141.6269\n",
      "\n",
      "Epoch 00416: loss improved from -141.09583 to -141.19950, saving model to gendance.h5\n",
      "Epoch 417/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -141.3008 - val_loss: -142.2678\n",
      "\n",
      "Epoch 00417: loss improved from -141.19950 to -141.30079, saving model to gendance.h5\n",
      "Epoch 418/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -141.4587 - val_loss: -141.6944\n",
      "\n",
      "Epoch 00418: loss improved from -141.30079 to -141.45866, saving model to gendance.h5\n",
      "Epoch 419/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -141.3613 - val_loss: -142.3895\n",
      "\n",
      "Epoch 00419: loss did not improve from -141.45866\n",
      "Epoch 420/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -141.2613 - val_loss: -142.5528\n",
      "\n",
      "Epoch 00420: loss did not improve from -141.45866\n",
      "Epoch 421/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -141.4620 - val_loss: -142.5200\n",
      "\n",
      "Epoch 00421: loss improved from -141.45866 to -141.46196, saving model to gendance.h5\n",
      "Epoch 422/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -141.5053 - val_loss: -142.6596\n",
      "\n",
      "Epoch 00422: loss improved from -141.46196 to -141.50529, saving model to gendance.h5\n",
      "Epoch 423/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -141.3343 - val_loss: -141.7653\n",
      "\n",
      "Epoch 00423: loss did not improve from -141.50529\n",
      "Epoch 424/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -141.3262 - val_loss: -142.0385\n",
      "\n",
      "Epoch 00424: loss did not improve from -141.50529\n",
      "Epoch 425/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -141.2892 - val_loss: -142.0989\n",
      "\n",
      "Epoch 00425: loss did not improve from -141.50529\n",
      "Epoch 426/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -141.6135 - val_loss: -141.7910\n",
      "\n",
      "Epoch 00426: loss improved from -141.50529 to -141.61348, saving model to gendance.h5\n",
      "Epoch 427/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -141.5705 - val_loss: -141.9491\n",
      "\n",
      "Epoch 00427: loss did not improve from -141.61348\n",
      "Epoch 428/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -141.5363 - val_loss: -142.1468\n",
      "\n",
      "Epoch 00428: loss did not improve from -141.61348\n",
      "Epoch 429/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -141.5359 - val_loss: -142.4741\n",
      "\n",
      "Epoch 00429: loss did not improve from -141.61348\n",
      "Epoch 430/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -141.8960 - val_loss: -142.3198\n",
      "\n",
      "Epoch 00430: loss improved from -141.61348 to -141.89605, saving model to gendance.h5\n",
      "Epoch 431/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -142.2018 - val_loss: -142.5244\n",
      "\n",
      "Epoch 00431: loss improved from -141.89605 to -142.20182, saving model to gendance.h5\n",
      "Epoch 432/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -142.0410 - val_loss: -142.1049\n",
      "\n",
      "Epoch 00432: loss did not improve from -142.20182\n",
      "Epoch 433/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -141.8997 - val_loss: -142.8708\n",
      "\n",
      "Epoch 00433: loss did not improve from -142.20182\n",
      "Epoch 434/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -141.9007 - val_loss: -143.2705\n",
      "\n",
      "Epoch 00434: loss did not improve from -142.20182\n",
      "Epoch 435/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -142.2080 - val_loss: -143.2338\n",
      "\n",
      "Epoch 00435: loss improved from -142.20182 to -142.20796, saving model to gendance.h5\n",
      "Epoch 436/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -142.0456 - val_loss: -143.9118\n",
      "\n",
      "Epoch 00436: loss did not improve from -142.20796\n",
      "Epoch 437/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -141.6710 - val_loss: -141.9302\n",
      "\n",
      "Epoch 00437: loss did not improve from -142.20796\n",
      "Epoch 438/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -141.4304 - val_loss: -141.5355\n",
      "\n",
      "Epoch 00438: loss did not improve from -142.20796\n",
      "Epoch 439/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -141.6980 - val_loss: -142.9885\n",
      "\n",
      "Epoch 00439: loss did not improve from -142.20796\n",
      "Epoch 440/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -141.2012 - val_loss: -141.7629\n",
      "\n",
      "Epoch 00440: loss did not improve from -142.20796\n",
      "Epoch 441/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -141.9454 - val_loss: -143.4486\n",
      "\n",
      "Epoch 00441: loss did not improve from -142.20796\n",
      "Epoch 442/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -142.0782 - val_loss: -143.5168\n",
      "\n",
      "Epoch 00442: loss did not improve from -142.20796\n",
      "Epoch 443/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -141.5110 - val_loss: -142.1619\n",
      "\n",
      "Epoch 00443: loss did not improve from -142.20796\n",
      "Epoch 444/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -142.3119 - val_loss: -143.1274\n",
      "\n",
      "Epoch 00444: loss improved from -142.20796 to -142.31190, saving model to gendance.h5\n",
      "Epoch 445/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -142.4804 - val_loss: -143.4601\n",
      "\n",
      "Epoch 00445: loss improved from -142.31190 to -142.48040, saving model to gendance.h5\n",
      "Epoch 446/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -142.4603 - val_loss: -141.7472\n",
      "\n",
      "Epoch 00446: loss did not improve from -142.48040\n",
      "Epoch 447/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -142.3314 - val_loss: -141.6964\n",
      "\n",
      "Epoch 00447: loss did not improve from -142.48040\n",
      "Epoch 448/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -142.4324 - val_loss: -142.8087\n",
      "\n",
      "Epoch 00448: loss did not improve from -142.48040\n",
      "Epoch 449/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -142.3242 - val_loss: -141.1446\n",
      "\n",
      "Epoch 00449: loss did not improve from -142.48040\n",
      "Epoch 450/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -142.5919 - val_loss: -142.8885\n",
      "\n",
      "Epoch 00450: loss improved from -142.48040 to -142.59193, saving model to gendance.h5\n",
      "Epoch 451/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -142.2539 - val_loss: -143.7703\n",
      "\n",
      "Epoch 00451: loss did not improve from -142.59193\n",
      "Epoch 452/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -142.0855 - val_loss: -141.9502\n",
      "\n",
      "Epoch 00452: loss did not improve from -142.59193\n",
      "Epoch 453/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -142.6719 - val_loss: -142.5637\n",
      "\n",
      "Epoch 00453: loss improved from -142.59193 to -142.67194, saving model to gendance.h5\n",
      "Epoch 454/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -143.0106 - val_loss: -144.5394\n",
      "\n",
      "Epoch 00454: loss improved from -142.67194 to -143.01057, saving model to gendance.h5\n",
      "Epoch 455/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -142.9355 - val_loss: -143.2092\n",
      "\n",
      "Epoch 00455: loss did not improve from -143.01057\n",
      "Epoch 456/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -142.5618 - val_loss: -142.2030\n",
      "\n",
      "Epoch 00456: loss did not improve from -143.01057\n",
      "Epoch 457/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -142.4827 - val_loss: -144.3640\n",
      "\n",
      "Epoch 00457: loss did not improve from -143.01057\n",
      "Epoch 458/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -142.5489 - val_loss: -143.2525\n",
      "\n",
      "Epoch 00458: loss did not improve from -143.01057\n",
      "Epoch 459/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -142.6087 - val_loss: -141.7611\n",
      "\n",
      "Epoch 00459: loss did not improve from -143.01057\n",
      "Epoch 460/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -142.5684 - val_loss: -144.1550\n",
      "\n",
      "Epoch 00460: loss did not improve from -143.01057\n",
      "Epoch 461/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -142.2211 - val_loss: -141.5126\n",
      "\n",
      "Epoch 00461: loss did not improve from -143.01057\n",
      "Epoch 462/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -142.8218 - val_loss: -142.6907\n",
      "\n",
      "Epoch 00462: loss did not improve from -143.01057\n",
      "Epoch 463/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -143.4576 - val_loss: -144.5996\n",
      "\n",
      "Epoch 00463: loss improved from -143.01057 to -143.45763, saving model to gendance.h5\n",
      "Epoch 464/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -143.7858 - val_loss: -143.9064\n",
      "\n",
      "Epoch 00464: loss improved from -143.45763 to -143.78578, saving model to gendance.h5\n",
      "Epoch 465/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -143.5870 - val_loss: -143.4536\n",
      "\n",
      "Epoch 00465: loss did not improve from -143.78578\n",
      "Epoch 466/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -143.2413 - val_loss: -144.1526\n",
      "\n",
      "Epoch 00466: loss did not improve from -143.78578\n",
      "Epoch 467/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -143.4610 - val_loss: -143.2306\n",
      "\n",
      "Epoch 00467: loss did not improve from -143.78578\n",
      "Epoch 468/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -143.6538 - val_loss: -143.5991\n",
      "\n",
      "Epoch 00468: loss did not improve from -143.78578\n",
      "Epoch 469/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -143.6666 - val_loss: -143.9093\n",
      "\n",
      "Epoch 00469: loss did not improve from -143.78578\n",
      "Epoch 470/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -143.8102 - val_loss: -144.2556\n",
      "\n",
      "Epoch 00470: loss improved from -143.78578 to -143.81023, saving model to gendance.h5\n",
      "Epoch 471/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -143.8427 - val_loss: -144.3671\n",
      "\n",
      "Epoch 00471: loss improved from -143.81023 to -143.84266, saving model to gendance.h5\n",
      "Epoch 472/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -143.9814 - val_loss: -143.9394\n",
      "\n",
      "Epoch 00472: loss improved from -143.84266 to -143.98143, saving model to gendance.h5\n",
      "Epoch 473/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -143.7606 - val_loss: -144.5049\n",
      "\n",
      "Epoch 00473: loss did not improve from -143.98143\n",
      "Epoch 474/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -143.6381 - val_loss: -143.5738\n",
      "\n",
      "Epoch 00474: loss did not improve from -143.98143\n",
      "Epoch 475/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -143.9361 - val_loss: -144.1849\n",
      "\n",
      "Epoch 00475: loss did not improve from -143.98143\n",
      "Epoch 476/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -143.7084 - val_loss: -144.2599\n",
      "\n",
      "Epoch 00476: loss did not improve from -143.98143\n",
      "Epoch 477/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -143.8154 - val_loss: -143.7048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00477: loss did not improve from -143.98143\n",
      "Epoch 478/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -143.8632 - val_loss: -144.1466\n",
      "\n",
      "Epoch 00478: loss did not improve from -143.98143\n",
      "Epoch 479/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -143.6369 - val_loss: -144.2379\n",
      "\n",
      "Epoch 00479: loss did not improve from -143.98143\n",
      "Epoch 480/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -143.6438 - val_loss: -143.9431\n",
      "\n",
      "Epoch 00480: loss did not improve from -143.98143\n",
      "Epoch 481/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -143.7557 - val_loss: -144.1996\n",
      "\n",
      "Epoch 00481: loss did not improve from -143.98143\n",
      "Epoch 482/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -144.2464 - val_loss: -145.6582\n",
      "\n",
      "Epoch 00482: loss improved from -143.98143 to -144.24639, saving model to gendance.h5\n",
      "Epoch 483/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -144.1114 - val_loss: -143.9694\n",
      "\n",
      "Epoch 00483: loss did not improve from -144.24639\n",
      "Epoch 484/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -144.2984 - val_loss: -144.4955\n",
      "\n",
      "Epoch 00484: loss improved from -144.24639 to -144.29836, saving model to gendance.h5\n",
      "Epoch 485/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -144.0813 - val_loss: -145.9809\n",
      "\n",
      "Epoch 00485: loss did not improve from -144.29836\n",
      "Epoch 486/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -143.5547 - val_loss: -143.9816\n",
      "\n",
      "Epoch 00486: loss did not improve from -144.29836\n",
      "Epoch 487/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -144.0696 - val_loss: -143.5972\n",
      "\n",
      "Epoch 00487: loss did not improve from -144.29836\n",
      "Epoch 488/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -144.3096 - val_loss: -145.4340\n",
      "\n",
      "Epoch 00488: loss improved from -144.29836 to -144.30956, saving model to gendance.h5\n",
      "Epoch 489/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -144.2570 - val_loss: -144.2213\n",
      "\n",
      "Epoch 00489: loss did not improve from -144.30956\n",
      "Epoch 490/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -144.4007 - val_loss: -144.7215\n",
      "\n",
      "Epoch 00490: loss improved from -144.30956 to -144.40069, saving model to gendance.h5\n",
      "Epoch 491/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -144.2776 - val_loss: -145.9804\n",
      "\n",
      "Epoch 00491: loss did not improve from -144.40069\n",
      "Epoch 492/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -144.0553 - val_loss: -144.3712\n",
      "\n",
      "Epoch 00492: loss did not improve from -144.40069\n",
      "Epoch 493/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -144.6414 - val_loss: -144.4821\n",
      "\n",
      "Epoch 00493: loss improved from -144.40069 to -144.64141, saving model to gendance.h5\n",
      "Epoch 494/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -144.9225 - val_loss: -146.5080\n",
      "\n",
      "Epoch 00494: loss improved from -144.64141 to -144.92246, saving model to gendance.h5\n",
      "Epoch 495/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -144.8017 - val_loss: -145.4634\n",
      "\n",
      "Epoch 00495: loss did not improve from -144.92246\n",
      "Epoch 496/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -144.6072 - val_loss: -144.8206\n",
      "\n",
      "Epoch 00496: loss did not improve from -144.92246\n",
      "Epoch 497/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -144.6486 - val_loss: -146.3878\n",
      "\n",
      "Epoch 00497: loss did not improve from -144.92246\n",
      "Epoch 498/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -144.3066 - val_loss: -144.2884\n",
      "\n",
      "Epoch 00498: loss did not improve from -144.92246\n",
      "Epoch 499/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -144.7717 - val_loss: -144.4986\n",
      "\n",
      "Epoch 00499: loss did not improve from -144.92246\n",
      "Epoch 500/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -144.6868 - val_loss: -146.6346\n",
      "\n",
      "Epoch 00500: loss did not improve from -144.92246\n",
      "Epoch 501/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -144.8185 - val_loss: -144.8432\n",
      "\n",
      "Epoch 00501: loss did not improve from -144.92246\n",
      "Epoch 502/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -144.9120 - val_loss: -144.8361\n",
      "\n",
      "Epoch 00502: loss did not improve from -144.92246\n",
      "Epoch 503/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -144.8195 - val_loss: -146.8217\n",
      "\n",
      "Epoch 00503: loss did not improve from -144.92246\n",
      "Epoch 504/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -145.0639 - val_loss: -145.3585\n",
      "\n",
      "Epoch 00504: loss improved from -144.92246 to -145.06385, saving model to gendance.h5\n",
      "Epoch 505/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -145.2402 - val_loss: -144.8941\n",
      "\n",
      "Epoch 00505: loss improved from -145.06385 to -145.24023, saving model to gendance.h5\n",
      "Epoch 506/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -145.1485 - val_loss: -146.7396\n",
      "\n",
      "Epoch 00506: loss did not improve from -145.24023\n",
      "Epoch 507/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -145.3173 - val_loss: -145.9192\n",
      "\n",
      "Epoch 00507: loss improved from -145.24023 to -145.31726, saving model to gendance.h5\n",
      "Epoch 508/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -145.6061 - val_loss: -146.0686\n",
      "\n",
      "Epoch 00508: loss improved from -145.31726 to -145.60606, saving model to gendance.h5\n",
      "Epoch 509/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -145.7197 - val_loss: -147.3207\n",
      "\n",
      "Epoch 00509: loss improved from -145.60606 to -145.71968, saving model to gendance.h5\n",
      "Epoch 510/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -145.7837 - val_loss: -146.6242\n",
      "\n",
      "Epoch 00510: loss improved from -145.71968 to -145.78372, saving model to gendance.h5\n",
      "Epoch 511/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -145.5762 - val_loss: -146.2423\n",
      "\n",
      "Epoch 00511: loss did not improve from -145.78372\n",
      "Epoch 512/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -145.3249 - val_loss: -146.9039\n",
      "\n",
      "Epoch 00512: loss did not improve from -145.78372\n",
      "Epoch 513/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -145.5518 - val_loss: -146.2988\n",
      "\n",
      "Epoch 00513: loss did not improve from -145.78372\n",
      "Epoch 514/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -146.0074 - val_loss: -146.9174\n",
      "\n",
      "Epoch 00514: loss improved from -145.78372 to -146.00743, saving model to gendance.h5\n",
      "Epoch 515/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -146.1700 - val_loss: -147.3307\n",
      "\n",
      "Epoch 00515: loss improved from -146.00743 to -146.17004, saving model to gendance.h5\n",
      "Epoch 516/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -145.6986 - val_loss: -146.5902\n",
      "\n",
      "Epoch 00516: loss did not improve from -146.17004\n",
      "Epoch 517/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -145.5049 - val_loss: -146.4761\n",
      "\n",
      "Epoch 00517: loss did not improve from -146.17004\n",
      "Epoch 518/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -145.6018 - val_loss: -147.1388\n",
      "\n",
      "Epoch 00518: loss did not improve from -146.17004\n",
      "Epoch 519/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -145.8588 - val_loss: -145.9335\n",
      "\n",
      "Epoch 00519: loss did not improve from -146.17004\n",
      "Epoch 520/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -145.8575 - val_loss: -147.3694\n",
      "\n",
      "Epoch 00520: loss did not improve from -146.17004\n",
      "Epoch 521/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -145.9779 - val_loss: -147.6865\n",
      "\n",
      "Epoch 00521: loss did not improve from -146.17004\n",
      "Epoch 522/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -146.0730 - val_loss: -146.7299\n",
      "\n",
      "Epoch 00522: loss did not improve from -146.17004\n",
      "Epoch 523/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -146.2095 - val_loss: -147.0929\n",
      "\n",
      "Epoch 00523: loss improved from -146.17004 to -146.20953, saving model to gendance.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 524/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -146.5667 - val_loss: -148.2710\n",
      "\n",
      "Epoch 00524: loss improved from -146.20953 to -146.56665, saving model to gendance.h5\n",
      "Epoch 525/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -146.3400 - val_loss: -147.1521\n",
      "\n",
      "Epoch 00525: loss did not improve from -146.56665\n",
      "Epoch 526/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -146.3017 - val_loss: -146.5331\n",
      "\n",
      "Epoch 00526: loss did not improve from -146.56665\n",
      "Epoch 527/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -146.0530 - val_loss: -147.8737\n",
      "\n",
      "Epoch 00527: loss did not improve from -146.56665\n",
      "Epoch 528/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -145.4403 - val_loss: -145.8406\n",
      "\n",
      "Epoch 00528: loss did not improve from -146.56665\n",
      "Epoch 529/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -145.4738 - val_loss: -145.1491\n",
      "\n",
      "Epoch 00529: loss did not improve from -146.56665\n",
      "Epoch 530/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -145.3275 - val_loss: -148.1891\n",
      "\n",
      "Epoch 00530: loss did not improve from -146.56665\n",
      "Epoch 531/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -145.3955 - val_loss: -146.0115\n",
      "\n",
      "Epoch 00531: loss did not improve from -146.56665\n",
      "Epoch 532/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -145.1665 - val_loss: -146.2588\n",
      "\n",
      "Epoch 00532: loss did not improve from -146.56665\n",
      "Epoch 533/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -145.1438 - val_loss: -147.7399\n",
      "\n",
      "Epoch 00533: loss did not improve from -146.56665\n",
      "Epoch 534/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -145.4325 - val_loss: -145.8130\n",
      "\n",
      "Epoch 00534: loss did not improve from -146.56665\n",
      "Epoch 535/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -146.0140 - val_loss: -147.3998\n",
      "\n",
      "Epoch 00535: loss did not improve from -146.56665\n",
      "Epoch 536/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -146.3304 - val_loss: -147.9588\n",
      "\n",
      "Epoch 00536: loss did not improve from -146.56665\n",
      "Epoch 537/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -146.0484 - val_loss: -146.0427\n",
      "\n",
      "Epoch 00537: loss did not improve from -146.56665\n",
      "Epoch 538/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -146.2330 - val_loss: -146.8104\n",
      "\n",
      "Epoch 00538: loss did not improve from -146.56665\n",
      "Epoch 539/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -146.5020 - val_loss: -148.5507\n",
      "\n",
      "Epoch 00539: loss did not improve from -146.56665\n",
      "Epoch 540/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -145.9547 - val_loss: -146.7397\n",
      "\n",
      "Epoch 00540: loss did not improve from -146.56665\n",
      "Epoch 541/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -145.5947 - val_loss: -146.3052\n",
      "\n",
      "Epoch 00541: loss did not improve from -146.56665\n",
      "Epoch 542/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -145.9248 - val_loss: -148.6300\n",
      "\n",
      "Epoch 00542: loss did not improve from -146.56665\n",
      "Epoch 543/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -145.9779 - val_loss: -146.3230\n",
      "\n",
      "Epoch 00543: loss did not improve from -146.56665\n",
      "Epoch 544/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -146.2997 - val_loss: -147.6379\n",
      "\n",
      "Epoch 00544: loss did not improve from -146.56665\n",
      "Epoch 545/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -146.5489 - val_loss: -148.3077\n",
      "\n",
      "Epoch 00545: loss did not improve from -146.56665\n",
      "Epoch 546/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -146.4561 - val_loss: -146.8804\n",
      "\n",
      "Epoch 00546: loss did not improve from -146.56665\n",
      "Epoch 547/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -146.4877 - val_loss: -147.5172\n",
      "\n",
      "Epoch 00547: loss did not improve from -146.56665\n",
      "Epoch 548/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -146.3911 - val_loss: -147.7375\n",
      "\n",
      "Epoch 00548: loss did not improve from -146.56665\n",
      "Epoch 549/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -146.2066 - val_loss: -146.9739\n",
      "\n",
      "Epoch 00549: loss did not improve from -146.56665\n",
      "Epoch 550/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -146.6654 - val_loss: -148.7605\n",
      "\n",
      "Epoch 00550: loss improved from -146.56665 to -146.66540, saving model to gendance.h5\n",
      "Epoch 551/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -147.0720 - val_loss: -148.6208\n",
      "\n",
      "Epoch 00551: loss improved from -146.66540 to -147.07204, saving model to gendance.h5\n",
      "Epoch 552/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -146.9944 - val_loss: -147.9206\n",
      "\n",
      "Epoch 00552: loss did not improve from -147.07204\n",
      "Epoch 553/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -147.1154 - val_loss: -148.4799\n",
      "\n",
      "Epoch 00553: loss improved from -147.07204 to -147.11543, saving model to gendance.h5\n",
      "Epoch 554/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -147.1690 - val_loss: -148.3428\n",
      "\n",
      "Epoch 00554: loss improved from -147.11543 to -147.16903, saving model to gendance.h5\n",
      "Epoch 555/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -147.1531 - val_loss: -148.2727\n",
      "\n",
      "Epoch 00555: loss did not improve from -147.16903\n",
      "Epoch 556/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -147.5878 - val_loss: -148.7101\n",
      "\n",
      "Epoch 00556: loss improved from -147.16903 to -147.58785, saving model to gendance.h5\n",
      "Epoch 557/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -147.3173 - val_loss: -148.2742\n",
      "\n",
      "Epoch 00557: loss did not improve from -147.58785\n",
      "Epoch 558/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -147.1875 - val_loss: -148.7958\n",
      "\n",
      "Epoch 00558: loss did not improve from -147.58785\n",
      "Epoch 559/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -147.3666 - val_loss: -148.3306\n",
      "\n",
      "Epoch 00559: loss did not improve from -147.58785\n",
      "Epoch 560/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -147.4119 - val_loss: -148.9424\n",
      "\n",
      "Epoch 00560: loss did not improve from -147.58785\n",
      "Epoch 561/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -147.6547 - val_loss: -149.1618\n",
      "\n",
      "Epoch 00561: loss improved from -147.58785 to -147.65473, saving model to gendance.h5\n",
      "Epoch 562/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -147.5331 - val_loss: -148.8830\n",
      "\n",
      "Epoch 00562: loss did not improve from -147.65473\n",
      "Epoch 563/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -147.5044 - val_loss: -149.1451\n",
      "\n",
      "Epoch 00563: loss did not improve from -147.65473\n",
      "Epoch 564/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -147.1903 - val_loss: -148.6328\n",
      "\n",
      "Epoch 00564: loss did not improve from -147.65473\n",
      "Epoch 565/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -147.3761 - val_loss: -147.2576\n",
      "\n",
      "Epoch 00565: loss did not improve from -147.65473\n",
      "Epoch 566/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -147.2993 - val_loss: -148.7943\n",
      "\n",
      "Epoch 00566: loss did not improve from -147.65473\n",
      "Epoch 567/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -146.5998 - val_loss: -147.8272\n",
      "\n",
      "Epoch 00567: loss did not improve from -147.65473\n",
      "Epoch 568/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -146.3465 - val_loss: -145.9984\n",
      "\n",
      "Epoch 00568: loss did not improve from -147.65473\n",
      "Epoch 569/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -146.4217 - val_loss: -148.6750\n",
      "\n",
      "Epoch 00569: loss did not improve from -147.65473\n",
      "Epoch 570/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -146.5401 - val_loss: -147.1317\n",
      "\n",
      "Epoch 00570: loss did not improve from -147.65473\n",
      "Epoch 571/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -147.1100 - val_loss: -147.7016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00571: loss did not improve from -147.65473\n",
      "Epoch 572/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -147.1119 - val_loss: -149.1827\n",
      "\n",
      "Epoch 00572: loss did not improve from -147.65473\n",
      "Epoch 573/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -147.0175 - val_loss: -147.4600\n",
      "\n",
      "Epoch 00573: loss did not improve from -147.65473\n",
      "Epoch 574/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -146.9934 - val_loss: -146.8136\n",
      "\n",
      "Epoch 00574: loss did not improve from -147.65473\n",
      "Epoch 575/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -146.4331 - val_loss: -148.8948\n",
      "\n",
      "Epoch 00575: loss did not improve from -147.65473\n",
      "Epoch 576/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -146.9139 - val_loss: -147.1625\n",
      "\n",
      "Epoch 00576: loss did not improve from -147.65473\n",
      "Epoch 577/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -147.4057 - val_loss: -147.8817\n",
      "\n",
      "Epoch 00577: loss did not improve from -147.65473\n",
      "Epoch 578/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -147.3150 - val_loss: -149.6114\n",
      "\n",
      "Epoch 00578: loss did not improve from -147.65473\n",
      "Epoch 579/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -147.2813 - val_loss: -147.9499\n",
      "\n",
      "Epoch 00579: loss did not improve from -147.65473\n",
      "Epoch 580/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -147.5793 - val_loss: -148.2692\n",
      "\n",
      "Epoch 00580: loss did not improve from -147.65473\n",
      "Epoch 581/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -147.7827 - val_loss: -149.6177\n",
      "\n",
      "Epoch 00581: loss improved from -147.65473 to -147.78272, saving model to gendance.h5\n",
      "Epoch 582/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -147.5432 - val_loss: -148.3200\n",
      "\n",
      "Epoch 00582: loss did not improve from -147.78272\n",
      "Epoch 583/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -147.5589 - val_loss: -148.8168\n",
      "\n",
      "Epoch 00583: loss did not improve from -147.78272\n",
      "Epoch 584/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -147.5929 - val_loss: -149.3042\n",
      "\n",
      "Epoch 00584: loss did not improve from -147.78272\n",
      "Epoch 585/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -147.5734 - val_loss: -148.1580\n",
      "\n",
      "Epoch 00585: loss did not improve from -147.78272\n",
      "Epoch 586/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -148.0622 - val_loss: -149.7334\n",
      "\n",
      "Epoch 00586: loss improved from -147.78272 to -148.06220, saving model to gendance.h5\n",
      "Epoch 587/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -148.1885 - val_loss: -149.3492\n",
      "\n",
      "Epoch 00587: loss improved from -148.06220 to -148.18852, saving model to gendance.h5\n",
      "Epoch 588/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -148.1722 - val_loss: -149.0386\n",
      "\n",
      "Epoch 00588: loss did not improve from -148.18852\n",
      "Epoch 589/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -148.4452 - val_loss: -149.3543\n",
      "\n",
      "Epoch 00589: loss improved from -148.18852 to -148.44523, saving model to gendance.h5\n",
      "Epoch 590/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -148.4058 - val_loss: -149.5451\n",
      "\n",
      "Epoch 00590: loss did not improve from -148.44523\n",
      "Epoch 591/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -148.5987 - val_loss: -150.1616\n",
      "\n",
      "Epoch 00591: loss improved from -148.44523 to -148.59866, saving model to gendance.h5\n",
      "Epoch 592/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -148.7030 - val_loss: -149.8565\n",
      "\n",
      "Epoch 00592: loss improved from -148.59866 to -148.70300, saving model to gendance.h5\n",
      "Epoch 593/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -148.4502 - val_loss: -149.4965\n",
      "\n",
      "Epoch 00593: loss did not improve from -148.70300\n",
      "Epoch 594/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -148.4617 - val_loss: -149.0561\n",
      "\n",
      "Epoch 00594: loss did not improve from -148.70300\n",
      "Epoch 595/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -148.2890 - val_loss: -149.6803\n",
      "\n",
      "Epoch 00595: loss did not improve from -148.70300\n",
      "Epoch 596/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -148.2464 - val_loss: -149.4575\n",
      "\n",
      "Epoch 00596: loss did not improve from -148.70300\n",
      "Epoch 597/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -148.1538 - val_loss: -149.8789\n",
      "\n",
      "Epoch 00597: loss did not improve from -148.70300\n",
      "Epoch 598/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -148.0987 - val_loss: -148.9310\n",
      "\n",
      "Epoch 00598: loss did not improve from -148.70300\n",
      "Epoch 599/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -147.8536 - val_loss: -147.9391\n",
      "\n",
      "Epoch 00599: loss did not improve from -148.70300\n",
      "Epoch 600/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -148.1515 - val_loss: -150.0517\n",
      "\n",
      "Epoch 00600: loss did not improve from -148.70300\n",
      "Epoch 601/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -148.2459 - val_loss: -149.4227\n",
      "\n",
      "Epoch 00601: loss did not improve from -148.70300\n",
      "Epoch 602/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -148.2601 - val_loss: -148.6224\n",
      "\n",
      "Epoch 00602: loss did not improve from -148.70300\n",
      "Epoch 603/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -148.3745 - val_loss: -150.3321\n",
      "\n",
      "Epoch 00603: loss did not improve from -148.70300\n",
      "Epoch 604/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -148.1883 - val_loss: -149.6305\n",
      "\n",
      "Epoch 00604: loss did not improve from -148.70300\n",
      "Epoch 605/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -148.2862 - val_loss: -148.8593\n",
      "\n",
      "Epoch 00605: loss did not improve from -148.70300\n",
      "Epoch 606/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -148.4174 - val_loss: -150.3210\n",
      "\n",
      "Epoch 00606: loss did not improve from -148.70300\n",
      "Epoch 607/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -148.4893 - val_loss: -150.2974\n",
      "\n",
      "Epoch 00607: loss did not improve from -148.70300\n",
      "Epoch 608/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -148.4922 - val_loss: -149.1689\n",
      "\n",
      "Epoch 00608: loss did not improve from -148.70300\n",
      "Epoch 609/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -148.5149 - val_loss: -150.6868\n",
      "\n",
      "Epoch 00609: loss did not improve from -148.70300\n",
      "Epoch 610/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -148.7964 - val_loss: -149.6869\n",
      "\n",
      "Epoch 00610: loss improved from -148.70300 to -148.79638, saving model to gendance.h5\n",
      "Epoch 611/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -148.6708 - val_loss: -148.9435\n",
      "\n",
      "Epoch 00611: loss did not improve from -148.79638\n",
      "Epoch 612/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -148.5832 - val_loss: -150.4698\n",
      "\n",
      "Epoch 00612: loss did not improve from -148.79638\n",
      "Epoch 613/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -148.4461 - val_loss: -148.4631\n",
      "\n",
      "Epoch 00613: loss did not improve from -148.79638\n",
      "Epoch 614/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -148.0357 - val_loss: -149.1848\n",
      "\n",
      "Epoch 00614: loss did not improve from -148.79638\n",
      "Epoch 615/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -148.2259 - val_loss: -150.5991\n",
      "\n",
      "Epoch 00615: loss did not improve from -148.79638\n",
      "Epoch 616/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -148.1003 - val_loss: -147.8624\n",
      "\n",
      "Epoch 00616: loss did not improve from -148.79638\n",
      "Epoch 617/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -148.3643 - val_loss: -149.5601\n",
      "\n",
      "Epoch 00617: loss did not improve from -148.79638\n",
      "Epoch 618/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -148.3666 - val_loss: -150.7741\n",
      "\n",
      "Epoch 00618: loss did not improve from -148.79638\n",
      "Epoch 619/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -147.8596 - val_loss: -147.2784\n",
      "\n",
      "Epoch 00619: loss did not improve from -148.79638\n",
      "Epoch 620/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -148.1746 - val_loss: -149.9535\n",
      "\n",
      "Epoch 00620: loss did not improve from -148.79638\n",
      "Epoch 621/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -148.7795 - val_loss: -150.8778\n",
      "\n",
      "Epoch 00621: loss did not improve from -148.79638\n",
      "Epoch 622/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -148.8950 - val_loss: -149.7374\n",
      "\n",
      "Epoch 00622: loss improved from -148.79638 to -148.89496, saving model to gendance.h5\n",
      "Epoch 623/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -149.1764 - val_loss: -150.4216\n",
      "\n",
      "Epoch 00623: loss improved from -148.89496 to -149.17642, saving model to gendance.h5\n",
      "Epoch 624/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -148.7707 - val_loss: -150.5048\n",
      "\n",
      "Epoch 00624: loss did not improve from -149.17642\n",
      "Epoch 625/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -148.6545 - val_loss: -148.7318\n",
      "\n",
      "Epoch 00625: loss did not improve from -149.17642\n",
      "Epoch 626/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -148.6759 - val_loss: -150.3390\n",
      "\n",
      "Epoch 00626: loss did not improve from -149.17642\n",
      "Epoch 627/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -149.1282 - val_loss: -150.4192\n",
      "\n",
      "Epoch 00627: loss did not improve from -149.17642\n",
      "Epoch 628/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -148.9418 - val_loss: -149.7042\n",
      "\n",
      "Epoch 00628: loss did not improve from -149.17642\n",
      "Epoch 629/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -149.0884 - val_loss: -150.9803\n",
      "\n",
      "Epoch 00629: loss did not improve from -149.17642\n",
      "Epoch 630/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -149.3492 - val_loss: -150.1551\n",
      "\n",
      "Epoch 00630: loss improved from -149.17642 to -149.34923, saving model to gendance.h5\n",
      "Epoch 631/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -149.4011 - val_loss: -150.5437\n",
      "\n",
      "Epoch 00631: loss improved from -149.34923 to -149.40107, saving model to gendance.h5\n",
      "Epoch 632/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -149.4203 - val_loss: -151.3766\n",
      "\n",
      "Epoch 00632: loss improved from -149.40107 to -149.42027, saving model to gendance.h5\n",
      "Epoch 633/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -149.7527 - val_loss: -150.7322\n",
      "\n",
      "Epoch 00633: loss improved from -149.42027 to -149.75272, saving model to gendance.h5\n",
      "Epoch 634/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -149.5522 - val_loss: -150.8337\n",
      "\n",
      "Epoch 00634: loss did not improve from -149.75272\n",
      "Epoch 635/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -149.7613 - val_loss: -151.8516\n",
      "\n",
      "Epoch 00635: loss improved from -149.75272 to -149.76130, saving model to gendance.h5\n",
      "Epoch 636/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -149.5276 - val_loss: -150.1869\n",
      "\n",
      "Epoch 00636: loss did not improve from -149.76130\n",
      "Epoch 637/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -149.8301 - val_loss: -151.4196\n",
      "\n",
      "Epoch 00637: loss improved from -149.76130 to -149.83006, saving model to gendance.h5\n",
      "Epoch 638/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -149.7305 - val_loss: -152.1903\n",
      "\n",
      "Epoch 00638: loss did not improve from -149.83006\n",
      "Epoch 639/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -149.1296 - val_loss: -148.6385\n",
      "\n",
      "Epoch 00639: loss did not improve from -149.83006\n",
      "Epoch 640/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -149.0216 - val_loss: -151.4562\n",
      "\n",
      "Epoch 00640: loss did not improve from -149.83006\n",
      "Epoch 641/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -149.4321 - val_loss: -150.9793\n",
      "\n",
      "Epoch 00641: loss did not improve from -149.83006\n",
      "Epoch 642/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -149.2665 - val_loss: -149.9571\n",
      "\n",
      "Epoch 00642: loss did not improve from -149.83006\n",
      "Epoch 643/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -149.1841 - val_loss: -151.5861\n",
      "\n",
      "Epoch 00643: loss did not improve from -149.83006\n",
      "Epoch 644/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -149.1494 - val_loss: -149.1471\n",
      "\n",
      "Epoch 00644: loss did not improve from -149.83006\n",
      "Epoch 645/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -148.5474 - val_loss: -150.3884\n",
      "\n",
      "Epoch 00645: loss did not improve from -149.83006\n",
      "Epoch 646/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -148.6028 - val_loss: -151.4172\n",
      "\n",
      "Epoch 00646: loss did not improve from -149.83006\n",
      "Epoch 647/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -148.3025 - val_loss: -148.5039\n",
      "\n",
      "Epoch 00647: loss did not improve from -149.83006\n",
      "Epoch 648/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -149.1050 - val_loss: -151.4034\n",
      "\n",
      "Epoch 00648: loss did not improve from -149.83006\n",
      "Epoch 649/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -149.8834 - val_loss: -152.0061\n",
      "\n",
      "Epoch 00649: loss improved from -149.83006 to -149.88335, saving model to gendance.h5\n",
      "Epoch 650/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -149.9024 - val_loss: -150.6478\n",
      "\n",
      "Epoch 00650: loss improved from -149.88335 to -149.90237, saving model to gendance.h5\n",
      "Epoch 651/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -150.1415 - val_loss: -151.6948\n",
      "\n",
      "Epoch 00651: loss improved from -149.90237 to -150.14147, saving model to gendance.h5\n",
      "Epoch 652/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -150.0592 - val_loss: -150.8546\n",
      "\n",
      "Epoch 00652: loss did not improve from -150.14147\n",
      "Epoch 653/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -149.9635 - val_loss: -151.5864\n",
      "\n",
      "Epoch 00653: loss did not improve from -150.14147\n",
      "Epoch 654/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -149.9879 - val_loss: -152.1452\n",
      "\n",
      "Epoch 00654: loss did not improve from -150.14147\n",
      "Epoch 655/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -149.6880 - val_loss: -150.2091\n",
      "\n",
      "Epoch 00655: loss did not improve from -150.14147\n",
      "Epoch 656/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -149.6033 - val_loss: -151.3708\n",
      "\n",
      "Epoch 00656: loss did not improve from -150.14147\n",
      "Epoch 657/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -149.6933 - val_loss: -150.5249\n",
      "\n",
      "Epoch 00657: loss did not improve from -150.14147\n",
      "Epoch 658/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -149.8408 - val_loss: -150.5989\n",
      "\n",
      "Epoch 00658: loss did not improve from -150.14147\n",
      "Epoch 659/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -149.6152 - val_loss: -151.8294\n",
      "\n",
      "Epoch 00659: loss did not improve from -150.14147\n",
      "Epoch 660/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -149.1793 - val_loss: -149.6651\n",
      "\n",
      "Epoch 00660: loss did not improve from -150.14147\n",
      "Epoch 661/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -149.1500 - val_loss: -149.7737\n",
      "\n",
      "Epoch 00661: loss did not improve from -150.14147\n",
      "Epoch 662/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -149.0236 - val_loss: -151.8154\n",
      "\n",
      "Epoch 00662: loss did not improve from -150.14147\n",
      "Epoch 663/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -148.7102 - val_loss: -148.2890\n",
      "\n",
      "Epoch 00663: loss did not improve from -150.14147\n",
      "Epoch 664/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -149.2048 - val_loss: -151.2237\n",
      "\n",
      "Epoch 00664: loss did not improve from -150.14147\n",
      "Epoch 665/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -150.1185 - val_loss: -152.0280\n",
      "\n",
      "Epoch 00665: loss did not improve from -150.14147\n",
      "Epoch 666/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -149.8898 - val_loss: -150.2029\n",
      "\n",
      "Epoch 00666: loss did not improve from -150.14147\n",
      "Epoch 667/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -150.0123 - val_loss: -151.9083\n",
      "\n",
      "Epoch 00667: loss did not improve from -150.14147\n",
      "Epoch 668/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -150.0066 - val_loss: -151.7305\n",
      "\n",
      "Epoch 00668: loss did not improve from -150.14147\n",
      "Epoch 669/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -149.9709 - val_loss: -150.6536\n",
      "\n",
      "Epoch 00669: loss did not improve from -150.14147\n",
      "Epoch 670/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -150.0917 - val_loss: -152.3436\n",
      "\n",
      "Epoch 00670: loss did not improve from -150.14147\n",
      "Epoch 671/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -150.1666 - val_loss: -151.1431\n",
      "\n",
      "Epoch 00671: loss improved from -150.14147 to -150.16658, saving model to gendance.h5\n",
      "Epoch 672/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -150.0388 - val_loss: -151.3352\n",
      "\n",
      "Epoch 00672: loss did not improve from -150.16658\n",
      "Epoch 673/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -150.0417 - val_loss: -152.3235\n",
      "\n",
      "Epoch 00673: loss did not improve from -150.16658\n",
      "Epoch 674/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -149.9718 - val_loss: -150.2709\n",
      "\n",
      "Epoch 00674: loss did not improve from -150.16658\n",
      "Epoch 675/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -150.2849 - val_loss: -151.7942\n",
      "\n",
      "Epoch 00675: loss improved from -150.16658 to -150.28486, saving model to gendance.h5\n",
      "Epoch 676/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -150.2970 - val_loss: -152.5912\n",
      "\n",
      "Epoch 00676: loss improved from -150.28486 to -150.29705, saving model to gendance.h5\n",
      "Epoch 677/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -149.8977 - val_loss: -150.3910\n",
      "\n",
      "Epoch 00677: loss did not improve from -150.29705\n",
      "Epoch 678/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -150.4673 - val_loss: -151.9401\n",
      "\n",
      "Epoch 00678: loss improved from -150.29705 to -150.46728, saving model to gendance.h5\n",
      "Epoch 679/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -150.6105 - val_loss: -152.5589\n",
      "\n",
      "Epoch 00679: loss improved from -150.46728 to -150.61054, saving model to gendance.h5\n",
      "Epoch 680/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -150.5203 - val_loss: -151.8196\n",
      "\n",
      "Epoch 00680: loss did not improve from -150.61054\n",
      "Epoch 681/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -150.6361 - val_loss: -152.4706\n",
      "\n",
      "Epoch 00681: loss improved from -150.61054 to -150.63607, saving model to gendance.h5\n",
      "Epoch 682/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -150.5127 - val_loss: -152.0781\n",
      "\n",
      "Epoch 00682: loss did not improve from -150.63607\n",
      "Epoch 683/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -150.3760 - val_loss: -151.0199\n",
      "\n",
      "Epoch 00683: loss did not improve from -150.63607\n",
      "Epoch 684/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -150.5468 - val_loss: -152.6593\n",
      "\n",
      "Epoch 00684: loss did not improve from -150.63607\n",
      "Epoch 685/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -150.5399 - val_loss: -151.8395\n",
      "\n",
      "Epoch 00685: loss did not improve from -150.63607\n",
      "Epoch 686/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -150.4983 - val_loss: -150.8655\n",
      "\n",
      "Epoch 00686: loss did not improve from -150.63607\n",
      "Epoch 687/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -150.3716 - val_loss: -152.6586\n",
      "\n",
      "Epoch 00687: loss did not improve from -150.63607\n",
      "Epoch 688/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -150.1186 - val_loss: -151.0886\n",
      "\n",
      "Epoch 00688: loss did not improve from -150.63607\n",
      "Epoch 689/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -149.8779 - val_loss: -151.1381\n",
      "\n",
      "Epoch 00689: loss did not improve from -150.63607\n",
      "Epoch 690/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -149.6819 - val_loss: -152.5082\n",
      "\n",
      "Epoch 00690: loss did not improve from -150.63607\n",
      "Epoch 691/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -150.0529 - val_loss: -150.6839\n",
      "\n",
      "Epoch 00691: loss did not improve from -150.63607\n",
      "Epoch 692/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -150.4995 - val_loss: -152.6737\n",
      "\n",
      "Epoch 00692: loss did not improve from -150.63607\n",
      "Epoch 693/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -151.1379 - val_loss: -152.7181\n",
      "\n",
      "Epoch 00693: loss improved from -150.63607 to -151.13792, saving model to gendance.h5\n",
      "Epoch 694/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -150.8867 - val_loss: -151.9500\n",
      "\n",
      "Epoch 00694: loss did not improve from -151.13792\n",
      "Epoch 695/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -150.8167 - val_loss: -153.1271\n",
      "\n",
      "Epoch 00695: loss did not improve from -151.13792\n",
      "Epoch 696/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -150.7796 - val_loss: -152.6139\n",
      "\n",
      "Epoch 00696: loss did not improve from -151.13792\n",
      "Epoch 697/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -150.7178 - val_loss: -150.9277\n",
      "\n",
      "Epoch 00697: loss did not improve from -151.13792\n",
      "Epoch 698/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -150.4554 - val_loss: -153.0728\n",
      "\n",
      "Epoch 00698: loss did not improve from -151.13792\n",
      "Epoch 699/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -150.5932 - val_loss: -151.6718\n",
      "\n",
      "Epoch 00699: loss did not improve from -151.13792\n",
      "Epoch 700/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -150.4127 - val_loss: -151.0426\n",
      "\n",
      "Epoch 00700: loss did not improve from -151.13792\n",
      "Epoch 701/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -150.4470 - val_loss: -152.9071\n",
      "\n",
      "Epoch 00701: loss did not improve from -151.13792\n",
      "Epoch 702/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -150.5653 - val_loss: -151.6894\n",
      "\n",
      "Epoch 00702: loss did not improve from -151.13792\n",
      "Epoch 703/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -150.6501 - val_loss: -151.9714\n",
      "\n",
      "Epoch 00703: loss did not improve from -151.13792\n",
      "Epoch 704/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -150.9425 - val_loss: -153.1821\n",
      "\n",
      "Epoch 00704: loss did not improve from -151.13792\n",
      "Epoch 705/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -150.7092 - val_loss: -150.8972\n",
      "\n",
      "Epoch 00705: loss did not improve from -151.13792\n",
      "Epoch 706/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -151.0271 - val_loss: -153.1850\n",
      "\n",
      "Epoch 00706: loss did not improve from -151.13792\n",
      "Epoch 707/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -151.3543 - val_loss: -152.8596\n",
      "\n",
      "Epoch 00707: loss improved from -151.13792 to -151.35429, saving model to gendance.h5\n",
      "Epoch 708/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -150.8723 - val_loss: -152.0390\n",
      "\n",
      "Epoch 00708: loss did not improve from -151.35429\n",
      "Epoch 709/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -150.8907 - val_loss: -153.4813\n",
      "\n",
      "Epoch 00709: loss did not improve from -151.35429\n",
      "Epoch 710/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -150.9210 - val_loss: -151.6669\n",
      "\n",
      "Epoch 00710: loss did not improve from -151.35429\n",
      "Epoch 711/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -150.7109 - val_loss: -152.2891\n",
      "\n",
      "Epoch 00711: loss did not improve from -151.35429\n",
      "Epoch 712/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -151.0773 - val_loss: -153.2690\n",
      "\n",
      "Epoch 00712: loss did not improve from -151.35429\n",
      "Epoch 713/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -150.9476 - val_loss: -152.3091\n",
      "\n",
      "Epoch 00713: loss did not improve from -151.35429\n",
      "Epoch 714/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -151.1314 - val_loss: -152.6216\n",
      "\n",
      "Epoch 00714: loss did not improve from -151.35429\n",
      "Epoch 715/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -150.9748 - val_loss: -153.0035\n",
      "\n",
      "Epoch 00715: loss did not improve from -151.35429\n",
      "Epoch 716/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -150.5566 - val_loss: -151.1722\n",
      "\n",
      "Epoch 00716: loss did not improve from -151.35429\n",
      "Epoch 717/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -150.9444 - val_loss: -153.6084\n",
      "\n",
      "Epoch 00717: loss did not improve from -151.35429\n",
      "Epoch 718/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -150.9959 - val_loss: -152.3486\n",
      "\n",
      "Epoch 00718: loss did not improve from -151.35429\n",
      "Epoch 719/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -150.9112 - val_loss: -151.3158\n",
      "\n",
      "Epoch 00719: loss did not improve from -151.35429\n",
      "Epoch 720/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -150.8812 - val_loss: -153.6224\n",
      "\n",
      "Epoch 00720: loss did not improve from -151.35429\n",
      "Epoch 721/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -150.5866 - val_loss: -151.8965\n",
      "\n",
      "Epoch 00721: loss did not improve from -151.35429\n",
      "Epoch 722/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -150.7880 - val_loss: -152.2324\n",
      "\n",
      "Epoch 00722: loss did not improve from -151.35429\n",
      "Epoch 723/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -150.5927 - val_loss: -152.7367\n",
      "\n",
      "Epoch 00723: loss did not improve from -151.35429\n",
      "Epoch 724/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -150.5358 - val_loss: -151.0324\n",
      "\n",
      "Epoch 00724: loss did not improve from -151.35429\n",
      "Epoch 725/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -150.5735 - val_loss: -152.3590\n",
      "\n",
      "Epoch 00725: loss did not improve from -151.35429\n",
      "Epoch 726/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -151.2269 - val_loss: -153.1454\n",
      "\n",
      "Epoch 00726: loss did not improve from -151.35429\n",
      "Epoch 727/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -151.2584 - val_loss: -152.6224\n",
      "\n",
      "Epoch 00727: loss did not improve from -151.35429\n",
      "Epoch 728/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -151.4651 - val_loss: -153.3384\n",
      "\n",
      "Epoch 00728: loss improved from -151.35429 to -151.46510, saving model to gendance.h5\n",
      "Epoch 729/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -151.5021 - val_loss: -152.8652\n",
      "\n",
      "Epoch 00729: loss improved from -151.46510 to -151.50211, saving model to gendance.h5\n",
      "Epoch 730/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -151.5994 - val_loss: -153.3066\n",
      "\n",
      "Epoch 00730: loss improved from -151.50211 to -151.59937, saving model to gendance.h5\n",
      "Epoch 731/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -151.8650 - val_loss: -153.4328\n",
      "\n",
      "Epoch 00731: loss improved from -151.59937 to -151.86498, saving model to gendance.h5\n",
      "Epoch 732/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -151.6906 - val_loss: -152.5509\n",
      "\n",
      "Epoch 00732: loss did not improve from -151.86498\n",
      "Epoch 733/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -151.6703 - val_loss: -153.6233\n",
      "\n",
      "Epoch 00733: loss did not improve from -151.86498\n",
      "Epoch 734/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -151.4916 - val_loss: -153.0978\n",
      "\n",
      "Epoch 00734: loss did not improve from -151.86498\n",
      "Epoch 735/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -151.0344 - val_loss: -152.0646\n",
      "\n",
      "Epoch 00735: loss did not improve from -151.86498\n",
      "Epoch 736/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -151.2184 - val_loss: -153.2331\n",
      "\n",
      "Epoch 00736: loss did not improve from -151.86498\n",
      "Epoch 737/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -151.4894 - val_loss: -152.7780\n",
      "\n",
      "Epoch 00737: loss did not improve from -151.86498\n",
      "Epoch 738/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -151.4291 - val_loss: -152.6702\n",
      "\n",
      "Epoch 00738: loss did not improve from -151.86498\n",
      "Epoch 739/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -151.7439 - val_loss: -153.9407\n",
      "\n",
      "Epoch 00739: loss did not improve from -151.86498\n",
      "Epoch 740/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -151.4803 - val_loss: -152.9299\n",
      "\n",
      "Epoch 00740: loss did not improve from -151.86498\n",
      "Epoch 741/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -151.6920 - val_loss: -153.4355\n",
      "\n",
      "Epoch 00741: loss did not improve from -151.86498\n",
      "Epoch 742/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -151.7123 - val_loss: -153.4797\n",
      "\n",
      "Epoch 00742: loss did not improve from -151.86498\n",
      "Epoch 743/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -151.6836 - val_loss: -152.5699\n",
      "\n",
      "Epoch 00743: loss did not improve from -151.86498\n",
      "Epoch 744/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -151.7491 - val_loss: -153.6808\n",
      "\n",
      "Epoch 00744: loss did not improve from -151.86498\n",
      "Epoch 745/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -151.4898 - val_loss: -153.4179\n",
      "\n",
      "Epoch 00745: loss did not improve from -151.86498\n",
      "Epoch 746/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -151.2389 - val_loss: -152.1394\n",
      "\n",
      "Epoch 00746: loss did not improve from -151.86498\n",
      "Epoch 747/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -151.4392 - val_loss: -154.0381\n",
      "\n",
      "Epoch 00747: loss did not improve from -151.86498\n",
      "Epoch 748/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -151.3204 - val_loss: -151.3259\n",
      "\n",
      "Epoch 00748: loss did not improve from -151.86498\n",
      "Epoch 749/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -151.3659 - val_loss: -153.2506\n",
      "\n",
      "Epoch 00749: loss did not improve from -151.86498\n",
      "Epoch 750/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -151.5983 - val_loss: -154.0350\n",
      "\n",
      "Epoch 00750: loss did not improve from -151.86498\n",
      "Epoch 751/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -151.5262 - val_loss: -151.7040\n",
      "\n",
      "Epoch 00751: loss did not improve from -151.86498\n",
      "Epoch 752/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -151.6390 - val_loss: -153.9732\n",
      "\n",
      "Epoch 00752: loss did not improve from -151.86498\n",
      "Epoch 753/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -151.7503 - val_loss: -153.5463\n",
      "\n",
      "Epoch 00753: loss did not improve from -151.86498\n",
      "Epoch 754/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -151.7466 - val_loss: -152.5638\n",
      "\n",
      "Epoch 00754: loss did not improve from -151.86498\n",
      "Epoch 755/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -151.5991 - val_loss: -154.2279\n",
      "\n",
      "Epoch 00755: loss did not improve from -151.86498\n",
      "Epoch 756/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -151.5521 - val_loss: -152.6592\n",
      "\n",
      "Epoch 00756: loss did not improve from -151.86498\n",
      "Epoch 757/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -151.6735 - val_loss: -152.9442\n",
      "\n",
      "Epoch 00757: loss did not improve from -151.86498\n",
      "Epoch 758/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -151.2908 - val_loss: -153.0357\n",
      "\n",
      "Epoch 00758: loss did not improve from -151.86498\n",
      "Epoch 759/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -150.8174 - val_loss: -151.3506\n",
      "\n",
      "Epoch 00759: loss did not improve from -151.86498\n",
      "Epoch 760/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -151.5896 - val_loss: -153.9502\n",
      "\n",
      "Epoch 00760: loss did not improve from -151.86498\n",
      "Epoch 761/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -151.9150 - val_loss: -152.7389\n",
      "\n",
      "Epoch 00761: loss improved from -151.86498 to -151.91496, saving model to gendance.h5\n",
      "Epoch 762/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -151.7301 - val_loss: -152.8942\n",
      "\n",
      "Epoch 00762: loss did not improve from -151.91496\n",
      "Epoch 763/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -151.8461 - val_loss: -154.2216\n",
      "\n",
      "Epoch 00763: loss did not improve from -151.91496\n",
      "Epoch 764/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -151.7122 - val_loss: -152.3676\n",
      "\n",
      "Epoch 00764: loss did not improve from -151.91496\n",
      "Epoch 765/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -151.9595 - val_loss: -153.1814\n",
      "\n",
      "Epoch 00765: loss improved from -151.91496 to -151.95947, saving model to gendance.h5\n",
      "Epoch 766/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -151.6517 - val_loss: -153.9199\n",
      "\n",
      "Epoch 00766: loss did not improve from -151.95947\n",
      "Epoch 767/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -151.6265 - val_loss: -152.0073\n",
      "\n",
      "Epoch 00767: loss did not improve from -151.95947\n",
      "Epoch 768/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -151.8942 - val_loss: -154.1534\n",
      "\n",
      "Epoch 00768: loss did not improve from -151.95947\n",
      "Epoch 769/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -152.0603 - val_loss: -153.8525\n",
      "\n",
      "Epoch 00769: loss improved from -151.95947 to -152.06028, saving model to gendance.h5\n",
      "Epoch 770/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -152.1945 - val_loss: -152.9481\n",
      "\n",
      "Epoch 00770: loss improved from -152.06028 to -152.19455, saving model to gendance.h5\n",
      "Epoch 771/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -152.1801 - val_loss: -154.2905\n",
      "\n",
      "Epoch 00771: loss did not improve from -152.19455\n",
      "Epoch 772/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -151.9245 - val_loss: -152.1518\n",
      "\n",
      "Epoch 00772: loss did not improve from -152.19455\n",
      "Epoch 773/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -152.0034 - val_loss: -153.9360\n",
      "\n",
      "Epoch 00773: loss did not improve from -152.19455\n",
      "Epoch 774/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -152.0746 - val_loss: -154.4064\n",
      "\n",
      "Epoch 00774: loss did not improve from -152.19455\n",
      "Epoch 775/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -151.8593 - val_loss: -152.4032\n",
      "\n",
      "Epoch 00775: loss did not improve from -152.19455\n",
      "Epoch 776/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -151.9307 - val_loss: -154.0042\n",
      "\n",
      "Epoch 00776: loss did not improve from -152.19455\n",
      "Epoch 777/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -152.2109 - val_loss: -153.8142\n",
      "\n",
      "Epoch 00777: loss improved from -152.19455 to -152.21087, saving model to gendance.h5\n",
      "Epoch 778/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -152.2901 - val_loss: -153.5996\n",
      "\n",
      "Epoch 00778: loss improved from -152.21087 to -152.29008, saving model to gendance.h5\n",
      "Epoch 779/10000\n",
      "16167/16167 [==============================] - 1s 33us/step - loss: -152.1159 - val_loss: -154.6597\n",
      "\n",
      "Epoch 00779: loss did not improve from -152.29008\n",
      "Epoch 780/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -152.0458 - val_loss: -152.7602\n",
      "\n",
      "Epoch 00780: loss did not improve from -152.29008\n",
      "Epoch 781/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -152.0112 - val_loss: -154.1444\n",
      "\n",
      "Epoch 00781: loss did not improve from -152.29008\n",
      "Epoch 782/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -152.3554 - val_loss: -154.7364\n",
      "\n",
      "Epoch 00782: loss improved from -152.29008 to -152.35541, saving model to gendance.h5\n",
      "Epoch 783/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -152.0329 - val_loss: -153.2147\n",
      "\n",
      "Epoch 00783: loss did not improve from -152.35541\n",
      "Epoch 784/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -152.4301 - val_loss: -154.5927\n",
      "\n",
      "Epoch 00784: loss improved from -152.35541 to -152.43005, saving model to gendance.h5\n",
      "Epoch 785/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -152.6340 - val_loss: -154.3984\n",
      "\n",
      "Epoch 00785: loss improved from -152.43005 to -152.63398, saving model to gendance.h5\n",
      "Epoch 786/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -152.5283 - val_loss: -153.7384\n",
      "\n",
      "Epoch 00786: loss did not improve from -152.63398\n",
      "Epoch 787/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -152.4892 - val_loss: -154.7664\n",
      "\n",
      "Epoch 00787: loss did not improve from -152.63398\n",
      "Epoch 788/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -152.3733 - val_loss: -153.8823\n",
      "\n",
      "Epoch 00788: loss did not improve from -152.63398\n",
      "Epoch 789/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -152.6331 - val_loss: -153.9693\n",
      "\n",
      "Epoch 00789: loss did not improve from -152.63398\n",
      "Epoch 790/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -152.0519 - val_loss: -154.2686\n",
      "\n",
      "Epoch 00790: loss did not improve from -152.63398\n",
      "Epoch 791/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -152.2627 - val_loss: -153.3951\n",
      "\n",
      "Epoch 00791: loss did not improve from -152.63398\n",
      "Epoch 792/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -152.3886 - val_loss: -154.7961\n",
      "\n",
      "Epoch 00792: loss did not improve from -152.63398\n",
      "Epoch 793/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -152.8971 - val_loss: -154.7013\n",
      "\n",
      "Epoch 00793: loss improved from -152.63398 to -152.89710, saving model to gendance.h5\n",
      "Epoch 794/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -152.7746 - val_loss: -154.1196\n",
      "\n",
      "Epoch 00794: loss did not improve from -152.89710\n",
      "Epoch 795/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -153.0225 - val_loss: -155.1825\n",
      "\n",
      "Epoch 00795: loss improved from -152.89710 to -153.02254, saving model to gendance.h5\n",
      "Epoch 796/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -152.8600 - val_loss: -154.5288\n",
      "\n",
      "Epoch 00796: loss did not improve from -153.02254\n",
      "Epoch 797/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -152.9673 - val_loss: -154.0246\n",
      "\n",
      "Epoch 00797: loss did not improve from -153.02254\n",
      "Epoch 798/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -152.6583 - val_loss: -155.2299\n",
      "\n",
      "Epoch 00798: loss did not improve from -153.02254\n",
      "Epoch 799/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -152.4648 - val_loss: -153.7500\n",
      "\n",
      "Epoch 00799: loss did not improve from -153.02254\n",
      "Epoch 800/10000\n",
      "16167/16167 [==============================] - 1s 31us/step - loss: -152.6469 - val_loss: -154.4120\n",
      "\n",
      "Epoch 00800: loss did not improve from -153.02254\n",
      "Epoch 801/10000\n",
      "16167/16167 [==============================] - 1s 32us/step - loss: -152.5583 - val_loss: -155.1693\n",
      "\n",
      "Epoch 00801: loss did not improve from -153.02254\n",
      "Epoch 802/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -152.5736 - val_loss: -153.0743\n",
      "\n",
      "Epoch 00802: loss did not improve from -153.02254\n",
      "Epoch 803/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -152.5227 - val_loss: -155.3297\n",
      "\n",
      "Epoch 00803: loss did not improve from -153.02254\n",
      "Epoch 804/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -152.8180 - val_loss: -154.5334\n",
      "\n",
      "Epoch 00804: loss did not improve from -153.02254\n",
      "Epoch 805/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -152.9718 - val_loss: -154.6147\n",
      "\n",
      "Epoch 00805: loss did not improve from -153.02254\n",
      "Epoch 806/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -152.3627 - val_loss: -155.0981\n",
      "\n",
      "Epoch 00806: loss did not improve from -153.02254\n",
      "Epoch 807/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -152.3268 - val_loss: -153.3838\n",
      "\n",
      "Epoch 00807: loss did not improve from -153.02254\n",
      "Epoch 808/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -152.6836 - val_loss: -154.6242\n",
      "\n",
      "Epoch 00808: loss did not improve from -153.02254\n",
      "Epoch 809/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -152.5537 - val_loss: -154.7711\n",
      "\n",
      "Epoch 00809: loss did not improve from -153.02254\n",
      "Epoch 810/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -152.6878 - val_loss: -153.5401\n",
      "\n",
      "Epoch 00810: loss did not improve from -153.02254\n",
      "Epoch 811/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -152.9956 - val_loss: -155.2297\n",
      "\n",
      "Epoch 00811: loss did not improve from -153.02254\n",
      "Epoch 812/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -152.9651 - val_loss: -154.6068\n",
      "\n",
      "Epoch 00812: loss did not improve from -153.02254\n",
      "Epoch 813/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -152.8435 - val_loss: -153.5795\n",
      "\n",
      "Epoch 00813: loss did not improve from -153.02254\n",
      "Epoch 814/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -152.7202 - val_loss: -155.3516\n",
      "\n",
      "Epoch 00814: loss did not improve from -153.02254\n",
      "Epoch 815/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -152.7245 - val_loss: -153.8777\n",
      "\n",
      "Epoch 00815: loss did not improve from -153.02254\n",
      "Epoch 816/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -152.7784 - val_loss: -154.1224\n",
      "\n",
      "Epoch 00816: loss did not improve from -153.02254\n",
      "Epoch 817/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -152.3320 - val_loss: -154.6148\n",
      "\n",
      "Epoch 00817: loss did not improve from -153.02254\n",
      "Epoch 818/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -152.2291 - val_loss: -153.3279\n",
      "\n",
      "Epoch 00818: loss did not improve from -153.02254\n",
      "Epoch 819/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -152.6852 - val_loss: -155.4045\n",
      "\n",
      "Epoch 00819: loss did not improve from -153.02254\n",
      "Epoch 820/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -153.1462 - val_loss: -154.8435\n",
      "\n",
      "Epoch 00820: loss improved from -153.02254 to -153.14620, saving model to gendance.h5\n",
      "Epoch 821/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -153.0262 - val_loss: -154.5861\n",
      "\n",
      "Epoch 00821: loss did not improve from -153.14620\n",
      "Epoch 822/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -153.1651 - val_loss: -155.8133\n",
      "\n",
      "Epoch 00822: loss improved from -153.14620 to -153.16515, saving model to gendance.h5\n",
      "Epoch 823/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -152.6812 - val_loss: -153.0345\n",
      "\n",
      "Epoch 00823: loss did not improve from -153.16515\n",
      "Epoch 824/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -153.0540 - val_loss: -154.9757\n",
      "\n",
      "Epoch 00824: loss did not improve from -153.16515\n",
      "Epoch 825/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -153.2096 - val_loss: -155.5797\n",
      "\n",
      "Epoch 00825: loss improved from -153.16515 to -153.20959, saving model to gendance.h5\n",
      "Epoch 826/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -152.8959 - val_loss: -153.8039\n",
      "\n",
      "Epoch 00826: loss did not improve from -153.20959\n",
      "Epoch 827/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -153.0837 - val_loss: -155.2204\n",
      "\n",
      "Epoch 00827: loss did not improve from -153.20959\n",
      "Epoch 828/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -153.2007 - val_loss: -155.2055\n",
      "\n",
      "Epoch 00828: loss did not improve from -153.20959\n",
      "Epoch 829/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -153.0365 - val_loss: -154.3420\n",
      "\n",
      "Epoch 00829: loss did not improve from -153.20959\n",
      "Epoch 830/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -152.9962 - val_loss: -155.5463\n",
      "\n",
      "Epoch 00830: loss did not improve from -153.20959\n",
      "Epoch 831/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -153.0171 - val_loss: -153.4413\n",
      "\n",
      "Epoch 00831: loss did not improve from -153.20959\n",
      "Epoch 832/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -153.0515 - val_loss: -154.9233\n",
      "\n",
      "Epoch 00832: loss did not improve from -153.20959\n",
      "Epoch 833/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -153.2062 - val_loss: -155.9421\n",
      "\n",
      "Epoch 00833: loss did not improve from -153.20959\n",
      "Epoch 834/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -152.9281 - val_loss: -153.5671\n",
      "\n",
      "Epoch 00834: loss did not improve from -153.20959\n",
      "Epoch 835/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -153.1539 - val_loss: -155.3729\n",
      "\n",
      "Epoch 00835: loss did not improve from -153.20959\n",
      "Epoch 836/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -152.9187 - val_loss: -154.8274\n",
      "\n",
      "Epoch 00836: loss did not improve from -153.20959\n",
      "Epoch 837/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -152.8664 - val_loss: -153.5533\n",
      "\n",
      "Epoch 00837: loss did not improve from -153.20959\n",
      "Epoch 838/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -152.9205 - val_loss: -155.4758\n",
      "\n",
      "Epoch 00838: loss did not improve from -153.20959\n",
      "Epoch 839/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -153.3383 - val_loss: -153.7490\n",
      "\n",
      "Epoch 00839: loss improved from -153.20959 to -153.33829, saving model to gendance.h5\n",
      "Epoch 840/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -153.4795 - val_loss: -155.1351\n",
      "\n",
      "Epoch 00840: loss improved from -153.33829 to -153.47953, saving model to gendance.h5\n",
      "Epoch 841/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -153.5244 - val_loss: -155.7452\n",
      "\n",
      "Epoch 00841: loss improved from -153.47953 to -153.52437, saving model to gendance.h5\n",
      "Epoch 842/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -153.6477 - val_loss: -154.2144\n",
      "\n",
      "Epoch 00842: loss improved from -153.52437 to -153.64771, saving model to gendance.h5\n",
      "Epoch 843/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -153.6053 - val_loss: -155.5507\n",
      "\n",
      "Epoch 00843: loss did not improve from -153.64771\n",
      "Epoch 844/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -153.6500 - val_loss: -155.3469\n",
      "\n",
      "Epoch 00844: loss improved from -153.64771 to -153.65002, saving model to gendance.h5\n",
      "Epoch 845/10000\n",
      "16167/16167 [==============================] - 1s 32us/step - loss: -153.4560 - val_loss: -154.6844\n",
      "\n",
      "Epoch 00845: loss did not improve from -153.65002\n",
      "Epoch 846/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -153.3243 - val_loss: -155.8191\n",
      "\n",
      "Epoch 00846: loss did not improve from -153.65002\n",
      "Epoch 847/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -153.1989 - val_loss: -154.3985\n",
      "\n",
      "Epoch 00847: loss did not improve from -153.65002\n",
      "Epoch 848/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -152.9060 - val_loss: -154.1657\n",
      "\n",
      "Epoch 00848: loss did not improve from -153.65002\n",
      "Epoch 849/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -152.9198 - val_loss: -155.7915\n",
      "\n",
      "Epoch 00849: loss did not improve from -153.65002\n",
      "Epoch 850/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -152.8485 - val_loss: -153.7547\n",
      "\n",
      "Epoch 00850: loss did not improve from -153.65002\n",
      "Epoch 851/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -153.4294 - val_loss: -155.7626\n",
      "\n",
      "Epoch 00851: loss did not improve from -153.65002\n",
      "Epoch 852/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -153.7596 - val_loss: -155.9068\n",
      "\n",
      "Epoch 00852: loss improved from -153.65002 to -153.75957, saving model to gendance.h5\n",
      "Epoch 853/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -153.5963 - val_loss: -154.9105\n",
      "\n",
      "Epoch 00853: loss did not improve from -153.75957\n",
      "Epoch 854/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -153.6877 - val_loss: -156.1811\n",
      "\n",
      "Epoch 00854: loss did not improve from -153.75957\n",
      "Epoch 855/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -153.7937 - val_loss: -155.2410\n",
      "\n",
      "Epoch 00855: loss improved from -153.75957 to -153.79367, saving model to gendance.h5\n",
      "Epoch 856/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -153.6122 - val_loss: -155.0493\n",
      "\n",
      "Epoch 00856: loss did not improve from -153.79367\n",
      "Epoch 857/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -153.5868 - val_loss: -156.2264\n",
      "\n",
      "Epoch 00857: loss did not improve from -153.79367\n",
      "Epoch 858/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -153.5282 - val_loss: -155.3095\n",
      "\n",
      "Epoch 00858: loss did not improve from -153.79367\n",
      "Epoch 859/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -153.4449 - val_loss: -155.5116\n",
      "\n",
      "Epoch 00859: loss did not improve from -153.79367\n",
      "Epoch 860/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -153.6554 - val_loss: -155.5659\n",
      "\n",
      "Epoch 00860: loss did not improve from -153.79367\n",
      "Epoch 861/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -153.7186 - val_loss: -155.3914\n",
      "\n",
      "Epoch 00861: loss did not improve from -153.79367\n",
      "Epoch 862/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -153.5157 - val_loss: -156.0315\n",
      "\n",
      "Epoch 00862: loss did not improve from -153.79367\n",
      "Epoch 863/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -153.3373 - val_loss: -154.7225\n",
      "\n",
      "Epoch 00863: loss did not improve from -153.79367\n",
      "Epoch 864/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -153.1944 - val_loss: -154.4150\n",
      "\n",
      "Epoch 00864: loss did not improve from -153.79367\n",
      "Epoch 865/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -153.3517 - val_loss: -156.1386\n",
      "\n",
      "Epoch 00865: loss did not improve from -153.79367\n",
      "Epoch 866/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -153.3317 - val_loss: -154.4102\n",
      "\n",
      "Epoch 00866: loss did not improve from -153.79367\n",
      "Epoch 867/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -153.9246 - val_loss: -155.7715\n",
      "\n",
      "Epoch 00867: loss improved from -153.79367 to -153.92458, saving model to gendance.h5\n",
      "Epoch 868/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -153.9215 - val_loss: -156.4984\n",
      "\n",
      "Epoch 00868: loss did not improve from -153.92458\n",
      "Epoch 869/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -153.9637 - val_loss: -155.0083\n",
      "\n",
      "Epoch 00869: loss improved from -153.92458 to -153.96374, saving model to gendance.h5\n",
      "Epoch 870/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -154.0763 - val_loss: -156.4737\n",
      "\n",
      "Epoch 00870: loss improved from -153.96374 to -154.07635, saving model to gendance.h5\n",
      "Epoch 871/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -153.9966 - val_loss: -155.5730\n",
      "\n",
      "Epoch 00871: loss did not improve from -154.07635\n",
      "Epoch 872/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -153.7400 - val_loss: -154.9451\n",
      "\n",
      "Epoch 00872: loss did not improve from -154.07635\n",
      "Epoch 873/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -153.5971 - val_loss: -156.2195\n",
      "\n",
      "Epoch 00873: loss did not improve from -154.07635\n",
      "Epoch 874/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -153.5706 - val_loss: -154.1673\n",
      "\n",
      "Epoch 00874: loss did not improve from -154.07635\n",
      "Epoch 875/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -153.4292 - val_loss: -155.1512\n",
      "\n",
      "Epoch 00875: loss did not improve from -154.07635\n",
      "Epoch 876/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -153.5707 - val_loss: -156.0071\n",
      "\n",
      "Epoch 00876: loss did not improve from -154.07635\n",
      "Epoch 877/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -153.4481 - val_loss: -154.5368\n",
      "\n",
      "Epoch 00877: loss did not improve from -154.07635\n",
      "Epoch 878/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -153.7428 - val_loss: -156.0774\n",
      "\n",
      "Epoch 00878: loss did not improve from -154.07635\n",
      "Epoch 879/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.0813 - val_loss: -155.8589\n",
      "\n",
      "Epoch 00879: loss improved from -154.07635 to -154.08131, saving model to gendance.h5\n",
      "Epoch 880/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.2461 - val_loss: -155.6125\n",
      "\n",
      "Epoch 00880: loss improved from -154.08131 to -154.24613, saving model to gendance.h5\n",
      "Epoch 881/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.3109 - val_loss: -156.4620\n",
      "\n",
      "Epoch 00881: loss improved from -154.24613 to -154.31094, saving model to gendance.h5\n",
      "Epoch 882/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.3131 - val_loss: -155.8496\n",
      "\n",
      "Epoch 00882: loss improved from -154.31094 to -154.31311, saving model to gendance.h5\n",
      "Epoch 883/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.1036 - val_loss: -155.9901\n",
      "\n",
      "Epoch 00883: loss did not improve from -154.31311\n",
      "Epoch 884/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.0468 - val_loss: -155.9301\n",
      "\n",
      "Epoch 00884: loss did not improve from -154.31311\n",
      "Epoch 885/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.0706 - val_loss: -155.5621\n",
      "\n",
      "Epoch 00885: loss did not improve from -154.31311\n",
      "Epoch 886/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.0875 - val_loss: -156.2855\n",
      "\n",
      "Epoch 00886: loss did not improve from -154.31311\n",
      "Epoch 887/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.0098 - val_loss: -155.2227\n",
      "\n",
      "Epoch 00887: loss did not improve from -154.31311\n",
      "Epoch 888/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.1071 - val_loss: -155.6129\n",
      "\n",
      "Epoch 00888: loss did not improve from -154.31311\n",
      "Epoch 889/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.2002 - val_loss: -156.5932\n",
      "\n",
      "Epoch 00889: loss did not improve from -154.31311\n",
      "Epoch 890/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.2011 - val_loss: -155.5439\n",
      "\n",
      "Epoch 00890: loss did not improve from -154.31311\n",
      "Epoch 891/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.1160 - val_loss: -155.5900\n",
      "\n",
      "Epoch 00891: loss did not improve from -154.31311\n",
      "Epoch 892/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -153.9864 - val_loss: -156.3613\n",
      "\n",
      "Epoch 00892: loss did not improve from -154.31311\n",
      "Epoch 893/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -153.7766 - val_loss: -154.1084\n",
      "\n",
      "Epoch 00893: loss did not improve from -154.31311\n",
      "Epoch 894/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.0194 - val_loss: -156.4568\n",
      "\n",
      "Epoch 00894: loss did not improve from -154.31311\n",
      "Epoch 895/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.1945 - val_loss: -155.9496\n",
      "\n",
      "Epoch 00895: loss did not improve from -154.31311\n",
      "Epoch 896/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.0106 - val_loss: -154.4146\n",
      "\n",
      "Epoch 00896: loss did not improve from -154.31311\n",
      "Epoch 897/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -153.9229 - val_loss: -156.2046\n",
      "\n",
      "Epoch 00897: loss did not improve from -154.31311\n",
      "Epoch 898/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -153.9093 - val_loss: -155.0710\n",
      "\n",
      "Epoch 00898: loss did not improve from -154.31311\n",
      "Epoch 899/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -153.9117 - val_loss: -156.1415\n",
      "\n",
      "Epoch 00899: loss did not improve from -154.31311\n",
      "Epoch 900/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.1890 - val_loss: -155.5188\n",
      "\n",
      "Epoch 00900: loss did not improve from -154.31311\n",
      "Epoch 901/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.1756 - val_loss: -155.2993\n",
      "\n",
      "Epoch 00901: loss did not improve from -154.31311\n",
      "Epoch 902/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.2154 - val_loss: -156.9061\n",
      "\n",
      "Epoch 00902: loss did not improve from -154.31311\n",
      "Epoch 903/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.0780 - val_loss: -154.7495\n",
      "\n",
      "Epoch 00903: loss did not improve from -154.31311\n",
      "Epoch 904/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.2541 - val_loss: -156.1266\n",
      "\n",
      "Epoch 00904: loss did not improve from -154.31311\n",
      "Epoch 905/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.3020 - val_loss: -156.7017\n",
      "\n",
      "Epoch 00905: loss did not improve from -154.31311\n",
      "Epoch 906/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.2967 - val_loss: -153.7865\n",
      "\n",
      "Epoch 00906: loss did not improve from -154.31311\n",
      "Epoch 907/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -153.9035 - val_loss: -156.2150\n",
      "\n",
      "Epoch 00907: loss did not improve from -154.31311\n",
      "Epoch 908/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.2220 - val_loss: -156.5848\n",
      "\n",
      "Epoch 00908: loss did not improve from -154.31311\n",
      "Epoch 909/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -153.9241 - val_loss: -154.7910\n",
      "\n",
      "Epoch 00909: loss did not improve from -154.31311\n",
      "Epoch 910/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -153.9711 - val_loss: -156.4165\n",
      "\n",
      "Epoch 00910: loss did not improve from -154.31311\n",
      "Epoch 911/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.5024 - val_loss: -155.8107\n",
      "\n",
      "Epoch 00911: loss improved from -154.31311 to -154.50241, saving model to gendance.h5\n",
      "Epoch 912/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.5816 - val_loss: -155.9768\n",
      "\n",
      "Epoch 00912: loss improved from -154.50241 to -154.58158, saving model to gendance.h5\n",
      "Epoch 913/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.5080 - val_loss: -157.0951\n",
      "\n",
      "Epoch 00913: loss did not improve from -154.58158\n",
      "Epoch 914/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.1971 - val_loss: -155.0773\n",
      "\n",
      "Epoch 00914: loss did not improve from -154.58158\n",
      "Epoch 915/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.3097 - val_loss: -156.3043\n",
      "\n",
      "Epoch 00915: loss did not improve from -154.58158\n",
      "Epoch 916/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.2560 - val_loss: -156.2764\n",
      "\n",
      "Epoch 00916: loss did not improve from -154.58158\n",
      "Epoch 917/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.2246 - val_loss: -155.3114\n",
      "\n",
      "Epoch 00917: loss did not improve from -154.58158\n",
      "Epoch 918/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.3933 - val_loss: -156.9944\n",
      "\n",
      "Epoch 00918: loss did not improve from -154.58158\n",
      "Epoch 919/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.5319 - val_loss: -155.5713\n",
      "\n",
      "Epoch 00919: loss did not improve from -154.58158\n",
      "Epoch 920/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.3290 - val_loss: -156.1336\n",
      "\n",
      "Epoch 00920: loss did not improve from -154.58158\n",
      "Epoch 921/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.2830 - val_loss: -156.8892\n",
      "\n",
      "Epoch 00921: loss did not improve from -154.58158\n",
      "Epoch 922/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.3464 - val_loss: -154.8210\n",
      "\n",
      "Epoch 00922: loss did not improve from -154.58158\n",
      "Epoch 923/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.4822 - val_loss: -156.8385\n",
      "\n",
      "Epoch 00923: loss did not improve from -154.58158\n",
      "Epoch 924/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.4758 - val_loss: -156.2995\n",
      "\n",
      "Epoch 00924: loss did not improve from -154.58158\n",
      "Epoch 925/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.5326 - val_loss: -155.8060\n",
      "\n",
      "Epoch 00925: loss did not improve from -154.58158\n",
      "Epoch 926/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.1807 - val_loss: -156.4173\n",
      "\n",
      "Epoch 00926: loss did not improve from -154.58158\n",
      "Epoch 927/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -153.9581 - val_loss: -155.2471\n",
      "\n",
      "Epoch 00927: loss did not improve from -154.58158\n",
      "Epoch 928/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.3412 - val_loss: -155.8814\n",
      "\n",
      "Epoch 00928: loss did not improve from -154.58158\n",
      "Epoch 929/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.4478 - val_loss: -156.9656\n",
      "\n",
      "Epoch 00929: loss did not improve from -154.58158\n",
      "Epoch 930/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.6568 - val_loss: -155.6007\n",
      "\n",
      "Epoch 00930: loss improved from -154.58158 to -154.65679, saving model to gendance.h5\n",
      "Epoch 931/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -154.7168 - val_loss: -156.6573\n",
      "\n",
      "Epoch 00931: loss improved from -154.65679 to -154.71680, saving model to gendance.h5\n",
      "Epoch 932/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.8321 - val_loss: -156.4926\n",
      "\n",
      "Epoch 00932: loss improved from -154.71680 to -154.83211, saving model to gendance.h5\n",
      "Epoch 933/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.6497 - val_loss: -156.2375\n",
      "\n",
      "Epoch 00933: loss did not improve from -154.83211\n",
      "Epoch 934/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.6828 - val_loss: -156.5536\n",
      "\n",
      "Epoch 00934: loss did not improve from -154.83211\n",
      "Epoch 935/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.7545 - val_loss: -156.2319\n",
      "\n",
      "Epoch 00935: loss did not improve from -154.83211\n",
      "Epoch 936/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.9608 - val_loss: -157.0516\n",
      "\n",
      "Epoch 00936: loss improved from -154.83211 to -154.96083, saving model to gendance.h5\n",
      "Epoch 937/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.9805 - val_loss: -156.5230\n",
      "\n",
      "Epoch 00937: loss improved from -154.96083 to -154.98054, saving model to gendance.h5\n",
      "Epoch 938/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.9915 - val_loss: -156.6875\n",
      "\n",
      "Epoch 00938: loss improved from -154.98054 to -154.99147, saving model to gendance.h5\n",
      "Epoch 939/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.1735 - val_loss: -157.3640\n",
      "\n",
      "Epoch 00939: loss improved from -154.99147 to -155.17349, saving model to gendance.h5\n",
      "Epoch 940/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.0918 - val_loss: -155.9327\n",
      "\n",
      "Epoch 00940: loss did not improve from -155.17349\n",
      "Epoch 941/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.8369 - val_loss: -157.2927\n",
      "\n",
      "Epoch 00941: loss did not improve from -155.17349\n",
      "Epoch 942/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.0507 - val_loss: -156.8295\n",
      "\n",
      "Epoch 00942: loss did not improve from -155.17349\n",
      "Epoch 943/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.6728 - val_loss: -156.3236\n",
      "\n",
      "Epoch 00943: loss did not improve from -155.17349\n",
      "Epoch 944/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.6946 - val_loss: -157.3051\n",
      "\n",
      "Epoch 00944: loss did not improve from -155.17349\n",
      "Epoch 945/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.8179 - val_loss: -155.8893\n",
      "\n",
      "Epoch 00945: loss did not improve from -155.17349\n",
      "Epoch 946/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.9659 - val_loss: -157.3606\n",
      "\n",
      "Epoch 00946: loss did not improve from -155.17349\n",
      "Epoch 947/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.8509 - val_loss: -156.3392\n",
      "\n",
      "Epoch 00947: loss did not improve from -155.17349\n",
      "Epoch 948/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.5697 - val_loss: -155.3594\n",
      "\n",
      "Epoch 00948: loss did not improve from -155.17349\n",
      "Epoch 949/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.2503 - val_loss: -156.7830\n",
      "\n",
      "Epoch 00949: loss did not improve from -155.17349\n",
      "Epoch 950/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -153.9831 - val_loss: -154.6723\n",
      "\n",
      "Epoch 00950: loss did not improve from -155.17349\n",
      "Epoch 951/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.6054 - val_loss: -156.2904\n",
      "\n",
      "Epoch 00951: loss did not improve from -155.17349\n",
      "Epoch 952/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.9475 - val_loss: -157.1865\n",
      "\n",
      "Epoch 00952: loss did not improve from -155.17349\n",
      "Epoch 953/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.8418 - val_loss: -155.6575\n",
      "\n",
      "Epoch 00953: loss did not improve from -155.17349\n",
      "Epoch 954/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.9530 - val_loss: -157.0302\n",
      "\n",
      "Epoch 00954: loss did not improve from -155.17349\n",
      "Epoch 955/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -155.0907 - val_loss: -156.9327\n",
      "\n",
      "Epoch 00955: loss did not improve from -155.17349\n",
      "Epoch 956/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.9768 - val_loss: -156.3086\n",
      "\n",
      "Epoch 00956: loss did not improve from -155.17349\n",
      "Epoch 957/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.0933 - val_loss: -157.4804\n",
      "\n",
      "Epoch 00957: loss did not improve from -155.17349\n",
      "Epoch 958/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.3091 - val_loss: -156.5713\n",
      "\n",
      "Epoch 00958: loss improved from -155.17349 to -155.30908, saving model to gendance.h5\n",
      "Epoch 959/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.3716 - val_loss: -157.0557\n",
      "\n",
      "Epoch 00959: loss improved from -155.30908 to -155.37156, saving model to gendance.h5\n",
      "Epoch 960/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.2997 - val_loss: -157.5174\n",
      "\n",
      "Epoch 00960: loss did not improve from -155.37156\n",
      "Epoch 961/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.1900 - val_loss: -156.1648\n",
      "\n",
      "Epoch 00961: loss did not improve from -155.37156\n",
      "Epoch 962/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.2157 - val_loss: -157.5060\n",
      "\n",
      "Epoch 00962: loss did not improve from -155.37156\n",
      "Epoch 963/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.3823 - val_loss: -157.1036\n",
      "\n",
      "Epoch 00963: loss improved from -155.37156 to -155.38231, saving model to gendance.h5\n",
      "Epoch 964/10000\n",
      "16167/16167 [==============================] - 1s 32us/step - loss: -155.3716 - val_loss: -156.6108\n",
      "\n",
      "Epoch 00964: loss did not improve from -155.38231\n",
      "Epoch 965/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.2831 - val_loss: -157.6950\n",
      "\n",
      "Epoch 00965: loss did not improve from -155.38231\n",
      "Epoch 966/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.8837 - val_loss: -155.9693\n",
      "\n",
      "Epoch 00966: loss did not improve from -155.38231\n",
      "Epoch 967/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.8985 - val_loss: -156.4105\n",
      "\n",
      "Epoch 00967: loss did not improve from -155.38231\n",
      "Epoch 968/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.5106 - val_loss: -157.5105\n",
      "\n",
      "Epoch 00968: loss did not improve from -155.38231\n",
      "Epoch 969/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.6677 - val_loss: -155.5306\n",
      "\n",
      "Epoch 00969: loss did not improve from -155.38231\n",
      "Epoch 970/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.1652 - val_loss: -157.4256\n",
      "\n",
      "Epoch 00970: loss did not improve from -155.38231\n",
      "Epoch 971/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.1813 - val_loss: -157.1542\n",
      "\n",
      "Epoch 00971: loss did not improve from -155.38231\n",
      "Epoch 972/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.1816 - val_loss: -156.2326\n",
      "\n",
      "Epoch 00972: loss did not improve from -155.38231\n",
      "Epoch 973/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -155.1054 - val_loss: -157.6196\n",
      "\n",
      "Epoch 00973: loss did not improve from -155.38231\n",
      "Epoch 974/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.8495 - val_loss: -155.8601\n",
      "\n",
      "Epoch 00974: loss did not improve from -155.38231\n",
      "Epoch 975/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.7043 - val_loss: -156.3609\n",
      "\n",
      "Epoch 00975: loss did not improve from -155.38231\n",
      "Epoch 976/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.9665 - val_loss: -157.5135\n",
      "\n",
      "Epoch 00976: loss did not improve from -155.38231\n",
      "Epoch 977/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.8593 - val_loss: -155.2282\n",
      "\n",
      "Epoch 00977: loss did not improve from -155.38231\n",
      "Epoch 978/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.8595 - val_loss: -157.1581\n",
      "\n",
      "Epoch 00978: loss did not improve from -155.38231\n",
      "Epoch 979/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.2970 - val_loss: -157.4161\n",
      "\n",
      "Epoch 00979: loss did not improve from -155.38231\n",
      "Epoch 980/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.4734 - val_loss: -156.7513\n",
      "\n",
      "Epoch 00980: loss improved from -155.38231 to -155.47338, saving model to gendance.h5\n",
      "Epoch 981/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.4229 - val_loss: -157.6659\n",
      "\n",
      "Epoch 00981: loss did not improve from -155.47338\n",
      "Epoch 982/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.6568 - val_loss: -157.3288\n",
      "\n",
      "Epoch 00982: loss improved from -155.47338 to -155.65680, saving model to gendance.h5\n",
      "Epoch 983/10000\n",
      "16167/16167 [==============================] - 1s 36us/step - loss: -155.5299 - val_loss: -157.2485\n",
      "\n",
      "Epoch 00983: loss did not improve from -155.65680\n",
      "Epoch 984/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.2556 - val_loss: -157.1482\n",
      "\n",
      "Epoch 00984: loss did not improve from -155.65680\n",
      "Epoch 985/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.2140 - val_loss: -156.6070\n",
      "\n",
      "Epoch 00985: loss did not improve from -155.65680\n",
      "Epoch 986/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.3085 - val_loss: -157.3948\n",
      "\n",
      "Epoch 00986: loss did not improve from -155.65680\n",
      "Epoch 987/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.3573 - val_loss: -157.1170\n",
      "\n",
      "Epoch 00987: loss did not improve from -155.65680\n",
      "Epoch 988/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.4150 - val_loss: -156.8328\n",
      "\n",
      "Epoch 00988: loss did not improve from -155.65680\n",
      "Epoch 989/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.6488 - val_loss: -158.0903\n",
      "\n",
      "Epoch 00989: loss did not improve from -155.65680\n",
      "Epoch 990/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.3679 - val_loss: -156.3985\n",
      "\n",
      "Epoch 00990: loss did not improve from -155.65680\n",
      "Epoch 991/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.6793 - val_loss: -157.5187\n",
      "\n",
      "Epoch 00991: loss improved from -155.65680 to -155.67927, saving model to gendance.h5\n",
      "Epoch 992/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.3729 - val_loss: -158.1831\n",
      "\n",
      "Epoch 00992: loss did not improve from -155.67927\n",
      "Epoch 993/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.1994 - val_loss: -156.2572\n",
      "\n",
      "Epoch 00993: loss did not improve from -155.67927\n",
      "Epoch 994/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.4996 - val_loss: -157.6259\n",
      "\n",
      "Epoch 00994: loss did not improve from -155.67927\n",
      "Epoch 995/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.6677 - val_loss: -157.0244\n",
      "\n",
      "Epoch 00995: loss did not improve from -155.67927\n",
      "Epoch 996/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.7002 - val_loss: -157.5189\n",
      "\n",
      "Epoch 00996: loss improved from -155.67927 to -155.70015, saving model to gendance.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 997/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.7502 - val_loss: -158.1035\n",
      "\n",
      "Epoch 00997: loss improved from -155.70015 to -155.75016, saving model to gendance.h5\n",
      "Epoch 998/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.5946 - val_loss: -156.3859\n",
      "\n",
      "Epoch 00998: loss did not improve from -155.75016\n",
      "Epoch 999/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.5914 - val_loss: -157.5955\n",
      "\n",
      "Epoch 00999: loss did not improve from -155.75016\n",
      "Epoch 1000/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.6596 - val_loss: -157.4589\n",
      "\n",
      "Epoch 01000: loss did not improve from -155.75016\n",
      "Epoch 1001/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.1975 - val_loss: -156.2287\n",
      "\n",
      "Epoch 01001: loss did not improve from -155.75016\n",
      "Epoch 1002/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.9987 - val_loss: -157.7289\n",
      "\n",
      "Epoch 01002: loss did not improve from -155.75016\n",
      "Epoch 1003/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.0175 - val_loss: -155.5905\n",
      "\n",
      "Epoch 01003: loss did not improve from -155.75016\n",
      "Epoch 1004/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -154.8096 - val_loss: -156.8856\n",
      "\n",
      "Epoch 01004: loss did not improve from -155.75016\n",
      "Epoch 1005/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.0987 - val_loss: -157.6768\n",
      "\n",
      "Epoch 01005: loss did not improve from -155.75016\n",
      "Epoch 1006/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.1702 - val_loss: -155.6253\n",
      "\n",
      "Epoch 01006: loss did not improve from -155.75016\n",
      "Epoch 1007/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.4489 - val_loss: -157.8306\n",
      "\n",
      "Epoch 01007: loss did not improve from -155.75016\n",
      "Epoch 1008/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.6300 - val_loss: -157.3941\n",
      "\n",
      "Epoch 01008: loss did not improve from -155.75016\n",
      "Epoch 1009/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.5616 - val_loss: -157.1268\n",
      "\n",
      "Epoch 01009: loss did not improve from -155.75016\n",
      "Epoch 1010/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.5149 - val_loss: -157.5534\n",
      "\n",
      "Epoch 01010: loss did not improve from -155.75016\n",
      "Epoch 1011/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.4185 - val_loss: -156.7723\n",
      "\n",
      "Epoch 01011: loss did not improve from -155.75016\n",
      "Epoch 1012/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.6302 - val_loss: -157.6573\n",
      "\n",
      "Epoch 01012: loss did not improve from -155.75016\n",
      "Epoch 1013/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.8294 - val_loss: -157.6837\n",
      "\n",
      "Epoch 01013: loss improved from -155.75016 to -155.82939, saving model to gendance.h5\n",
      "Epoch 1014/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -156.0198 - val_loss: -156.7612\n",
      "\n",
      "Epoch 01014: loss improved from -155.82939 to -156.01979, saving model to gendance.h5\n",
      "Epoch 1015/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.9022 - val_loss: -158.1612\n",
      "\n",
      "Epoch 01015: loss did not improve from -156.01979\n",
      "Epoch 1016/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.8076 - val_loss: -157.2503\n",
      "\n",
      "Epoch 01016: loss did not improve from -156.01979\n",
      "Epoch 1017/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.8324 - val_loss: -157.6439\n",
      "\n",
      "Epoch 01017: loss did not improve from -156.01979\n",
      "Epoch 1018/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.1470 - val_loss: -158.0729\n",
      "\n",
      "Epoch 01018: loss improved from -156.01979 to -156.14695, saving model to gendance.h5\n",
      "Epoch 1019/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.5312 - val_loss: -157.1956\n",
      "\n",
      "Epoch 01019: loss did not improve from -156.14695\n",
      "Epoch 1020/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.0955 - val_loss: -158.0767\n",
      "\n",
      "Epoch 01020: loss did not improve from -156.14695\n",
      "Epoch 1021/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.0032 - val_loss: -157.5157\n",
      "\n",
      "Epoch 01021: loss did not improve from -156.14695\n",
      "Epoch 1022/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.8572 - val_loss: -157.4829\n",
      "\n",
      "Epoch 01022: loss did not improve from -156.14695\n",
      "Epoch 1023/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.9320 - val_loss: -158.5356\n",
      "\n",
      "Epoch 01023: loss did not improve from -156.14695\n",
      "Epoch 1024/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.7712 - val_loss: -156.2299\n",
      "\n",
      "Epoch 01024: loss did not improve from -156.14695\n",
      "Epoch 1025/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.6973 - val_loss: -157.8118\n",
      "\n",
      "Epoch 01025: loss did not improve from -156.14695\n",
      "Epoch 1026/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.7600 - val_loss: -158.0953\n",
      "\n",
      "Epoch 01026: loss did not improve from -156.14695\n",
      "Epoch 1027/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.7330 - val_loss: -157.0793\n",
      "\n",
      "Epoch 01027: loss did not improve from -156.14695\n",
      "Epoch 1028/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.9326 - val_loss: -158.1982\n",
      "\n",
      "Epoch 01028: loss did not improve from -156.14695\n",
      "Epoch 1029/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.8757 - val_loss: -157.3011\n",
      "\n",
      "Epoch 01029: loss did not improve from -156.14695\n",
      "Epoch 1030/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.7174 - val_loss: -157.1031\n",
      "\n",
      "Epoch 01030: loss did not improve from -156.14695\n",
      "Epoch 1031/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.5489 - val_loss: -158.0870\n",
      "\n",
      "Epoch 01031: loss did not improve from -156.14695\n",
      "Epoch 1032/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.4819 - val_loss: -155.9801\n",
      "\n",
      "Epoch 01032: loss did not improve from -156.14695\n",
      "Epoch 1033/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.6388 - val_loss: -157.7421\n",
      "\n",
      "Epoch 01033: loss did not improve from -156.14695\n",
      "Epoch 1034/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.7997 - val_loss: -158.1396\n",
      "\n",
      "Epoch 01034: loss did not improve from -156.14695\n",
      "Epoch 1035/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.7345 - val_loss: -156.9686\n",
      "\n",
      "Epoch 01035: loss did not improve from -156.14695\n",
      "Epoch 1036/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.8578 - val_loss: -158.4645\n",
      "\n",
      "Epoch 01036: loss did not improve from -156.14695\n",
      "Epoch 1037/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.0364 - val_loss: -156.9190\n",
      "\n",
      "Epoch 01037: loss did not improve from -156.14695\n",
      "Epoch 1038/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.9940 - val_loss: -157.7295\n",
      "\n",
      "Epoch 01038: loss did not improve from -156.14695\n",
      "Epoch 1039/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.0411 - val_loss: -158.4804\n",
      "\n",
      "Epoch 01039: loss did not improve from -156.14695\n",
      "Epoch 1040/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.9130 - val_loss: -156.8108\n",
      "\n",
      "Epoch 01040: loss did not improve from -156.14695\n",
      "Epoch 1041/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.0145 - val_loss: -158.2727\n",
      "\n",
      "Epoch 01041: loss did not improve from -156.14695\n",
      "Epoch 1042/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.1535 - val_loss: -157.9099\n",
      "\n",
      "Epoch 01042: loss improved from -156.14695 to -156.15352, saving model to gendance.h5\n",
      "Epoch 1043/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.0568 - val_loss: -157.3076\n",
      "\n",
      "Epoch 01043: loss did not improve from -156.15352\n",
      "Epoch 1044/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.7641 - val_loss: -158.5135\n",
      "\n",
      "Epoch 01044: loss did not improve from -156.15352\n",
      "Epoch 1045/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.9020 - val_loss: -156.6504\n",
      "\n",
      "Epoch 01045: loss did not improve from -156.15352\n",
      "Epoch 1046/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.6946 - val_loss: -157.5818\n",
      "\n",
      "Epoch 01046: loss did not improve from -156.15352\n",
      "Epoch 1047/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.9793 - val_loss: -158.3444\n",
      "\n",
      "Epoch 01047: loss did not improve from -156.15352\n",
      "Epoch 1048/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.8658 - val_loss: -156.6427\n",
      "\n",
      "Epoch 01048: loss did not improve from -156.15352\n",
      "Epoch 1049/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.9185 - val_loss: -158.4083\n",
      "\n",
      "Epoch 01049: loss did not improve from -156.15352\n",
      "Epoch 1050/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.0505 - val_loss: -157.4472\n",
      "\n",
      "Epoch 01050: loss did not improve from -156.15352\n",
      "Epoch 1051/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.8819 - val_loss: -157.4352\n",
      "\n",
      "Epoch 01051: loss did not improve from -156.15352\n",
      "Epoch 1052/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.0858 - val_loss: -158.6992\n",
      "\n",
      "Epoch 01052: loss did not improve from -156.15352\n",
      "Epoch 1053/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.7766 - val_loss: -156.7667\n",
      "\n",
      "Epoch 01053: loss did not improve from -156.15352\n",
      "Epoch 1054/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.3264 - val_loss: -158.1951\n",
      "\n",
      "Epoch 01054: loss improved from -156.15352 to -156.32641, saving model to gendance.h5\n",
      "Epoch 1055/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.2290 - val_loss: -158.5434\n",
      "\n",
      "Epoch 01055: loss did not improve from -156.32641\n",
      "Epoch 1056/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.9834 - val_loss: -157.4193\n",
      "\n",
      "Epoch 01056: loss did not improve from -156.32641\n",
      "Epoch 1057/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -155.9503 - val_loss: -158.7231\n",
      "\n",
      "Epoch 01057: loss did not improve from -156.32641\n",
      "Epoch 1058/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.1749 - val_loss: -157.7241\n",
      "\n",
      "Epoch 01058: loss did not improve from -156.32641\n",
      "Epoch 1059/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.2430 - val_loss: -158.3924\n",
      "\n",
      "Epoch 01059: loss did not improve from -156.32641\n",
      "Epoch 1060/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.3212 - val_loss: -158.3722\n",
      "\n",
      "Epoch 01060: loss did not improve from -156.32641\n",
      "Epoch 1061/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.6441 - val_loss: -158.3430\n",
      "\n",
      "Epoch 01061: loss improved from -156.32641 to -156.64407, saving model to gendance.h5\n",
      "Epoch 1062/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.3315 - val_loss: -158.7454\n",
      "\n",
      "Epoch 01062: loss did not improve from -156.64407\n",
      "Epoch 1063/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.2623 - val_loss: -157.5631\n",
      "\n",
      "Epoch 01063: loss did not improve from -156.64407\n",
      "Epoch 1064/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.3117 - val_loss: -158.2163\n",
      "\n",
      "Epoch 01064: loss did not improve from -156.64407\n",
      "Epoch 1065/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.2304 - val_loss: -158.8223\n",
      "\n",
      "Epoch 01065: loss did not improve from -156.64407\n",
      "Epoch 1066/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.2978 - val_loss: -157.1870\n",
      "\n",
      "Epoch 01066: loss did not improve from -156.64407\n",
      "Epoch 1067/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.1742 - val_loss: -158.7103\n",
      "\n",
      "Epoch 01067: loss did not improve from -156.64407\n",
      "Epoch 1068/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.3907 - val_loss: -157.9100\n",
      "\n",
      "Epoch 01068: loss did not improve from -156.64407\n",
      "Epoch 1069/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.4423 - val_loss: -158.2919\n",
      "\n",
      "Epoch 01069: loss did not improve from -156.64407\n",
      "Epoch 1070/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.4126 - val_loss: -158.9020\n",
      "\n",
      "Epoch 01070: loss did not improve from -156.64407\n",
      "Epoch 1071/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -156.5010 - val_loss: -157.4744\n",
      "\n",
      "Epoch 01071: loss did not improve from -156.64407\n",
      "Epoch 1072/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.5219 - val_loss: -158.9144\n",
      "\n",
      "Epoch 01072: loss did not improve from -156.64407\n",
      "Epoch 1073/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.5277 - val_loss: -158.2384\n",
      "\n",
      "Epoch 01073: loss did not improve from -156.64407\n",
      "Epoch 1074/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.4727 - val_loss: -157.9006\n",
      "\n",
      "Epoch 01074: loss did not improve from -156.64407\n",
      "Epoch 1075/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.2271 - val_loss: -158.8324\n",
      "\n",
      "Epoch 01075: loss did not improve from -156.64407\n",
      "Epoch 1076/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.1542 - val_loss: -157.0929\n",
      "\n",
      "Epoch 01076: loss did not improve from -156.64407\n",
      "Epoch 1077/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.3395 - val_loss: -158.3638\n",
      "\n",
      "Epoch 01077: loss did not improve from -156.64407\n",
      "Epoch 1078/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.6859 - val_loss: -159.0830\n",
      "\n",
      "Epoch 01078: loss improved from -156.64407 to -156.68595, saving model to gendance.h5\n",
      "Epoch 1079/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.3934 - val_loss: -157.4153\n",
      "\n",
      "Epoch 01079: loss did not improve from -156.68595\n",
      "Epoch 1080/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.5172 - val_loss: -158.9948\n",
      "\n",
      "Epoch 01080: loss did not improve from -156.68595\n",
      "Epoch 1081/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.5207 - val_loss: -158.3386\n",
      "\n",
      "Epoch 01081: loss did not improve from -156.68595\n",
      "Epoch 1082/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.6591 - val_loss: -158.2898\n",
      "\n",
      "Epoch 01082: loss did not improve from -156.68595\n",
      "Epoch 1083/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.6656 - val_loss: -158.8329\n",
      "\n",
      "Epoch 01083: loss did not improve from -156.68595\n",
      "Epoch 1084/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.6715 - val_loss: -158.7553\n",
      "\n",
      "Epoch 01084: loss did not improve from -156.68595\n",
      "Epoch 1085/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.9638 - val_loss: -158.9072\n",
      "\n",
      "Epoch 01085: loss improved from -156.68595 to -156.96376, saving model to gendance.h5\n",
      "Epoch 1086/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.8618 - val_loss: -158.6999\n",
      "\n",
      "Epoch 01086: loss did not improve from -156.96376\n",
      "Epoch 1087/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.7679 - val_loss: -158.8021\n",
      "\n",
      "Epoch 01087: loss did not improve from -156.96376\n",
      "Epoch 1088/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.7527 - val_loss: -159.1093\n",
      "\n",
      "Epoch 01088: loss did not improve from -156.96376\n",
      "Epoch 1089/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.7771 - val_loss: -158.6557\n",
      "\n",
      "Epoch 01089: loss did not improve from -156.96376\n",
      "Epoch 1090/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.7138 - val_loss: -158.8772\n",
      "\n",
      "Epoch 01090: loss did not improve from -156.96376\n",
      "Epoch 1091/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -156.8905 - val_loss: -158.2977\n",
      "\n",
      "Epoch 01091: loss did not improve from -156.96376\n",
      "Epoch 1092/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.8246 - val_loss: -158.7754\n",
      "\n",
      "Epoch 01092: loss did not improve from -156.96376\n",
      "Epoch 1093/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.6091 - val_loss: -159.1469\n",
      "\n",
      "Epoch 01093: loss did not improve from -156.96376\n",
      "Epoch 1094/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.6585 - val_loss: -157.8859\n",
      "\n",
      "Epoch 01094: loss did not improve from -156.96376\n",
      "Epoch 1095/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.7659 - val_loss: -159.2414\n",
      "\n",
      "Epoch 01095: loss did not improve from -156.96376\n",
      "Epoch 1096/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.7744 - val_loss: -158.8775\n",
      "\n",
      "Epoch 01096: loss did not improve from -156.96376\n",
      "Epoch 1097/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.4386 - val_loss: -157.2911\n",
      "\n",
      "Epoch 01097: loss did not improve from -156.96376\n",
      "Epoch 1098/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.2878 - val_loss: -158.8865\n",
      "\n",
      "Epoch 01098: loss did not improve from -156.96376\n",
      "Epoch 1099/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.2671 - val_loss: -157.1282\n",
      "\n",
      "Epoch 01099: loss did not improve from -156.96376\n",
      "Epoch 1100/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.5096 - val_loss: -158.6878\n",
      "\n",
      "Epoch 01100: loss did not improve from -156.96376\n",
      "Epoch 1101/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.9153 - val_loss: -158.9889\n",
      "\n",
      "Epoch 01101: loss did not improve from -156.96376\n",
      "Epoch 1102/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.5443 - val_loss: -157.5008\n",
      "\n",
      "Epoch 01102: loss did not improve from -156.96376\n",
      "Epoch 1103/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.7669 - val_loss: -159.4273\n",
      "\n",
      "Epoch 01103: loss did not improve from -156.96376\n",
      "Epoch 1104/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.8135 - val_loss: -157.9095\n",
      "\n",
      "Epoch 01104: loss did not improve from -156.96376\n",
      "Epoch 1105/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.7950 - val_loss: -158.3291\n",
      "\n",
      "Epoch 01105: loss did not improve from -156.96376\n",
      "Epoch 1106/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.9662 - val_loss: -159.4927\n",
      "\n",
      "Epoch 01106: loss improved from -156.96376 to -156.96625, saving model to gendance.h5\n",
      "Epoch 1107/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.7099 - val_loss: -157.5157\n",
      "\n",
      "Epoch 01107: loss did not improve from -156.96625\n",
      "Epoch 1108/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.8982 - val_loss: -159.3373\n",
      "\n",
      "Epoch 01108: loss did not improve from -156.96625\n",
      "Epoch 1109/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.9834 - val_loss: -159.0551\n",
      "\n",
      "Epoch 01109: loss improved from -156.96625 to -156.98345, saving model to gendance.h5\n",
      "Epoch 1110/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.9285 - val_loss: -158.6625\n",
      "\n",
      "Epoch 01110: loss did not improve from -156.98345\n",
      "Epoch 1111/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.2020 - val_loss: -159.4891\n",
      "\n",
      "Epoch 01111: loss improved from -156.98345 to -157.20203, saving model to gendance.h5\n",
      "Epoch 1112/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.0707 - val_loss: -158.4836\n",
      "\n",
      "Epoch 01112: loss did not improve from -157.20203\n",
      "Epoch 1113/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.0633 - val_loss: -159.0163\n",
      "\n",
      "Epoch 01113: loss did not improve from -157.20203\n",
      "Epoch 1114/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.1540 - val_loss: -158.9532\n",
      "\n",
      "Epoch 01114: loss did not improve from -157.20203\n",
      "Epoch 1115/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.7961 - val_loss: -158.3804\n",
      "\n",
      "Epoch 01115: loss did not improve from -157.20203\n",
      "Epoch 1116/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.9612 - val_loss: -159.5393\n",
      "\n",
      "Epoch 01116: loss did not improve from -157.20203\n",
      "Epoch 1117/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.8630 - val_loss: -158.3353\n",
      "\n",
      "Epoch 01117: loss did not improve from -157.20203\n",
      "Epoch 1118/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -157.0027 - val_loss: -158.4837\n",
      "\n",
      "Epoch 01118: loss did not improve from -157.20203\n",
      "Epoch 1119/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.0891 - val_loss: -159.6879\n",
      "\n",
      "Epoch 01119: loss did not improve from -157.20203\n",
      "Epoch 1120/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.0545 - val_loss: -158.6387\n",
      "\n",
      "Epoch 01120: loss did not improve from -157.20203\n",
      "Epoch 1121/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.1548 - val_loss: -159.3957\n",
      "\n",
      "Epoch 01121: loss did not improve from -157.20203\n",
      "Epoch 1122/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.0575 - val_loss: -158.8451\n",
      "\n",
      "Epoch 01122: loss did not improve from -157.20203\n",
      "Epoch 1123/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.0242 - val_loss: -158.5068\n",
      "\n",
      "Epoch 01123: loss did not improve from -157.20203\n",
      "Epoch 1124/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.0617 - val_loss: -159.4620\n",
      "\n",
      "Epoch 01124: loss did not improve from -157.20203\n",
      "Epoch 1125/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.9340 - val_loss: -157.9659\n",
      "\n",
      "Epoch 01125: loss did not improve from -157.20203\n",
      "Epoch 1126/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.2642 - val_loss: -158.9961\n",
      "\n",
      "Epoch 01126: loss improved from -157.20203 to -157.26423, saving model to gendance.h5\n",
      "Epoch 1127/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.9703 - val_loss: -159.2074\n",
      "\n",
      "Epoch 01127: loss did not improve from -157.26423\n",
      "Epoch 1128/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.0184 - val_loss: -158.4987\n",
      "\n",
      "Epoch 01128: loss did not improve from -157.26423\n",
      "Epoch 1129/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.9252 - val_loss: -159.3558\n",
      "\n",
      "Epoch 01129: loss did not improve from -157.26423\n",
      "Epoch 1130/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.2049 - val_loss: -158.4850\n",
      "\n",
      "Epoch 01130: loss did not improve from -157.26423\n",
      "Epoch 1131/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.1069 - val_loss: -159.0403\n",
      "\n",
      "Epoch 01131: loss did not improve from -157.26423\n",
      "Epoch 1132/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.0317 - val_loss: -159.3909\n",
      "\n",
      "Epoch 01132: loss did not improve from -157.26423\n",
      "Epoch 1133/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.9847 - val_loss: -158.1346\n",
      "\n",
      "Epoch 01133: loss did not improve from -157.26423\n",
      "Epoch 1134/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.9647 - val_loss: -159.4410\n",
      "\n",
      "Epoch 01134: loss did not improve from -157.26423\n",
      "Epoch 1135/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.0228 - val_loss: -158.1997\n",
      "\n",
      "Epoch 01135: loss did not improve from -157.26423\n",
      "Epoch 1136/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.1070 - val_loss: -158.9654\n",
      "\n",
      "Epoch 01136: loss did not improve from -157.26423\n",
      "Epoch 1137/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.0996 - val_loss: -159.4450\n",
      "\n",
      "Epoch 01137: loss did not improve from -157.26423\n",
      "Epoch 1138/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.7704 - val_loss: -158.1944\n",
      "\n",
      "Epoch 01138: loss did not improve from -157.26423\n",
      "Epoch 1139/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.8819 - val_loss: -159.2733\n",
      "\n",
      "Epoch 01139: loss did not improve from -157.26423\n",
      "Epoch 1140/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.9925 - val_loss: -158.4523\n",
      "\n",
      "Epoch 01140: loss did not improve from -157.26423\n",
      "Epoch 1141/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.2810 - val_loss: -159.3411\n",
      "\n",
      "Epoch 01141: loss improved from -157.26423 to -157.28101, saving model to gendance.h5\n",
      "Epoch 1142/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.2020 - val_loss: -159.2665\n",
      "\n",
      "Epoch 01142: loss did not improve from -157.28101\n",
      "Epoch 1143/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.1118 - val_loss: -158.2866\n",
      "\n",
      "Epoch 01143: loss did not improve from -157.28101\n",
      "Epoch 1144/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.1036 - val_loss: -159.6067\n",
      "\n",
      "Epoch 01144: loss did not improve from -157.28101\n",
      "Epoch 1145/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.2532 - val_loss: -158.4389\n",
      "\n",
      "Epoch 01145: loss did not improve from -157.28101\n",
      "Epoch 1146/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.5130 - val_loss: -159.6147\n",
      "\n",
      "Epoch 01146: loss improved from -157.28101 to -157.51296, saving model to gendance.h5\n",
      "Epoch 1147/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.4865 - val_loss: -159.4747\n",
      "\n",
      "Epoch 01147: loss did not improve from -157.51296\n",
      "Epoch 1148/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.4560 - val_loss: -159.1173\n",
      "\n",
      "Epoch 01148: loss did not improve from -157.51296\n",
      "Epoch 1149/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.3134 - val_loss: -159.8349\n",
      "\n",
      "Epoch 01149: loss did not improve from -157.51296\n",
      "Epoch 1150/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.0356 - val_loss: -158.5006\n",
      "\n",
      "Epoch 01150: loss did not improve from -157.51296\n",
      "Epoch 1151/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.3771 - val_loss: -159.6076\n",
      "\n",
      "Epoch 01151: loss did not improve from -157.51296\n",
      "Epoch 1152/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.4193 - val_loss: -159.8648\n",
      "\n",
      "Epoch 01152: loss did not improve from -157.51296\n",
      "Epoch 1153/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.2538 - val_loss: -158.4536\n",
      "\n",
      "Epoch 01153: loss did not improve from -157.51296\n",
      "Epoch 1154/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.4195 - val_loss: -159.9999\n",
      "\n",
      "Epoch 01154: loss did not improve from -157.51296\n",
      "Epoch 1155/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.4917 - val_loss: -159.2480\n",
      "\n",
      "Epoch 01155: loss did not improve from -157.51296\n",
      "Epoch 1156/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.4254 - val_loss: -159.5724\n",
      "\n",
      "Epoch 01156: loss did not improve from -157.51296\n",
      "Epoch 1157/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.8732 - val_loss: -159.9433\n",
      "\n",
      "Epoch 01157: loss improved from -157.51296 to -157.87319, saving model to gendance.h5\n",
      "Epoch 1158/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.7954 - val_loss: -159.5114\n",
      "\n",
      "Epoch 01158: loss did not improve from -157.87319\n",
      "Epoch 1159/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.8394 - val_loss: -160.0784\n",
      "\n",
      "Epoch 01159: loss did not improve from -157.87319\n",
      "Epoch 1160/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.5164 - val_loss: -159.7859\n",
      "\n",
      "Epoch 01160: loss did not improve from -157.87319\n",
      "Epoch 1161/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.6786 - val_loss: -159.4294\n",
      "\n",
      "Epoch 01161: loss did not improve from -157.87319\n",
      "Epoch 1162/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.6714 - val_loss: -159.8367\n",
      "\n",
      "Epoch 01162: loss did not improve from -157.87319\n",
      "Epoch 1163/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.5800 - val_loss: -159.1366\n",
      "\n",
      "Epoch 01163: loss did not improve from -157.87319\n",
      "Epoch 1164/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.6641 - val_loss: -159.4539\n",
      "\n",
      "Epoch 01164: loss did not improve from -157.87319\n",
      "Epoch 1165/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.6166 - val_loss: -159.5452\n",
      "\n",
      "Epoch 01165: loss did not improve from -157.87319\n",
      "Epoch 1166/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.6652 - val_loss: -159.6700\n",
      "\n",
      "Epoch 01166: loss did not improve from -157.87319\n",
      "Epoch 1167/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.7216 - val_loss: -160.1337\n",
      "\n",
      "Epoch 01167: loss did not improve from -157.87319\n",
      "Epoch 1168/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.6935 - val_loss: -159.1429\n",
      "\n",
      "Epoch 01168: loss did not improve from -157.87319\n",
      "Epoch 1169/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.7607 - val_loss: -159.7922\n",
      "\n",
      "Epoch 01169: loss did not improve from -157.87319\n",
      "Epoch 1170/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.8619 - val_loss: -160.2469\n",
      "\n",
      "Epoch 01170: loss did not improve from -157.87319\n",
      "Epoch 1171/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.4451 - val_loss: -158.8077\n",
      "\n",
      "Epoch 01171: loss did not improve from -157.87319\n",
      "Epoch 1172/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.3426 - val_loss: -159.9014\n",
      "\n",
      "Epoch 01172: loss did not improve from -157.87319\n",
      "Epoch 1173/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.6400 - val_loss: -158.9405\n",
      "\n",
      "Epoch 01173: loss did not improve from -157.87319\n",
      "Epoch 1174/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.5519 - val_loss: -159.4753\n",
      "\n",
      "Epoch 01174: loss did not improve from -157.87319\n",
      "Epoch 1175/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.5381 - val_loss: -160.0972\n",
      "\n",
      "Epoch 01175: loss did not improve from -157.87319\n",
      "Epoch 1176/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.5014 - val_loss: -158.4376\n",
      "\n",
      "Epoch 01176: loss did not improve from -157.87319\n",
      "Epoch 1177/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.5925 - val_loss: -159.7809\n",
      "\n",
      "Epoch 01177: loss did not improve from -157.87319\n",
      "Epoch 1178/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.5025 - val_loss: -159.4648\n",
      "\n",
      "Epoch 01178: loss did not improve from -157.87319\n",
      "Epoch 1179/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.3723 - val_loss: -158.5274\n",
      "\n",
      "Epoch 01179: loss did not improve from -157.87319\n",
      "Epoch 1180/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -156.9986 - val_loss: -159.7730\n",
      "\n",
      "Epoch 01180: loss did not improve from -157.87319\n",
      "Epoch 1181/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.1228 - val_loss: -158.1549\n",
      "\n",
      "Epoch 01181: loss did not improve from -157.87319\n",
      "Epoch 1182/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.4918 - val_loss: -159.5832\n",
      "\n",
      "Epoch 01182: loss did not improve from -157.87319\n",
      "Epoch 1183/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.8889 - val_loss: -159.8244\n",
      "\n",
      "Epoch 01183: loss improved from -157.87319 to -157.88890, saving model to gendance.h5\n",
      "Epoch 1184/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.8052 - val_loss: -159.5622\n",
      "\n",
      "Epoch 01184: loss did not improve from -157.88890\n",
      "Epoch 1185/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.9166 - val_loss: -160.1474\n",
      "\n",
      "Epoch 01185: loss improved from -157.88890 to -157.91657, saving model to gendance.h5\n",
      "Epoch 1186/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.7565 - val_loss: -158.9749\n",
      "\n",
      "Epoch 01186: loss did not improve from -157.91657\n",
      "Epoch 1187/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.9743 - val_loss: -160.3690\n",
      "\n",
      "Epoch 01187: loss improved from -157.91657 to -157.97425, saving model to gendance.h5\n",
      "Epoch 1188/10000\n",
      "16167/16167 [==============================] - 1s 32us/step - loss: -157.9231 - val_loss: -159.8350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01188: loss did not improve from -157.97425\n",
      "Epoch 1189/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.6998 - val_loss: -159.2902\n",
      "\n",
      "Epoch 01189: loss did not improve from -157.97425\n",
      "Epoch 1190/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.7626 - val_loss: -160.2749\n",
      "\n",
      "Epoch 01190: loss did not improve from -157.97425\n",
      "Epoch 1191/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.9348 - val_loss: -159.1052\n",
      "\n",
      "Epoch 01191: loss did not improve from -157.97425\n",
      "Epoch 1192/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.9116 - val_loss: -160.3928\n",
      "\n",
      "Epoch 01192: loss did not improve from -157.97425\n",
      "Epoch 1193/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.0082 - val_loss: -160.1598\n",
      "\n",
      "Epoch 01193: loss improved from -157.97425 to -158.00818, saving model to gendance.h5\n",
      "Epoch 1194/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.9901 - val_loss: -159.6431\n",
      "\n",
      "Epoch 01194: loss did not improve from -158.00818\n",
      "Epoch 1195/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.8885 - val_loss: -160.0494\n",
      "\n",
      "Epoch 01195: loss did not improve from -158.00818\n",
      "Epoch 1196/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.9243 - val_loss: -159.9168\n",
      "\n",
      "Epoch 01196: loss did not improve from -158.00818\n",
      "Epoch 1197/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.0062 - val_loss: -160.0664\n",
      "\n",
      "Epoch 01197: loss did not improve from -158.00818\n",
      "Epoch 1198/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.1851 - val_loss: -160.1045\n",
      "\n",
      "Epoch 01198: loss improved from -158.00818 to -158.18515, saving model to gendance.h5\n",
      "Epoch 1199/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.9103 - val_loss: -160.1030\n",
      "\n",
      "Epoch 01199: loss did not improve from -158.18515\n",
      "Epoch 1200/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.0870 - val_loss: -159.9747\n",
      "\n",
      "Epoch 01200: loss did not improve from -158.18515\n",
      "Epoch 1201/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.0846 - val_loss: -159.7117\n",
      "\n",
      "Epoch 01201: loss did not improve from -158.18515\n",
      "Epoch 1202/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.9145 - val_loss: -160.2129\n",
      "\n",
      "Epoch 01202: loss did not improve from -158.18515\n",
      "Epoch 1203/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.8044 - val_loss: -159.4611\n",
      "\n",
      "Epoch 01203: loss did not improve from -158.18515\n",
      "Epoch 1204/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.9655 - val_loss: -159.8195\n",
      "\n",
      "Epoch 01204: loss did not improve from -158.18515\n",
      "Epoch 1205/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.8290 - val_loss: -160.5464\n",
      "\n",
      "Epoch 01205: loss did not improve from -158.18515\n",
      "Epoch 1206/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.5928 - val_loss: -158.7614\n",
      "\n",
      "Epoch 01206: loss did not improve from -158.18515\n",
      "Epoch 1207/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.4374 - val_loss: -160.1224\n",
      "\n",
      "Epoch 01207: loss did not improve from -158.18515\n",
      "Epoch 1208/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.7021 - val_loss: -159.2174\n",
      "\n",
      "Epoch 01208: loss did not improve from -158.18515\n",
      "Epoch 1209/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.2211 - val_loss: -160.2893\n",
      "\n",
      "Epoch 01209: loss improved from -158.18515 to -158.22107, saving model to gendance.h5\n",
      "Epoch 1210/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.1557 - val_loss: -160.4696\n",
      "\n",
      "Epoch 01210: loss did not improve from -158.22107\n",
      "Epoch 1211/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.2455 - val_loss: -159.2182\n",
      "\n",
      "Epoch 01211: loss improved from -158.22107 to -158.24553, saving model to gendance.h5\n",
      "Epoch 1212/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.1068 - val_loss: -160.3494\n",
      "\n",
      "Epoch 01212: loss did not improve from -158.24553\n",
      "Epoch 1213/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.9073 - val_loss: -159.6246\n",
      "\n",
      "Epoch 01213: loss did not improve from -158.24553\n",
      "Epoch 1214/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.8925 - val_loss: -159.8307\n",
      "\n",
      "Epoch 01214: loss did not improve from -158.24553\n",
      "Epoch 1215/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.0477 - val_loss: -160.6498\n",
      "\n",
      "Epoch 01215: loss did not improve from -158.24553\n",
      "Epoch 1216/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.8022 - val_loss: -158.1819\n",
      "\n",
      "Epoch 01216: loss did not improve from -158.24553\n",
      "Epoch 1217/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.8519 - val_loss: -160.4195\n",
      "\n",
      "Epoch 01217: loss did not improve from -158.24553\n",
      "Epoch 1218/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.9174 - val_loss: -159.8055\n",
      "\n",
      "Epoch 01218: loss did not improve from -158.24553\n",
      "Epoch 1219/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.1657 - val_loss: -159.5918\n",
      "\n",
      "Epoch 01219: loss did not improve from -158.24553\n",
      "Epoch 1220/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.7113 - val_loss: -160.5090\n",
      "\n",
      "Epoch 01220: loss did not improve from -158.24553\n",
      "Epoch 1221/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.0689 - val_loss: -159.4742\n",
      "\n",
      "Epoch 01221: loss did not improve from -158.24553\n",
      "Epoch 1222/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.1144 - val_loss: -160.4192\n",
      "\n",
      "Epoch 01222: loss did not improve from -158.24553\n",
      "Epoch 1223/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.1144 - val_loss: -159.7821\n",
      "\n",
      "Epoch 01223: loss did not improve from -158.24553\n",
      "Epoch 1224/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.2477 - val_loss: -160.1535\n",
      "\n",
      "Epoch 01224: loss improved from -158.24553 to -158.24767, saving model to gendance.h5\n",
      "Epoch 1225/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.4087 - val_loss: -160.8955\n",
      "\n",
      "Epoch 01225: loss improved from -158.24767 to -158.40866, saving model to gendance.h5\n",
      "Epoch 1226/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -158.0730 - val_loss: -159.0765\n",
      "\n",
      "Epoch 01226: loss did not improve from -158.40866\n",
      "Epoch 1227/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.2572 - val_loss: -160.5525\n",
      "\n",
      "Epoch 01227: loss did not improve from -158.40866\n",
      "Epoch 1228/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.1372 - val_loss: -160.6419\n",
      "\n",
      "Epoch 01228: loss did not improve from -158.40866\n",
      "Epoch 1229/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.6876 - val_loss: -158.5728\n",
      "\n",
      "Epoch 01229: loss did not improve from -158.40866\n",
      "Epoch 1230/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.2532 - val_loss: -159.7395\n",
      "\n",
      "Epoch 01230: loss did not improve from -158.40866\n",
      "Epoch 1231/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.6355 - val_loss: -159.4935\n",
      "\n",
      "Epoch 01231: loss did not improve from -158.40866\n",
      "Epoch 1232/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.2963 - val_loss: -160.3978\n",
      "\n",
      "Epoch 01232: loss did not improve from -158.40866\n",
      "Epoch 1233/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.1463 - val_loss: -160.5519\n",
      "\n",
      "Epoch 01233: loss did not improve from -158.40866\n",
      "Epoch 1234/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.1680 - val_loss: -159.9084\n",
      "\n",
      "Epoch 01234: loss did not improve from -158.40866\n",
      "Epoch 1235/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.5294 - val_loss: -160.7447\n",
      "\n",
      "Epoch 01235: loss improved from -158.40866 to -158.52938, saving model to gendance.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1236/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.2638 - val_loss: -160.5313\n",
      "\n",
      "Epoch 01236: loss did not improve from -158.52938\n",
      "Epoch 1237/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.3946 - val_loss: -159.9098\n",
      "\n",
      "Epoch 01237: loss did not improve from -158.52938\n",
      "Epoch 1238/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.1385 - val_loss: -160.7738\n",
      "\n",
      "Epoch 01238: loss did not improve from -158.52938\n",
      "Epoch 1239/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.3057 - val_loss: -159.8144\n",
      "\n",
      "Epoch 01239: loss did not improve from -158.52938\n",
      "Epoch 1240/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.3259 - val_loss: -160.4562\n",
      "\n",
      "Epoch 01240: loss did not improve from -158.52938\n",
      "Epoch 1241/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.5114 - val_loss: -160.8125\n",
      "\n",
      "Epoch 01241: loss did not improve from -158.52938\n",
      "Epoch 1242/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.6429 - val_loss: -160.1302\n",
      "\n",
      "Epoch 01242: loss improved from -158.52938 to -158.64291, saving model to gendance.h5\n",
      "Epoch 1243/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.5684 - val_loss: -161.0861\n",
      "\n",
      "Epoch 01243: loss did not improve from -158.64291\n",
      "Epoch 1244/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.5802 - val_loss: -160.5425\n",
      "\n",
      "Epoch 01244: loss did not improve from -158.64291\n",
      "Epoch 1245/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.5295 - val_loss: -160.6150\n",
      "\n",
      "Epoch 01245: loss did not improve from -158.64291\n",
      "Epoch 1246/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.4581 - val_loss: -161.0221\n",
      "\n",
      "Epoch 01246: loss did not improve from -158.64291\n",
      "Epoch 1247/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.6066 - val_loss: -160.0733\n",
      "\n",
      "Epoch 01247: loss did not improve from -158.64291\n",
      "Epoch 1248/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.4021 - val_loss: -160.8395\n",
      "\n",
      "Epoch 01248: loss did not improve from -158.64291\n",
      "Epoch 1249/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.4988 - val_loss: -160.2905\n",
      "\n",
      "Epoch 01249: loss did not improve from -158.64291\n",
      "Epoch 1250/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.4700 - val_loss: -160.2925\n",
      "\n",
      "Epoch 01250: loss did not improve from -158.64291\n",
      "Epoch 1251/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.5286 - val_loss: -160.6479\n",
      "\n",
      "Epoch 01251: loss did not improve from -158.64291\n",
      "Epoch 1252/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.4569 - val_loss: -160.3211\n",
      "\n",
      "Epoch 01252: loss did not improve from -158.64291\n",
      "Epoch 1253/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.5144 - val_loss: -161.0013\n",
      "\n",
      "Epoch 01253: loss did not improve from -158.64291\n",
      "Epoch 1254/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.4135 - val_loss: -160.3031\n",
      "\n",
      "Epoch 01254: loss did not improve from -158.64291\n",
      "Epoch 1255/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.1498 - val_loss: -159.9301\n",
      "\n",
      "Epoch 01255: loss did not improve from -158.64291\n",
      "Epoch 1256/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.4070 - val_loss: -161.0221\n",
      "\n",
      "Epoch 01256: loss did not improve from -158.64291\n",
      "Epoch 1257/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.4038 - val_loss: -159.4800\n",
      "\n",
      "Epoch 01257: loss did not improve from -158.64291\n",
      "Epoch 1258/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.2669 - val_loss: -161.0325\n",
      "\n",
      "Epoch 01258: loss did not improve from -158.64291\n",
      "Epoch 1259/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.6165 - val_loss: -160.4552\n",
      "\n",
      "Epoch 01259: loss did not improve from -158.64291\n",
      "Epoch 1260/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.8450 - val_loss: -160.3385\n",
      "\n",
      "Epoch 01260: loss improved from -158.64291 to -158.84501, saving model to gendance.h5\n",
      "Epoch 1261/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.7038 - val_loss: -161.1035\n",
      "\n",
      "Epoch 01261: loss did not improve from -158.84501\n",
      "Epoch 1262/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.6544 - val_loss: -160.0839\n",
      "\n",
      "Epoch 01262: loss did not improve from -158.84501\n",
      "Epoch 1263/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.6291 - val_loss: -161.1237\n",
      "\n",
      "Epoch 01263: loss did not improve from -158.84501\n",
      "Epoch 1264/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.6399 - val_loss: -160.2751\n",
      "\n",
      "Epoch 01264: loss did not improve from -158.84501\n",
      "Epoch 1265/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.8205 - val_loss: -160.7493\n",
      "\n",
      "Epoch 01265: loss did not improve from -158.84501\n",
      "Epoch 1266/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.5628 - val_loss: -161.1183\n",
      "\n",
      "Epoch 01266: loss did not improve from -158.84501\n",
      "Epoch 1267/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.5439 - val_loss: -159.4727\n",
      "\n",
      "Epoch 01267: loss did not improve from -158.84501\n",
      "Epoch 1268/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.4394 - val_loss: -160.9796\n",
      "\n",
      "Epoch 01268: loss did not improve from -158.84501\n",
      "Epoch 1269/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.5142 - val_loss: -159.7057\n",
      "\n",
      "Epoch 01269: loss did not improve from -158.84501\n",
      "Epoch 1270/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.9629 - val_loss: -159.3678\n",
      "\n",
      "Epoch 01270: loss did not improve from -158.84501\n",
      "Epoch 1271/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.8505 - val_loss: -160.4084\n",
      "\n",
      "Epoch 01271: loss did not improve from -158.84501\n",
      "Epoch 1272/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -157.7545 - val_loss: -158.6730\n",
      "\n",
      "Epoch 01272: loss did not improve from -158.84501\n",
      "Epoch 1273/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.0336 - val_loss: -160.5406\n",
      "\n",
      "Epoch 01273: loss did not improve from -158.84501\n",
      "Epoch 1274/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.5640 - val_loss: -160.4693\n",
      "\n",
      "Epoch 01274: loss did not improve from -158.84501\n",
      "Epoch 1275/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.4645 - val_loss: -160.6077\n",
      "\n",
      "Epoch 01275: loss did not improve from -158.84501\n",
      "Epoch 1276/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.4190 - val_loss: -160.8539\n",
      "\n",
      "Epoch 01276: loss did not improve from -158.84501\n",
      "Epoch 1277/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.7508 - val_loss: -160.1810\n",
      "\n",
      "Epoch 01277: loss did not improve from -158.84501\n",
      "Epoch 1278/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.7548 - val_loss: -160.9945\n",
      "\n",
      "Epoch 01278: loss did not improve from -158.84501\n",
      "Epoch 1279/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.9798 - val_loss: -160.6145\n",
      "\n",
      "Epoch 01279: loss improved from -158.84501 to -158.97976, saving model to gendance.h5\n",
      "Epoch 1280/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.8696 - val_loss: -160.8816\n",
      "\n",
      "Epoch 01280: loss did not improve from -158.97976\n",
      "Epoch 1281/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.1226 - val_loss: -161.2293\n",
      "\n",
      "Epoch 01281: loss improved from -158.97976 to -159.12257, saving model to gendance.h5\n",
      "Epoch 1282/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.6578 - val_loss: -160.0119\n",
      "\n",
      "Epoch 01282: loss did not improve from -159.12257\n",
      "Epoch 1283/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.6799 - val_loss: -161.3332\n",
      "\n",
      "Epoch 01283: loss did not improve from -159.12257\n",
      "Epoch 1284/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.8653 - val_loss: -160.3227\n",
      "\n",
      "Epoch 01284: loss did not improve from -159.12257\n",
      "Epoch 1285/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.9127 - val_loss: -160.9635\n",
      "\n",
      "Epoch 01285: loss did not improve from -159.12257\n",
      "Epoch 1286/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.0310 - val_loss: -161.3836\n",
      "\n",
      "Epoch 01286: loss did not improve from -159.12257\n",
      "Epoch 1287/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.9665 - val_loss: -160.4124\n",
      "\n",
      "Epoch 01287: loss did not improve from -159.12257\n",
      "Epoch 1288/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.9442 - val_loss: -161.3405\n",
      "\n",
      "Epoch 01288: loss did not improve from -159.12257\n",
      "Epoch 1289/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.0182 - val_loss: -160.6560\n",
      "\n",
      "Epoch 01289: loss did not improve from -159.12257\n",
      "Epoch 1290/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.8977 - val_loss: -161.0156\n",
      "\n",
      "Epoch 01290: loss did not improve from -159.12257\n",
      "Epoch 1291/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.8095 - val_loss: -161.2104\n",
      "\n",
      "Epoch 01291: loss did not improve from -159.12257\n",
      "Epoch 1292/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.5078 - val_loss: -160.1865\n",
      "\n",
      "Epoch 01292: loss did not improve from -159.12257\n",
      "Epoch 1293/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.8408 - val_loss: -161.3311\n",
      "\n",
      "Epoch 01293: loss did not improve from -159.12257\n",
      "Epoch 1294/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.8864 - val_loss: -160.1752\n",
      "\n",
      "Epoch 01294: loss did not improve from -159.12257\n",
      "Epoch 1295/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.7570 - val_loss: -160.8028\n",
      "\n",
      "Epoch 01295: loss did not improve from -159.12257\n",
      "Epoch 1296/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.8886 - val_loss: -161.2945\n",
      "\n",
      "Epoch 01296: loss did not improve from -159.12257\n",
      "Epoch 1297/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.8543 - val_loss: -159.7696\n",
      "\n",
      "Epoch 01297: loss did not improve from -159.12257\n",
      "Epoch 1298/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.9138 - val_loss: -161.1752\n",
      "\n",
      "Epoch 01298: loss did not improve from -159.12257\n",
      "Epoch 1299/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.6253 - val_loss: -160.6762\n",
      "\n",
      "Epoch 01299: loss did not improve from -159.12257\n",
      "Epoch 1300/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.7305 - val_loss: -160.6435\n",
      "\n",
      "Epoch 01300: loss did not improve from -159.12257\n",
      "Epoch 1301/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.6380 - val_loss: -161.2194\n",
      "\n",
      "Epoch 01301: loss did not improve from -159.12257\n",
      "Epoch 1302/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.7341 - val_loss: -160.1515\n",
      "\n",
      "Epoch 01302: loss did not improve from -159.12257\n",
      "Epoch 1303/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.8394 - val_loss: -161.3912\n",
      "\n",
      "Epoch 01303: loss did not improve from -159.12257\n",
      "Epoch 1304/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.8258 - val_loss: -160.5606\n",
      "\n",
      "Epoch 01304: loss did not improve from -159.12257\n",
      "Epoch 1305/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.0603 - val_loss: -161.1507\n",
      "\n",
      "Epoch 01305: loss did not improve from -159.12257\n",
      "Epoch 1306/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.2150 - val_loss: -161.5465\n",
      "\n",
      "Epoch 01306: loss improved from -159.12257 to -159.21498, saving model to gendance.h5\n",
      "Epoch 1307/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.2751 - val_loss: -160.6400\n",
      "\n",
      "Epoch 01307: loss improved from -159.21498 to -159.27505, saving model to gendance.h5\n",
      "Epoch 1308/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.2422 - val_loss: -161.5907\n",
      "\n",
      "Epoch 01308: loss did not improve from -159.27505\n",
      "Epoch 1309/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.2823 - val_loss: -160.9839\n",
      "\n",
      "Epoch 01309: loss improved from -159.27505 to -159.28225, saving model to gendance.h5\n",
      "Epoch 1310/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.1267 - val_loss: -160.9554\n",
      "\n",
      "Epoch 01310: loss did not improve from -159.28225\n",
      "Epoch 1311/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.3111 - val_loss: -161.2969\n",
      "\n",
      "Epoch 01311: loss improved from -159.28225 to -159.31106, saving model to gendance.h5\n",
      "Epoch 1312/10000\n",
      "16167/16167 [==============================] - 1s 33us/step - loss: -159.0182 - val_loss: -160.8764\n",
      "\n",
      "Epoch 01312: loss did not improve from -159.31106\n",
      "Epoch 1313/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.3323 - val_loss: -161.4420\n",
      "\n",
      "Epoch 01313: loss improved from -159.31106 to -159.33225, saving model to gendance.h5\n",
      "Epoch 1314/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.3706 - val_loss: -160.9218\n",
      "\n",
      "Epoch 01314: loss improved from -159.33225 to -159.37062, saving model to gendance.h5\n",
      "Epoch 1315/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.2604 - val_loss: -161.5476\n",
      "\n",
      "Epoch 01315: loss did not improve from -159.37062\n",
      "Epoch 1316/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.2446 - val_loss: -161.3135\n",
      "\n",
      "Epoch 01316: loss did not improve from -159.37062\n",
      "Epoch 1317/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.2682 - val_loss: -160.8207\n",
      "\n",
      "Epoch 01317: loss did not improve from -159.37062\n",
      "Epoch 1318/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.3892 - val_loss: -161.9753\n",
      "\n",
      "Epoch 01318: loss improved from -159.37062 to -159.38917, saving model to gendance.h5\n",
      "Epoch 1319/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.0843 - val_loss: -160.2977\n",
      "\n",
      "Epoch 01319: loss did not improve from -159.38917\n",
      "Epoch 1320/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.1696 - val_loss: -161.1555\n",
      "\n",
      "Epoch 01320: loss did not improve from -159.38917\n",
      "Epoch 1321/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.3719 - val_loss: -161.8398\n",
      "\n",
      "Epoch 01321: loss did not improve from -159.38917\n",
      "Epoch 1322/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.1134 - val_loss: -160.3095\n",
      "\n",
      "Epoch 01322: loss did not improve from -159.38917\n",
      "Epoch 1323/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.0562 - val_loss: -161.3985\n",
      "\n",
      "Epoch 01323: loss did not improve from -159.38917\n",
      "Epoch 1324/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.1915 - val_loss: -159.8535\n",
      "\n",
      "Epoch 01324: loss did not improve from -159.38917\n",
      "Epoch 1325/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.9302 - val_loss: -161.2080\n",
      "\n",
      "Epoch 01325: loss did not improve from -159.38917\n",
      "Epoch 1326/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.0486 - val_loss: -161.3403\n",
      "\n",
      "Epoch 01326: loss did not improve from -159.38917\n",
      "Epoch 1327/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.3581 - val_loss: -160.3726\n",
      "\n",
      "Epoch 01327: loss did not improve from -159.38917\n",
      "Epoch 1328/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.0657 - val_loss: -161.8077\n",
      "\n",
      "Epoch 01328: loss did not improve from -159.38917\n",
      "Epoch 1329/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.3610 - val_loss: -160.1015\n",
      "\n",
      "Epoch 01329: loss did not improve from -159.38917\n",
      "Epoch 1330/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.1065 - val_loss: -161.4386\n",
      "\n",
      "Epoch 01330: loss did not improve from -159.38917\n",
      "Epoch 1331/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.1841 - val_loss: -161.5760\n",
      "\n",
      "Epoch 01331: loss did not improve from -159.38917\n",
      "Epoch 1332/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.9215 - val_loss: -160.0145\n",
      "\n",
      "Epoch 01332: loss did not improve from -159.38917\n",
      "Epoch 1333/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.8447 - val_loss: -161.1776\n",
      "\n",
      "Epoch 01333: loss did not improve from -159.38917\n",
      "Epoch 1334/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -158.7431 - val_loss: -159.7122\n",
      "\n",
      "Epoch 01334: loss did not improve from -159.38917\n",
      "Epoch 1335/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.0244 - val_loss: -161.1032\n",
      "\n",
      "Epoch 01335: loss did not improve from -159.38917\n",
      "Epoch 1336/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.2667 - val_loss: -161.7150\n",
      "\n",
      "Epoch 01336: loss did not improve from -159.38917\n",
      "Epoch 1337/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.2003 - val_loss: -160.6726\n",
      "\n",
      "Epoch 01337: loss did not improve from -159.38917\n",
      "Epoch 1338/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.1284 - val_loss: -161.5416\n",
      "\n",
      "Epoch 01338: loss did not improve from -159.38917\n",
      "Epoch 1339/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.3173 - val_loss: -160.5585\n",
      "\n",
      "Epoch 01339: loss did not improve from -159.38917\n",
      "Epoch 1340/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.3935 - val_loss: -161.7949\n",
      "\n",
      "Epoch 01340: loss improved from -159.38917 to -159.39351, saving model to gendance.h5\n",
      "Epoch 1341/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.5398 - val_loss: -161.3327\n",
      "\n",
      "Epoch 01341: loss improved from -159.39351 to -159.53984, saving model to gendance.h5\n",
      "Epoch 1342/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.5373 - val_loss: -161.2533\n",
      "\n",
      "Epoch 01342: loss did not improve from -159.53984\n",
      "Epoch 1343/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.5126 - val_loss: -161.7181\n",
      "\n",
      "Epoch 01343: loss did not improve from -159.53984\n",
      "Epoch 1344/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.4794 - val_loss: -161.2228\n",
      "\n",
      "Epoch 01344: loss did not improve from -159.53984\n",
      "Epoch 1345/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.3249 - val_loss: -161.5059\n",
      "\n",
      "Epoch 01345: loss did not improve from -159.53984\n",
      "Epoch 1346/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.4659 - val_loss: -161.3405\n",
      "\n",
      "Epoch 01346: loss did not improve from -159.53984\n",
      "Epoch 1347/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.4289 - val_loss: -161.4633\n",
      "\n",
      "Epoch 01347: loss did not improve from -159.53984\n",
      "Epoch 1348/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.4888 - val_loss: -161.8128\n",
      "\n",
      "Epoch 01348: loss did not improve from -159.53984\n",
      "Epoch 1349/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.7278 - val_loss: -160.9451\n",
      "\n",
      "Epoch 01349: loss improved from -159.53984 to -159.72783, saving model to gendance.h5\n",
      "Epoch 1350/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -159.6561 - val_loss: -161.9625\n",
      "\n",
      "Epoch 01350: loss did not improve from -159.72783\n",
      "Epoch 1351/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.7311 - val_loss: -161.7715\n",
      "\n",
      "Epoch 01351: loss improved from -159.72783 to -159.73107, saving model to gendance.h5\n",
      "Epoch 1352/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.8359 - val_loss: -161.6035\n",
      "\n",
      "Epoch 01352: loss improved from -159.73107 to -159.83592, saving model to gendance.h5\n",
      "Epoch 1353/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.8054 - val_loss: -161.8737\n",
      "\n",
      "Epoch 01353: loss did not improve from -159.83592\n",
      "Epoch 1354/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.6318 - val_loss: -161.5597\n",
      "\n",
      "Epoch 01354: loss did not improve from -159.83592\n",
      "Epoch 1355/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.4654 - val_loss: -160.9969\n",
      "\n",
      "Epoch 01355: loss did not improve from -159.83592\n",
      "Epoch 1356/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.4192 - val_loss: -161.8789\n",
      "\n",
      "Epoch 01356: loss did not improve from -159.83592\n",
      "Epoch 1357/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.2937 - val_loss: -160.8303\n",
      "\n",
      "Epoch 01357: loss did not improve from -159.83592\n",
      "Epoch 1358/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.6104 - val_loss: -161.8014\n",
      "\n",
      "Epoch 01358: loss did not improve from -159.83592\n",
      "Epoch 1359/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.6403 - val_loss: -161.4561\n",
      "\n",
      "Epoch 01359: loss did not improve from -159.83592\n",
      "Epoch 1360/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.6278 - val_loss: -161.3906\n",
      "\n",
      "Epoch 01360: loss did not improve from -159.83592\n",
      "Epoch 1361/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.6571 - val_loss: -161.8997\n",
      "\n",
      "Epoch 01361: loss did not improve from -159.83592\n",
      "Epoch 1362/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.4031 - val_loss: -160.6627\n",
      "\n",
      "Epoch 01362: loss did not improve from -159.83592\n",
      "Epoch 1363/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.6602 - val_loss: -162.0548\n",
      "\n",
      "Epoch 01363: loss did not improve from -159.83592\n",
      "Epoch 1364/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.6039 - val_loss: -161.4042\n",
      "\n",
      "Epoch 01364: loss did not improve from -159.83592\n",
      "Epoch 1365/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.5392 - val_loss: -160.9906\n",
      "\n",
      "Epoch 01365: loss did not improve from -159.83592\n",
      "Epoch 1366/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.3275 - val_loss: -161.8268\n",
      "\n",
      "Epoch 01366: loss did not improve from -159.83592\n",
      "Epoch 1367/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.2859 - val_loss: -160.4001\n",
      "\n",
      "Epoch 01367: loss did not improve from -159.83592\n",
      "Epoch 1368/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.6587 - val_loss: -162.0354\n",
      "\n",
      "Epoch 01368: loss did not improve from -159.83592\n",
      "Epoch 1369/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.6628 - val_loss: -161.3901\n",
      "\n",
      "Epoch 01369: loss did not improve from -159.83592\n",
      "Epoch 1370/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.6538 - val_loss: -161.5323\n",
      "\n",
      "Epoch 01370: loss did not improve from -159.83592\n",
      "Epoch 1371/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.5622 - val_loss: -162.0923\n",
      "\n",
      "Epoch 01371: loss did not improve from -159.83592\n",
      "Epoch 1372/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.3949 - val_loss: -160.7515\n",
      "\n",
      "Epoch 01372: loss did not improve from -159.83592\n",
      "Epoch 1373/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.5795 - val_loss: -162.0761\n",
      "\n",
      "Epoch 01373: loss did not improve from -159.83592\n",
      "Epoch 1374/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.5509 - val_loss: -161.0816\n",
      "\n",
      "Epoch 01374: loss did not improve from -159.83592\n",
      "Epoch 1375/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.2829 - val_loss: -161.2817\n",
      "\n",
      "Epoch 01375: loss did not improve from -159.83592\n",
      "Epoch 1376/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.4885 - val_loss: -161.8684\n",
      "\n",
      "Epoch 01376: loss did not improve from -159.83592\n",
      "Epoch 1377/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.2016 - val_loss: -160.0708\n",
      "\n",
      "Epoch 01377: loss did not improve from -159.83592\n",
      "Epoch 1378/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.3259 - val_loss: -161.6142\n",
      "\n",
      "Epoch 01378: loss did not improve from -159.83592\n",
      "Epoch 1379/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.5672 - val_loss: -161.6809\n",
      "\n",
      "Epoch 01379: loss did not improve from -159.83592\n",
      "Epoch 1380/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.6397 - val_loss: -161.3919\n",
      "\n",
      "Epoch 01380: loss did not improve from -159.83592\n",
      "Epoch 1381/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.5286 - val_loss: -162.0052\n",
      "\n",
      "Epoch 01381: loss did not improve from -159.83592\n",
      "Epoch 1382/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.6141 - val_loss: -161.3101\n",
      "\n",
      "Epoch 01382: loss did not improve from -159.83592\n",
      "Epoch 1383/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.7671 - val_loss: -161.9695\n",
      "\n",
      "Epoch 01383: loss did not improve from -159.83592\n",
      "Epoch 1384/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.7827 - val_loss: -161.9906\n",
      "\n",
      "Epoch 01384: loss did not improve from -159.83592\n",
      "Epoch 1385/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.8574 - val_loss: -161.9475\n",
      "\n",
      "Epoch 01385: loss improved from -159.83592 to -159.85737, saving model to gendance.h5\n",
      "Epoch 1386/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.9173 - val_loss: -162.2807\n",
      "\n",
      "Epoch 01386: loss improved from -159.85737 to -159.91734, saving model to gendance.h5\n",
      "Epoch 1387/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.8289 - val_loss: -161.5431\n",
      "\n",
      "Epoch 01387: loss did not improve from -159.91734\n",
      "Epoch 1388/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.0787 - val_loss: -162.2083\n",
      "\n",
      "Epoch 01388: loss improved from -159.91734 to -160.07872, saving model to gendance.h5\n",
      "Epoch 1389/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.9431 - val_loss: -161.9475\n",
      "\n",
      "Epoch 01389: loss did not improve from -160.07872\n",
      "Epoch 1390/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.0572 - val_loss: -161.8941\n",
      "\n",
      "Epoch 01390: loss did not improve from -160.07872\n",
      "Epoch 1391/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.9461 - val_loss: -162.1108\n",
      "\n",
      "Epoch 01391: loss did not improve from -160.07872\n",
      "Epoch 1392/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.9462 - val_loss: -161.4831\n",
      "\n",
      "Epoch 01392: loss did not improve from -160.07872\n",
      "Epoch 1393/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.0294 - val_loss: -162.2430\n",
      "\n",
      "Epoch 01393: loss did not improve from -160.07872\n",
      "Epoch 1394/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.7695 - val_loss: -161.4437\n",
      "\n",
      "Epoch 01394: loss did not improve from -160.07872\n",
      "Epoch 1395/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.8093 - val_loss: -161.6164\n",
      "\n",
      "Epoch 01395: loss did not improve from -160.07872\n",
      "Epoch 1396/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.6680 - val_loss: -162.1985\n",
      "\n",
      "Epoch 01396: loss did not improve from -160.07872\n",
      "Epoch 1397/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.8203 - val_loss: -161.1781\n",
      "\n",
      "Epoch 01397: loss did not improve from -160.07872\n",
      "Epoch 1398/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -159.9892 - val_loss: -162.1979\n",
      "\n",
      "Epoch 01398: loss did not improve from -160.07872\n",
      "Epoch 1399/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.1040 - val_loss: -162.0456\n",
      "\n",
      "Epoch 01399: loss improved from -160.07872 to -160.10397, saving model to gendance.h5\n",
      "Epoch 1400/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.8472 - val_loss: -161.7229\n",
      "\n",
      "Epoch 01400: loss did not improve from -160.10397\n",
      "Epoch 1401/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.8774 - val_loss: -162.1631\n",
      "\n",
      "Epoch 01401: loss did not improve from -160.10397\n",
      "Epoch 1402/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.4503 - val_loss: -161.0098\n",
      "\n",
      "Epoch 01402: loss did not improve from -160.10397\n",
      "Epoch 1403/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.7634 - val_loss: -162.2498\n",
      "\n",
      "Epoch 01403: loss did not improve from -160.10397\n",
      "Epoch 1404/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.9537 - val_loss: -161.7096\n",
      "\n",
      "Epoch 01404: loss did not improve from -160.10397\n",
      "Epoch 1405/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.8431 - val_loss: -162.0977\n",
      "\n",
      "Epoch 01405: loss did not improve from -160.10397\n",
      "Epoch 1406/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.9568 - val_loss: -162.2000\n",
      "\n",
      "Epoch 01406: loss did not improve from -160.10397\n",
      "Epoch 1407/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.9663 - val_loss: -161.4251\n",
      "\n",
      "Epoch 01407: loss did not improve from -160.10397\n",
      "Epoch 1408/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.6622 - val_loss: -162.3524\n",
      "\n",
      "Epoch 01408: loss did not improve from -160.10397\n",
      "Epoch 1409/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.7458 - val_loss: -161.1637\n",
      "\n",
      "Epoch 01409: loss did not improve from -160.10397\n",
      "Epoch 1410/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -159.8552 - val_loss: -162.2598\n",
      "\n",
      "Epoch 01410: loss did not improve from -160.10397\n",
      "Epoch 1411/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.9908 - val_loss: -161.9821\n",
      "\n",
      "Epoch 01411: loss did not improve from -160.10397\n",
      "Epoch 1412/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -159.8364 - val_loss: -161.5288\n",
      "\n",
      "Epoch 01412: loss did not improve from -160.10397\n",
      "Epoch 1413/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.9143 - val_loss: -162.0252\n",
      "\n",
      "Epoch 01413: loss did not improve from -160.10397\n",
      "Epoch 1414/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.7301 - val_loss: -160.8973\n",
      "\n",
      "Epoch 01414: loss did not improve from -160.10397\n",
      "Epoch 1415/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.6969 - val_loss: -161.8636\n",
      "\n",
      "Epoch 01415: loss did not improve from -160.10397\n",
      "Epoch 1416/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.8062 - val_loss: -162.1833\n",
      "\n",
      "Epoch 01416: loss did not improve from -160.10397\n",
      "Epoch 1417/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.8007 - val_loss: -161.5133\n",
      "\n",
      "Epoch 01417: loss did not improve from -160.10397\n",
      "Epoch 1418/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.7695 - val_loss: -161.9262\n",
      "\n",
      "Epoch 01418: loss did not improve from -160.10397\n",
      "Epoch 1419/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.8478 - val_loss: -161.8191\n",
      "\n",
      "Epoch 01419: loss did not improve from -160.10397\n",
      "Epoch 1420/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.0000 - val_loss: -162.1441\n",
      "\n",
      "Epoch 01420: loss did not improve from -160.10397\n",
      "Epoch 1421/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.9037 - val_loss: -162.1956\n",
      "\n",
      "Epoch 01421: loss did not improve from -160.10397\n",
      "Epoch 1422/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.1281 - val_loss: -161.9774\n",
      "\n",
      "Epoch 01422: loss improved from -160.10397 to -160.12811, saving model to gendance.h5\n",
      "Epoch 1423/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.1079 - val_loss: -162.5281\n",
      "\n",
      "Epoch 01423: loss did not improve from -160.12811\n",
      "Epoch 1424/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.2154 - val_loss: -162.2030\n",
      "\n",
      "Epoch 01424: loss improved from -160.12811 to -160.21538, saving model to gendance.h5\n",
      "Epoch 1425/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.1237 - val_loss: -162.2963\n",
      "\n",
      "Epoch 01425: loss did not improve from -160.21538\n",
      "Epoch 1426/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.3286 - val_loss: -162.5269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01426: loss improved from -160.21538 to -160.32857, saving model to gendance.h5\n",
      "Epoch 1427/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.1489 - val_loss: -162.1936\n",
      "\n",
      "Epoch 01427: loss did not improve from -160.32857\n",
      "Epoch 1428/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.2502 - val_loss: -162.4910\n",
      "\n",
      "Epoch 01428: loss did not improve from -160.32857\n",
      "Epoch 1429/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.3255 - val_loss: -162.0695\n",
      "\n",
      "Epoch 01429: loss did not improve from -160.32857\n",
      "Epoch 1430/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.4644 - val_loss: -162.6207\n",
      "\n",
      "Epoch 01430: loss improved from -160.32857 to -160.46439, saving model to gendance.h5\n",
      "Epoch 1431/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.1596 - val_loss: -162.0641\n",
      "\n",
      "Epoch 01431: loss did not improve from -160.46439\n",
      "Epoch 1432/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.3341 - val_loss: -162.3634\n",
      "\n",
      "Epoch 01432: loss did not improve from -160.46439\n",
      "Epoch 1433/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.9386 - val_loss: -162.2048\n",
      "\n",
      "Epoch 01433: loss did not improve from -160.46439\n",
      "Epoch 1434/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.1226 - val_loss: -161.0558\n",
      "\n",
      "Epoch 01434: loss did not improve from -160.46439\n",
      "Epoch 1435/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.0788 - val_loss: -162.6257\n",
      "\n",
      "Epoch 01435: loss did not improve from -160.46439\n",
      "Epoch 1436/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.8646 - val_loss: -161.3396\n",
      "\n",
      "Epoch 01436: loss did not improve from -160.46439\n",
      "Epoch 1437/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.1317 - val_loss: -161.9008\n",
      "\n",
      "Epoch 01437: loss did not improve from -160.46439\n",
      "Epoch 1438/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.0163 - val_loss: -162.4647\n",
      "\n",
      "Epoch 01438: loss did not improve from -160.46439\n",
      "Epoch 1439/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.7998 - val_loss: -161.0119\n",
      "\n",
      "Epoch 01439: loss did not improve from -160.46439\n",
      "Epoch 1440/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.9258 - val_loss: -162.4990\n",
      "\n",
      "Epoch 01440: loss did not improve from -160.46439\n",
      "Epoch 1441/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.0797 - val_loss: -161.9754\n",
      "\n",
      "Epoch 01441: loss did not improve from -160.46439\n",
      "Epoch 1442/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.1600 - val_loss: -161.7217\n",
      "\n",
      "Epoch 01442: loss did not improve from -160.46439\n",
      "Epoch 1443/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.3651 - val_loss: -162.7864\n",
      "\n",
      "Epoch 01443: loss did not improve from -160.46439\n",
      "Epoch 1444/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.2242 - val_loss: -161.3320\n",
      "\n",
      "Epoch 01444: loss did not improve from -160.46439\n",
      "Epoch 1445/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.1970 - val_loss: -162.3868\n",
      "\n",
      "Epoch 01445: loss did not improve from -160.46439\n",
      "Epoch 1446/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.2124 - val_loss: -162.4934\n",
      "\n",
      "Epoch 01446: loss did not improve from -160.46439\n",
      "Epoch 1447/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.4601 - val_loss: -162.0357\n",
      "\n",
      "Epoch 01447: loss did not improve from -160.46439\n",
      "Epoch 1448/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.5580 - val_loss: -162.5735\n",
      "\n",
      "Epoch 01448: loss improved from -160.46439 to -160.55796, saving model to gendance.h5\n",
      "Epoch 1449/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.3093 - val_loss: -162.0505\n",
      "\n",
      "Epoch 01449: loss did not improve from -160.55796\n",
      "Epoch 1450/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.5823 - val_loss: -162.8596\n",
      "\n",
      "Epoch 01450: loss improved from -160.55796 to -160.58233, saving model to gendance.h5\n",
      "Epoch 1451/10000\n",
      "16167/16167 [==============================] - 1s 31us/step - loss: -160.4291 - val_loss: -162.5969\n",
      "\n",
      "Epoch 01451: loss did not improve from -160.58233\n",
      "Epoch 1452/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.4929 - val_loss: -162.0894\n",
      "\n",
      "Epoch 01452: loss did not improve from -160.58233\n",
      "Epoch 1453/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -160.2421 - val_loss: -162.5400\n",
      "\n",
      "Epoch 01453: loss did not improve from -160.58233\n",
      "Epoch 1454/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.5972 - val_loss: -162.6369\n",
      "\n",
      "Epoch 01454: loss improved from -160.58233 to -160.59719, saving model to gendance.h5\n",
      "Epoch 1455/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.3772 - val_loss: -161.8114\n",
      "\n",
      "Epoch 01455: loss did not improve from -160.59719\n",
      "Epoch 1456/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.1814 - val_loss: -162.5982\n",
      "\n",
      "Epoch 01456: loss did not improve from -160.59719\n",
      "Epoch 1457/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.2677 - val_loss: -161.4755\n",
      "\n",
      "Epoch 01457: loss did not improve from -160.59719\n",
      "Epoch 1458/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.3369 - val_loss: -162.4969\n",
      "\n",
      "Epoch 01458: loss did not improve from -160.59719\n",
      "Epoch 1459/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.4665 - val_loss: -162.8725\n",
      "\n",
      "Epoch 01459: loss did not improve from -160.59719\n",
      "Epoch 1460/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -160.3272 - val_loss: -161.2506\n",
      "\n",
      "Epoch 01460: loss did not improve from -160.59719\n",
      "Epoch 1461/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.1857 - val_loss: -162.6837\n",
      "\n",
      "Epoch 01461: loss did not improve from -160.59719\n",
      "Epoch 1462/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.3555 - val_loss: -161.9320\n",
      "\n",
      "Epoch 01462: loss did not improve from -160.59719\n",
      "Epoch 1463/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.2832 - val_loss: -162.6032\n",
      "\n",
      "Epoch 01463: loss did not improve from -160.59719\n",
      "Epoch 1464/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.4204 - val_loss: -162.6462\n",
      "\n",
      "Epoch 01464: loss did not improve from -160.59719\n",
      "Epoch 1465/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.4418 - val_loss: -162.2484\n",
      "\n",
      "Epoch 01465: loss did not improve from -160.59719\n",
      "Epoch 1466/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.4408 - val_loss: -162.8318\n",
      "\n",
      "Epoch 01466: loss did not improve from -160.59719\n",
      "Epoch 1467/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.5318 - val_loss: -161.8700\n",
      "\n",
      "Epoch 01467: loss did not improve from -160.59719\n",
      "Epoch 1468/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.5974 - val_loss: -162.9086\n",
      "\n",
      "Epoch 01468: loss improved from -160.59719 to -160.59744, saving model to gendance.h5\n",
      "Epoch 1469/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.5635 - val_loss: -162.7301\n",
      "\n",
      "Epoch 01469: loss did not improve from -160.59744\n",
      "Epoch 1470/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.7104 - val_loss: -162.2887\n",
      "\n",
      "Epoch 01470: loss improved from -160.59744 to -160.71043, saving model to gendance.h5\n",
      "Epoch 1471/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.7834 - val_loss: -163.0789\n",
      "\n",
      "Epoch 01471: loss improved from -160.71043 to -160.78337, saving model to gendance.h5\n",
      "Epoch 1472/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.3066 - val_loss: -161.8449\n",
      "\n",
      "Epoch 01472: loss did not improve from -160.78337\n",
      "Epoch 1473/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.5158 - val_loss: -162.2940\n",
      "\n",
      "Epoch 01473: loss did not improve from -160.78337\n",
      "Epoch 1474/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.5216 - val_loss: -163.1102\n",
      "\n",
      "Epoch 01474: loss did not improve from -160.78337\n",
      "Epoch 1475/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.5479 - val_loss: -162.1016\n",
      "\n",
      "Epoch 01475: loss did not improve from -160.78337\n",
      "Epoch 1476/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.6614 - val_loss: -162.7955\n",
      "\n",
      "Epoch 01476: loss did not improve from -160.78337\n",
      "Epoch 1477/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.5615 - val_loss: -162.4472\n",
      "\n",
      "Epoch 01477: loss did not improve from -160.78337\n",
      "Epoch 1478/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.7551 - val_loss: -162.8046\n",
      "\n",
      "Epoch 01478: loss did not improve from -160.78337\n",
      "Epoch 1479/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.6459 - val_loss: -162.6993\n",
      "\n",
      "Epoch 01479: loss did not improve from -160.78337\n",
      "Epoch 1480/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.5957 - val_loss: -162.5517\n",
      "\n",
      "Epoch 01480: loss did not improve from -160.78337\n",
      "Epoch 1481/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.8956 - val_loss: -163.1665\n",
      "\n",
      "Epoch 01481: loss improved from -160.78337 to -160.89555, saving model to gendance.h5\n",
      "Epoch 1482/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.6902 - val_loss: -162.3258\n",
      "\n",
      "Epoch 01482: loss did not improve from -160.89555\n",
      "Epoch 1483/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.8278 - val_loss: -163.1175\n",
      "\n",
      "Epoch 01483: loss did not improve from -160.89555\n",
      "Epoch 1484/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.8698 - val_loss: -162.8778\n",
      "\n",
      "Epoch 01484: loss did not improve from -160.89555\n",
      "Epoch 1485/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.6534 - val_loss: -162.5289\n",
      "\n",
      "Epoch 01485: loss did not improve from -160.89555\n",
      "Epoch 1486/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.9560 - val_loss: -163.3197\n",
      "\n",
      "Epoch 01486: loss improved from -160.89555 to -160.95603, saving model to gendance.h5\n",
      "Epoch 1487/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.6369 - val_loss: -161.8710\n",
      "\n",
      "Epoch 01487: loss did not improve from -160.95603\n",
      "Epoch 1488/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.7562 - val_loss: -162.8987\n",
      "\n",
      "Epoch 01488: loss did not improve from -160.95603\n",
      "Epoch 1489/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.7721 - val_loss: -162.8931\n",
      "\n",
      "Epoch 01489: loss did not improve from -160.95603\n",
      "Epoch 1490/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.8627 - val_loss: -162.3931\n",
      "\n",
      "Epoch 01490: loss did not improve from -160.95603\n",
      "Epoch 1491/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.6012 - val_loss: -163.0172\n",
      "\n",
      "Epoch 01491: loss did not improve from -160.95603\n",
      "Epoch 1492/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.6832 - val_loss: -161.7341\n",
      "\n",
      "Epoch 01492: loss did not improve from -160.95603\n",
      "Epoch 1493/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.2382 - val_loss: -162.6005\n",
      "\n",
      "Epoch 01493: loss did not improve from -160.95603\n",
      "Epoch 1494/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.3429 - val_loss: -162.4269\n",
      "\n",
      "Epoch 01494: loss did not improve from -160.95603\n",
      "Epoch 1495/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.0503 - val_loss: -161.4015\n",
      "\n",
      "Epoch 01495: loss did not improve from -160.95603\n",
      "Epoch 1496/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.0742 - val_loss: -162.4953\n",
      "\n",
      "Epoch 01496: loss did not improve from -160.95603\n",
      "Epoch 1497/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -159.9526 - val_loss: -160.8600\n",
      "\n",
      "Epoch 01497: loss did not improve from -160.95603\n",
      "Epoch 1498/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.1114 - val_loss: -162.5876\n",
      "\n",
      "Epoch 01498: loss did not improve from -160.95603\n",
      "Epoch 1499/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.5566 - val_loss: -162.6749\n",
      "\n",
      "Epoch 01499: loss did not improve from -160.95603\n",
      "Epoch 1500/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.3913 - val_loss: -161.8678\n",
      "\n",
      "Epoch 01500: loss did not improve from -160.95603\n",
      "Epoch 1501/10000\n",
      "16167/16167 [==============================] - 1s 32us/step - loss: -160.4464 - val_loss: -163.1245\n",
      "\n",
      "Epoch 01501: loss did not improve from -160.95603\n",
      "Epoch 1502/10000\n",
      "16167/16167 [==============================] - 1s 32us/step - loss: -160.5474 - val_loss: -161.7592\n",
      "\n",
      "Epoch 01502: loss did not improve from -160.95603\n",
      "Epoch 1503/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.7690 - val_loss: -163.0122\n",
      "\n",
      "Epoch 01503: loss did not improve from -160.95603\n",
      "Epoch 1504/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.0289 - val_loss: -162.9112\n",
      "\n",
      "Epoch 01504: loss improved from -160.95603 to -161.02893, saving model to gendance.h5\n",
      "Epoch 1505/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.6106 - val_loss: -162.3001\n",
      "\n",
      "Epoch 01505: loss did not improve from -161.02893\n",
      "Epoch 1506/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.8347 - val_loss: -163.2543\n",
      "\n",
      "Epoch 01506: loss did not improve from -161.02893\n",
      "Epoch 1507/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.9686 - val_loss: -162.2951\n",
      "\n",
      "Epoch 01507: loss did not improve from -161.02893\n",
      "Epoch 1508/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.9231 - val_loss: -162.9982\n",
      "\n",
      "Epoch 01508: loss did not improve from -161.02893\n",
      "Epoch 1509/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.8572 - val_loss: -163.1344\n",
      "\n",
      "Epoch 01509: loss did not improve from -161.02893\n",
      "Epoch 1510/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.9448 - val_loss: -162.6993\n",
      "\n",
      "Epoch 01510: loss did not improve from -161.02893\n",
      "Epoch 1511/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.0313 - val_loss: -163.5650\n",
      "\n",
      "Epoch 01511: loss improved from -161.02893 to -161.03127, saving model to gendance.h5\n",
      "Epoch 1512/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.9526 - val_loss: -162.6623\n",
      "\n",
      "Epoch 01512: loss did not improve from -161.03127\n",
      "Epoch 1513/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.0449 - val_loss: -163.1267\n",
      "\n",
      "Epoch 01513: loss improved from -161.03127 to -161.04486, saving model to gendance.h5\n",
      "Epoch 1514/10000\n",
      "16167/16167 [==============================] - 1s 31us/step - loss: -160.9933 - val_loss: -163.2197\n",
      "\n",
      "Epoch 01514: loss did not improve from -161.04486\n",
      "Epoch 1515/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.9017 - val_loss: -162.8278\n",
      "\n",
      "Epoch 01515: loss did not improve from -161.04486\n",
      "Epoch 1516/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.0475 - val_loss: -163.4729\n",
      "\n",
      "Epoch 01516: loss improved from -161.04486 to -161.04752, saving model to gendance.h5\n",
      "Epoch 1517/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.0746 - val_loss: -162.9082\n",
      "\n",
      "Epoch 01517: loss improved from -161.04752 to -161.07461, saving model to gendance.h5\n",
      "Epoch 1518/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.7375 - val_loss: -162.9809\n",
      "\n",
      "Epoch 01518: loss did not improve from -161.07461\n",
      "Epoch 1519/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.0799 - val_loss: -162.9708\n",
      "\n",
      "Epoch 01519: loss improved from -161.07461 to -161.07991, saving model to gendance.h5\n",
      "Epoch 1520/10000\n",
      "16167/16167 [==============================] - 1s 33us/step - loss: -160.9140 - val_loss: -162.5369\n",
      "\n",
      "Epoch 01520: loss did not improve from -161.07991\n",
      "Epoch 1521/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.9731 - val_loss: -163.1670\n",
      "\n",
      "Epoch 01521: loss did not improve from -161.07991\n",
      "Epoch 1522/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.8960 - val_loss: -162.7153\n",
      "\n",
      "Epoch 01522: loss did not improve from -161.07991\n",
      "Epoch 1523/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.7961 - val_loss: -163.1761\n",
      "\n",
      "Epoch 01523: loss did not improve from -161.07991\n",
      "Epoch 1524/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.8346 - val_loss: -162.8977\n",
      "\n",
      "Epoch 01524: loss did not improve from -161.07991\n",
      "Epoch 1525/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.0958 - val_loss: -162.7849\n",
      "\n",
      "Epoch 01525: loss improved from -161.07991 to -161.09580, saving model to gendance.h5\n",
      "Epoch 1526/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.9172 - val_loss: -163.3869\n",
      "\n",
      "Epoch 01526: loss did not improve from -161.09580\n",
      "Epoch 1527/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.9011 - val_loss: -162.3277\n",
      "\n",
      "Epoch 01527: loss did not improve from -161.09580\n",
      "Epoch 1528/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.8134 - val_loss: -163.2641\n",
      "\n",
      "Epoch 01528: loss did not improve from -161.09580\n",
      "Epoch 1529/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.8130 - val_loss: -163.0364\n",
      "\n",
      "Epoch 01529: loss did not improve from -161.09580\n",
      "Epoch 1530/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.7880 - val_loss: -162.3069\n",
      "\n",
      "Epoch 01530: loss did not improve from -161.09580\n",
      "Epoch 1531/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.6004 - val_loss: -162.9901\n",
      "\n",
      "Epoch 01531: loss did not improve from -161.09580\n",
      "Epoch 1532/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.4677 - val_loss: -161.6266\n",
      "\n",
      "Epoch 01532: loss did not improve from -161.09580\n",
      "Epoch 1533/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.7064 - val_loss: -163.2213\n",
      "\n",
      "Epoch 01533: loss did not improve from -161.09580\n",
      "Epoch 1534/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.1427 - val_loss: -163.4339\n",
      "\n",
      "Epoch 01534: loss improved from -161.09580 to -161.14272, saving model to gendance.h5\n",
      "Epoch 1535/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.1256 - val_loss: -162.9325\n",
      "\n",
      "Epoch 01535: loss did not improve from -161.14272\n",
      "Epoch 1536/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.9045 - val_loss: -163.5212\n",
      "\n",
      "Epoch 01536: loss did not improve from -161.14272\n",
      "Epoch 1537/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.1859 - val_loss: -162.4507\n",
      "\n",
      "Epoch 01537: loss improved from -161.14272 to -161.18593, saving model to gendance.h5\n",
      "Epoch 1538/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.9287 - val_loss: -163.3276\n",
      "\n",
      "Epoch 01538: loss did not improve from -161.18593\n",
      "Epoch 1539/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.1845 - val_loss: -163.5090\n",
      "\n",
      "Epoch 01539: loss did not improve from -161.18593\n",
      "Epoch 1540/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.1593 - val_loss: -163.0882\n",
      "\n",
      "Epoch 01540: loss did not improve from -161.18593\n",
      "Epoch 1541/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.1652 - val_loss: -163.7886\n",
      "\n",
      "Epoch 01541: loss did not improve from -161.18593\n",
      "Epoch 1542/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.9693 - val_loss: -162.7111\n",
      "\n",
      "Epoch 01542: loss did not improve from -161.18593\n",
      "Epoch 1543/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.0023 - val_loss: -163.2431\n",
      "\n",
      "Epoch 01543: loss did not improve from -161.18593\n",
      "Epoch 1544/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.1072 - val_loss: -163.1821\n",
      "\n",
      "Epoch 01544: loss did not improve from -161.18593\n",
      "Epoch 1545/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.0401 - val_loss: -163.2250\n",
      "\n",
      "Epoch 01545: loss did not improve from -161.18593\n",
      "Epoch 1546/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.8908 - val_loss: -163.4156\n",
      "\n",
      "Epoch 01546: loss did not improve from -161.18593\n",
      "Epoch 1547/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.0940 - val_loss: -162.6448\n",
      "\n",
      "Epoch 01547: loss did not improve from -161.18593\n",
      "Epoch 1548/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.9806 - val_loss: -163.3678\n",
      "\n",
      "Epoch 01548: loss did not improve from -161.18593\n",
      "Epoch 1549/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.8357 - val_loss: -162.4779\n",
      "\n",
      "Epoch 01549: loss did not improve from -161.18593\n",
      "Epoch 1550/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.2979 - val_loss: -163.4041\n",
      "\n",
      "Epoch 01550: loss improved from -161.18593 to -161.29789, saving model to gendance.h5\n",
      "Epoch 1551/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.2795 - val_loss: -163.6732\n",
      "\n",
      "Epoch 01551: loss did not improve from -161.29789\n",
      "Epoch 1552/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.9781 - val_loss: -162.3956\n",
      "\n",
      "Epoch 01552: loss did not improve from -161.29789\n",
      "Epoch 1553/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.8679 - val_loss: -163.3711\n",
      "\n",
      "Epoch 01553: loss did not improve from -161.29789\n",
      "Epoch 1554/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.9069 - val_loss: -162.5253\n",
      "\n",
      "Epoch 01554: loss did not improve from -161.29789\n",
      "Epoch 1555/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.8263 - val_loss: -163.3720\n",
      "\n",
      "Epoch 01555: loss did not improve from -161.29789\n",
      "Epoch 1556/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.0216 - val_loss: -163.6842\n",
      "\n",
      "Epoch 01556: loss did not improve from -161.29789\n",
      "Epoch 1557/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.6169 - val_loss: -161.8031\n",
      "\n",
      "Epoch 01557: loss did not improve from -161.29789\n",
      "Epoch 1558/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.8653 - val_loss: -163.4776\n",
      "\n",
      "Epoch 01558: loss did not improve from -161.29789\n",
      "Epoch 1559/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -160.6648 - val_loss: -162.7409\n",
      "\n",
      "Epoch 01559: loss did not improve from -161.29789\n",
      "Epoch 1560/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.0617 - val_loss: -163.4160\n",
      "\n",
      "Epoch 01560: loss did not improve from -161.29789\n",
      "Epoch 1561/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.4015 - val_loss: -163.4628\n",
      "\n",
      "Epoch 01561: loss improved from -161.29789 to -161.40152, saving model to gendance.h5\n",
      "Epoch 1562/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -161.1765 - val_loss: -163.3499\n",
      "\n",
      "Epoch 01562: loss did not improve from -161.40152\n",
      "Epoch 1563/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.3744 - val_loss: -163.5837\n",
      "\n",
      "Epoch 01563: loss did not improve from -161.40152\n",
      "Epoch 1564/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.1901 - val_loss: -162.8901\n",
      "\n",
      "Epoch 01564: loss did not improve from -161.40152\n",
      "Epoch 1565/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.1709 - val_loss: -163.4263\n",
      "\n",
      "Epoch 01565: loss did not improve from -161.40152\n",
      "Epoch 1566/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.3125 - val_loss: -163.6042\n",
      "\n",
      "Epoch 01566: loss did not improve from -161.40152\n",
      "Epoch 1567/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.2694 - val_loss: -163.0638\n",
      "\n",
      "Epoch 01567: loss did not improve from -161.40152\n",
      "Epoch 1568/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.2617 - val_loss: -163.6006\n",
      "\n",
      "Epoch 01568: loss did not improve from -161.40152\n",
      "Epoch 1569/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.1276 - val_loss: -162.7493\n",
      "\n",
      "Epoch 01569: loss did not improve from -161.40152\n",
      "Epoch 1570/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.3501 - val_loss: -163.8545\n",
      "\n",
      "Epoch 01570: loss did not improve from -161.40152\n",
      "Epoch 1571/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.1094 - val_loss: -163.0177\n",
      "\n",
      "Epoch 01571: loss did not improve from -161.40152\n",
      "Epoch 1572/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.4126 - val_loss: -163.5126\n",
      "\n",
      "Epoch 01572: loss improved from -161.40152 to -161.41264, saving model to gendance.h5\n",
      "Epoch 1573/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.1735 - val_loss: -163.9444\n",
      "\n",
      "Epoch 01573: loss did not improve from -161.41264\n",
      "Epoch 1574/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.2209 - val_loss: -162.5900\n",
      "\n",
      "Epoch 01574: loss did not improve from -161.41264\n",
      "Epoch 1575/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.1692 - val_loss: -163.8926\n",
      "\n",
      "Epoch 01575: loss did not improve from -161.41264\n",
      "Epoch 1576/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.2795 - val_loss: -162.6893\n",
      "\n",
      "Epoch 01576: loss did not improve from -161.41264\n",
      "Epoch 1577/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.2683 - val_loss: -163.6533\n",
      "\n",
      "Epoch 01577: loss did not improve from -161.41264\n",
      "Epoch 1578/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.3959 - val_loss: -163.7291\n",
      "\n",
      "Epoch 01578: loss did not improve from -161.41264\n",
      "Epoch 1579/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.3982 - val_loss: -163.2178\n",
      "\n",
      "Epoch 01579: loss did not improve from -161.41264\n",
      "Epoch 1580/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.4205 - val_loss: -163.8609\n",
      "\n",
      "Epoch 01580: loss improved from -161.41264 to -161.42052, saving model to gendance.h5\n",
      "Epoch 1581/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.3453 - val_loss: -163.0923\n",
      "\n",
      "Epoch 01581: loss did not improve from -161.42052\n",
      "Epoch 1582/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.4363 - val_loss: -163.5490\n",
      "\n",
      "Epoch 01582: loss improved from -161.42052 to -161.43631, saving model to gendance.h5\n",
      "Epoch 1583/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.5778 - val_loss: -164.0932\n",
      "\n",
      "Epoch 01583: loss improved from -161.43631 to -161.57784, saving model to gendance.h5\n",
      "Epoch 1584/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.4411 - val_loss: -163.4091\n",
      "\n",
      "Epoch 01584: loss did not improve from -161.57784\n",
      "Epoch 1585/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.4722 - val_loss: -164.0997\n",
      "\n",
      "Epoch 01585: loss did not improve from -161.57784\n",
      "Epoch 1586/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.3616 - val_loss: -162.9299\n",
      "\n",
      "Epoch 01586: loss did not improve from -161.57784\n",
      "Epoch 1587/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.3562 - val_loss: -163.7786\n",
      "\n",
      "Epoch 01587: loss did not improve from -161.57784\n",
      "Epoch 1588/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.6819 - val_loss: -163.8591\n",
      "\n",
      "Epoch 01588: loss improved from -161.57784 to -161.68192, saving model to gendance.h5\n",
      "Epoch 1589/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.3498 - val_loss: -163.3921\n",
      "\n",
      "Epoch 01589: loss did not improve from -161.68192\n",
      "Epoch 1590/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.6477 - val_loss: -164.0668\n",
      "\n",
      "Epoch 01590: loss did not improve from -161.68192\n",
      "Epoch 1591/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.6120 - val_loss: -163.3204\n",
      "\n",
      "Epoch 01591: loss did not improve from -161.68192\n",
      "Epoch 1592/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.4750 - val_loss: -163.7436\n",
      "\n",
      "Epoch 01592: loss did not improve from -161.68192\n",
      "Epoch 1593/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.4809 - val_loss: -163.7239\n",
      "\n",
      "Epoch 01593: loss did not improve from -161.68192\n",
      "Epoch 1594/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.5589 - val_loss: -163.6418\n",
      "\n",
      "Epoch 01594: loss did not improve from -161.68192\n",
      "Epoch 1595/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.4921 - val_loss: -164.0003\n",
      "\n",
      "Epoch 01595: loss did not improve from -161.68192\n",
      "Epoch 1596/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.3601 - val_loss: -163.2866\n",
      "\n",
      "Epoch 01596: loss did not improve from -161.68192\n",
      "Epoch 1597/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.4474 - val_loss: -163.9273\n",
      "\n",
      "Epoch 01597: loss did not improve from -161.68192\n",
      "Epoch 1598/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.6638 - val_loss: -163.5066\n",
      "\n",
      "Epoch 01598: loss did not improve from -161.68192\n",
      "Epoch 1599/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.5650 - val_loss: -163.8379\n",
      "\n",
      "Epoch 01599: loss did not improve from -161.68192\n",
      "Epoch 1600/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.5556 - val_loss: -163.7552\n",
      "\n",
      "Epoch 01600: loss did not improve from -161.68192\n",
      "Epoch 1601/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.3429 - val_loss: -163.3155\n",
      "\n",
      "Epoch 01601: loss did not improve from -161.68192\n",
      "Epoch 1602/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.4495 - val_loss: -163.9291\n",
      "\n",
      "Epoch 01602: loss did not improve from -161.68192\n",
      "Epoch 1603/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.3303 - val_loss: -163.4385\n",
      "\n",
      "Epoch 01603: loss did not improve from -161.68192\n",
      "Epoch 1604/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.4209 - val_loss: -163.7710\n",
      "\n",
      "Epoch 01604: loss did not improve from -161.68192\n",
      "Epoch 1605/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.6981 - val_loss: -163.8888\n",
      "\n",
      "Epoch 01605: loss improved from -161.68192 to -161.69811, saving model to gendance.h5\n",
      "Epoch 1606/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.7540 - val_loss: -163.8851\n",
      "\n",
      "Epoch 01606: loss improved from -161.69811 to -161.75398, saving model to gendance.h5\n",
      "Epoch 1607/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.7714 - val_loss: -163.7929\n",
      "\n",
      "Epoch 01607: loss improved from -161.75398 to -161.77141, saving model to gendance.h5\n",
      "Epoch 1608/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.6809 - val_loss: -163.9914\n",
      "\n",
      "Epoch 01608: loss did not improve from -161.77141\n",
      "Epoch 1609/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.8201 - val_loss: -164.1331\n",
      "\n",
      "Epoch 01609: loss improved from -161.77141 to -161.82015, saving model to gendance.h5\n",
      "Epoch 1610/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.7724 - val_loss: -163.7193\n",
      "\n",
      "Epoch 01610: loss did not improve from -161.82015\n",
      "Epoch 1611/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.6934 - val_loss: -164.1750\n",
      "\n",
      "Epoch 01611: loss did not improve from -161.82015\n",
      "Epoch 1612/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.8967 - val_loss: -163.6364\n",
      "\n",
      "Epoch 01612: loss improved from -161.82015 to -161.89673, saving model to gendance.h5\n",
      "Epoch 1613/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.8630 - val_loss: -163.6626\n",
      "\n",
      "Epoch 01613: loss did not improve from -161.89673\n",
      "Epoch 1614/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.3252 - val_loss: -163.8926\n",
      "\n",
      "Epoch 01614: loss did not improve from -161.89673\n",
      "Epoch 1615/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.1533 - val_loss: -162.3205\n",
      "\n",
      "Epoch 01615: loss did not improve from -161.89673\n",
      "Epoch 1616/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.4757 - val_loss: -163.9855\n",
      "\n",
      "Epoch 01616: loss did not improve from -161.89673\n",
      "Epoch 1617/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.4243 - val_loss: -163.9761\n",
      "\n",
      "Epoch 01617: loss did not improve from -161.89673\n",
      "Epoch 1618/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.6114 - val_loss: -163.5684\n",
      "\n",
      "Epoch 01618: loss did not improve from -161.89673\n",
      "Epoch 1619/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.1892 - val_loss: -163.8666\n",
      "\n",
      "Epoch 01619: loss did not improve from -161.89673\n",
      "Epoch 1620/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.4159 - val_loss: -162.8269\n",
      "\n",
      "Epoch 01620: loss did not improve from -161.89673\n",
      "Epoch 1621/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.1035 - val_loss: -163.9769\n",
      "\n",
      "Epoch 01621: loss did not improve from -161.89673\n",
      "Epoch 1622/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.5628 - val_loss: -163.3452\n",
      "\n",
      "Epoch 01622: loss did not improve from -161.89673\n",
      "Epoch 1623/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.7130 - val_loss: -164.1009\n",
      "\n",
      "Epoch 01623: loss did not improve from -161.89673\n",
      "Epoch 1624/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.7176 - val_loss: -163.7590\n",
      "\n",
      "Epoch 01624: loss did not improve from -161.89673\n",
      "Epoch 1625/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.6154 - val_loss: -163.8311\n",
      "\n",
      "Epoch 01625: loss did not improve from -161.89673\n",
      "Epoch 1626/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.3915 - val_loss: -164.0080\n",
      "\n",
      "Epoch 01626: loss did not improve from -161.89673\n",
      "Epoch 1627/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.2789 - val_loss: -162.6899\n",
      "\n",
      "Epoch 01627: loss did not improve from -161.89673\n",
      "Epoch 1628/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.4894 - val_loss: -164.1256\n",
      "\n",
      "Epoch 01628: loss did not improve from -161.89673\n",
      "Epoch 1629/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.6907 - val_loss: -163.7802\n",
      "\n",
      "Epoch 01629: loss did not improve from -161.89673\n",
      "Epoch 1630/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.8253 - val_loss: -163.7696\n",
      "\n",
      "Epoch 01630: loss did not improve from -161.89673\n",
      "Epoch 1631/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.6728 - val_loss: -164.3141\n",
      "\n",
      "Epoch 01631: loss did not improve from -161.89673\n",
      "Epoch 1632/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.5522 - val_loss: -163.1586\n",
      "\n",
      "Epoch 01632: loss did not improve from -161.89673\n",
      "Epoch 1633/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.8233 - val_loss: -164.3775\n",
      "\n",
      "Epoch 01633: loss did not improve from -161.89673\n",
      "Epoch 1634/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.8050 - val_loss: -163.8380\n",
      "\n",
      "Epoch 01634: loss did not improve from -161.89673\n",
      "Epoch 1635/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.6845 - val_loss: -163.7667\n",
      "\n",
      "Epoch 01635: loss did not improve from -161.89673\n",
      "Epoch 1636/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.5142 - val_loss: -164.0830\n",
      "\n",
      "Epoch 01636: loss did not improve from -161.89673\n",
      "Epoch 1637/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.4134 - val_loss: -163.1556\n",
      "\n",
      "Epoch 01637: loss did not improve from -161.89673\n",
      "Epoch 1638/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.4530 - val_loss: -164.2210\n",
      "\n",
      "Epoch 01638: loss did not improve from -161.89673\n",
      "Epoch 1639/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.2543 - val_loss: -163.1136\n",
      "\n",
      "Epoch 01639: loss did not improve from -161.89673\n",
      "Epoch 1640/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.6296 - val_loss: -164.0844\n",
      "\n",
      "Epoch 01640: loss did not improve from -161.89673\n",
      "Epoch 1641/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.9833 - val_loss: -164.2666\n",
      "\n",
      "Epoch 01641: loss improved from -161.89673 to -161.98333, saving model to gendance.h5\n",
      "Epoch 1642/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.0211 - val_loss: -164.1483\n",
      "\n",
      "Epoch 01642: loss improved from -161.98333 to -162.02107, saving model to gendance.h5\n",
      "Epoch 1643/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.8691 - val_loss: -164.4540\n",
      "\n",
      "Epoch 01643: loss did not improve from -162.02107\n",
      "Epoch 1644/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.8978 - val_loss: -163.6027\n",
      "\n",
      "Epoch 01644: loss did not improve from -162.02107\n",
      "Epoch 1645/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.7752 - val_loss: -164.2610\n",
      "\n",
      "Epoch 01645: loss did not improve from -162.02107\n",
      "Epoch 1646/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.1499 - val_loss: -164.4705\n",
      "\n",
      "Epoch 01646: loss improved from -162.02107 to -162.14991, saving model to gendance.h5\n",
      "Epoch 1647/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.9761 - val_loss: -164.1970\n",
      "\n",
      "Epoch 01647: loss did not improve from -162.14991\n",
      "Epoch 1648/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.9792 - val_loss: -164.2667\n",
      "\n",
      "Epoch 01648: loss did not improve from -162.14991\n",
      "Epoch 1649/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.8701 - val_loss: -163.7956\n",
      "\n",
      "Epoch 01649: loss did not improve from -162.14991\n",
      "Epoch 1650/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.8821 - val_loss: -164.3719\n",
      "\n",
      "Epoch 01650: loss did not improve from -162.14991\n",
      "Epoch 1651/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.9030 - val_loss: -163.7237\n",
      "\n",
      "Epoch 01651: loss did not improve from -162.14991\n",
      "Epoch 1652/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.9953 - val_loss: -164.2405\n",
      "\n",
      "Epoch 01652: loss did not improve from -162.14991\n",
      "Epoch 1653/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.9787 - val_loss: -164.2589\n",
      "\n",
      "Epoch 01653: loss did not improve from -162.14991\n",
      "Epoch 1654/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.9966 - val_loss: -163.9627\n",
      "\n",
      "Epoch 01654: loss did not improve from -162.14991\n",
      "Epoch 1655/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.9910 - val_loss: -164.5206\n",
      "\n",
      "Epoch 01655: loss did not improve from -162.14991\n",
      "Epoch 1656/10000\n",
      "16167/16167 [==============================] - 1s 32us/step - loss: -161.5976 - val_loss: -163.5201\n",
      "\n",
      "Epoch 01656: loss did not improve from -162.14991\n",
      "Epoch 1657/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.0099 - val_loss: -164.5006\n",
      "\n",
      "Epoch 01657: loss did not improve from -162.14991\n",
      "Epoch 1658/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.1776 - val_loss: -164.0014\n",
      "\n",
      "Epoch 01658: loss improved from -162.14991 to -162.17757, saving model to gendance.h5\n",
      "Epoch 1659/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.8572 - val_loss: -164.2147\n",
      "\n",
      "Epoch 01659: loss did not improve from -162.17757\n",
      "Epoch 1660/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.1404 - val_loss: -164.6618\n",
      "\n",
      "Epoch 01660: loss did not improve from -162.17757\n",
      "Epoch 1661/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.2326 - val_loss: -163.4493\n",
      "\n",
      "Epoch 01661: loss improved from -162.17757 to -162.23263, saving model to gendance.h5\n",
      "Epoch 1662/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.9389 - val_loss: -164.4605\n",
      "\n",
      "Epoch 01662: loss did not improve from -162.23263\n",
      "Epoch 1663/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.7922 - val_loss: -163.7855\n",
      "\n",
      "Epoch 01663: loss did not improve from -162.23263\n",
      "Epoch 1664/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.0304 - val_loss: -163.9411\n",
      "\n",
      "Epoch 01664: loss did not improve from -162.23263\n",
      "Epoch 1665/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.9171 - val_loss: -164.4528\n",
      "\n",
      "Epoch 01665: loss did not improve from -162.23263\n",
      "Epoch 1666/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.6555 - val_loss: -162.7908\n",
      "\n",
      "Epoch 01666: loss did not improve from -162.23263\n",
      "Epoch 1667/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.5213 - val_loss: -164.6418\n",
      "\n",
      "Epoch 01667: loss did not improve from -162.23263\n",
      "Epoch 1668/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.0311 - val_loss: -163.8456\n",
      "\n",
      "Epoch 01668: loss did not improve from -162.23263\n",
      "Epoch 1669/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.0962 - val_loss: -164.1092\n",
      "\n",
      "Epoch 01669: loss did not improve from -162.23263\n",
      "Epoch 1670/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.3131 - val_loss: -164.7695\n",
      "\n",
      "Epoch 01670: loss improved from -162.23263 to -162.31309, saving model to gendance.h5\n",
      "Epoch 1671/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.3685 - val_loss: -164.1111\n",
      "\n",
      "Epoch 01671: loss improved from -162.31309 to -162.36848, saving model to gendance.h5\n",
      "Epoch 1672/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.2776 - val_loss: -164.7383\n",
      "\n",
      "Epoch 01672: loss did not improve from -162.36848\n",
      "Epoch 1673/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.1074 - val_loss: -164.1814\n",
      "\n",
      "Epoch 01673: loss did not improve from -162.36848\n",
      "Epoch 1674/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.9446 - val_loss: -164.1163\n",
      "\n",
      "Epoch 01674: loss did not improve from -162.36848\n",
      "Epoch 1675/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.9110 - val_loss: -164.5046\n",
      "\n",
      "Epoch 01675: loss did not improve from -162.36848\n",
      "Epoch 1676/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.9421 - val_loss: -163.6027\n",
      "\n",
      "Epoch 01676: loss did not improve from -162.36848\n",
      "Epoch 1677/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.0881 - val_loss: -164.2296\n",
      "\n",
      "Epoch 01677: loss did not improve from -162.36848\n",
      "Epoch 1678/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.1909 - val_loss: -164.4375\n",
      "\n",
      "Epoch 01678: loss did not improve from -162.36848\n",
      "Epoch 1679/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.1527 - val_loss: -164.0911\n",
      "\n",
      "Epoch 01679: loss did not improve from -162.36848\n",
      "Epoch 1680/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.0932 - val_loss: -164.6960\n",
      "\n",
      "Epoch 01680: loss did not improve from -162.36848\n",
      "Epoch 1681/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.0635 - val_loss: -163.9211\n",
      "\n",
      "Epoch 01681: loss did not improve from -162.36848\n",
      "Epoch 1682/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.0453 - val_loss: -164.5736\n",
      "\n",
      "Epoch 01682: loss did not improve from -162.36848\n",
      "Epoch 1683/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.0109 - val_loss: -164.1304\n",
      "\n",
      "Epoch 01683: loss did not improve from -162.36848\n",
      "Epoch 1684/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.3198 - val_loss: -164.3959\n",
      "\n",
      "Epoch 01684: loss did not improve from -162.36848\n",
      "Epoch 1685/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.0232 - val_loss: -164.7474\n",
      "\n",
      "Epoch 01685: loss did not improve from -162.36848\n",
      "Epoch 1686/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.9085 - val_loss: -163.7229\n",
      "\n",
      "Epoch 01686: loss did not improve from -162.36848\n",
      "Epoch 1687/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.1147 - val_loss: -164.7525\n",
      "\n",
      "Epoch 01687: loss did not improve from -162.36848\n",
      "Epoch 1688/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.9911 - val_loss: -163.9118\n",
      "\n",
      "Epoch 01688: loss did not improve from -162.36848\n",
      "Epoch 1689/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.9671 - val_loss: -163.8709\n",
      "\n",
      "Epoch 01689: loss did not improve from -162.36848\n",
      "Epoch 1690/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.7941 - val_loss: -164.7121\n",
      "\n",
      "Epoch 01690: loss did not improve from -162.36848\n",
      "Epoch 1691/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.3912 - val_loss: -163.1171\n",
      "\n",
      "Epoch 01691: loss did not improve from -162.36848\n",
      "Epoch 1692/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.9150 - val_loss: -164.6271\n",
      "\n",
      "Epoch 01692: loss did not improve from -162.36848\n",
      "Epoch 1693/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.0063 - val_loss: -163.8008\n",
      "\n",
      "Epoch 01693: loss did not improve from -162.36848\n",
      "Epoch 1694/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.3641 - val_loss: -164.6493\n",
      "\n",
      "Epoch 01694: loss did not improve from -162.36848\n",
      "Epoch 1695/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.4797 - val_loss: -164.6801\n",
      "\n",
      "Epoch 01695: loss improved from -162.36848 to -162.47965, saving model to gendance.h5\n",
      "Epoch 1696/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.4718 - val_loss: -164.1668\n",
      "\n",
      "Epoch 01696: loss did not improve from -162.47965\n",
      "Epoch 1697/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.0388 - val_loss: -164.7483\n",
      "\n",
      "Epoch 01697: loss did not improve from -162.47965\n",
      "Epoch 1698/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.0039 - val_loss: -163.2316\n",
      "\n",
      "Epoch 01698: loss did not improve from -162.47965\n",
      "Epoch 1699/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -161.8798 - val_loss: -164.5113\n",
      "\n",
      "Epoch 01699: loss did not improve from -162.47965\n",
      "Epoch 1700/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.1576 - val_loss: -164.2829\n",
      "\n",
      "Epoch 01700: loss did not improve from -162.47965\n",
      "Epoch 1701/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.3125 - val_loss: -164.3944\n",
      "\n",
      "Epoch 01701: loss did not improve from -162.47965\n",
      "Epoch 1702/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.1139 - val_loss: -164.5710\n",
      "\n",
      "Epoch 01702: loss did not improve from -162.47965\n",
      "Epoch 1703/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.0167 - val_loss: -163.9500\n",
      "\n",
      "Epoch 01703: loss did not improve from -162.47965\n",
      "Epoch 1704/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.0886 - val_loss: -164.5698\n",
      "\n",
      "Epoch 01704: loss did not improve from -162.47965\n",
      "Epoch 1705/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.0948 - val_loss: -164.6732\n",
      "\n",
      "Epoch 01705: loss did not improve from -162.47965\n",
      "Epoch 1706/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.2122 - val_loss: -164.1466\n",
      "\n",
      "Epoch 01706: loss did not improve from -162.47965\n",
      "Epoch 1707/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.1022 - val_loss: -164.5605\n",
      "\n",
      "Epoch 01707: loss did not improve from -162.47965\n",
      "Epoch 1708/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.5027 - val_loss: -164.3652\n",
      "\n",
      "Epoch 01708: loss improved from -162.47965 to -162.50274, saving model to gendance.h5\n",
      "Epoch 1709/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.2877 - val_loss: -164.8543\n",
      "\n",
      "Epoch 01709: loss did not improve from -162.50274\n",
      "Epoch 1710/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.5111 - val_loss: -164.6362\n",
      "\n",
      "Epoch 01710: loss improved from -162.50274 to -162.51110, saving model to gendance.h5\n",
      "Epoch 1711/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.4968 - val_loss: -164.6903\n",
      "\n",
      "Epoch 01711: loss did not improve from -162.51110\n",
      "Epoch 1712/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.2622 - val_loss: -164.5802\n",
      "\n",
      "Epoch 01712: loss did not improve from -162.51110\n",
      "Epoch 1713/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.1755 - val_loss: -164.3140\n",
      "\n",
      "Epoch 01713: loss did not improve from -162.51110\n",
      "Epoch 1714/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.3798 - val_loss: -165.0063\n",
      "\n",
      "Epoch 01714: loss did not improve from -162.51110\n",
      "Epoch 1715/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.2651 - val_loss: -163.9071\n",
      "\n",
      "Epoch 01715: loss did not improve from -162.51110\n",
      "Epoch 1716/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.2958 - val_loss: -164.7775\n",
      "\n",
      "Epoch 01716: loss did not improve from -162.51110\n",
      "Epoch 1717/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.2521 - val_loss: -164.8720\n",
      "\n",
      "Epoch 01717: loss did not improve from -162.51110\n",
      "Epoch 1718/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.2370 - val_loss: -164.1843\n",
      "\n",
      "Epoch 01718: loss did not improve from -162.51110\n",
      "Epoch 1719/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.2649 - val_loss: -164.8062\n",
      "\n",
      "Epoch 01719: loss did not improve from -162.51110\n",
      "Epoch 1720/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.0728 - val_loss: -164.1132\n",
      "\n",
      "Epoch 01720: loss did not improve from -162.51110\n",
      "Epoch 1721/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.3736 - val_loss: -164.8239\n",
      "\n",
      "Epoch 01721: loss did not improve from -162.51110\n",
      "Epoch 1722/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.4754 - val_loss: -165.0661\n",
      "\n",
      "Epoch 01722: loss did not improve from -162.51110\n",
      "Epoch 1723/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.6803 - val_loss: -164.2514\n",
      "\n",
      "Epoch 01723: loss improved from -162.51110 to -162.68032, saving model to gendance.h5\n",
      "Epoch 1724/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.1458 - val_loss: -164.9211\n",
      "\n",
      "Epoch 01724: loss did not improve from -162.68032\n",
      "Epoch 1725/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.1934 - val_loss: -164.0119\n",
      "\n",
      "Epoch 01725: loss did not improve from -162.68032\n",
      "Epoch 1726/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.2158 - val_loss: -164.8287\n",
      "\n",
      "Epoch 01726: loss did not improve from -162.68032\n",
      "Epoch 1727/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.4361 - val_loss: -164.9541\n",
      "\n",
      "Epoch 01727: loss did not improve from -162.68032\n",
      "Epoch 1728/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.6073 - val_loss: -164.4965\n",
      "\n",
      "Epoch 01728: loss did not improve from -162.68032\n",
      "Epoch 1729/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.5253 - val_loss: -165.0700\n",
      "\n",
      "Epoch 01729: loss did not improve from -162.68032\n",
      "Epoch 1730/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.4334 - val_loss: -164.2798\n",
      "\n",
      "Epoch 01730: loss did not improve from -162.68032\n",
      "Epoch 1731/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.5213 - val_loss: -164.6746\n",
      "\n",
      "Epoch 01731: loss did not improve from -162.68032\n",
      "Epoch 1732/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.4734 - val_loss: -164.8664\n",
      "\n",
      "Epoch 01732: loss did not improve from -162.68032\n",
      "Epoch 1733/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.2105 - val_loss: -164.4080\n",
      "\n",
      "Epoch 01733: loss did not improve from -162.68032\n",
      "Epoch 1734/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.1618 - val_loss: -164.6792\n",
      "\n",
      "Epoch 01734: loss did not improve from -162.68032\n",
      "Epoch 1735/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.2864 - val_loss: -163.8484\n",
      "\n",
      "Epoch 01735: loss did not improve from -162.68032\n",
      "Epoch 1736/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.3674 - val_loss: -164.8210\n",
      "\n",
      "Epoch 01736: loss did not improve from -162.68032\n",
      "Epoch 1737/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.4799 - val_loss: -164.7045\n",
      "\n",
      "Epoch 01737: loss did not improve from -162.68032\n",
      "Epoch 1738/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.6281 - val_loss: -164.7708\n",
      "\n",
      "Epoch 01738: loss did not improve from -162.68032\n",
      "Epoch 1739/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -162.5780 - val_loss: -164.8289\n",
      "\n",
      "Epoch 01739: loss did not improve from -162.68032\n",
      "Epoch 1740/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.4812 - val_loss: -164.2752\n",
      "\n",
      "Epoch 01740: loss did not improve from -162.68032\n",
      "Epoch 1741/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.3423 - val_loss: -164.7997\n",
      "\n",
      "Epoch 01741: loss did not improve from -162.68032\n",
      "Epoch 1742/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.3776 - val_loss: -164.2075\n",
      "\n",
      "Epoch 01742: loss did not improve from -162.68032\n",
      "Epoch 1743/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.5148 - val_loss: -164.8324\n",
      "\n",
      "Epoch 01743: loss did not improve from -162.68032\n",
      "Epoch 1744/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.4060 - val_loss: -164.7872\n",
      "\n",
      "Epoch 01744: loss did not improve from -162.68032\n",
      "Epoch 1745/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.2226 - val_loss: -164.1330\n",
      "\n",
      "Epoch 01745: loss did not improve from -162.68032\n",
      "Epoch 1746/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.3457 - val_loss: -164.6500\n",
      "\n",
      "Epoch 01746: loss did not improve from -162.68032\n",
      "Epoch 1747/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.1754 - val_loss: -164.0364\n",
      "\n",
      "Epoch 01747: loss did not improve from -162.68032\n",
      "Epoch 1748/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.6196 - val_loss: -165.1424\n",
      "\n",
      "Epoch 01748: loss did not improve from -162.68032\n",
      "Epoch 1749/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.6286 - val_loss: -164.6845\n",
      "\n",
      "Epoch 01749: loss did not improve from -162.68032\n",
      "Epoch 1750/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.8277 - val_loss: -165.1662\n",
      "\n",
      "Epoch 01750: loss improved from -162.68032 to -162.82769, saving model to gendance.h5\n",
      "Epoch 1751/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.8215 - val_loss: -164.4985\n",
      "\n",
      "Epoch 01751: loss did not improve from -162.82769\n",
      "Epoch 1752/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.7400 - val_loss: -165.2898\n",
      "\n",
      "Epoch 01752: loss did not improve from -162.82769\n",
      "Epoch 1753/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.5058 - val_loss: -164.6626\n",
      "\n",
      "Epoch 01753: loss did not improve from -162.82769\n",
      "Epoch 1754/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.5109 - val_loss: -164.2963\n",
      "\n",
      "Epoch 01754: loss did not improve from -162.82769\n",
      "Epoch 1755/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.5212 - val_loss: -165.1138\n",
      "\n",
      "Epoch 01755: loss did not improve from -162.82769\n",
      "Epoch 1756/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.6370 - val_loss: -164.6258\n",
      "\n",
      "Epoch 01756: loss did not improve from -162.82769\n",
      "Epoch 1757/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.5792 - val_loss: -164.8968\n",
      "\n",
      "Epoch 01757: loss did not improve from -162.82769\n",
      "Epoch 1758/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.5010 - val_loss: -164.9952\n",
      "\n",
      "Epoch 01758: loss did not improve from -162.82769\n",
      "Epoch 1759/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.3924 - val_loss: -164.0854\n",
      "\n",
      "Epoch 01759: loss did not improve from -162.82769\n",
      "Epoch 1760/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.5369 - val_loss: -165.1903\n",
      "\n",
      "Epoch 01760: loss did not improve from -162.82769\n",
      "Epoch 1761/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.7198 - val_loss: -164.2020\n",
      "\n",
      "Epoch 01761: loss did not improve from -162.82769\n",
      "Epoch 1762/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.3842 - val_loss: -164.8578\n",
      "\n",
      "Epoch 01762: loss did not improve from -162.82769\n",
      "Epoch 1763/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.2927 - val_loss: -164.6430\n",
      "\n",
      "Epoch 01763: loss did not improve from -162.82769\n",
      "Epoch 1764/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.2477 - val_loss: -163.9786\n",
      "\n",
      "Epoch 01764: loss did not improve from -162.82769\n",
      "Epoch 1765/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.3746 - val_loss: -165.0664\n",
      "\n",
      "Epoch 01765: loss did not improve from -162.82769\n",
      "Epoch 1766/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.6656 - val_loss: -164.3735\n",
      "\n",
      "Epoch 01766: loss did not improve from -162.82769\n",
      "Epoch 1767/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.7547 - val_loss: -164.7467\n",
      "\n",
      "Epoch 01767: loss did not improve from -162.82769\n",
      "Epoch 1768/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.5933 - val_loss: -164.8127\n",
      "\n",
      "Epoch 01768: loss did not improve from -162.82769\n",
      "Epoch 1769/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.0940 - val_loss: -164.9139\n",
      "\n",
      "Epoch 01769: loss improved from -162.82769 to -163.09402, saving model to gendance.h5\n",
      "Epoch 1770/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.8005 - val_loss: -165.1173\n",
      "\n",
      "Epoch 01770: loss did not improve from -163.09402\n",
      "Epoch 1771/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.8223 - val_loss: -164.6155\n",
      "\n",
      "Epoch 01771: loss did not improve from -163.09402\n",
      "Epoch 1772/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.6490 - val_loss: -165.1396\n",
      "\n",
      "Epoch 01772: loss did not improve from -163.09402\n",
      "Epoch 1773/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.6138 - val_loss: -164.5351\n",
      "\n",
      "Epoch 01773: loss did not improve from -163.09402\n",
      "Epoch 1774/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.7457 - val_loss: -165.0136\n",
      "\n",
      "Epoch 01774: loss did not improve from -163.09402\n",
      "Epoch 1775/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.7512 - val_loss: -165.1027\n",
      "\n",
      "Epoch 01775: loss did not improve from -163.09402\n",
      "Epoch 1776/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.6001 - val_loss: -164.2260\n",
      "\n",
      "Epoch 01776: loss did not improve from -163.09402\n",
      "Epoch 1777/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.7828 - val_loss: -165.3086\n",
      "\n",
      "Epoch 01777: loss did not improve from -163.09402\n",
      "Epoch 1778/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.5724 - val_loss: -164.4683\n",
      "\n",
      "Epoch 01778: loss did not improve from -163.09402\n",
      "Epoch 1779/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.5612 - val_loss: -164.7850\n",
      "\n",
      "Epoch 01779: loss did not improve from -163.09402\n",
      "Epoch 1780/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.6591 - val_loss: -165.2768\n",
      "\n",
      "Epoch 01780: loss did not improve from -163.09402\n",
      "Epoch 1781/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.4478 - val_loss: -163.8502\n",
      "\n",
      "Epoch 01781: loss did not improve from -163.09402\n",
      "Epoch 1782/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.4503 - val_loss: -165.2028\n",
      "\n",
      "Epoch 01782: loss did not improve from -163.09402\n",
      "Epoch 1783/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.4868 - val_loss: -164.0444\n",
      "\n",
      "Epoch 01783: loss did not improve from -163.09402\n",
      "Epoch 1784/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.8046 - val_loss: -165.2898\n",
      "\n",
      "Epoch 01784: loss did not improve from -163.09402\n",
      "Epoch 1785/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.0259 - val_loss: -164.9531\n",
      "\n",
      "Epoch 01785: loss did not improve from -163.09402\n",
      "Epoch 1786/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.2138 - val_loss: -164.9004\n",
      "\n",
      "Epoch 01786: loss improved from -163.09402 to -163.21383, saving model to gendance.h5\n",
      "Epoch 1787/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.8924 - val_loss: -165.3148\n",
      "\n",
      "Epoch 01787: loss did not improve from -163.21383\n",
      "Epoch 1788/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.7008 - val_loss: -164.6000\n",
      "\n",
      "Epoch 01788: loss did not improve from -163.21383\n",
      "Epoch 1789/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.6375 - val_loss: -165.2471\n",
      "\n",
      "Epoch 01789: loss did not improve from -163.21383\n",
      "Epoch 1790/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.6435 - val_loss: -164.6085\n",
      "\n",
      "Epoch 01790: loss did not improve from -163.21383\n",
      "Epoch 1791/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.6405 - val_loss: -165.2994\n",
      "\n",
      "Epoch 01791: loss did not improve from -163.21383\n",
      "Epoch 1792/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.6942 - val_loss: -165.1798\n",
      "\n",
      "Epoch 01792: loss did not improve from -163.21383\n",
      "Epoch 1793/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.7418 - val_loss: -164.5411\n",
      "\n",
      "Epoch 01793: loss did not improve from -163.21383\n",
      "Epoch 1794/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.7565 - val_loss: -165.4591\n",
      "\n",
      "Epoch 01794: loss did not improve from -163.21383\n",
      "Epoch 1795/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.2982 - val_loss: -163.7689\n",
      "\n",
      "Epoch 01795: loss did not improve from -163.21383\n",
      "Epoch 1796/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.6697 - val_loss: -165.0939\n",
      "\n",
      "Epoch 01796: loss did not improve from -163.21383\n",
      "Epoch 1797/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.8572 - val_loss: -165.3917\n",
      "\n",
      "Epoch 01797: loss did not improve from -163.21383\n",
      "Epoch 1798/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.8318 - val_loss: -164.6417\n",
      "\n",
      "Epoch 01798: loss did not improve from -163.21383\n",
      "Epoch 1799/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -162.6326 - val_loss: -165.4893\n",
      "\n",
      "Epoch 01799: loss did not improve from -163.21383\n",
      "Epoch 1800/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.7685 - val_loss: -164.7538\n",
      "\n",
      "Epoch 01800: loss did not improve from -163.21383\n",
      "Epoch 1801/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.8705 - val_loss: -165.2468\n",
      "\n",
      "Epoch 01801: loss did not improve from -163.21383\n",
      "Epoch 1802/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.9159 - val_loss: -165.0647\n",
      "\n",
      "Epoch 01802: loss did not improve from -163.21383\n",
      "Epoch 1803/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.8896 - val_loss: -164.9459\n",
      "\n",
      "Epoch 01803: loss did not improve from -163.21383\n",
      "Epoch 1804/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.0424 - val_loss: -165.4966\n",
      "\n",
      "Epoch 01804: loss did not improve from -163.21383\n",
      "Epoch 1805/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.8868 - val_loss: -164.7048\n",
      "\n",
      "Epoch 01805: loss did not improve from -163.21383\n",
      "Epoch 1806/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.9856 - val_loss: -165.4561\n",
      "\n",
      "Epoch 01806: loss did not improve from -163.21383\n",
      "Epoch 1807/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.7258 - val_loss: -164.9846\n",
      "\n",
      "Epoch 01807: loss did not improve from -163.21383\n",
      "Epoch 1808/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.9765 - val_loss: -164.9923\n",
      "\n",
      "Epoch 01808: loss did not improve from -163.21383\n",
      "Epoch 1809/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.8542 - val_loss: -165.4028\n",
      "\n",
      "Epoch 01809: loss did not improve from -163.21383\n",
      "Epoch 1810/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.0119 - val_loss: -164.5361\n",
      "\n",
      "Epoch 01810: loss did not improve from -163.21383\n",
      "Epoch 1811/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.9997 - val_loss: -165.4179\n",
      "\n",
      "Epoch 01811: loss did not improve from -163.21383\n",
      "Epoch 1812/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.7851 - val_loss: -165.1179\n",
      "\n",
      "Epoch 01812: loss did not improve from -163.21383\n",
      "Epoch 1813/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.0022 - val_loss: -165.0352\n",
      "\n",
      "Epoch 01813: loss did not improve from -163.21383\n",
      "Epoch 1814/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.9858 - val_loss: -165.7659\n",
      "\n",
      "Epoch 01814: loss did not improve from -163.21383\n",
      "Epoch 1815/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.0621 - val_loss: -165.1889\n",
      "\n",
      "Epoch 01815: loss did not improve from -163.21383\n",
      "Epoch 1816/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.1006 - val_loss: -165.3457\n",
      "\n",
      "Epoch 01816: loss did not improve from -163.21383\n",
      "Epoch 1817/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.0004 - val_loss: -165.3347\n",
      "\n",
      "Epoch 01817: loss did not improve from -163.21383\n",
      "Epoch 1818/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.0834 - val_loss: -165.5971\n",
      "\n",
      "Epoch 01818: loss did not improve from -163.21383\n",
      "Epoch 1819/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.1229 - val_loss: -165.4607\n",
      "\n",
      "Epoch 01819: loss did not improve from -163.21383\n",
      "Epoch 1820/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.1726 - val_loss: -164.8441\n",
      "\n",
      "Epoch 01820: loss did not improve from -163.21383\n",
      "Epoch 1821/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.0396 - val_loss: -165.4042\n",
      "\n",
      "Epoch 01821: loss did not improve from -163.21383\n",
      "Epoch 1822/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.9439 - val_loss: -164.9186\n",
      "\n",
      "Epoch 01822: loss did not improve from -163.21383\n",
      "Epoch 1823/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.6656 - val_loss: -164.9505\n",
      "\n",
      "Epoch 01823: loss did not improve from -163.21383\n",
      "Epoch 1824/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.8047 - val_loss: -165.3217\n",
      "\n",
      "Epoch 01824: loss did not improve from -163.21383\n",
      "Epoch 1825/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.7538 - val_loss: -164.3967\n",
      "\n",
      "Epoch 01825: loss did not improve from -163.21383\n",
      "Epoch 1826/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.8393 - val_loss: -165.4515\n",
      "\n",
      "Epoch 01826: loss did not improve from -163.21383\n",
      "Epoch 1827/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.7135 - val_loss: -164.3239\n",
      "\n",
      "Epoch 01827: loss did not improve from -163.21383\n",
      "Epoch 1828/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.0452 - val_loss: -165.3931\n",
      "\n",
      "Epoch 01828: loss did not improve from -163.21383\n",
      "Epoch 1829/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.0037 - val_loss: -165.1948\n",
      "\n",
      "Epoch 01829: loss did not improve from -163.21383\n",
      "Epoch 1830/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.8110 - val_loss: -164.7407\n",
      "\n",
      "Epoch 01830: loss did not improve from -163.21383\n",
      "Epoch 1831/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.9185 - val_loss: -165.4690\n",
      "\n",
      "Epoch 01831: loss did not improve from -163.21383\n",
      "Epoch 1832/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.8121 - val_loss: -164.3217\n",
      "\n",
      "Epoch 01832: loss did not improve from -163.21383\n",
      "Epoch 1833/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.8877 - val_loss: -165.4139\n",
      "\n",
      "Epoch 01833: loss did not improve from -163.21383\n",
      "Epoch 1834/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.9667 - val_loss: -165.0823\n",
      "\n",
      "Epoch 01834: loss did not improve from -163.21383\n",
      "Epoch 1835/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.3103 - val_loss: -165.5828\n",
      "\n",
      "Epoch 01835: loss improved from -163.21383 to -163.31028, saving model to gendance.h5\n",
      "Epoch 1836/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.3236 - val_loss: -165.8474\n",
      "\n",
      "Epoch 01836: loss improved from -163.31028 to -163.32362, saving model to gendance.h5\n",
      "Epoch 1837/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.2281 - val_loss: -165.0815\n",
      "\n",
      "Epoch 01837: loss did not improve from -163.32362\n",
      "Epoch 1838/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.3958 - val_loss: -165.8354\n",
      "\n",
      "Epoch 01838: loss improved from -163.32362 to -163.39579, saving model to gendance.h5\n",
      "Epoch 1839/10000\n",
      "16167/16167 [==============================] - 1s 34us/step - loss: -163.3791 - val_loss: -165.2660\n",
      "\n",
      "Epoch 01839: loss did not improve from -163.39579\n",
      "Epoch 1840/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.3649 - val_loss: -165.6883\n",
      "\n",
      "Epoch 01840: loss did not improve from -163.39579\n",
      "Epoch 1841/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.4833 - val_loss: -165.7955\n",
      "\n",
      "Epoch 01841: loss improved from -163.39579 to -163.48333, saving model to gendance.h5\n",
      "Epoch 1842/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.0964 - val_loss: -165.1017\n",
      "\n",
      "Epoch 01842: loss did not improve from -163.48333\n",
      "Epoch 1843/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.3451 - val_loss: -165.6747\n",
      "\n",
      "Epoch 01843: loss did not improve from -163.48333\n",
      "Epoch 1844/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.9427 - val_loss: -165.5142\n",
      "\n",
      "Epoch 01844: loss did not improve from -163.48333\n",
      "Epoch 1845/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.5090 - val_loss: -165.7521\n",
      "\n",
      "Epoch 01845: loss improved from -163.48333 to -163.50899, saving model to gendance.h5\n",
      "Epoch 1846/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.3190 - val_loss: -165.3639\n",
      "\n",
      "Epoch 01846: loss did not improve from -163.50899\n",
      "Epoch 1847/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.2514 - val_loss: -165.7919\n",
      "\n",
      "Epoch 01847: loss did not improve from -163.50899\n",
      "Epoch 1848/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.2538 - val_loss: -165.5810\n",
      "\n",
      "Epoch 01848: loss did not improve from -163.50899\n",
      "Epoch 1849/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.3222 - val_loss: -165.6698\n",
      "\n",
      "Epoch 01849: loss did not improve from -163.50899\n",
      "Epoch 1850/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.2195 - val_loss: -165.5890\n",
      "\n",
      "Epoch 01850: loss did not improve from -163.50899\n",
      "Epoch 1851/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.1720 - val_loss: -165.3429\n",
      "\n",
      "Epoch 01851: loss did not improve from -163.50899\n",
      "Epoch 1852/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.0011 - val_loss: -165.5556\n",
      "\n",
      "Epoch 01852: loss did not improve from -163.50899\n",
      "Epoch 1853/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.2597 - val_loss: -164.8817\n",
      "\n",
      "Epoch 01853: loss did not improve from -163.50899\n",
      "Epoch 1854/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -163.0896 - val_loss: -165.8402\n",
      "\n",
      "Epoch 01854: loss did not improve from -163.50899\n",
      "Epoch 1855/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.0515 - val_loss: -164.6223\n",
      "\n",
      "Epoch 01855: loss did not improve from -163.50899\n",
      "Epoch 1856/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.9791 - val_loss: -165.2679\n",
      "\n",
      "Epoch 01856: loss did not improve from -163.50899\n",
      "Epoch 1857/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.0163 - val_loss: -165.9833\n",
      "\n",
      "Epoch 01857: loss did not improve from -163.50899\n",
      "Epoch 1858/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.9581 - val_loss: -164.1966\n",
      "\n",
      "Epoch 01858: loss did not improve from -163.50899\n",
      "Epoch 1859/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.7657 - val_loss: -165.4602\n",
      "\n",
      "Epoch 01859: loss did not improve from -163.50899\n",
      "Epoch 1860/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.7117 - val_loss: -164.1744\n",
      "\n",
      "Epoch 01860: loss did not improve from -163.50899\n",
      "Epoch 1861/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.9061 - val_loss: -165.4505\n",
      "\n",
      "Epoch 01861: loss did not improve from -163.50899\n",
      "Epoch 1862/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.0126 - val_loss: -165.3555\n",
      "\n",
      "Epoch 01862: loss did not improve from -163.50899\n",
      "Epoch 1863/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.0453 - val_loss: -164.8670\n",
      "\n",
      "Epoch 01863: loss did not improve from -163.50899\n",
      "Epoch 1864/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.8274 - val_loss: -165.5369\n",
      "\n",
      "Epoch 01864: loss did not improve from -163.50899\n",
      "Epoch 1865/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.0656 - val_loss: -164.7600\n",
      "\n",
      "Epoch 01865: loss did not improve from -163.50899\n",
      "Epoch 1866/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.2447 - val_loss: -165.7033\n",
      "\n",
      "Epoch 01866: loss did not improve from -163.50899\n",
      "Epoch 1867/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.3216 - val_loss: -164.8593\n",
      "\n",
      "Epoch 01867: loss did not improve from -163.50899\n",
      "Epoch 1868/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.1838 - val_loss: -165.6614\n",
      "\n",
      "Epoch 01868: loss did not improve from -163.50899\n",
      "Epoch 1869/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.1899 - val_loss: -165.5513\n",
      "\n",
      "Epoch 01869: loss did not improve from -163.50899\n",
      "Epoch 1870/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.0310 - val_loss: -164.9666\n",
      "\n",
      "Epoch 01870: loss did not improve from -163.50899\n",
      "Epoch 1871/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.1973 - val_loss: -166.0620\n",
      "\n",
      "Epoch 01871: loss did not improve from -163.50899\n",
      "Epoch 1872/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.2409 - val_loss: -165.3447\n",
      "\n",
      "Epoch 01872: loss did not improve from -163.50899\n",
      "Epoch 1873/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.3375 - val_loss: -165.7795\n",
      "\n",
      "Epoch 01873: loss did not improve from -163.50899\n",
      "Epoch 1874/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.5743 - val_loss: -165.8298\n",
      "\n",
      "Epoch 01874: loss improved from -163.50899 to -163.57433, saving model to gendance.h5\n",
      "Epoch 1875/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.1964 - val_loss: -165.6541\n",
      "\n",
      "Epoch 01875: loss did not improve from -163.57433\n",
      "Epoch 1876/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.1955 - val_loss: -165.7902\n",
      "\n",
      "Epoch 01876: loss did not improve from -163.57433\n",
      "Epoch 1877/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.9030 - val_loss: -165.2032\n",
      "\n",
      "Epoch 01877: loss did not improve from -163.57433\n",
      "Epoch 1878/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.4409 - val_loss: -165.8464\n",
      "\n",
      "Epoch 01878: loss did not improve from -163.57433\n",
      "Epoch 1879/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.5346 - val_loss: -165.7180\n",
      "\n",
      "Epoch 01879: loss did not improve from -163.57433\n",
      "Epoch 1880/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.2029 - val_loss: -165.5318\n",
      "\n",
      "Epoch 01880: loss did not improve from -163.57433\n",
      "Epoch 1881/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.0448 - val_loss: -165.2735\n",
      "\n",
      "Epoch 01881: loss did not improve from -163.57433\n",
      "Epoch 1882/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.3329 - val_loss: -165.5319\n",
      "\n",
      "Epoch 01882: loss did not improve from -163.57433\n",
      "Epoch 1883/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.1535 - val_loss: -165.6190\n",
      "\n",
      "Epoch 01883: loss did not improve from -163.57433\n",
      "Epoch 1884/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.2717 - val_loss: -165.1680\n",
      "\n",
      "Epoch 01884: loss did not improve from -163.57433\n",
      "Epoch 1885/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.1971 - val_loss: -165.8323\n",
      "\n",
      "Epoch 01885: loss did not improve from -163.57433\n",
      "Epoch 1886/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.1487 - val_loss: -165.3195\n",
      "\n",
      "Epoch 01886: loss did not improve from -163.57433\n",
      "Epoch 1887/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.2318 - val_loss: -165.7136\n",
      "\n",
      "Epoch 01887: loss did not improve from -163.57433\n",
      "Epoch 1888/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.3682 - val_loss: -165.7336\n",
      "\n",
      "Epoch 01888: loss did not improve from -163.57433\n",
      "Epoch 1889/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.4327 - val_loss: -165.3523\n",
      "\n",
      "Epoch 01889: loss did not improve from -163.57433\n",
      "Epoch 1890/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.2683 - val_loss: -166.0114\n",
      "\n",
      "Epoch 01890: loss did not improve from -163.57433\n",
      "Epoch 1891/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.2091 - val_loss: -164.7713\n",
      "\n",
      "Epoch 01891: loss did not improve from -163.57433\n",
      "Epoch 1892/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.2146 - val_loss: -165.7826\n",
      "\n",
      "Epoch 01892: loss did not improve from -163.57433\n",
      "Epoch 1893/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.3432 - val_loss: -165.5753\n",
      "\n",
      "Epoch 01893: loss did not improve from -163.57433\n",
      "Epoch 1894/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.2417 - val_loss: -165.4994\n",
      "\n",
      "Epoch 01894: loss did not improve from -163.57433\n",
      "Epoch 1895/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.3292 - val_loss: -166.2895\n",
      "\n",
      "Epoch 01895: loss did not improve from -163.57433\n",
      "Epoch 1896/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.1918 - val_loss: -164.8143\n",
      "\n",
      "Epoch 01896: loss did not improve from -163.57433\n",
      "Epoch 1897/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.4365 - val_loss: -165.9520\n",
      "\n",
      "Epoch 01897: loss did not improve from -163.57433\n",
      "Epoch 1898/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.3914 - val_loss: -165.6341\n",
      "\n",
      "Epoch 01898: loss did not improve from -163.57433\n",
      "Epoch 1899/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.6466 - val_loss: -165.8881\n",
      "\n",
      "Epoch 01899: loss improved from -163.57433 to -163.64665, saving model to gendance.h5\n",
      "Epoch 1900/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.6402 - val_loss: -166.3306\n",
      "\n",
      "Epoch 01900: loss did not improve from -163.64665\n",
      "Epoch 1901/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.5380 - val_loss: -165.6960\n",
      "\n",
      "Epoch 01901: loss did not improve from -163.64665\n",
      "Epoch 1902/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.6595 - val_loss: -166.1274\n",
      "\n",
      "Epoch 01902: loss improved from -163.64665 to -163.65949, saving model to gendance.h5\n",
      "Epoch 1903/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.4184 - val_loss: -165.7957\n",
      "\n",
      "Epoch 01903: loss did not improve from -163.65949\n",
      "Epoch 1904/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.7973 - val_loss: -166.3200\n",
      "\n",
      "Epoch 01904: loss improved from -163.65949 to -163.79734, saving model to gendance.h5\n",
      "Epoch 1905/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.6596 - val_loss: -165.9885\n",
      "\n",
      "Epoch 01905: loss did not improve from -163.79734\n",
      "Epoch 1906/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.7333 - val_loss: -165.9873\n",
      "\n",
      "Epoch 01906: loss did not improve from -163.79734\n",
      "Epoch 1907/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.5990 - val_loss: -166.1992\n",
      "\n",
      "Epoch 01907: loss did not improve from -163.79734\n",
      "Epoch 1908/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.6824 - val_loss: -165.9558\n",
      "\n",
      "Epoch 01908: loss did not improve from -163.79734\n",
      "Epoch 1909/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.8662 - val_loss: -166.0801\n",
      "\n",
      "Epoch 01909: loss improved from -163.79734 to -163.86618, saving model to gendance.h5\n",
      "Epoch 1910/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.6160 - val_loss: -166.0391\n",
      "\n",
      "Epoch 01910: loss did not improve from -163.86618\n",
      "Epoch 1911/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.6309 - val_loss: -166.0579\n",
      "\n",
      "Epoch 01911: loss did not improve from -163.86618\n",
      "Epoch 1912/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.6582 - val_loss: -166.0820\n",
      "\n",
      "Epoch 01912: loss did not improve from -163.86618\n",
      "Epoch 1913/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.9462 - val_loss: -166.1804\n",
      "\n",
      "Epoch 01913: loss improved from -163.86618 to -163.94616, saving model to gendance.h5\n",
      "Epoch 1914/10000\n",
      "16167/16167 [==============================] - 1s 33us/step - loss: -163.7534 - val_loss: -166.1057\n",
      "\n",
      "Epoch 01914: loss did not improve from -163.94616\n",
      "Epoch 1915/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.5399 - val_loss: -165.9741\n",
      "\n",
      "Epoch 01915: loss did not improve from -163.94616\n",
      "Epoch 1916/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.5501 - val_loss: -165.9066\n",
      "\n",
      "Epoch 01916: loss did not improve from -163.94616\n",
      "Epoch 1917/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.3342 - val_loss: -165.8262\n",
      "\n",
      "Epoch 01917: loss did not improve from -163.94616\n",
      "Epoch 1918/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.4846 - val_loss: -166.0357\n",
      "\n",
      "Epoch 01918: loss did not improve from -163.94616\n",
      "Epoch 1919/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.5877 - val_loss: -165.5972\n",
      "\n",
      "Epoch 01919: loss did not improve from -163.94616\n",
      "Epoch 1920/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.6854 - val_loss: -165.8397\n",
      "\n",
      "Epoch 01920: loss did not improve from -163.94616\n",
      "Epoch 1921/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.7010 - val_loss: -165.9372\n",
      "\n",
      "Epoch 01921: loss did not improve from -163.94616\n",
      "Epoch 1922/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.4291 - val_loss: -165.6262\n",
      "\n",
      "Epoch 01922: loss did not improve from -163.94616\n",
      "Epoch 1923/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.6081 - val_loss: -166.1978\n",
      "\n",
      "Epoch 01923: loss did not improve from -163.94616\n",
      "Epoch 1924/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.4981 - val_loss: -164.8801\n",
      "\n",
      "Epoch 01924: loss did not improve from -163.94616\n",
      "Epoch 1925/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.4903 - val_loss: -165.9889\n",
      "\n",
      "Epoch 01925: loss did not improve from -163.94616\n",
      "Epoch 1926/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.4852 - val_loss: -165.5394\n",
      "\n",
      "Epoch 01926: loss did not improve from -163.94616\n",
      "Epoch 1927/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.5674 - val_loss: -165.6606\n",
      "\n",
      "Epoch 01927: loss did not improve from -163.94616\n",
      "Epoch 1928/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.3665 - val_loss: -166.2522\n",
      "\n",
      "Epoch 01928: loss did not improve from -163.94616\n",
      "Epoch 1929/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.1112 - val_loss: -164.8495\n",
      "\n",
      "Epoch 01929: loss did not improve from -163.94616\n",
      "Epoch 1930/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.3685 - val_loss: -166.0188\n",
      "\n",
      "Epoch 01930: loss did not improve from -163.94616\n",
      "Epoch 1931/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.1898 - val_loss: -165.4944\n",
      "\n",
      "Epoch 01931: loss did not improve from -163.94616\n",
      "Epoch 1932/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.6572 - val_loss: -165.9817\n",
      "\n",
      "Epoch 01932: loss did not improve from -163.94616\n",
      "Epoch 1933/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.5287 - val_loss: -165.8909\n",
      "\n",
      "Epoch 01933: loss did not improve from -163.94616\n",
      "Epoch 1934/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -163.4464 - val_loss: -165.0838\n",
      "\n",
      "Epoch 01934: loss did not improve from -163.94616\n",
      "Epoch 1935/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.9915 - val_loss: -165.9116\n",
      "\n",
      "Epoch 01935: loss did not improve from -163.94616\n",
      "Epoch 1936/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -162.9503 - val_loss: -164.7373\n",
      "\n",
      "Epoch 01936: loss did not improve from -163.94616\n",
      "Epoch 1937/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.3715 - val_loss: -166.0747\n",
      "\n",
      "Epoch 01937: loss did not improve from -163.94616\n",
      "Epoch 1938/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.7879 - val_loss: -165.8492\n",
      "\n",
      "Epoch 01938: loss did not improve from -163.94616\n",
      "Epoch 1939/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.8978 - val_loss: -166.1683\n",
      "\n",
      "Epoch 01939: loss did not improve from -163.94616\n",
      "Epoch 1940/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.8694 - val_loss: -166.2302\n",
      "\n",
      "Epoch 01940: loss did not improve from -163.94616\n",
      "Epoch 1941/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.0756 - val_loss: -165.9544\n",
      "\n",
      "Epoch 01941: loss improved from -163.94616 to -164.07557, saving model to gendance.h5\n",
      "Epoch 1942/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.0308 - val_loss: -166.3378\n",
      "\n",
      "Epoch 01942: loss did not improve from -164.07557\n",
      "Epoch 1943/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.8316 - val_loss: -165.5813\n",
      "\n",
      "Epoch 01943: loss did not improve from -164.07557\n",
      "Epoch 1944/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.7914 - val_loss: -166.2761\n",
      "\n",
      "Epoch 01944: loss did not improve from -164.07557\n",
      "Epoch 1945/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.7266 - val_loss: -166.1122\n",
      "\n",
      "Epoch 01945: loss did not improve from -164.07557\n",
      "Epoch 1946/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.8930 - val_loss: -165.9482\n",
      "\n",
      "Epoch 01946: loss did not improve from -164.07557\n",
      "Epoch 1947/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.6237 - val_loss: -166.1607\n",
      "\n",
      "Epoch 01947: loss did not improve from -164.07557\n",
      "Epoch 1948/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.6467 - val_loss: -165.5038\n",
      "\n",
      "Epoch 01948: loss did not improve from -164.07557\n",
      "Epoch 1949/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.7056 - val_loss: -166.3309\n",
      "\n",
      "Epoch 01949: loss did not improve from -164.07557\n",
      "Epoch 1950/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.5199 - val_loss: -165.1533\n",
      "\n",
      "Epoch 01950: loss did not improve from -164.07557\n",
      "Epoch 1951/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.6912 - val_loss: -166.2106\n",
      "\n",
      "Epoch 01951: loss did not improve from -164.07557\n",
      "Epoch 1952/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.5938 - val_loss: -166.0265\n",
      "\n",
      "Epoch 01952: loss did not improve from -164.07557\n",
      "Epoch 1953/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.3895 - val_loss: -165.2581\n",
      "\n",
      "Epoch 01953: loss did not improve from -164.07557\n",
      "Epoch 1954/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.5326 - val_loss: -166.2899\n",
      "\n",
      "Epoch 01954: loss did not improve from -164.07557\n",
      "Epoch 1955/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.3353 - val_loss: -165.1489\n",
      "\n",
      "Epoch 01955: loss did not improve from -164.07557\n",
      "Epoch 1956/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.6480 - val_loss: -166.0326\n",
      "\n",
      "Epoch 01956: loss did not improve from -164.07557\n",
      "Epoch 1957/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.6655 - val_loss: -166.3313\n",
      "\n",
      "Epoch 01957: loss did not improve from -164.07557\n",
      "Epoch 1958/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.9522 - val_loss: -166.0204\n",
      "\n",
      "Epoch 01958: loss did not improve from -164.07557\n",
      "Epoch 1959/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.7577 - val_loss: -166.2220\n",
      "\n",
      "Epoch 01959: loss did not improve from -164.07557\n",
      "Epoch 1960/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.8551 - val_loss: -165.7195\n",
      "\n",
      "Epoch 01960: loss did not improve from -164.07557\n",
      "Epoch 1961/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.8300 - val_loss: -166.3972\n",
      "\n",
      "Epoch 01961: loss did not improve from -164.07557\n",
      "Epoch 1962/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.8271 - val_loss: -166.2515\n",
      "\n",
      "Epoch 01962: loss did not improve from -164.07557\n",
      "Epoch 1963/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.6535 - val_loss: -165.5976\n",
      "\n",
      "Epoch 01963: loss did not improve from -164.07557\n",
      "Epoch 1964/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.9133 - val_loss: -166.4139\n",
      "\n",
      "Epoch 01964: loss did not improve from -164.07557\n",
      "Epoch 1965/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.9583 - val_loss: -166.1293\n",
      "\n",
      "Epoch 01965: loss did not improve from -164.07557\n",
      "Epoch 1966/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.9119 - val_loss: -166.1249\n",
      "\n",
      "Epoch 01966: loss did not improve from -164.07557\n",
      "Epoch 1967/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.0025 - val_loss: -166.3032\n",
      "\n",
      "Epoch 01967: loss did not improve from -164.07557\n",
      "Epoch 1968/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.0933 - val_loss: -166.0701\n",
      "\n",
      "Epoch 01968: loss improved from -164.07557 to -164.09332, saving model to gendance.h5\n",
      "Epoch 1969/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.9793 - val_loss: -166.2923\n",
      "\n",
      "Epoch 01969: loss did not improve from -164.09332\n",
      "Epoch 1970/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.1912 - val_loss: -165.9559\n",
      "\n",
      "Epoch 01970: loss improved from -164.09332 to -164.19125, saving model to gendance.h5\n",
      "Epoch 1971/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.0301 - val_loss: -166.2571\n",
      "\n",
      "Epoch 01971: loss did not improve from -164.19125\n",
      "Epoch 1972/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.7294 - val_loss: -165.8975\n",
      "\n",
      "Epoch 01972: loss did not improve from -164.19125\n",
      "Epoch 1973/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.7202 - val_loss: -165.5591\n",
      "\n",
      "Epoch 01973: loss did not improve from -164.19125\n",
      "Epoch 1974/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.4722 - val_loss: -166.1051\n",
      "\n",
      "Epoch 01974: loss did not improve from -164.19125\n",
      "Epoch 1975/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.7563 - val_loss: -165.5530\n",
      "\n",
      "Epoch 01975: loss did not improve from -164.19125\n",
      "Epoch 1976/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.7647 - val_loss: -166.3766\n",
      "\n",
      "Epoch 01976: loss did not improve from -164.19125\n",
      "Epoch 1977/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.8194 - val_loss: -165.6917\n",
      "\n",
      "Epoch 01977: loss did not improve from -164.19125\n",
      "Epoch 1978/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.7607 - val_loss: -166.3088\n",
      "\n",
      "Epoch 01978: loss did not improve from -164.19125\n",
      "Epoch 1979/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.0985 - val_loss: -166.3111\n",
      "\n",
      "Epoch 01979: loss did not improve from -164.19125\n",
      "Epoch 1980/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.0372 - val_loss: -165.8923\n",
      "\n",
      "Epoch 01980: loss did not improve from -164.19125\n",
      "Epoch 1981/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.8517 - val_loss: -166.4749\n",
      "\n",
      "Epoch 01981: loss did not improve from -164.19125\n",
      "Epoch 1982/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.7175 - val_loss: -165.8130\n",
      "\n",
      "Epoch 01982: loss did not improve from -164.19125\n",
      "Epoch 1983/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.7989 - val_loss: -166.3666\n",
      "\n",
      "Epoch 01983: loss did not improve from -164.19125\n",
      "Epoch 1984/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.8209 - val_loss: -165.7316\n",
      "\n",
      "Epoch 01984: loss did not improve from -164.19125\n",
      "Epoch 1985/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.7684 - val_loss: -166.2513\n",
      "\n",
      "Epoch 01985: loss did not improve from -164.19125\n",
      "Epoch 1986/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.8721 - val_loss: -166.1296\n",
      "\n",
      "Epoch 01986: loss did not improve from -164.19125\n",
      "Epoch 1987/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.7301 - val_loss: -165.9313\n",
      "\n",
      "Epoch 01987: loss did not improve from -164.19125\n",
      "Epoch 1988/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.7436 - val_loss: -166.3649\n",
      "\n",
      "Epoch 01988: loss did not improve from -164.19125\n",
      "Epoch 1989/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.4754 - val_loss: -165.0182\n",
      "\n",
      "Epoch 01989: loss did not improve from -164.19125\n",
      "Epoch 1990/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.7389 - val_loss: -166.4226\n",
      "\n",
      "Epoch 01990: loss did not improve from -164.19125\n",
      "Epoch 1991/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.0975 - val_loss: -166.0926\n",
      "\n",
      "Epoch 01991: loss did not improve from -164.19125\n",
      "Epoch 1992/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.9112 - val_loss: -165.8669\n",
      "\n",
      "Epoch 01992: loss did not improve from -164.19125\n",
      "Epoch 1993/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.0699 - val_loss: -166.6078\n",
      "\n",
      "Epoch 01993: loss did not improve from -164.19125\n",
      "Epoch 1994/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.9873 - val_loss: -166.0929\n",
      "\n",
      "Epoch 01994: loss did not improve from -164.19125\n",
      "Epoch 1995/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.9339 - val_loss: -166.3777\n",
      "\n",
      "Epoch 01995: loss did not improve from -164.19125\n",
      "Epoch 1996/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.1986 - val_loss: -166.0274\n",
      "\n",
      "Epoch 01996: loss improved from -164.19125 to -164.19858, saving model to gendance.h5\n",
      "Epoch 1997/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.1114 - val_loss: -166.5674\n",
      "\n",
      "Epoch 01997: loss did not improve from -164.19858\n",
      "Epoch 1998/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.0668 - val_loss: -166.3779\n",
      "\n",
      "Epoch 01998: loss did not improve from -164.19858\n",
      "Epoch 1999/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.9667 - val_loss: -166.2833\n",
      "\n",
      "Epoch 01999: loss did not improve from -164.19858\n",
      "Epoch 2000/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.0743 - val_loss: -166.5677\n",
      "\n",
      "Epoch 02000: loss did not improve from -164.19858\n",
      "Epoch 2001/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.1678 - val_loss: -165.8542\n",
      "\n",
      "Epoch 02001: loss did not improve from -164.19858\n",
      "Epoch 2002/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.0729 - val_loss: -166.4921\n",
      "\n",
      "Epoch 02002: loss did not improve from -164.19858\n",
      "Epoch 2003/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.0633 - val_loss: -165.6750\n",
      "\n",
      "Epoch 02003: loss did not improve from -164.19858\n",
      "Epoch 2004/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.9118 - val_loss: -166.4787\n",
      "\n",
      "Epoch 02004: loss did not improve from -164.19858\n",
      "Epoch 2005/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.8526 - val_loss: -166.0974\n",
      "\n",
      "Epoch 02005: loss did not improve from -164.19858\n",
      "Epoch 2006/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.8476 - val_loss: -166.1257\n",
      "\n",
      "Epoch 02006: loss did not improve from -164.19858\n",
      "Epoch 2007/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.9139 - val_loss: -166.6185\n",
      "\n",
      "Epoch 02007: loss did not improve from -164.19858\n",
      "Epoch 2008/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.8822 - val_loss: -165.5488\n",
      "\n",
      "Epoch 02008: loss did not improve from -164.19858\n",
      "Epoch 2009/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.9735 - val_loss: -166.5624\n",
      "\n",
      "Epoch 02009: loss did not improve from -164.19858\n",
      "Epoch 2010/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.0058 - val_loss: -166.1005\n",
      "\n",
      "Epoch 02010: loss did not improve from -164.19858\n",
      "Epoch 2011/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.0615 - val_loss: -166.3074\n",
      "\n",
      "Epoch 02011: loss did not improve from -164.19858\n",
      "Epoch 2012/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.1959 - val_loss: -166.5959\n",
      "\n",
      "Epoch 02012: loss did not improve from -164.19858\n",
      "Epoch 2013/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.9459 - val_loss: -165.9351\n",
      "\n",
      "Epoch 02013: loss did not improve from -164.19858\n",
      "Epoch 2014/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.0383 - val_loss: -166.6452\n",
      "\n",
      "Epoch 02014: loss did not improve from -164.19858\n",
      "Epoch 2015/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.0420 - val_loss: -165.3709\n",
      "\n",
      "Epoch 02015: loss did not improve from -164.19858\n",
      "Epoch 2016/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.8822 - val_loss: -166.5772\n",
      "\n",
      "Epoch 02016: loss did not improve from -164.19858\n",
      "Epoch 2017/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.1682 - val_loss: -166.1972\n",
      "\n",
      "Epoch 02017: loss did not improve from -164.19858\n",
      "Epoch 2018/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.1504 - val_loss: -166.5650\n",
      "\n",
      "Epoch 02018: loss did not improve from -164.19858\n",
      "Epoch 2019/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.1617 - val_loss: -166.6219\n",
      "\n",
      "Epoch 02019: loss did not improve from -164.19858\n",
      "Epoch 2020/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.0343 - val_loss: -165.9965\n",
      "\n",
      "Epoch 02020: loss did not improve from -164.19858\n",
      "Epoch 2021/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.0544 - val_loss: -166.6840\n",
      "\n",
      "Epoch 02021: loss did not improve from -164.19858\n",
      "Epoch 2022/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.2109 - val_loss: -166.1993\n",
      "\n",
      "Epoch 02022: loss improved from -164.19858 to -164.21087, saving model to gendance.h5\n",
      "Epoch 2023/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -164.3293 - val_loss: -166.6315\n",
      "\n",
      "Epoch 02023: loss improved from -164.21087 to -164.32927, saving model to gendance.h5\n",
      "Epoch 2024/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.2304 - val_loss: -166.6543\n",
      "\n",
      "Epoch 02024: loss did not improve from -164.32927\n",
      "Epoch 2025/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.2152 - val_loss: -166.7968\n",
      "\n",
      "Epoch 02025: loss did not improve from -164.32927\n",
      "Epoch 2026/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.1138 - val_loss: -166.7031\n",
      "\n",
      "Epoch 02026: loss did not improve from -164.32927\n",
      "Epoch 2027/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.2425 - val_loss: -166.0389\n",
      "\n",
      "Epoch 02027: loss did not improve from -164.32927\n",
      "Epoch 2028/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.0975 - val_loss: -166.5351\n",
      "\n",
      "Epoch 02028: loss did not improve from -164.32927\n",
      "Epoch 2029/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.9682 - val_loss: -166.3945\n",
      "\n",
      "Epoch 02029: loss did not improve from -164.32927\n",
      "Epoch 2030/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.2273 - val_loss: -166.2315\n",
      "\n",
      "Epoch 02030: loss did not improve from -164.32927\n",
      "Epoch 2031/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.1848 - val_loss: -166.7092\n",
      "\n",
      "Epoch 02031: loss did not improve from -164.32927\n",
      "Epoch 2032/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.2917 - val_loss: -166.0392\n",
      "\n",
      "Epoch 02032: loss did not improve from -164.32927\n",
      "Epoch 2033/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.2559 - val_loss: -166.9101\n",
      "\n",
      "Epoch 02033: loss did not improve from -164.32927\n",
      "Epoch 2034/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.2019 - val_loss: -166.5124\n",
      "\n",
      "Epoch 02034: loss did not improve from -164.32927\n",
      "Epoch 2035/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.2695 - val_loss: -166.5567\n",
      "\n",
      "Epoch 02035: loss did not improve from -164.32927\n",
      "Epoch 2036/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.2623 - val_loss: -166.7017\n",
      "\n",
      "Epoch 02036: loss did not improve from -164.32927\n",
      "Epoch 2037/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.3321 - val_loss: -166.4540\n",
      "\n",
      "Epoch 02037: loss improved from -164.32927 to -164.33215, saving model to gendance.h5\n",
      "Epoch 2038/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.3544 - val_loss: -166.8198\n",
      "\n",
      "Epoch 02038: loss improved from -164.33215 to -164.35445, saving model to gendance.h5\n",
      "Epoch 2039/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -164.1981 - val_loss: -166.2576\n",
      "\n",
      "Epoch 02039: loss did not improve from -164.35445\n",
      "Epoch 2040/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.2966 - val_loss: -166.3385\n",
      "\n",
      "Epoch 02040: loss did not improve from -164.35445\n",
      "Epoch 2041/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.1111 - val_loss: -166.8502\n",
      "\n",
      "Epoch 02041: loss did not improve from -164.35445\n",
      "Epoch 2042/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.8834 - val_loss: -165.3449\n",
      "\n",
      "Epoch 02042: loss did not improve from -164.35445\n",
      "Epoch 2043/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.0460 - val_loss: -166.5756\n",
      "\n",
      "Epoch 02043: loss did not improve from -164.35445\n",
      "Epoch 2044/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.0089 - val_loss: -166.0080\n",
      "\n",
      "Epoch 02044: loss did not improve from -164.35445\n",
      "Epoch 2045/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.2025 - val_loss: -166.3936\n",
      "\n",
      "Epoch 02045: loss did not improve from -164.35445\n",
      "Epoch 2046/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.2181 - val_loss: -166.9303\n",
      "\n",
      "Epoch 02046: loss did not improve from -164.35445\n",
      "Epoch 2047/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.1798 - val_loss: -166.1681\n",
      "\n",
      "Epoch 02047: loss did not improve from -164.35445\n",
      "Epoch 2048/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.1141 - val_loss: -166.7637\n",
      "\n",
      "Epoch 02048: loss did not improve from -164.35445\n",
      "Epoch 2049/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.4454 - val_loss: -166.3158\n",
      "\n",
      "Epoch 02049: loss improved from -164.35445 to -164.44544, saving model to gendance.h5\n",
      "Epoch 2050/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.2782 - val_loss: -166.7897\n",
      "\n",
      "Epoch 02050: loss did not improve from -164.44544\n",
      "Epoch 2051/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.3619 - val_loss: -166.5380\n",
      "\n",
      "Epoch 02051: loss did not improve from -164.44544\n",
      "Epoch 2052/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.3855 - val_loss: -166.6457\n",
      "\n",
      "Epoch 02052: loss did not improve from -164.44544\n",
      "Epoch 2053/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.3460 - val_loss: -166.6681\n",
      "\n",
      "Epoch 02053: loss did not improve from -164.44544\n",
      "Epoch 2054/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.1899 - val_loss: -166.1115\n",
      "\n",
      "Epoch 02054: loss did not improve from -164.44544\n",
      "Epoch 2055/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.4290 - val_loss: -166.6681\n",
      "\n",
      "Epoch 02055: loss did not improve from -164.44544\n",
      "Epoch 2056/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.3001 - val_loss: -166.7121\n",
      "\n",
      "Epoch 02056: loss did not improve from -164.44544\n",
      "Epoch 2057/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -164.4300 - val_loss: -166.8286\n",
      "\n",
      "Epoch 02057: loss did not improve from -164.44544\n",
      "Epoch 2058/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.5652 - val_loss: -166.6895\n",
      "\n",
      "Epoch 02058: loss improved from -164.44544 to -164.56516, saving model to gendance.h5\n",
      "Epoch 2059/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.6060 - val_loss: -166.7873\n",
      "\n",
      "Epoch 02059: loss improved from -164.56516 to -164.60601, saving model to gendance.h5\n",
      "Epoch 2060/10000\n",
      "16167/16167 [==============================] - 1s 31us/step - loss: -164.5887 - val_loss: -166.7622\n",
      "\n",
      "Epoch 02060: loss did not improve from -164.60601\n",
      "Epoch 2061/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.3775 - val_loss: -166.8696\n",
      "\n",
      "Epoch 02061: loss did not improve from -164.60601\n",
      "Epoch 2062/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.6255 - val_loss: -167.0810\n",
      "\n",
      "Epoch 02062: loss improved from -164.60601 to -164.62546, saving model to gendance.h5\n",
      "Epoch 2063/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -164.3753 - val_loss: -166.2259\n",
      "\n",
      "Epoch 02063: loss did not improve from -164.62546\n",
      "Epoch 2064/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.1335 - val_loss: -166.9318\n",
      "\n",
      "Epoch 02064: loss did not improve from -164.62546\n",
      "Epoch 2065/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.3921 - val_loss: -166.1639\n",
      "\n",
      "Epoch 02065: loss did not improve from -164.62546\n",
      "Epoch 2066/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.0096 - val_loss: -166.3529\n",
      "\n",
      "Epoch 02066: loss did not improve from -164.62546\n",
      "Epoch 2067/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.2336 - val_loss: -166.7260\n",
      "\n",
      "Epoch 02067: loss did not improve from -164.62546\n",
      "Epoch 2068/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.3463 - val_loss: -166.3694\n",
      "\n",
      "Epoch 02068: loss did not improve from -164.62546\n",
      "Epoch 2069/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.3835 - val_loss: -166.9228\n",
      "\n",
      "Epoch 02069: loss did not improve from -164.62546\n",
      "Epoch 2070/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.3013 - val_loss: -166.2448\n",
      "\n",
      "Epoch 02070: loss did not improve from -164.62546\n",
      "Epoch 2071/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.1214 - val_loss: -166.7742\n",
      "\n",
      "Epoch 02071: loss did not improve from -164.62546\n",
      "Epoch 2072/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.5520 - val_loss: -166.5895\n",
      "\n",
      "Epoch 02072: loss did not improve from -164.62546\n",
      "Epoch 2073/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.5210 - val_loss: -166.8024\n",
      "\n",
      "Epoch 02073: loss did not improve from -164.62546\n",
      "Epoch 2074/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.3697 - val_loss: -166.9398\n",
      "\n",
      "Epoch 02074: loss did not improve from -164.62546\n",
      "Epoch 2075/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -164.3615 - val_loss: -166.4270\n",
      "\n",
      "Epoch 02075: loss did not improve from -164.62546\n",
      "Epoch 2076/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.5739 - val_loss: -167.0070\n",
      "\n",
      "Epoch 02076: loss did not improve from -164.62546\n",
      "Epoch 2077/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.5668 - val_loss: -166.1878\n",
      "\n",
      "Epoch 02077: loss did not improve from -164.62546\n",
      "Epoch 2078/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.5488 - val_loss: -166.8807\n",
      "\n",
      "Epoch 02078: loss did not improve from -164.62546\n",
      "Epoch 2079/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.5782 - val_loss: -166.8078\n",
      "\n",
      "Epoch 02079: loss did not improve from -164.62546\n",
      "Epoch 2080/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.5190 - val_loss: -166.5035\n",
      "\n",
      "Epoch 02080: loss did not improve from -164.62546\n",
      "Epoch 2081/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.2676 - val_loss: -166.7152\n",
      "\n",
      "Epoch 02081: loss did not improve from -164.62546\n",
      "Epoch 2082/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.6859 - val_loss: -165.9016\n",
      "\n",
      "Epoch 02082: loss did not improve from -164.62546\n",
      "Epoch 2083/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -163.5833 - val_loss: -166.6664\n",
      "\n",
      "Epoch 02083: loss did not improve from -164.62546\n",
      "Epoch 2084/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -164.0048 - val_loss: -166.0372\n",
      "\n",
      "Epoch 02084: loss did not improve from -164.62546\n",
      "Epoch 2085/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.3623 - val_loss: -167.1179\n",
      "\n",
      "Epoch 02085: loss did not improve from -164.62546\n",
      "Epoch 2086/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.4071 - val_loss: -166.4403\n",
      "\n",
      "Epoch 02086: loss did not improve from -164.62546\n",
      "Epoch 2087/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.3206 - val_loss: -166.7729\n",
      "\n",
      "Epoch 02087: loss did not improve from -164.62546\n",
      "Epoch 2088/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.3863 - val_loss: -166.6366\n",
      "\n",
      "Epoch 02088: loss did not improve from -164.62546\n",
      "Epoch 2089/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.2687 - val_loss: -166.6018\n",
      "\n",
      "Epoch 02089: loss did not improve from -164.62546\n",
      "Epoch 2090/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.5059 - val_loss: -167.0948\n",
      "\n",
      "Epoch 02090: loss did not improve from -164.62546\n",
      "Epoch 2091/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.4453 - val_loss: -166.0879\n",
      "\n",
      "Epoch 02091: loss did not improve from -164.62546\n",
      "Epoch 2092/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.5132 - val_loss: -166.8947\n",
      "\n",
      "Epoch 02092: loss did not improve from -164.62546\n",
      "Epoch 2093/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.4260 - val_loss: -166.6459\n",
      "\n",
      "Epoch 02093: loss did not improve from -164.62546\n",
      "Epoch 2094/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.5770 - val_loss: -166.7468\n",
      "\n",
      "Epoch 02094: loss did not improve from -164.62546\n",
      "Epoch 2095/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.8289 - val_loss: -167.0365\n",
      "\n",
      "Epoch 02095: loss improved from -164.62546 to -164.82893, saving model to gendance.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2096/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.4646 - val_loss: -166.6358\n",
      "\n",
      "Epoch 02096: loss did not improve from -164.82893\n",
      "Epoch 2097/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.4601 - val_loss: -166.8826\n",
      "\n",
      "Epoch 02097: loss did not improve from -164.82893\n",
      "Epoch 2098/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.4614 - val_loss: -166.6270\n",
      "\n",
      "Epoch 02098: loss did not improve from -164.82893\n",
      "Epoch 2099/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -164.6657 - val_loss: -166.7760\n",
      "\n",
      "Epoch 02099: loss did not improve from -164.82893\n",
      "Epoch 2100/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.2852 - val_loss: -166.6302\n",
      "\n",
      "Epoch 02100: loss did not improve from -164.82893\n",
      "Epoch 2101/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.5242 - val_loss: -166.8003\n",
      "\n",
      "Epoch 02101: loss did not improve from -164.82893\n",
      "Epoch 2102/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.7257 - val_loss: -166.7911\n",
      "\n",
      "Epoch 02102: loss did not improve from -164.82893\n",
      "Epoch 2103/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.7349 - val_loss: -166.6491\n",
      "\n",
      "Epoch 02103: loss did not improve from -164.82893\n",
      "Epoch 2104/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.6779 - val_loss: -167.0837\n",
      "\n",
      "Epoch 02104: loss did not improve from -164.82893\n",
      "Epoch 2105/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.7232 - val_loss: -166.9357\n",
      "\n",
      "Epoch 02105: loss did not improve from -164.82893\n",
      "Epoch 2106/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.8720 - val_loss: -166.9926\n",
      "\n",
      "Epoch 02106: loss improved from -164.82893 to -164.87204, saving model to gendance.h5\n",
      "Epoch 2107/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.7780 - val_loss: -166.9060\n",
      "\n",
      "Epoch 02107: loss did not improve from -164.87204\n",
      "Epoch 2108/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.8913 - val_loss: -166.9339\n",
      "\n",
      "Epoch 02108: loss improved from -164.87204 to -164.89134, saving model to gendance.h5\n",
      "Epoch 2109/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.6151 - val_loss: -167.1256\n",
      "\n",
      "Epoch 02109: loss did not improve from -164.89134\n",
      "Epoch 2110/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.6400 - val_loss: -166.5564\n",
      "\n",
      "Epoch 02110: loss did not improve from -164.89134\n",
      "Epoch 2111/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.6726 - val_loss: -167.2339\n",
      "\n",
      "Epoch 02111: loss did not improve from -164.89134\n",
      "Epoch 2112/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.8108 - val_loss: -166.9122\n",
      "\n",
      "Epoch 02112: loss did not improve from -164.89134\n",
      "Epoch 2113/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.6617 - val_loss: -167.1836\n",
      "\n",
      "Epoch 02113: loss did not improve from -164.89134\n",
      "Epoch 2114/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.5433 - val_loss: -166.7510\n",
      "\n",
      "Epoch 02114: loss did not improve from -164.89134\n",
      "Epoch 2115/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.8188 - val_loss: -167.0742\n",
      "\n",
      "Epoch 02115: loss did not improve from -164.89134\n",
      "Epoch 2116/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.4823 - val_loss: -167.1324\n",
      "\n",
      "Epoch 02116: loss did not improve from -164.89134\n",
      "Epoch 2117/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.9026 - val_loss: -166.7588\n",
      "\n",
      "Epoch 02117: loss improved from -164.89134 to -164.90265, saving model to gendance.h5\n",
      "Epoch 2118/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.7195 - val_loss: -167.2027\n",
      "\n",
      "Epoch 02118: loss did not improve from -164.90265\n",
      "Epoch 2119/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.6911 - val_loss: -166.3073\n",
      "\n",
      "Epoch 02119: loss did not improve from -164.90265\n",
      "Epoch 2120/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.5926 - val_loss: -167.0679\n",
      "\n",
      "Epoch 02120: loss did not improve from -164.90265\n",
      "Epoch 2121/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.6225 - val_loss: -166.8654\n",
      "\n",
      "Epoch 02121: loss did not improve from -164.90265\n",
      "Epoch 2122/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.5772 - val_loss: -166.8416\n",
      "\n",
      "Epoch 02122: loss did not improve from -164.90265\n",
      "Epoch 2123/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.3974 - val_loss: -166.9434\n",
      "\n",
      "Epoch 02123: loss did not improve from -164.90265\n",
      "Epoch 2124/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.5095 - val_loss: -166.4133\n",
      "\n",
      "Epoch 02124: loss did not improve from -164.90265\n",
      "Epoch 2125/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.4308 - val_loss: -167.0503\n",
      "\n",
      "Epoch 02125: loss did not improve from -164.90265\n",
      "Epoch 2126/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.5581 - val_loss: -166.3527\n",
      "\n",
      "Epoch 02126: loss did not improve from -164.90265\n",
      "Epoch 2127/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.6203 - val_loss: -166.8715\n",
      "\n",
      "Epoch 02127: loss did not improve from -164.90265\n",
      "Epoch 2128/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.8277 - val_loss: -166.6332\n",
      "\n",
      "Epoch 02128: loss did not improve from -164.90265\n",
      "Epoch 2129/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.6320 - val_loss: -166.8984\n",
      "\n",
      "Epoch 02129: loss did not improve from -164.90265\n",
      "Epoch 2130/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.4862 - val_loss: -167.1829\n",
      "\n",
      "Epoch 02130: loss did not improve from -164.90265\n",
      "Epoch 2131/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.1621 - val_loss: -165.5254\n",
      "\n",
      "Epoch 02131: loss did not improve from -164.90265\n",
      "Epoch 2132/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.2992 - val_loss: -166.8550\n",
      "\n",
      "Epoch 02132: loss did not improve from -164.90265\n",
      "Epoch 2133/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.1014 - val_loss: -166.0579\n",
      "\n",
      "Epoch 02133: loss did not improve from -164.90265\n",
      "Epoch 2134/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.6210 - val_loss: -166.9241\n",
      "\n",
      "Epoch 02134: loss did not improve from -164.90265\n",
      "Epoch 2135/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.7287 - val_loss: -166.9776\n",
      "\n",
      "Epoch 02135: loss did not improve from -164.90265\n",
      "Epoch 2136/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.4462 - val_loss: -166.3874\n",
      "\n",
      "Epoch 02136: loss did not improve from -164.90265\n",
      "Epoch 2137/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.5370 - val_loss: -167.2146\n",
      "\n",
      "Epoch 02137: loss did not improve from -164.90265\n",
      "Epoch 2138/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.6081 - val_loss: -166.0818\n",
      "\n",
      "Epoch 02138: loss did not improve from -164.90265\n",
      "Epoch 2139/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.7805 - val_loss: -167.3167\n",
      "\n",
      "Epoch 02139: loss did not improve from -164.90265\n",
      "Epoch 2140/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.6613 - val_loss: -166.8784\n",
      "\n",
      "Epoch 02140: loss did not improve from -164.90265\n",
      "Epoch 2141/10000\n",
      "16167/16167 [==============================] - 1s 32us/step - loss: -164.7254 - val_loss: -166.9203\n",
      "\n",
      "Epoch 02141: loss did not improve from -164.90265\n",
      "Epoch 2142/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.7037 - val_loss: -167.2195\n",
      "\n",
      "Epoch 02142: loss did not improve from -164.90265\n",
      "Epoch 2143/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.7343 - val_loss: -167.0478\n",
      "\n",
      "Epoch 02143: loss did not improve from -164.90265\n",
      "Epoch 2144/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.0229 - val_loss: -167.2509\n",
      "\n",
      "Epoch 02144: loss improved from -164.90265 to -165.02288, saving model to gendance.h5\n",
      "Epoch 2145/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.8002 - val_loss: -166.9333\n",
      "\n",
      "Epoch 02145: loss did not improve from -165.02288\n",
      "Epoch 2146/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.8668 - val_loss: -167.0658\n",
      "\n",
      "Epoch 02146: loss did not improve from -165.02288\n",
      "Epoch 2147/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.7951 - val_loss: -167.4840\n",
      "\n",
      "Epoch 02147: loss did not improve from -165.02288\n",
      "Epoch 2148/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.8204 - val_loss: -166.6081\n",
      "\n",
      "Epoch 02148: loss did not improve from -165.02288\n",
      "Epoch 2149/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.8290 - val_loss: -167.3156\n",
      "\n",
      "Epoch 02149: loss did not improve from -165.02288\n",
      "Epoch 2150/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.8282 - val_loss: -166.7558\n",
      "\n",
      "Epoch 02150: loss did not improve from -165.02288\n",
      "Epoch 2151/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.6167 - val_loss: -167.1425\n",
      "\n",
      "Epoch 02151: loss did not improve from -165.02288\n",
      "Epoch 2152/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.8062 - val_loss: -167.0125\n",
      "\n",
      "Epoch 02152: loss did not improve from -165.02288\n",
      "Epoch 2153/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.6899 - val_loss: -167.0351\n",
      "\n",
      "Epoch 02153: loss did not improve from -165.02288\n",
      "Epoch 2154/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.6843 - val_loss: -167.2877\n",
      "\n",
      "Epoch 02154: loss did not improve from -165.02288\n",
      "Epoch 2155/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.6678 - val_loss: -166.5398\n",
      "\n",
      "Epoch 02155: loss did not improve from -165.02288\n",
      "Epoch 2156/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.7783 - val_loss: -167.3920\n",
      "\n",
      "Epoch 02156: loss did not improve from -165.02288\n",
      "Epoch 2157/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.5994 - val_loss: -166.5176\n",
      "\n",
      "Epoch 02157: loss did not improve from -165.02288\n",
      "Epoch 2158/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.9141 - val_loss: -166.9637\n",
      "\n",
      "Epoch 02158: loss did not improve from -165.02288\n",
      "Epoch 2159/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.8541 - val_loss: -167.5502\n",
      "\n",
      "Epoch 02159: loss did not improve from -165.02288\n",
      "Epoch 2160/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.4707 - val_loss: -166.3296\n",
      "\n",
      "Epoch 02160: loss did not improve from -165.02288\n",
      "Epoch 2161/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.4492 - val_loss: -167.1380\n",
      "\n",
      "Epoch 02161: loss did not improve from -165.02288\n",
      "Epoch 2162/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.3057 - val_loss: -166.2492\n",
      "\n",
      "Epoch 02162: loss did not improve from -165.02288\n",
      "Epoch 2163/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.6491 - val_loss: -167.2743\n",
      "\n",
      "Epoch 02163: loss did not improve from -165.02288\n",
      "Epoch 2164/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.0068 - val_loss: -166.8637\n",
      "\n",
      "Epoch 02164: loss did not improve from -165.02288\n",
      "Epoch 2165/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.6706 - val_loss: -167.1095\n",
      "\n",
      "Epoch 02165: loss did not improve from -165.02288\n",
      "Epoch 2166/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.7245 - val_loss: -167.1530\n",
      "\n",
      "Epoch 02166: loss did not improve from -165.02288\n",
      "Epoch 2167/10000\n",
      "16167/16167 [==============================] - 1s 33us/step - loss: -164.8460 - val_loss: -167.0084\n",
      "\n",
      "Epoch 02167: loss did not improve from -165.02288\n",
      "Epoch 2168/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.8190 - val_loss: -167.3294\n",
      "\n",
      "Epoch 02168: loss did not improve from -165.02288\n",
      "Epoch 2169/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.1512 - val_loss: -166.9056\n",
      "\n",
      "Epoch 02169: loss improved from -165.02288 to -165.15116, saving model to gendance.h5\n",
      "Epoch 2170/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.0909 - val_loss: -167.3835\n",
      "\n",
      "Epoch 02170: loss did not improve from -165.15116\n",
      "Epoch 2171/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.8978 - val_loss: -166.8969\n",
      "\n",
      "Epoch 02171: loss did not improve from -165.15116\n",
      "Epoch 2172/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.8486 - val_loss: -167.0460\n",
      "\n",
      "Epoch 02172: loss did not improve from -165.15116\n",
      "Epoch 2173/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.9674 - val_loss: -167.2656\n",
      "\n",
      "Epoch 02173: loss did not improve from -165.15116\n",
      "Epoch 2174/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.5134 - val_loss: -166.5137\n",
      "\n",
      "Epoch 02174: loss did not improve from -165.15116\n",
      "Epoch 2175/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.6077 - val_loss: -167.3751\n",
      "\n",
      "Epoch 02175: loss did not improve from -165.15116\n",
      "Epoch 2176/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.6825 - val_loss: -166.4733\n",
      "\n",
      "Epoch 02176: loss did not improve from -165.15116\n",
      "Epoch 2177/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.8801 - val_loss: -167.1376\n",
      "\n",
      "Epoch 02177: loss did not improve from -165.15116\n",
      "Epoch 2178/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.9172 - val_loss: -167.1671\n",
      "\n",
      "Epoch 02178: loss did not improve from -165.15116\n",
      "Epoch 2179/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.8004 - val_loss: -167.0228\n",
      "\n",
      "Epoch 02179: loss did not improve from -165.15116\n",
      "Epoch 2180/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.8094 - val_loss: -167.6359\n",
      "\n",
      "Epoch 02180: loss did not improve from -165.15116\n",
      "Epoch 2181/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.6989 - val_loss: -166.1217\n",
      "\n",
      "Epoch 02181: loss did not improve from -165.15116\n",
      "Epoch 2182/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.5882 - val_loss: -167.2702\n",
      "\n",
      "Epoch 02182: loss did not improve from -165.15116\n",
      "Epoch 2183/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.6306 - val_loss: -166.6651\n",
      "\n",
      "Epoch 02183: loss did not improve from -165.15116\n",
      "Epoch 2184/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.9435 - val_loss: -167.2921\n",
      "\n",
      "Epoch 02184: loss did not improve from -165.15116\n",
      "Epoch 2185/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.8261 - val_loss: -167.4586\n",
      "\n",
      "Epoch 02185: loss did not improve from -165.15116\n",
      "Epoch 2186/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.1404 - val_loss: -166.7376\n",
      "\n",
      "Epoch 02186: loss did not improve from -165.15116\n",
      "Epoch 2187/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.1046 - val_loss: -167.5084\n",
      "\n",
      "Epoch 02187: loss did not improve from -165.15116\n",
      "Epoch 2188/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.0368 - val_loss: -166.9266\n",
      "\n",
      "Epoch 02188: loss did not improve from -165.15116\n",
      "Epoch 2189/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.0432 - val_loss: -167.4317\n",
      "\n",
      "Epoch 02189: loss did not improve from -165.15116\n",
      "Epoch 2190/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.1359 - val_loss: -167.5806\n",
      "\n",
      "Epoch 02190: loss did not improve from -165.15116\n",
      "Epoch 2191/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.9745 - val_loss: -166.8756\n",
      "\n",
      "Epoch 02191: loss did not improve from -165.15116\n",
      "Epoch 2192/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 31us/step - loss: -164.8016 - val_loss: -167.6389\n",
      "\n",
      "Epoch 02192: loss did not improve from -165.15116\n",
      "Epoch 2193/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.0282 - val_loss: -166.8199\n",
      "\n",
      "Epoch 02193: loss did not improve from -165.15116\n",
      "Epoch 2194/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.1616 - val_loss: -167.5947\n",
      "\n",
      "Epoch 02194: loss improved from -165.15116 to -165.16156, saving model to gendance.h5\n",
      "Epoch 2195/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.1338 - val_loss: -167.1061\n",
      "\n",
      "Epoch 02195: loss did not improve from -165.16156\n",
      "Epoch 2196/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.1432 - val_loss: -167.4781\n",
      "\n",
      "Epoch 02196: loss did not improve from -165.16156\n",
      "Epoch 2197/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.7232 - val_loss: -167.4744\n",
      "\n",
      "Epoch 02197: loss did not improve from -165.16156\n",
      "Epoch 2198/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.7430 - val_loss: -166.5399\n",
      "\n",
      "Epoch 02198: loss did not improve from -165.16156\n",
      "Epoch 2199/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.9149 - val_loss: -167.4905\n",
      "\n",
      "Epoch 02199: loss did not improve from -165.16156\n",
      "Epoch 2200/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.8049 - val_loss: -166.8062\n",
      "\n",
      "Epoch 02200: loss did not improve from -165.16156\n",
      "Epoch 2201/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.9476 - val_loss: -167.3311\n",
      "\n",
      "Epoch 02201: loss did not improve from -165.16156\n",
      "Epoch 2202/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.8718 - val_loss: -167.3044\n",
      "\n",
      "Epoch 02202: loss did not improve from -165.16156\n",
      "Epoch 2203/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -165.1129 - val_loss: -166.9474\n",
      "\n",
      "Epoch 02203: loss did not improve from -165.16156\n",
      "Epoch 2204/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.0435 - val_loss: -167.6795\n",
      "\n",
      "Epoch 02204: loss did not improve from -165.16156\n",
      "Epoch 2205/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.1100 - val_loss: -166.9109\n",
      "\n",
      "Epoch 02205: loss did not improve from -165.16156\n",
      "Epoch 2206/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.0736 - val_loss: -167.4760\n",
      "\n",
      "Epoch 02206: loss did not improve from -165.16156\n",
      "Epoch 2207/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.9130 - val_loss: -167.3627\n",
      "\n",
      "Epoch 02207: loss did not improve from -165.16156\n",
      "Epoch 2208/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.1791 - val_loss: -167.1894\n",
      "\n",
      "Epoch 02208: loss improved from -165.16156 to -165.17913, saving model to gendance.h5\n",
      "Epoch 2209/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.1668 - val_loss: -167.7735\n",
      "\n",
      "Epoch 02209: loss did not improve from -165.17913\n",
      "Epoch 2210/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.1809 - val_loss: -166.6924\n",
      "\n",
      "Epoch 02210: loss improved from -165.17913 to -165.18091, saving model to gendance.h5\n",
      "Epoch 2211/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.1995 - val_loss: -167.6043\n",
      "\n",
      "Epoch 02211: loss improved from -165.18091 to -165.19952, saving model to gendance.h5\n",
      "Epoch 2212/10000\n",
      "16167/16167 [==============================] - 1s 33us/step - loss: -165.0055 - val_loss: -167.0825\n",
      "\n",
      "Epoch 02212: loss did not improve from -165.19952\n",
      "Epoch 2213/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.1119 - val_loss: -167.2277\n",
      "\n",
      "Epoch 02213: loss did not improve from -165.19952\n",
      "Epoch 2214/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.7513 - val_loss: -167.5947\n",
      "\n",
      "Epoch 02214: loss did not improve from -165.19952\n",
      "Epoch 2215/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.8324 - val_loss: -166.6440\n",
      "\n",
      "Epoch 02215: loss did not improve from -165.19952\n",
      "Epoch 2216/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.9720 - val_loss: -167.5240\n",
      "\n",
      "Epoch 02216: loss did not improve from -165.19952\n",
      "Epoch 2217/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.8948 - val_loss: -167.0203\n",
      "\n",
      "Epoch 02217: loss did not improve from -165.19952\n",
      "Epoch 2218/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.9365 - val_loss: -167.1999\n",
      "\n",
      "Epoch 02218: loss did not improve from -165.19952\n",
      "Epoch 2219/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.0239 - val_loss: -167.3364\n",
      "\n",
      "Epoch 02219: loss did not improve from -165.19952\n",
      "Epoch 2220/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.0386 - val_loss: -167.0816\n",
      "\n",
      "Epoch 02220: loss did not improve from -165.19952\n",
      "Epoch 2221/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.0631 - val_loss: -167.7328\n",
      "\n",
      "Epoch 02221: loss did not improve from -165.19952\n",
      "Epoch 2222/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.0477 - val_loss: -166.6017\n",
      "\n",
      "Epoch 02222: loss did not improve from -165.19952\n",
      "Epoch 2223/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.1083 - val_loss: -167.4420\n",
      "\n",
      "Epoch 02223: loss did not improve from -165.19952\n",
      "Epoch 2224/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.0128 - val_loss: -167.4758\n",
      "\n",
      "Epoch 02224: loss did not improve from -165.19952\n",
      "Epoch 2225/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.9898 - val_loss: -167.2911\n",
      "\n",
      "Epoch 02225: loss did not improve from -165.19952\n",
      "Epoch 2226/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.9313 - val_loss: -167.6225\n",
      "\n",
      "Epoch 02226: loss did not improve from -165.19952\n",
      "Epoch 2227/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.9749 - val_loss: -166.9603\n",
      "\n",
      "Epoch 02227: loss did not improve from -165.19952\n",
      "Epoch 2228/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.0954 - val_loss: -167.4601\n",
      "\n",
      "Epoch 02228: loss did not improve from -165.19952\n",
      "Epoch 2229/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.0728 - val_loss: -167.0433\n",
      "\n",
      "Epoch 02229: loss did not improve from -165.19952\n",
      "Epoch 2230/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.1086 - val_loss: -167.4825\n",
      "\n",
      "Epoch 02230: loss did not improve from -165.19952\n",
      "Epoch 2231/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.1332 - val_loss: -167.0862\n",
      "\n",
      "Epoch 02231: loss did not improve from -165.19952\n",
      "Epoch 2232/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.1281 - val_loss: -167.5343\n",
      "\n",
      "Epoch 02232: loss did not improve from -165.19952\n",
      "Epoch 2233/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.2047 - val_loss: -167.5793\n",
      "\n",
      "Epoch 02233: loss improved from -165.19952 to -165.20473, saving model to gendance.h5\n",
      "Epoch 2234/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.9713 - val_loss: -167.2244\n",
      "\n",
      "Epoch 02234: loss did not improve from -165.20473\n",
      "Epoch 2235/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.0193 - val_loss: -167.6615\n",
      "\n",
      "Epoch 02235: loss did not improve from -165.20473\n",
      "Epoch 2236/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.1303 - val_loss: -167.1511\n",
      "\n",
      "Epoch 02236: loss did not improve from -165.20473\n",
      "Epoch 2237/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.3093 - val_loss: -167.9265\n",
      "\n",
      "Epoch 02237: loss improved from -165.20473 to -165.30926, saving model to gendance.h5\n",
      "Epoch 2238/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.2310 - val_loss: -167.3961\n",
      "\n",
      "Epoch 02238: loss did not improve from -165.30926\n",
      "Epoch 2239/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.3087 - val_loss: -167.4313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 02239: loss did not improve from -165.30926\n",
      "Epoch 2240/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.3954 - val_loss: -167.7231\n",
      "\n",
      "Epoch 02240: loss improved from -165.30926 to -165.39536, saving model to gendance.h5\n",
      "Epoch 2241/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.3575 - val_loss: -167.6641\n",
      "\n",
      "Epoch 02241: loss did not improve from -165.39536\n",
      "Epoch 2242/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.0950 - val_loss: -167.5737\n",
      "\n",
      "Epoch 02242: loss did not improve from -165.39536\n",
      "Epoch 2243/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.2156 - val_loss: -167.2874\n",
      "\n",
      "Epoch 02243: loss did not improve from -165.39536\n",
      "Epoch 2244/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.1993 - val_loss: -167.6631\n",
      "\n",
      "Epoch 02244: loss did not improve from -165.39536\n",
      "Epoch 2245/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.2720 - val_loss: -166.9056\n",
      "\n",
      "Epoch 02245: loss did not improve from -165.39536\n",
      "Epoch 2246/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.1069 - val_loss: -167.7943\n",
      "\n",
      "Epoch 02246: loss did not improve from -165.39536\n",
      "Epoch 2247/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.0802 - val_loss: -167.1375\n",
      "\n",
      "Epoch 02247: loss did not improve from -165.39536\n",
      "Epoch 2248/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.1765 - val_loss: -167.0898\n",
      "\n",
      "Epoch 02248: loss did not improve from -165.39536\n",
      "Epoch 2249/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.9928 - val_loss: -167.8893\n",
      "\n",
      "Epoch 02249: loss did not improve from -165.39536\n",
      "Epoch 2250/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.7900 - val_loss: -166.0200\n",
      "\n",
      "Epoch 02250: loss did not improve from -165.39536\n",
      "Epoch 2251/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.0220 - val_loss: -167.4581\n",
      "\n",
      "Epoch 02251: loss did not improve from -165.39536\n",
      "Epoch 2252/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.0366 - val_loss: -166.9672\n",
      "\n",
      "Epoch 02252: loss did not improve from -165.39536\n",
      "Epoch 2253/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.2150 - val_loss: -167.6122\n",
      "\n",
      "Epoch 02253: loss did not improve from -165.39536\n",
      "Epoch 2254/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.2620 - val_loss: -167.8011\n",
      "\n",
      "Epoch 02254: loss did not improve from -165.39536\n",
      "Epoch 2255/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.3138 - val_loss: -167.2121\n",
      "\n",
      "Epoch 02255: loss did not improve from -165.39536\n",
      "Epoch 2256/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.8816 - val_loss: -167.8463\n",
      "\n",
      "Epoch 02256: loss did not improve from -165.39536\n",
      "Epoch 2257/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.4805 - val_loss: -167.3126\n",
      "\n",
      "Epoch 02257: loss improved from -165.39536 to -165.48055, saving model to gendance.h5\n",
      "Epoch 2258/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.3368 - val_loss: -167.8194\n",
      "\n",
      "Epoch 02258: loss did not improve from -165.48055\n",
      "Epoch 2259/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.4127 - val_loss: -167.5633\n",
      "\n",
      "Epoch 02259: loss did not improve from -165.48055\n",
      "Epoch 2260/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.3214 - val_loss: -167.5203\n",
      "\n",
      "Epoch 02260: loss did not improve from -165.48055\n",
      "Epoch 2261/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.5225 - val_loss: -168.0109\n",
      "\n",
      "Epoch 02261: loss improved from -165.48055 to -165.52249, saving model to gendance.h5\n",
      "Epoch 2262/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.2871 - val_loss: -167.2977\n",
      "\n",
      "Epoch 02262: loss did not improve from -165.52249\n",
      "Epoch 2263/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.1381 - val_loss: -167.9199\n",
      "\n",
      "Epoch 02263: loss did not improve from -165.52249\n",
      "Epoch 2264/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.1407 - val_loss: -167.3111\n",
      "\n",
      "Epoch 02264: loss did not improve from -165.52249\n",
      "Epoch 2265/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.9584 - val_loss: -167.3328\n",
      "\n",
      "Epoch 02265: loss did not improve from -165.52249\n",
      "Epoch 2266/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.2496 - val_loss: -167.8517\n",
      "\n",
      "Epoch 02266: loss did not improve from -165.52249\n",
      "Epoch 2267/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.2127 - val_loss: -167.4414\n",
      "\n",
      "Epoch 02267: loss did not improve from -165.52249\n",
      "Epoch 2268/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.2610 - val_loss: -167.7247\n",
      "\n",
      "Epoch 02268: loss did not improve from -165.52249\n",
      "Epoch 2269/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.0067 - val_loss: -167.2208\n",
      "\n",
      "Epoch 02269: loss did not improve from -165.52249\n",
      "Epoch 2270/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.3160 - val_loss: -167.5968\n",
      "\n",
      "Epoch 02270: loss did not improve from -165.52249\n",
      "Epoch 2271/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.4336 - val_loss: -167.7450\n",
      "\n",
      "Epoch 02271: loss did not improve from -165.52249\n",
      "Epoch 2272/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.2374 - val_loss: -167.3011\n",
      "\n",
      "Epoch 02272: loss did not improve from -165.52249\n",
      "Epoch 2273/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.2682 - val_loss: -167.3160\n",
      "\n",
      "Epoch 02273: loss did not improve from -165.52249\n",
      "Epoch 2274/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.9826 - val_loss: -167.3281\n",
      "\n",
      "Epoch 02274: loss did not improve from -165.52249\n",
      "Epoch 2275/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.2321 - val_loss: -167.9738\n",
      "\n",
      "Epoch 02275: loss did not improve from -165.52249\n",
      "Epoch 2276/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.2244 - val_loss: -166.6410\n",
      "\n",
      "Epoch 02276: loss did not improve from -165.52249\n",
      "Epoch 2277/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -165.1099 - val_loss: -167.8165\n",
      "\n",
      "Epoch 02277: loss did not improve from -165.52249\n",
      "Epoch 2278/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.0642 - val_loss: -166.8702\n",
      "\n",
      "Epoch 02278: loss did not improve from -165.52249\n",
      "Epoch 2279/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.2548 - val_loss: -167.6990\n",
      "\n",
      "Epoch 02279: loss did not improve from -165.52249\n",
      "Epoch 2280/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.2498 - val_loss: -167.8435\n",
      "\n",
      "Epoch 02280: loss did not improve from -165.52249\n",
      "Epoch 2281/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.3277 - val_loss: -167.3528\n",
      "\n",
      "Epoch 02281: loss did not improve from -165.52249\n",
      "Epoch 2282/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.2904 - val_loss: -167.8778\n",
      "\n",
      "Epoch 02282: loss did not improve from -165.52249\n",
      "Epoch 2283/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.3982 - val_loss: -167.3039\n",
      "\n",
      "Epoch 02283: loss did not improve from -165.52249\n",
      "Epoch 2284/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.5647 - val_loss: -167.9702\n",
      "\n",
      "Epoch 02284: loss improved from -165.52249 to -165.56474, saving model to gendance.h5\n",
      "Epoch 2285/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.4735 - val_loss: -167.7053\n",
      "\n",
      "Epoch 02285: loss did not improve from -165.56474\n",
      "Epoch 2286/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.5955 - val_loss: -167.7149\n",
      "\n",
      "Epoch 02286: loss improved from -165.56474 to -165.59553, saving model to gendance.h5\n",
      "Epoch 2287/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.6581 - val_loss: -168.0321\n",
      "\n",
      "Epoch 02287: loss improved from -165.59553 to -165.65809, saving model to gendance.h5\n",
      "Epoch 2288/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.3905 - val_loss: -167.5924\n",
      "\n",
      "Epoch 02288: loss did not improve from -165.65809\n",
      "Epoch 2289/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.6595 - val_loss: -168.0563\n",
      "\n",
      "Epoch 02289: loss improved from -165.65809 to -165.65951, saving model to gendance.h5\n",
      "Epoch 2290/10000\n",
      "16167/16167 [==============================] - 1s 35us/step - loss: -165.4586 - val_loss: -167.8965\n",
      "\n",
      "Epoch 02290: loss did not improve from -165.65951\n",
      "Epoch 2291/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.6619 - val_loss: -168.0527\n",
      "\n",
      "Epoch 02291: loss improved from -165.65951 to -165.66190, saving model to gendance.h5\n",
      "Epoch 2292/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -165.6605 - val_loss: -167.6846\n",
      "\n",
      "Epoch 02292: loss did not improve from -165.66190\n",
      "Epoch 2293/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.5507 - val_loss: -167.8355\n",
      "\n",
      "Epoch 02293: loss did not improve from -165.66190\n",
      "Epoch 2294/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.5612 - val_loss: -167.7323\n",
      "\n",
      "Epoch 02294: loss did not improve from -165.66190\n",
      "Epoch 2295/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.5275 - val_loss: -167.8775\n",
      "\n",
      "Epoch 02295: loss did not improve from -165.66190\n",
      "Epoch 2296/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.3677 - val_loss: -167.8651\n",
      "\n",
      "Epoch 02296: loss did not improve from -165.66190\n",
      "Epoch 2297/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.3886 - val_loss: -167.4255\n",
      "\n",
      "Epoch 02297: loss did not improve from -165.66190\n",
      "Epoch 2298/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.6803 - val_loss: -168.0404\n",
      "\n",
      "Epoch 02298: loss improved from -165.66190 to -165.68031, saving model to gendance.h5\n",
      "Epoch 2299/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.5311 - val_loss: -167.8096\n",
      "\n",
      "Epoch 02299: loss did not improve from -165.68031\n",
      "Epoch 2300/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.5065 - val_loss: -167.8855\n",
      "\n",
      "Epoch 02300: loss did not improve from -165.68031\n",
      "Epoch 2301/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.4808 - val_loss: -167.4311\n",
      "\n",
      "Epoch 02301: loss did not improve from -165.68031\n",
      "Epoch 2302/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.4859 - val_loss: -167.9168\n",
      "\n",
      "Epoch 02302: loss did not improve from -165.68031\n",
      "Epoch 2303/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.5223 - val_loss: -167.2220\n",
      "\n",
      "Epoch 02303: loss did not improve from -165.68031\n",
      "Epoch 2304/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.8617 - val_loss: -167.2351\n",
      "\n",
      "Epoch 02304: loss did not improve from -165.68031\n",
      "Epoch 2305/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.5518 - val_loss: -167.5706\n",
      "\n",
      "Epoch 02305: loss did not improve from -165.68031\n",
      "Epoch 2306/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.5256 - val_loss: -166.0393\n",
      "\n",
      "Epoch 02306: loss did not improve from -165.68031\n",
      "Epoch 2307/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.8817 - val_loss: -167.3994\n",
      "\n",
      "Epoch 02307: loss did not improve from -165.68031\n",
      "Epoch 2308/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -164.8441 - val_loss: -167.0458\n",
      "\n",
      "Epoch 02308: loss did not improve from -165.68031\n",
      "Epoch 2309/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.1792 - val_loss: -167.7944\n",
      "\n",
      "Epoch 02309: loss did not improve from -165.68031\n",
      "Epoch 2310/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.1821 - val_loss: -167.5957\n",
      "\n",
      "Epoch 02310: loss did not improve from -165.68031\n",
      "Epoch 2311/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.6108 - val_loss: -167.9017\n",
      "\n",
      "Epoch 02311: loss did not improve from -165.68031\n",
      "Epoch 2312/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.6113 - val_loss: -168.0620\n",
      "\n",
      "Epoch 02312: loss did not improve from -165.68031\n",
      "Epoch 2313/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.8364 - val_loss: -167.8295\n",
      "\n",
      "Epoch 02313: loss improved from -165.68031 to -165.83642, saving model to gendance.h5\n",
      "Epoch 2314/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.6407 - val_loss: -168.1884\n",
      "\n",
      "Epoch 02314: loss did not improve from -165.83642\n",
      "Epoch 2315/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.4775 - val_loss: -167.5892\n",
      "\n",
      "Epoch 02315: loss did not improve from -165.83642\n",
      "Epoch 2316/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.5324 - val_loss: -168.0971\n",
      "\n",
      "Epoch 02316: loss did not improve from -165.83642\n",
      "Epoch 2317/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.5422 - val_loss: -167.8113\n",
      "\n",
      "Epoch 02317: loss did not improve from -165.83642\n",
      "Epoch 2318/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.4042 - val_loss: -167.8181\n",
      "\n",
      "Epoch 02318: loss did not improve from -165.83642\n",
      "Epoch 2319/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.6987 - val_loss: -168.0968\n",
      "\n",
      "Epoch 02319: loss did not improve from -165.83642\n",
      "Epoch 2320/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.3524 - val_loss: -167.3488\n",
      "\n",
      "Epoch 02320: loss did not improve from -165.83642\n",
      "Epoch 2321/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.5701 - val_loss: -168.0594\n",
      "\n",
      "Epoch 02321: loss did not improve from -165.83642\n",
      "Epoch 2322/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.6988 - val_loss: -167.9055\n",
      "\n",
      "Epoch 02322: loss did not improve from -165.83642\n",
      "Epoch 2323/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.7635 - val_loss: -168.0888\n",
      "\n",
      "Epoch 02323: loss did not improve from -165.83642\n",
      "Epoch 2324/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.7724 - val_loss: -168.1079\n",
      "\n",
      "Epoch 02324: loss did not improve from -165.83642\n",
      "Epoch 2325/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.8043 - val_loss: -167.7949\n",
      "\n",
      "Epoch 02325: loss did not improve from -165.83642\n",
      "Epoch 2326/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.4858 - val_loss: -168.0504\n",
      "\n",
      "Epoch 02326: loss did not improve from -165.83642\n",
      "Epoch 2327/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.3339 - val_loss: -167.1043\n",
      "\n",
      "Epoch 02327: loss did not improve from -165.83642\n",
      "Epoch 2328/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.2935 - val_loss: -167.9165\n",
      "\n",
      "Epoch 02328: loss did not improve from -165.83642\n",
      "Epoch 2329/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.5016 - val_loss: -167.6258\n",
      "\n",
      "Epoch 02329: loss did not improve from -165.83642\n",
      "Epoch 2330/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.6143 - val_loss: -168.2021\n",
      "\n",
      "Epoch 02330: loss did not improve from -165.83642\n",
      "Epoch 2331/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.6591 - val_loss: -167.5237\n",
      "\n",
      "Epoch 02331: loss did not improve from -165.83642\n",
      "Epoch 2332/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.5386 - val_loss: -167.8330\n",
      "\n",
      "Epoch 02332: loss did not improve from -165.83642\n",
      "Epoch 2333/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.7631 - val_loss: -168.2748\n",
      "\n",
      "Epoch 02333: loss did not improve from -165.83642\n",
      "Epoch 2334/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.3782 - val_loss: -166.9785\n",
      "\n",
      "Epoch 02334: loss did not improve from -165.83642\n",
      "Epoch 2335/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.3289 - val_loss: -168.0448\n",
      "\n",
      "Epoch 02335: loss did not improve from -165.83642\n",
      "Epoch 2336/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.4043 - val_loss: -167.3262\n",
      "\n",
      "Epoch 02336: loss did not improve from -165.83642\n",
      "Epoch 2337/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.4146 - val_loss: -168.0220\n",
      "\n",
      "Epoch 02337: loss did not improve from -165.83642\n",
      "Epoch 2338/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.5512 - val_loss: -167.8639\n",
      "\n",
      "Epoch 02338: loss did not improve from -165.83642\n",
      "Epoch 2339/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.6957 - val_loss: -167.9529\n",
      "\n",
      "Epoch 02339: loss did not improve from -165.83642\n",
      "Epoch 2340/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.6302 - val_loss: -168.1578\n",
      "\n",
      "Epoch 02340: loss did not improve from -165.83642\n",
      "Epoch 2341/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.7512 - val_loss: -167.5553\n",
      "\n",
      "Epoch 02341: loss did not improve from -165.83642\n",
      "Epoch 2342/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.8718 - val_loss: -168.0837\n",
      "\n",
      "Epoch 02342: loss improved from -165.83642 to -165.87182, saving model to gendance.h5\n",
      "Epoch 2343/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.5713 - val_loss: -167.7419\n",
      "\n",
      "Epoch 02343: loss did not improve from -165.87182\n",
      "Epoch 2344/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.7007 - val_loss: -167.8477\n",
      "\n",
      "Epoch 02344: loss did not improve from -165.87182\n",
      "Epoch 2345/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.6539 - val_loss: -167.9508\n",
      "\n",
      "Epoch 02345: loss did not improve from -165.87182\n",
      "Epoch 2346/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.7311 - val_loss: -167.9594\n",
      "\n",
      "Epoch 02346: loss did not improve from -165.87182\n",
      "Epoch 2347/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.8124 - val_loss: -168.1958\n",
      "\n",
      "Epoch 02347: loss did not improve from -165.87182\n",
      "Epoch 2348/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.8654 - val_loss: -167.9684\n",
      "\n",
      "Epoch 02348: loss did not improve from -165.87182\n",
      "Epoch 2349/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.7739 - val_loss: -168.0677\n",
      "\n",
      "Epoch 02349: loss did not improve from -165.87182\n",
      "Epoch 2350/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.7579 - val_loss: -167.9397\n",
      "\n",
      "Epoch 02350: loss did not improve from -165.87182\n",
      "Epoch 2351/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.5900 - val_loss: -167.5899\n",
      "\n",
      "Epoch 02351: loss did not improve from -165.87182\n",
      "Epoch 2352/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.6705 - val_loss: -168.0842\n",
      "\n",
      "Epoch 02352: loss did not improve from -165.87182\n",
      "Epoch 2353/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.7313 - val_loss: -167.8514\n",
      "\n",
      "Epoch 02353: loss did not improve from -165.87182\n",
      "Epoch 2354/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.8140 - val_loss: -167.9443\n",
      "\n",
      "Epoch 02354: loss did not improve from -165.87182\n",
      "Epoch 2355/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.5198 - val_loss: -167.7966\n",
      "\n",
      "Epoch 02355: loss did not improve from -165.87182\n",
      "Epoch 2356/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.8119 - val_loss: -167.9069\n",
      "\n",
      "Epoch 02356: loss did not improve from -165.87182\n",
      "Epoch 2357/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.3929 - val_loss: -168.1760\n",
      "\n",
      "Epoch 02357: loss did not improve from -165.87182\n",
      "Epoch 2358/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.7379 - val_loss: -167.5384\n",
      "\n",
      "Epoch 02358: loss did not improve from -165.87182\n",
      "Epoch 2359/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.5304 - val_loss: -168.3548\n",
      "\n",
      "Epoch 02359: loss did not improve from -165.87182\n",
      "Epoch 2360/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.5610 - val_loss: -167.3049\n",
      "\n",
      "Epoch 02360: loss did not improve from -165.87182\n",
      "Epoch 2361/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.4632 - val_loss: -168.0872\n",
      "\n",
      "Epoch 02361: loss did not improve from -165.87182\n",
      "Epoch 2362/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.6361 - val_loss: -167.9837\n",
      "\n",
      "Epoch 02362: loss did not improve from -165.87182\n",
      "Epoch 2363/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -165.4076 - val_loss: -167.2065\n",
      "\n",
      "Epoch 02363: loss did not improve from -165.87182\n",
      "Epoch 2364/10000\n",
      "16167/16167 [==============================] - 1s 33us/step - loss: -165.3247 - val_loss: -168.0479\n",
      "\n",
      "Epoch 02364: loss did not improve from -165.87182\n",
      "Epoch 2365/10000\n",
      "16167/16167 [==============================] - 1s 33us/step - loss: -165.1235 - val_loss: -166.9430\n",
      "\n",
      "Epoch 02365: loss did not improve from -165.87182\n",
      "Epoch 2366/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.3081 - val_loss: -167.9678\n",
      "\n",
      "Epoch 02366: loss did not improve from -165.87182\n",
      "Epoch 2367/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.4597 - val_loss: -167.9658\n",
      "\n",
      "Epoch 02367: loss did not improve from -165.87182\n",
      "Epoch 2368/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.7141 - val_loss: -167.5703\n",
      "\n",
      "Epoch 02368: loss did not improve from -165.87182\n",
      "Epoch 2369/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.3697 - val_loss: -167.9692\n",
      "\n",
      "Epoch 02369: loss did not improve from -165.87182\n",
      "Epoch 2370/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.5521 - val_loss: -167.3923\n",
      "\n",
      "Epoch 02370: loss did not improve from -165.87182\n",
      "Epoch 2371/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.6330 - val_loss: -168.1999\n",
      "\n",
      "Epoch 02371: loss did not improve from -165.87182\n",
      "Epoch 2372/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.4891 - val_loss: -167.4848\n",
      "\n",
      "Epoch 02372: loss did not improve from -165.87182\n",
      "Epoch 2373/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.7866 - val_loss: -168.1598\n",
      "\n",
      "Epoch 02373: loss did not improve from -165.87182\n",
      "Epoch 2374/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.8284 - val_loss: -168.1375\n",
      "\n",
      "Epoch 02374: loss did not improve from -165.87182\n",
      "Epoch 2375/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.9054 - val_loss: -167.8427\n",
      "\n",
      "Epoch 02375: loss improved from -165.87182 to -165.90540, saving model to gendance.h5\n",
      "Epoch 2376/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.7456 - val_loss: -168.2870\n",
      "\n",
      "Epoch 02376: loss did not improve from -165.90540\n",
      "Epoch 2377/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.4700 - val_loss: -167.5445\n",
      "\n",
      "Epoch 02377: loss did not improve from -165.90540\n",
      "Epoch 2378/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.7122 - val_loss: -168.2675\n",
      "\n",
      "Epoch 02378: loss did not improve from -165.90540\n",
      "Epoch 2379/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.8265 - val_loss: -167.2578\n",
      "\n",
      "Epoch 02379: loss did not improve from -165.90540\n",
      "Epoch 2380/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.7771 - val_loss: -168.0216\n",
      "\n",
      "Epoch 02380: loss did not improve from -165.90540\n",
      "Epoch 2381/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.7863 - val_loss: -168.0498\n",
      "\n",
      "Epoch 02381: loss did not improve from -165.90540\n",
      "Epoch 2382/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.6667 - val_loss: -167.6784\n",
      "\n",
      "Epoch 02382: loss did not improve from -165.90540\n",
      "Epoch 2383/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.6246 - val_loss: -168.2377\n",
      "\n",
      "Epoch 02383: loss did not improve from -165.90540\n",
      "Epoch 2384/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.5317 - val_loss: -167.1892\n",
      "\n",
      "Epoch 02384: loss did not improve from -165.90540\n",
      "Epoch 2385/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.5460 - val_loss: -168.1295\n",
      "\n",
      "Epoch 02385: loss did not improve from -165.90540\n",
      "Epoch 2386/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.5516 - val_loss: -167.5933\n",
      "\n",
      "Epoch 02386: loss did not improve from -165.90540\n",
      "Epoch 2387/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.9533 - val_loss: -168.3170\n",
      "\n",
      "Epoch 02387: loss improved from -165.90540 to -165.95334, saving model to gendance.h5\n",
      "Epoch 2388/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.6035 - val_loss: -167.9804\n",
      "\n",
      "Epoch 02388: loss did not improve from -165.95334\n",
      "Epoch 2389/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.8259 - val_loss: -167.7582\n",
      "\n",
      "Epoch 02389: loss did not improve from -165.95334\n",
      "Epoch 2390/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.7570 - val_loss: -168.4306\n",
      "\n",
      "Epoch 02390: loss did not improve from -165.95334\n",
      "Epoch 2391/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.6650 - val_loss: -167.4484\n",
      "\n",
      "Epoch 02391: loss did not improve from -165.95334\n",
      "Epoch 2392/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.6618 - val_loss: -168.1325\n",
      "\n",
      "Epoch 02392: loss did not improve from -165.95334\n",
      "Epoch 2393/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.8324 - val_loss: -167.8665\n",
      "\n",
      "Epoch 02393: loss did not improve from -165.95334\n",
      "Epoch 2394/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.8307 - val_loss: -168.4477\n",
      "\n",
      "Epoch 02394: loss did not improve from -165.95334\n",
      "Epoch 2395/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.7555 - val_loss: -168.3182\n",
      "\n",
      "Epoch 02395: loss did not improve from -165.95334\n",
      "Epoch 2396/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.8791 - val_loss: -167.9072\n",
      "\n",
      "Epoch 02396: loss did not improve from -165.95334\n",
      "Epoch 2397/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.8839 - val_loss: -168.4015\n",
      "\n",
      "Epoch 02397: loss did not improve from -165.95334\n",
      "Epoch 2398/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.8200 - val_loss: -167.7359\n",
      "\n",
      "Epoch 02398: loss did not improve from -165.95334\n",
      "Epoch 2399/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.9295 - val_loss: -168.2591\n",
      "\n",
      "Epoch 02399: loss did not improve from -165.95334\n",
      "Epoch 2400/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.0052 - val_loss: -167.9235\n",
      "\n",
      "Epoch 02400: loss improved from -165.95334 to -166.00521, saving model to gendance.h5\n",
      "Epoch 2401/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.1043 - val_loss: -168.3586\n",
      "\n",
      "Epoch 02401: loss improved from -166.00521 to -166.10433, saving model to gendance.h5\n",
      "Epoch 2402/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.0834 - val_loss: -168.2398\n",
      "\n",
      "Epoch 02402: loss did not improve from -166.10433\n",
      "Epoch 2403/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.9369 - val_loss: -167.9589\n",
      "\n",
      "Epoch 02403: loss did not improve from -166.10433\n",
      "Epoch 2404/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.8268 - val_loss: -168.2613\n",
      "\n",
      "Epoch 02404: loss did not improve from -166.10433\n",
      "Epoch 2405/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.5396 - val_loss: -167.6368\n",
      "\n",
      "Epoch 02405: loss did not improve from -166.10433\n",
      "Epoch 2406/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -166.0185 - val_loss: -168.2019\n",
      "\n",
      "Epoch 02406: loss did not improve from -166.10433\n",
      "Epoch 2407/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.9117 - val_loss: -167.7225\n",
      "\n",
      "Epoch 02407: loss did not improve from -166.10433\n",
      "Epoch 2408/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.0302 - val_loss: -168.4099\n",
      "\n",
      "Epoch 02408: loss did not improve from -166.10433\n",
      "Epoch 2409/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.8327 - val_loss: -168.1311\n",
      "\n",
      "Epoch 02409: loss did not improve from -166.10433\n",
      "Epoch 2410/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.1011 - val_loss: -168.0184\n",
      "\n",
      "Epoch 02410: loss did not improve from -166.10433\n",
      "Epoch 2411/10000\n",
      "16167/16167 [==============================] - 1s 32us/step - loss: -165.9777 - val_loss: -168.5036\n",
      "\n",
      "Epoch 02411: loss did not improve from -166.10433\n",
      "Epoch 2412/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.9035 - val_loss: -167.5365\n",
      "\n",
      "Epoch 02412: loss did not improve from -166.10433\n",
      "Epoch 2413/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.7540 - val_loss: -168.4552\n",
      "\n",
      "Epoch 02413: loss did not improve from -166.10433\n",
      "Epoch 2414/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.0037 - val_loss: -167.8679\n",
      "\n",
      "Epoch 02414: loss did not improve from -166.10433\n",
      "Epoch 2415/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.0691 - val_loss: -168.2211\n",
      "\n",
      "Epoch 02415: loss did not improve from -166.10433\n",
      "Epoch 2416/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.8212 - val_loss: -168.4155\n",
      "\n",
      "Epoch 02416: loss did not improve from -166.10433\n",
      "Epoch 2417/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.7339 - val_loss: -167.7708\n",
      "\n",
      "Epoch 02417: loss did not improve from -166.10433\n",
      "Epoch 2418/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.8464 - val_loss: -168.3751\n",
      "\n",
      "Epoch 02418: loss did not improve from -166.10433\n",
      "Epoch 2419/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.6011 - val_loss: -167.2079\n",
      "\n",
      "Epoch 02419: loss did not improve from -166.10433\n",
      "Epoch 2420/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.7614 - val_loss: -168.4078\n",
      "\n",
      "Epoch 02420: loss did not improve from -166.10433\n",
      "Epoch 2421/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.8046 - val_loss: -168.2203\n",
      "\n",
      "Epoch 02421: loss did not improve from -166.10433\n",
      "Epoch 2422/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.8751 - val_loss: -167.7913\n",
      "\n",
      "Epoch 02422: loss did not improve from -166.10433\n",
      "Epoch 2423/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.7911 - val_loss: -168.3345\n",
      "\n",
      "Epoch 02423: loss did not improve from -166.10433\n",
      "Epoch 2424/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.5713 - val_loss: -167.7691\n",
      "\n",
      "Epoch 02424: loss did not improve from -166.10433\n",
      "Epoch 2425/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.8155 - val_loss: -168.2917\n",
      "\n",
      "Epoch 02425: loss did not improve from -166.10433\n",
      "Epoch 2426/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.8154 - val_loss: -168.0162\n",
      "\n",
      "Epoch 02426: loss did not improve from -166.10433\n",
      "Epoch 2427/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.0818 - val_loss: -168.5403\n",
      "\n",
      "Epoch 02427: loss did not improve from -166.10433\n",
      "Epoch 2428/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.0682 - val_loss: -167.9451\n",
      "\n",
      "Epoch 02428: loss did not improve from -166.10433\n",
      "Epoch 2429/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.1724 - val_loss: -168.4843\n",
      "\n",
      "Epoch 02429: loss improved from -166.10433 to -166.17237, saving model to gendance.h5\n",
      "Epoch 2430/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -165.9882 - val_loss: -168.5743\n",
      "\n",
      "Epoch 02430: loss did not improve from -166.17237\n",
      "Epoch 2431/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.0136 - val_loss: -168.0399\n",
      "\n",
      "Epoch 02431: loss did not improve from -166.17237\n",
      "Epoch 2432/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.1254 - val_loss: -168.4944\n",
      "\n",
      "Epoch 02432: loss did not improve from -166.17237\n",
      "Epoch 2433/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.9784 - val_loss: -167.8329\n",
      "\n",
      "Epoch 02433: loss did not improve from -166.17237\n",
      "Epoch 2434/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.9993 - val_loss: -168.6034\n",
      "\n",
      "Epoch 02434: loss did not improve from -166.17237\n",
      "Epoch 2435/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.0312 - val_loss: -168.1884\n",
      "\n",
      "Epoch 02435: loss did not improve from -166.17237\n",
      "Epoch 2436/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.1150 - val_loss: -168.3955\n",
      "\n",
      "Epoch 02436: loss did not improve from -166.17237\n",
      "Epoch 2437/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.2242 - val_loss: -168.4163\n",
      "\n",
      "Epoch 02437: loss improved from -166.17237 to -166.22415, saving model to gendance.h5\n",
      "Epoch 2438/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.1096 - val_loss: -168.2772\n",
      "\n",
      "Epoch 02438: loss did not improve from -166.22415\n",
      "Epoch 2439/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.2450 - val_loss: -168.5405\n",
      "\n",
      "Epoch 02439: loss improved from -166.22415 to -166.24497, saving model to gendance.h5\n",
      "Epoch 2440/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.9154 - val_loss: -167.9324\n",
      "\n",
      "Epoch 02440: loss did not improve from -166.24497\n",
      "Epoch 2441/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.7568 - val_loss: -168.4451\n",
      "\n",
      "Epoch 02441: loss did not improve from -166.24497\n",
      "Epoch 2442/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.6571 - val_loss: -167.4912\n",
      "\n",
      "Epoch 02442: loss did not improve from -166.24497\n",
      "Epoch 2443/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.0335 - val_loss: -168.5325\n",
      "\n",
      "Epoch 02443: loss did not improve from -166.24497\n",
      "Epoch 2444/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.0881 - val_loss: -168.5084\n",
      "\n",
      "Epoch 02444: loss did not improve from -166.24497\n",
      "Epoch 2445/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.8840 - val_loss: -168.1462\n",
      "\n",
      "Epoch 02445: loss did not improve from -166.24497\n",
      "Epoch 2446/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.0050 - val_loss: -168.5397\n",
      "\n",
      "Epoch 02446: loss did not improve from -166.24497\n",
      "Epoch 2447/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.1126 - val_loss: -168.3728\n",
      "\n",
      "Epoch 02447: loss did not improve from -166.24497\n",
      "Epoch 2448/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.0712 - val_loss: -168.4500\n",
      "\n",
      "Epoch 02448: loss did not improve from -166.24497\n",
      "Epoch 2449/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.1951 - val_loss: -168.2610\n",
      "\n",
      "Epoch 02449: loss did not improve from -166.24497\n",
      "Epoch 2450/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.3075 - val_loss: -168.7070\n",
      "\n",
      "Epoch 02450: loss improved from -166.24497 to -166.30746, saving model to gendance.h5\n",
      "Epoch 2451/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.1878 - val_loss: -168.2918\n",
      "\n",
      "Epoch 02451: loss did not improve from -166.30746\n",
      "Epoch 2452/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.9280 - val_loss: -167.8755\n",
      "\n",
      "Epoch 02452: loss did not improve from -166.30746\n",
      "Epoch 2453/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.1255 - val_loss: -168.5933\n",
      "\n",
      "Epoch 02453: loss did not improve from -166.30746\n",
      "Epoch 2454/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.6040 - val_loss: -167.6075\n",
      "\n",
      "Epoch 02454: loss did not improve from -166.30746\n",
      "Epoch 2455/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.6808 - val_loss: -168.4626\n",
      "\n",
      "Epoch 02455: loss did not improve from -166.30746\n",
      "Epoch 2456/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.6363 - val_loss: -167.6960\n",
      "\n",
      "Epoch 02456: loss did not improve from -166.30746\n",
      "Epoch 2457/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.0274 - val_loss: -168.5120\n",
      "\n",
      "Epoch 02457: loss did not improve from -166.30746\n",
      "Epoch 2458/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.0158 - val_loss: -168.0043\n",
      "\n",
      "Epoch 02458: loss did not improve from -166.30746\n",
      "Epoch 2459/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.9169 - val_loss: -168.4980\n",
      "\n",
      "Epoch 02459: loss did not improve from -166.30746\n",
      "Epoch 2460/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.3495 - val_loss: -168.4071\n",
      "\n",
      "Epoch 02460: loss improved from -166.30746 to -166.34950, saving model to gendance.h5\n",
      "Epoch 2461/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.1023 - val_loss: -168.2855\n",
      "\n",
      "Epoch 02461: loss did not improve from -166.34950\n",
      "Epoch 2462/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.1850 - val_loss: -168.6581\n",
      "\n",
      "Epoch 02462: loss did not improve from -166.34950\n",
      "Epoch 2463/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.1414 - val_loss: -167.9358\n",
      "\n",
      "Epoch 02463: loss did not improve from -166.34950\n",
      "Epoch 2464/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.0133 - val_loss: -168.5187\n",
      "\n",
      "Epoch 02464: loss did not improve from -166.34950\n",
      "Epoch 2465/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.8859 - val_loss: -168.0114\n",
      "\n",
      "Epoch 02465: loss did not improve from -166.34950\n",
      "Epoch 2466/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.2014 - val_loss: -168.5141\n",
      "\n",
      "Epoch 02466: loss did not improve from -166.34950\n",
      "Epoch 2467/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.1500 - val_loss: -168.2457\n",
      "\n",
      "Epoch 02467: loss did not improve from -166.34950\n",
      "Epoch 2468/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.0823 - val_loss: -168.3415\n",
      "\n",
      "Epoch 02468: loss did not improve from -166.34950\n",
      "Epoch 2469/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.1454 - val_loss: -168.5636\n",
      "\n",
      "Epoch 02469: loss did not improve from -166.34950\n",
      "Epoch 2470/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.0674 - val_loss: -167.8711\n",
      "\n",
      "Epoch 02470: loss did not improve from -166.34950\n",
      "Epoch 2471/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.0623 - val_loss: -168.5710\n",
      "\n",
      "Epoch 02471: loss did not improve from -166.34950\n",
      "Epoch 2472/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.2297 - val_loss: -168.0034\n",
      "\n",
      "Epoch 02472: loss did not improve from -166.34950\n",
      "Epoch 2473/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.2360 - val_loss: -168.7633\n",
      "\n",
      "Epoch 02473: loss did not improve from -166.34950\n",
      "Epoch 2474/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.3034 - val_loss: -168.1332\n",
      "\n",
      "Epoch 02474: loss did not improve from -166.34950\n",
      "Epoch 2475/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.0709 - val_loss: -168.4712\n",
      "\n",
      "Epoch 02475: loss did not improve from -166.34950\n",
      "Epoch 2476/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.1065 - val_loss: -168.3733\n",
      "\n",
      "Epoch 02476: loss did not improve from -166.34950\n",
      "Epoch 2477/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.0084 - val_loss: -167.9642\n",
      "\n",
      "Epoch 02477: loss did not improve from -166.34950\n",
      "Epoch 2478/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.9102 - val_loss: -168.4868\n",
      "\n",
      "Epoch 02478: loss did not improve from -166.34950\n",
      "Epoch 2479/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.9903 - val_loss: -167.8441\n",
      "\n",
      "Epoch 02479: loss did not improve from -166.34950\n",
      "Epoch 2480/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.9860 - val_loss: -168.4389\n",
      "\n",
      "Epoch 02480: loss did not improve from -166.34950\n",
      "Epoch 2481/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.1591 - val_loss: -168.0438\n",
      "\n",
      "Epoch 02481: loss did not improve from -166.34950\n",
      "Epoch 2482/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.0905 - val_loss: -168.2917\n",
      "\n",
      "Epoch 02482: loss did not improve from -166.34950\n",
      "Epoch 2483/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.0888 - val_loss: -168.3676\n",
      "\n",
      "Epoch 02483: loss did not improve from -166.34950\n",
      "Epoch 2484/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.8539 - val_loss: -167.8165\n",
      "\n",
      "Epoch 02484: loss did not improve from -166.34950\n",
      "Epoch 2485/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.2628 - val_loss: -168.8304\n",
      "\n",
      "Epoch 02485: loss did not improve from -166.34950\n",
      "Epoch 2486/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.8376 - val_loss: -167.8938\n",
      "\n",
      "Epoch 02486: loss did not improve from -166.34950\n",
      "Epoch 2487/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.9864 - val_loss: -168.5028\n",
      "\n",
      "Epoch 02487: loss did not improve from -166.34950\n",
      "Epoch 2488/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.2150 - val_loss: -168.4221\n",
      "\n",
      "Epoch 02488: loss did not improve from -166.34950\n",
      "Epoch 2489/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.1019 - val_loss: -168.4844\n",
      "\n",
      "Epoch 02489: loss did not improve from -166.34950\n",
      "Epoch 2490/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.1520 - val_loss: -168.5689\n",
      "\n",
      "Epoch 02490: loss did not improve from -166.34950\n",
      "Epoch 2491/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.0671 - val_loss: -168.3324\n",
      "\n",
      "Epoch 02491: loss did not improve from -166.34950\n",
      "Epoch 2492/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.2062 - val_loss: -168.9032\n",
      "\n",
      "Epoch 02492: loss did not improve from -166.34950\n",
      "Epoch 2493/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.2186 - val_loss: -168.0132\n",
      "\n",
      "Epoch 02493: loss did not improve from -166.34950\n",
      "Epoch 2494/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.2803 - val_loss: -168.9884\n",
      "\n",
      "Epoch 02494: loss did not improve from -166.34950\n",
      "Epoch 2495/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.2058 - val_loss: -168.3345\n",
      "\n",
      "Epoch 02495: loss did not improve from -166.34950\n",
      "Epoch 2496/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.2851 - val_loss: -168.2946\n",
      "\n",
      "Epoch 02496: loss did not improve from -166.34950\n",
      "Epoch 2497/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.9443 - val_loss: -168.7398\n",
      "\n",
      "Epoch 02497: loss did not improve from -166.34950\n",
      "Epoch 2498/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.0946 - val_loss: -168.1140\n",
      "\n",
      "Epoch 02498: loss did not improve from -166.34950\n",
      "Epoch 2499/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.9103 - val_loss: -168.5381\n",
      "\n",
      "Epoch 02499: loss did not improve from -166.34950\n",
      "Epoch 2500/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.3882 - val_loss: -168.6474\n",
      "\n",
      "Epoch 02500: loss improved from -166.34950 to -166.38818, saving model to gendance.h5\n",
      "Epoch 2501/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.4865 - val_loss: -168.5845\n",
      "\n",
      "Epoch 02501: loss improved from -166.38818 to -166.48653, saving model to gendance.h5\n",
      "Epoch 2502/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.4245 - val_loss: -168.5196\n",
      "\n",
      "Epoch 02502: loss did not improve from -166.48653\n",
      "Epoch 2503/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.4548 - val_loss: -168.6831\n",
      "\n",
      "Epoch 02503: loss did not improve from -166.48653\n",
      "Epoch 2504/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.3194 - val_loss: -168.6462\n",
      "\n",
      "Epoch 02504: loss did not improve from -166.48653\n",
      "Epoch 2505/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.2812 - val_loss: -168.3525\n",
      "\n",
      "Epoch 02505: loss did not improve from -166.48653\n",
      "Epoch 2506/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.4236 - val_loss: -168.5294\n",
      "\n",
      "Epoch 02506: loss did not improve from -166.48653\n",
      "Epoch 2507/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.3819 - val_loss: -168.7466\n",
      "\n",
      "Epoch 02507: loss did not improve from -166.48653\n",
      "Epoch 2508/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.3653 - val_loss: -168.4283\n",
      "\n",
      "Epoch 02508: loss did not improve from -166.48653\n",
      "Epoch 2509/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.2696 - val_loss: -168.6405\n",
      "\n",
      "Epoch 02509: loss did not improve from -166.48653\n",
      "Epoch 2510/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.2534 - val_loss: -168.1778\n",
      "\n",
      "Epoch 02510: loss did not improve from -166.48653\n",
      "Epoch 2511/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.3304 - val_loss: -168.3563\n",
      "\n",
      "Epoch 02511: loss did not improve from -166.48653\n",
      "Epoch 2512/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.1789 - val_loss: -168.8562\n",
      "\n",
      "Epoch 02512: loss did not improve from -166.48653\n",
      "Epoch 2513/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.5494 - val_loss: -168.1913\n",
      "\n",
      "Epoch 02513: loss improved from -166.48653 to -166.54937, saving model to gendance.h5\n",
      "Epoch 2514/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.2164 - val_loss: -168.6639\n",
      "\n",
      "Epoch 02514: loss did not improve from -166.54937\n",
      "Epoch 2515/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.2206 - val_loss: -168.2232\n",
      "\n",
      "Epoch 02515: loss did not improve from -166.54937\n",
      "Epoch 2516/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.2523 - val_loss: -168.5302\n",
      "\n",
      "Epoch 02516: loss did not improve from -166.54937\n",
      "Epoch 2517/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.1110 - val_loss: -168.5338\n",
      "\n",
      "Epoch 02517: loss did not improve from -166.54937\n",
      "Epoch 2518/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.1071 - val_loss: -168.1575\n",
      "\n",
      "Epoch 02518: loss did not improve from -166.54937\n",
      "Epoch 2519/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.5908 - val_loss: -168.4944\n",
      "\n",
      "Epoch 02519: loss did not improve from -166.54937\n",
      "Epoch 2520/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.7613 - val_loss: -167.3846\n",
      "\n",
      "Epoch 02520: loss did not improve from -166.54937\n",
      "Epoch 2521/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -165.8726 - val_loss: -168.6147\n",
      "\n",
      "Epoch 02521: loss did not improve from -166.54937\n",
      "Epoch 2522/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.2999 - val_loss: -168.0764\n",
      "\n",
      "Epoch 02522: loss did not improve from -166.54937\n",
      "Epoch 2523/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.2530 - val_loss: -168.5289\n",
      "\n",
      "Epoch 02523: loss did not improve from -166.54937\n",
      "Epoch 2524/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.4497 - val_loss: -168.8183\n",
      "\n",
      "Epoch 02524: loss did not improve from -166.54937\n",
      "Epoch 2525/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.3221 - val_loss: -168.4609\n",
      "\n",
      "Epoch 02525: loss did not improve from -166.54937\n",
      "Epoch 2526/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.1540 - val_loss: -168.6747\n",
      "\n",
      "Epoch 02526: loss did not improve from -166.54937\n",
      "Epoch 2527/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.3485 - val_loss: -168.7287\n",
      "\n",
      "Epoch 02527: loss did not improve from -166.54937\n",
      "Epoch 2528/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.3409 - val_loss: -168.7643\n",
      "\n",
      "Epoch 02528: loss did not improve from -166.54937\n",
      "Epoch 2529/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.3590 - val_loss: -168.6369\n",
      "\n",
      "Epoch 02529: loss did not improve from -166.54937\n",
      "Epoch 2530/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -166.3848 - val_loss: -168.7330\n",
      "\n",
      "Epoch 02530: loss did not improve from -166.54937\n",
      "Epoch 2531/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.3582 - val_loss: -168.4904\n",
      "\n",
      "Epoch 02531: loss did not improve from -166.54937\n",
      "Epoch 2532/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.5832 - val_loss: -168.9786\n",
      "\n",
      "Epoch 02532: loss improved from -166.54937 to -166.58323, saving model to gendance.h5\n",
      "Epoch 2533/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.2692 - val_loss: -168.6808\n",
      "\n",
      "Epoch 02533: loss did not improve from -166.58323\n",
      "Epoch 2534/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.5515 - val_loss: -169.0046\n",
      "\n",
      "Epoch 02534: loss did not improve from -166.58323\n",
      "Epoch 2535/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.4991 - val_loss: -168.7144\n",
      "\n",
      "Epoch 02535: loss did not improve from -166.58323\n",
      "Epoch 2536/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.6049 - val_loss: -168.8486\n",
      "\n",
      "Epoch 02536: loss improved from -166.58323 to -166.60491, saving model to gendance.h5\n",
      "Epoch 2537/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.5923 - val_loss: -168.8679\n",
      "\n",
      "Epoch 02537: loss did not improve from -166.60491\n",
      "Epoch 2538/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.6110 - val_loss: -169.0736\n",
      "\n",
      "Epoch 02538: loss improved from -166.60491 to -166.61102, saving model to gendance.h5\n",
      "Epoch 2539/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.5634 - val_loss: -168.7483\n",
      "\n",
      "Epoch 02539: loss did not improve from -166.61102\n",
      "Epoch 2540/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.4491 - val_loss: -168.8365\n",
      "\n",
      "Epoch 02540: loss did not improve from -166.61102\n",
      "Epoch 2541/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.2140 - val_loss: -168.9076\n",
      "\n",
      "Epoch 02541: loss did not improve from -166.61102\n",
      "Epoch 2542/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.2728 - val_loss: -168.1494\n",
      "\n",
      "Epoch 02542: loss did not improve from -166.61102\n",
      "Epoch 2543/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.3363 - val_loss: -168.8981\n",
      "\n",
      "Epoch 02543: loss did not improve from -166.61102\n",
      "Epoch 2544/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.3149 - val_loss: -168.0805\n",
      "\n",
      "Epoch 02544: loss did not improve from -166.61102\n",
      "Epoch 2545/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.2062 - val_loss: -168.8071\n",
      "\n",
      "Epoch 02545: loss did not improve from -166.61102\n",
      "Epoch 2546/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.3859 - val_loss: -168.6747\n",
      "\n",
      "Epoch 02546: loss did not improve from -166.61102\n",
      "Epoch 2547/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.3328 - val_loss: -168.3454\n",
      "\n",
      "Epoch 02547: loss did not improve from -166.61102\n",
      "Epoch 2548/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.2772 - val_loss: -168.7951\n",
      "\n",
      "Epoch 02548: loss did not improve from -166.61102\n",
      "Epoch 2549/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.2358 - val_loss: -168.0982\n",
      "\n",
      "Epoch 02549: loss did not improve from -166.61102\n",
      "Epoch 2550/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.3146 - val_loss: -168.8949\n",
      "\n",
      "Epoch 02550: loss did not improve from -166.61102\n",
      "Epoch 2551/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.6099 - val_loss: -168.1836\n",
      "\n",
      "Epoch 02551: loss did not improve from -166.61102\n",
      "Epoch 2552/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.5041 - val_loss: -168.7602\n",
      "\n",
      "Epoch 02552: loss did not improve from -166.61102\n",
      "Epoch 2553/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.2469 - val_loss: -168.5776\n",
      "\n",
      "Epoch 02553: loss did not improve from -166.61102\n",
      "Epoch 2554/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.5880 - val_loss: -168.6908\n",
      "\n",
      "Epoch 02554: loss did not improve from -166.61102\n",
      "Epoch 2555/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.5072 - val_loss: -168.9068\n",
      "\n",
      "Epoch 02555: loss did not improve from -166.61102\n",
      "Epoch 2556/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.2022 - val_loss: -167.9491\n",
      "\n",
      "Epoch 02556: loss did not improve from -166.61102\n",
      "Epoch 2557/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.3042 - val_loss: -168.7494\n",
      "\n",
      "Epoch 02557: loss did not improve from -166.61102\n",
      "Epoch 2558/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.1328 - val_loss: -168.5157\n",
      "\n",
      "Epoch 02558: loss did not improve from -166.61102\n",
      "Epoch 2559/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.2352 - val_loss: -168.8081\n",
      "\n",
      "Epoch 02559: loss did not improve from -166.61102\n",
      "Epoch 2560/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.4629 - val_loss: -168.6241\n",
      "\n",
      "Epoch 02560: loss did not improve from -166.61102\n",
      "Epoch 2561/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.5727 - val_loss: -168.7854\n",
      "\n",
      "Epoch 02561: loss did not improve from -166.61102\n",
      "Epoch 2562/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.4879 - val_loss: -168.6810\n",
      "\n",
      "Epoch 02562: loss did not improve from -166.61102\n",
      "Epoch 2563/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.3266 - val_loss: -168.7513\n",
      "\n",
      "Epoch 02563: loss did not improve from -166.61102\n",
      "Epoch 2564/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.3484 - val_loss: -169.0092\n",
      "\n",
      "Epoch 02564: loss did not improve from -166.61102\n",
      "Epoch 2565/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.4870 - val_loss: -168.5757\n",
      "\n",
      "Epoch 02565: loss did not improve from -166.61102\n",
      "Epoch 2566/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.4273 - val_loss: -168.8799\n",
      "\n",
      "Epoch 02566: loss did not improve from -166.61102\n",
      "Epoch 2567/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.6770 - val_loss: -168.5219\n",
      "\n",
      "Epoch 02567: loss improved from -166.61102 to -166.67705, saving model to gendance.h5\n",
      "Epoch 2568/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.8112 - val_loss: -168.9694\n",
      "\n",
      "Epoch 02568: loss improved from -166.67705 to -166.81119, saving model to gendance.h5\n",
      "Epoch 2569/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -166.4889 - val_loss: -168.8657\n",
      "\n",
      "Epoch 02569: loss did not improve from -166.81119\n",
      "Epoch 2570/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.5163 - val_loss: -168.5282\n",
      "\n",
      "Epoch 02570: loss did not improve from -166.81119\n",
      "Epoch 2571/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.4825 - val_loss: -168.9765\n",
      "\n",
      "Epoch 02571: loss did not improve from -166.81119\n",
      "Epoch 2572/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.3526 - val_loss: -168.1545\n",
      "\n",
      "Epoch 02572: loss did not improve from -166.81119\n",
      "Epoch 2573/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.5316 - val_loss: -169.1979\n",
      "\n",
      "Epoch 02573: loss did not improve from -166.81119\n",
      "Epoch 2574/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.4092 - val_loss: -167.9325\n",
      "\n",
      "Epoch 02574: loss did not improve from -166.81119\n",
      "Epoch 2575/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.2570 - val_loss: -168.8999\n",
      "\n",
      "Epoch 02575: loss did not improve from -166.81119\n",
      "Epoch 2576/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.3790 - val_loss: -168.4911\n",
      "\n",
      "Epoch 02576: loss did not improve from -166.81119\n",
      "Epoch 2577/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.3849 - val_loss: -168.5708\n",
      "\n",
      "Epoch 02577: loss did not improve from -166.81119\n",
      "Epoch 2578/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.3162 - val_loss: -169.0812\n",
      "\n",
      "Epoch 02578: loss did not improve from -166.81119\n",
      "Epoch 2579/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.3402 - val_loss: -168.0329\n",
      "\n",
      "Epoch 02579: loss did not improve from -166.81119\n",
      "Epoch 2580/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.3870 - val_loss: -168.8201\n",
      "\n",
      "Epoch 02580: loss did not improve from -166.81119\n",
      "Epoch 2581/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.5487 - val_loss: -168.6234\n",
      "\n",
      "Epoch 02581: loss did not improve from -166.81119\n",
      "Epoch 2582/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.4173 - val_loss: -168.8588\n",
      "\n",
      "Epoch 02582: loss did not improve from -166.81119\n",
      "Epoch 2583/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.4566 - val_loss: -168.8330\n",
      "\n",
      "Epoch 02583: loss did not improve from -166.81119\n",
      "Epoch 2584/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.8498 - val_loss: -168.9747\n",
      "\n",
      "Epoch 02584: loss improved from -166.81119 to -166.84978, saving model to gendance.h5\n",
      "Epoch 2585/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.5078 - val_loss: -169.0169\n",
      "\n",
      "Epoch 02585: loss did not improve from -166.84978\n",
      "Epoch 2586/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.4326 - val_loss: -168.4011\n",
      "\n",
      "Epoch 02586: loss did not improve from -166.84978\n",
      "Epoch 2587/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.3411 - val_loss: -168.8116\n",
      "\n",
      "Epoch 02587: loss did not improve from -166.84978\n",
      "Epoch 2588/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.2780 - val_loss: -167.7833\n",
      "\n",
      "Epoch 02588: loss did not improve from -166.84978\n",
      "Epoch 2589/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.3952 - val_loss: -168.8827\n",
      "\n",
      "Epoch 02589: loss did not improve from -166.84978\n",
      "Epoch 2590/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.3016 - val_loss: -168.2445\n",
      "\n",
      "Epoch 02590: loss did not improve from -166.84978\n",
      "Epoch 2591/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.6038 - val_loss: -168.9461\n",
      "\n",
      "Epoch 02591: loss did not improve from -166.84978\n",
      "Epoch 2592/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.6462 - val_loss: -168.9608\n",
      "\n",
      "Epoch 02592: loss did not improve from -166.84978\n",
      "Epoch 2593/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.5109 - val_loss: -168.3955\n",
      "\n",
      "Epoch 02593: loss did not improve from -166.84978\n",
      "Epoch 2594/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.1187 - val_loss: -168.8325\n",
      "\n",
      "Epoch 02594: loss did not improve from -166.84978\n",
      "Epoch 2595/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.0763 - val_loss: -167.7377\n",
      "\n",
      "Epoch 02595: loss did not improve from -166.84978\n",
      "Epoch 2596/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.5121 - val_loss: -168.9913\n",
      "\n",
      "Epoch 02596: loss did not improve from -166.84978\n",
      "Epoch 2597/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.3400 - val_loss: -168.4413\n",
      "\n",
      "Epoch 02597: loss did not improve from -166.84978\n",
      "Epoch 2598/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.4976 - val_loss: -168.8309\n",
      "\n",
      "Epoch 02598: loss did not improve from -166.84978\n",
      "Epoch 2599/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.5483 - val_loss: -168.6249\n",
      "\n",
      "Epoch 02599: loss did not improve from -166.84978\n",
      "Epoch 2600/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.6821 - val_loss: -169.0254\n",
      "\n",
      "Epoch 02600: loss did not improve from -166.84978\n",
      "Epoch 2601/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.7161 - val_loss: -169.0079\n",
      "\n",
      "Epoch 02601: loss did not improve from -166.84978\n",
      "Epoch 2602/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.6539 - val_loss: -168.7032\n",
      "\n",
      "Epoch 02602: loss did not improve from -166.84978\n",
      "Epoch 2603/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.5596 - val_loss: -168.9697\n",
      "\n",
      "Epoch 02603: loss did not improve from -166.84978\n",
      "Epoch 2604/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.4581 - val_loss: -168.2186\n",
      "\n",
      "Epoch 02604: loss did not improve from -166.84978\n",
      "Epoch 2605/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.5565 - val_loss: -169.1044\n",
      "\n",
      "Epoch 02605: loss did not improve from -166.84978\n",
      "Epoch 2606/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.6314 - val_loss: -168.7743\n",
      "\n",
      "Epoch 02606: loss did not improve from -166.84978\n",
      "Epoch 2607/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.7659 - val_loss: -169.0653\n",
      "\n",
      "Epoch 02607: loss did not improve from -166.84978\n",
      "Epoch 2608/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.7440 - val_loss: -169.0860\n",
      "\n",
      "Epoch 02608: loss did not improve from -166.84978\n",
      "Epoch 2609/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.5954 - val_loss: -168.6384\n",
      "\n",
      "Epoch 02609: loss did not improve from -166.84978\n",
      "Epoch 2610/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.2918 - val_loss: -169.1756\n",
      "\n",
      "Epoch 02610: loss did not improve from -166.84978\n",
      "Epoch 2611/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.5317 - val_loss: -168.4502\n",
      "\n",
      "Epoch 02611: loss did not improve from -166.84978\n",
      "Epoch 2612/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.7458 - val_loss: -169.0432\n",
      "\n",
      "Epoch 02612: loss did not improve from -166.84978\n",
      "Epoch 2613/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.6179 - val_loss: -168.7219\n",
      "\n",
      "Epoch 02613: loss did not improve from -166.84978\n",
      "Epoch 2614/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.5824 - val_loss: -169.1017\n",
      "\n",
      "Epoch 02614: loss did not improve from -166.84978\n",
      "Epoch 2615/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.4711 - val_loss: -168.6689\n",
      "\n",
      "Epoch 02615: loss did not improve from -166.84978\n",
      "Epoch 2616/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.7078 - val_loss: -168.6841\n",
      "\n",
      "Epoch 02616: loss did not improve from -166.84978\n",
      "Epoch 2617/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.3519 - val_loss: -169.0560\n",
      "\n",
      "Epoch 02617: loss did not improve from -166.84978\n",
      "Epoch 2618/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.3643 - val_loss: -168.2718\n",
      "\n",
      "Epoch 02618: loss did not improve from -166.84978\n",
      "Epoch 2619/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -166.3089 - val_loss: -168.8596\n",
      "\n",
      "Epoch 02619: loss did not improve from -166.84978\n",
      "Epoch 2620/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.5790 - val_loss: -168.8541\n",
      "\n",
      "Epoch 02620: loss did not improve from -166.84978\n",
      "Epoch 2621/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.6701 - val_loss: -169.1160\n",
      "\n",
      "Epoch 02621: loss did not improve from -166.84978\n",
      "Epoch 2622/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.7704 - val_loss: -169.0687\n",
      "\n",
      "Epoch 02622: loss did not improve from -166.84978\n",
      "Epoch 2623/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.8345 - val_loss: -169.0426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 02623: loss did not improve from -166.84978\n",
      "Epoch 2624/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.7074 - val_loss: -169.2405\n",
      "\n",
      "Epoch 02624: loss did not improve from -166.84978\n",
      "Epoch 2625/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.7166 - val_loss: -169.0515\n",
      "\n",
      "Epoch 02625: loss did not improve from -166.84978\n",
      "Epoch 2626/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.8517 - val_loss: -169.0527\n",
      "\n",
      "Epoch 02626: loss improved from -166.84978 to -166.85167, saving model to gendance.h5\n",
      "Epoch 2627/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.8535 - val_loss: -169.2209\n",
      "\n",
      "Epoch 02627: loss improved from -166.85167 to -166.85348, saving model to gendance.h5\n",
      "Epoch 2628/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.7482 - val_loss: -168.9207\n",
      "\n",
      "Epoch 02628: loss did not improve from -166.85348\n",
      "Epoch 2629/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.7612 - val_loss: -169.2076\n",
      "\n",
      "Epoch 02629: loss did not improve from -166.85348\n",
      "Epoch 2630/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.6251 - val_loss: -169.0003\n",
      "\n",
      "Epoch 02630: loss did not improve from -166.85348\n",
      "Epoch 2631/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.8794 - val_loss: -168.9214\n",
      "\n",
      "Epoch 02631: loss improved from -166.85348 to -166.87937, saving model to gendance.h5\n",
      "Epoch 2632/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -166.4420 - val_loss: -168.8546\n",
      "\n",
      "Epoch 02632: loss did not improve from -166.87937\n",
      "Epoch 2633/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.5587 - val_loss: -168.9363\n",
      "\n",
      "Epoch 02633: loss did not improve from -166.87937\n",
      "Epoch 2634/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.5679 - val_loss: -168.7199\n",
      "\n",
      "Epoch 02634: loss did not improve from -166.87937\n",
      "Epoch 2635/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.7143 - val_loss: -168.8440\n",
      "\n",
      "Epoch 02635: loss did not improve from -166.87937\n",
      "Epoch 2636/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.5693 - val_loss: -169.0892\n",
      "\n",
      "Epoch 02636: loss did not improve from -166.87937\n",
      "Epoch 2637/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.7770 - val_loss: -168.4919\n",
      "\n",
      "Epoch 02637: loss did not improve from -166.87937\n",
      "Epoch 2638/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.6799 - val_loss: -169.2556\n",
      "\n",
      "Epoch 02638: loss did not improve from -166.87937\n",
      "Epoch 2639/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -166.7562 - val_loss: -168.9163\n",
      "\n",
      "Epoch 02639: loss did not improve from -166.87937\n",
      "Epoch 2640/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.5275 - val_loss: -168.9671\n",
      "\n",
      "Epoch 02640: loss did not improve from -166.87937\n",
      "Epoch 2641/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.6881 - val_loss: -169.3072\n",
      "\n",
      "Epoch 02641: loss did not improve from -166.87937\n",
      "Epoch 2642/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.6923 - val_loss: -168.3786\n",
      "\n",
      "Epoch 02642: loss did not improve from -166.87937\n",
      "Epoch 2643/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.5520 - val_loss: -169.1423\n",
      "\n",
      "Epoch 02643: loss did not improve from -166.87937\n",
      "Epoch 2644/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.5103 - val_loss: -168.3294\n",
      "\n",
      "Epoch 02644: loss did not improve from -166.87937\n",
      "Epoch 2645/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.6043 - val_loss: -169.1603\n",
      "\n",
      "Epoch 02645: loss did not improve from -166.87937\n",
      "Epoch 2646/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.7402 - val_loss: -168.5219\n",
      "\n",
      "Epoch 02646: loss did not improve from -166.87937\n",
      "Epoch 2647/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.7631 - val_loss: -169.2374\n",
      "\n",
      "Epoch 02647: loss did not improve from -166.87937\n",
      "Epoch 2648/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.6733 - val_loss: -168.8083\n",
      "\n",
      "Epoch 02648: loss did not improve from -166.87937\n",
      "Epoch 2649/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.5103 - val_loss: -168.5359\n",
      "\n",
      "Epoch 02649: loss did not improve from -166.87937\n",
      "Epoch 2650/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.6165 - val_loss: -169.2260\n",
      "\n",
      "Epoch 02650: loss did not improve from -166.87937\n",
      "Epoch 2651/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.1882 - val_loss: -167.9645\n",
      "\n",
      "Epoch 02651: loss did not improve from -166.87937\n",
      "Epoch 2652/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.5930 - val_loss: -169.1097\n",
      "\n",
      "Epoch 02652: loss did not improve from -166.87937\n",
      "Epoch 2653/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -166.4637 - val_loss: -168.5726\n",
      "\n",
      "Epoch 02653: loss did not improve from -166.87937\n",
      "Epoch 2654/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.7083 - val_loss: -168.9364\n",
      "\n",
      "Epoch 02654: loss did not improve from -166.87937\n",
      "Epoch 2655/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.6850 - val_loss: -169.3153\n",
      "\n",
      "Epoch 02655: loss did not improve from -166.87937\n",
      "Epoch 2656/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.8891 - val_loss: -168.9204\n",
      "\n",
      "Epoch 02656: loss improved from -166.87937 to -166.88912, saving model to gendance.h5\n",
      "Epoch 2657/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -167.0993 - val_loss: -169.2157\n",
      "\n",
      "Epoch 02657: loss improved from -166.88912 to -167.09934, saving model to gendance.h5\n",
      "Epoch 2658/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.8104 - val_loss: -168.8978\n",
      "\n",
      "Epoch 02658: loss did not improve from -167.09934\n",
      "Epoch 2659/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.8643 - val_loss: -169.2769\n",
      "\n",
      "Epoch 02659: loss did not improve from -167.09934\n",
      "Epoch 2660/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.7136 - val_loss: -168.5711\n",
      "\n",
      "Epoch 02660: loss did not improve from -167.09934\n",
      "Epoch 2661/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.8268 - val_loss: -169.2530\n",
      "\n",
      "Epoch 02661: loss did not improve from -167.09934\n",
      "Epoch 2662/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.8980 - val_loss: -168.8941\n",
      "\n",
      "Epoch 02662: loss did not improve from -167.09934\n",
      "Epoch 2663/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.9165 - val_loss: -169.0614\n",
      "\n",
      "Epoch 02663: loss did not improve from -167.09934\n",
      "Epoch 2664/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.8078 - val_loss: -169.1506\n",
      "\n",
      "Epoch 02664: loss did not improve from -167.09934\n",
      "Epoch 2665/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.7992 - val_loss: -169.2233\n",
      "\n",
      "Epoch 02665: loss did not improve from -167.09934\n",
      "Epoch 2666/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.8092 - val_loss: -169.1339\n",
      "\n",
      "Epoch 02666: loss did not improve from -167.09934\n",
      "Epoch 2667/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.7102 - val_loss: -169.0348\n",
      "\n",
      "Epoch 02667: loss did not improve from -167.09934\n",
      "Epoch 2668/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.9645 - val_loss: -169.3107\n",
      "\n",
      "Epoch 02668: loss did not improve from -167.09934\n",
      "Epoch 2669/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.0499 - val_loss: -169.3282\n",
      "\n",
      "Epoch 02669: loss did not improve from -167.09934\n",
      "Epoch 2670/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.0573 - val_loss: -168.6769\n",
      "\n",
      "Epoch 02670: loss did not improve from -167.09934\n",
      "Epoch 2671/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.8961 - val_loss: -169.3621\n",
      "\n",
      "Epoch 02671: loss did not improve from -167.09934\n",
      "Epoch 2672/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.1013 - val_loss: -169.0107\n",
      "\n",
      "Epoch 02672: loss improved from -167.09934 to -167.10125, saving model to gendance.h5\n",
      "Epoch 2673/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.9382 - val_loss: -169.0809\n",
      "\n",
      "Epoch 02673: loss did not improve from -167.10125\n",
      "Epoch 2674/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.8514 - val_loss: -169.1408\n",
      "\n",
      "Epoch 02674: loss did not improve from -167.10125\n",
      "Epoch 2675/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.9176 - val_loss: -168.8692\n",
      "\n",
      "Epoch 02675: loss did not improve from -167.10125\n",
      "Epoch 2676/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.9686 - val_loss: -169.4784\n",
      "\n",
      "Epoch 02676: loss did not improve from -167.10125\n",
      "Epoch 2677/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.7903 - val_loss: -168.4278\n",
      "\n",
      "Epoch 02677: loss did not improve from -167.10125\n",
      "Epoch 2678/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.7225 - val_loss: -169.3580\n",
      "\n",
      "Epoch 02678: loss did not improve from -167.10125\n",
      "Epoch 2679/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.6960 - val_loss: -168.7350\n",
      "\n",
      "Epoch 02679: loss did not improve from -167.10125\n",
      "Epoch 2680/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.7328 - val_loss: -168.8963\n",
      "\n",
      "Epoch 02680: loss did not improve from -167.10125\n",
      "Epoch 2681/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.8182 - val_loss: -169.3398\n",
      "\n",
      "Epoch 02681: loss did not improve from -167.10125\n",
      "Epoch 2682/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -166.8518 - val_loss: -168.4739\n",
      "\n",
      "Epoch 02682: loss did not improve from -167.10125\n",
      "Epoch 2683/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.6985 - val_loss: -169.3079\n",
      "\n",
      "Epoch 02683: loss did not improve from -167.10125\n",
      "Epoch 2684/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.6441 - val_loss: -168.8420\n",
      "\n",
      "Epoch 02684: loss did not improve from -167.10125\n",
      "Epoch 2685/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.8737 - val_loss: -169.3243\n",
      "\n",
      "Epoch 02685: loss did not improve from -167.10125\n",
      "Epoch 2686/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.8893 - val_loss: -169.1220\n",
      "\n",
      "Epoch 02686: loss did not improve from -167.10125\n",
      "Epoch 2687/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.7477 - val_loss: -169.1040\n",
      "\n",
      "Epoch 02687: loss did not improve from -167.10125\n",
      "Epoch 2688/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.7428 - val_loss: -169.0178\n",
      "\n",
      "Epoch 02688: loss did not improve from -167.10125\n",
      "Epoch 2689/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.6814 - val_loss: -168.9777\n",
      "\n",
      "Epoch 02689: loss did not improve from -167.10125\n",
      "Epoch 2690/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.8667 - val_loss: -169.2738\n",
      "\n",
      "Epoch 02690: loss did not improve from -167.10125\n",
      "Epoch 2691/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.9212 - val_loss: -169.1707\n",
      "\n",
      "Epoch 02691: loss did not improve from -167.10125\n",
      "Epoch 2692/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.8640 - val_loss: -169.3985\n",
      "\n",
      "Epoch 02692: loss did not improve from -167.10125\n",
      "Epoch 2693/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.9780 - val_loss: -169.1157\n",
      "\n",
      "Epoch 02693: loss did not improve from -167.10125\n",
      "Epoch 2694/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.9476 - val_loss: -169.3389\n",
      "\n",
      "Epoch 02694: loss did not improve from -167.10125\n",
      "Epoch 2695/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.0184 - val_loss: -168.9682\n",
      "\n",
      "Epoch 02695: loss did not improve from -167.10125\n",
      "Epoch 2696/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.9991 - val_loss: -169.6108\n",
      "\n",
      "Epoch 02696: loss did not improve from -167.10125\n",
      "Epoch 2697/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.9265 - val_loss: -168.6752\n",
      "\n",
      "Epoch 02697: loss did not improve from -167.10125\n",
      "Epoch 2698/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.8793 - val_loss: -169.1523\n",
      "\n",
      "Epoch 02698: loss did not improve from -167.10125\n",
      "Epoch 2699/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.9461 - val_loss: -169.2883\n",
      "\n",
      "Epoch 02699: loss did not improve from -167.10125\n",
      "Epoch 2700/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.9265 - val_loss: -168.5943\n",
      "\n",
      "Epoch 02700: loss did not improve from -167.10125\n",
      "Epoch 2701/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.8898 - val_loss: -169.3927\n",
      "\n",
      "Epoch 02701: loss did not improve from -167.10125\n",
      "Epoch 2702/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.6436 - val_loss: -168.1920\n",
      "\n",
      "Epoch 02702: loss did not improve from -167.10125\n",
      "Epoch 2703/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.8605 - val_loss: -169.4328\n",
      "\n",
      "Epoch 02703: loss did not improve from -167.10125\n",
      "Epoch 2704/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.7787 - val_loss: -168.4141\n",
      "\n",
      "Epoch 02704: loss did not improve from -167.10125\n",
      "Epoch 2705/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.9389 - val_loss: -169.4697\n",
      "\n",
      "Epoch 02705: loss did not improve from -167.10125\n",
      "Epoch 2706/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.9901 - val_loss: -169.0642\n",
      "\n",
      "Epoch 02706: loss did not improve from -167.10125\n",
      "Epoch 2707/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.0456 - val_loss: -168.9801\n",
      "\n",
      "Epoch 02707: loss did not improve from -167.10125\n",
      "Epoch 2708/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.7425 - val_loss: -169.5421\n",
      "\n",
      "Epoch 02708: loss did not improve from -167.10125\n",
      "Epoch 2709/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.9201 - val_loss: -168.6609\n",
      "\n",
      "Epoch 02709: loss did not improve from -167.10125\n",
      "Epoch 2710/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.8541 - val_loss: -169.3894\n",
      "\n",
      "Epoch 02710: loss did not improve from -167.10125\n",
      "Epoch 2711/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.7380 - val_loss: -169.0377\n",
      "\n",
      "Epoch 02711: loss did not improve from -167.10125\n",
      "Epoch 2712/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.9726 - val_loss: -169.4252\n",
      "\n",
      "Epoch 02712: loss did not improve from -167.10125\n",
      "Epoch 2713/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.1255 - val_loss: -169.4382\n",
      "\n",
      "Epoch 02713: loss improved from -167.10125 to -167.12553, saving model to gendance.h5\n",
      "Epoch 2714/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -167.1889 - val_loss: -169.3683\n",
      "\n",
      "Epoch 02714: loss improved from -167.12553 to -167.18893, saving model to gendance.h5\n",
      "Epoch 2715/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -167.0796 - val_loss: -169.2612\n",
      "\n",
      "Epoch 02715: loss did not improve from -167.18893\n",
      "Epoch 2716/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.1722 - val_loss: -169.4408\n",
      "\n",
      "Epoch 02716: loss did not improve from -167.18893\n",
      "Epoch 2717/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.1490 - val_loss: -169.4358\n",
      "\n",
      "Epoch 02717: loss did not improve from -167.18893\n",
      "Epoch 2718/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.0589 - val_loss: -169.1439\n",
      "\n",
      "Epoch 02718: loss did not improve from -167.18893\n",
      "Epoch 2719/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.0228 - val_loss: -169.6200\n",
      "\n",
      "Epoch 02719: loss did not improve from -167.18893\n",
      "Epoch 2720/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.0969 - val_loss: -169.1437\n",
      "\n",
      "Epoch 02720: loss did not improve from -167.18893\n",
      "Epoch 2721/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.0382 - val_loss: -169.2138\n",
      "\n",
      "Epoch 02721: loss did not improve from -167.18893\n",
      "Epoch 2722/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.8604 - val_loss: -169.3519\n",
      "\n",
      "Epoch 02722: loss did not improve from -167.18893\n",
      "Epoch 2723/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.1366 - val_loss: -169.3137\n",
      "\n",
      "Epoch 02723: loss did not improve from -167.18893\n",
      "Epoch 2724/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.1227 - val_loss: -169.4967\n",
      "\n",
      "Epoch 02724: loss did not improve from -167.18893\n",
      "Epoch 2725/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.9044 - val_loss: -169.1973\n",
      "\n",
      "Epoch 02725: loss did not improve from -167.18893\n",
      "Epoch 2726/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.0061 - val_loss: -169.2120\n",
      "\n",
      "Epoch 02726: loss did not improve from -167.18893\n",
      "Epoch 2727/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.9109 - val_loss: -169.2197\n",
      "\n",
      "Epoch 02727: loss did not improve from -167.18893\n",
      "Epoch 2728/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.6543 - val_loss: -169.2841\n",
      "\n",
      "Epoch 02728: loss did not improve from -167.18893\n",
      "Epoch 2729/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.8692 - val_loss: -168.2386\n",
      "\n",
      "Epoch 02729: loss did not improve from -167.18893\n",
      "Epoch 2730/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.7741 - val_loss: -169.1497\n",
      "\n",
      "Epoch 02730: loss did not improve from -167.18893\n",
      "Epoch 2731/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.7034 - val_loss: -168.4293\n",
      "\n",
      "Epoch 02731: loss did not improve from -167.18893\n",
      "Epoch 2732/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.8856 - val_loss: -169.3952\n",
      "\n",
      "Epoch 02732: loss did not improve from -167.18893\n",
      "Epoch 2733/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.0192 - val_loss: -168.9896\n",
      "\n",
      "Epoch 02733: loss did not improve from -167.18893\n",
      "Epoch 2734/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.0039 - val_loss: -169.3564\n",
      "\n",
      "Epoch 02734: loss did not improve from -167.18893\n",
      "Epoch 2735/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.1886 - val_loss: -169.3343\n",
      "\n",
      "Epoch 02735: loss did not improve from -167.18893\n",
      "Epoch 2736/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.0225 - val_loss: -169.2805\n",
      "\n",
      "Epoch 02736: loss did not improve from -167.18893\n",
      "Epoch 2737/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.9513 - val_loss: -169.4006\n",
      "\n",
      "Epoch 02737: loss did not improve from -167.18893\n",
      "Epoch 2738/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.8166 - val_loss: -168.6716\n",
      "\n",
      "Epoch 02738: loss did not improve from -167.18893\n",
      "Epoch 2739/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.1469 - val_loss: -169.5751\n",
      "\n",
      "Epoch 02739: loss did not improve from -167.18893\n",
      "Epoch 2740/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.1040 - val_loss: -168.9609\n",
      "\n",
      "Epoch 02740: loss did not improve from -167.18893\n",
      "Epoch 2741/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.0185 - val_loss: -169.4060\n",
      "\n",
      "Epoch 02741: loss did not improve from -167.18893\n",
      "Epoch 2742/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.0725 - val_loss: -169.5869\n",
      "\n",
      "Epoch 02742: loss did not improve from -167.18893\n",
      "Epoch 2743/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.3341 - val_loss: -169.3460\n",
      "\n",
      "Epoch 02743: loss improved from -167.18893 to -167.33410, saving model to gendance.h5\n",
      "Epoch 2744/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.8736 - val_loss: -169.5652\n",
      "\n",
      "Epoch 02744: loss did not improve from -167.33410\n",
      "Epoch 2745/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.3933 - val_loss: -169.2532\n",
      "\n",
      "Epoch 02745: loss improved from -167.33410 to -167.39326, saving model to gendance.h5\n",
      "Epoch 2746/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.0785 - val_loss: -169.4812\n",
      "\n",
      "Epoch 02746: loss did not improve from -167.39326\n",
      "Epoch 2747/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.0869 - val_loss: -169.1600\n",
      "\n",
      "Epoch 02747: loss did not improve from -167.39326\n",
      "Epoch 2748/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.2596 - val_loss: -169.4768\n",
      "\n",
      "Epoch 02748: loss did not improve from -167.39326\n",
      "Epoch 2749/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.1099 - val_loss: -169.1340\n",
      "\n",
      "Epoch 02749: loss did not improve from -167.39326\n",
      "Epoch 2750/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.2103 - val_loss: -169.4570\n",
      "\n",
      "Epoch 02750: loss did not improve from -167.39326\n",
      "Epoch 2751/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.2113 - val_loss: -169.6101\n",
      "\n",
      "Epoch 02751: loss did not improve from -167.39326\n",
      "Epoch 2752/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.1084 - val_loss: -169.1456\n",
      "\n",
      "Epoch 02752: loss did not improve from -167.39326\n",
      "Epoch 2753/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.2478 - val_loss: -169.6029\n",
      "\n",
      "Epoch 02753: loss did not improve from -167.39326\n",
      "Epoch 2754/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.2462 - val_loss: -169.2592\n",
      "\n",
      "Epoch 02754: loss did not improve from -167.39326\n",
      "Epoch 2755/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.1684 - val_loss: -169.4309\n",
      "\n",
      "Epoch 02755: loss did not improve from -167.39326\n",
      "Epoch 2756/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -167.1390 - val_loss: -169.4550\n",
      "\n",
      "Epoch 02756: loss did not improve from -167.39326\n",
      "Epoch 2757/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.2102 - val_loss: -169.0703\n",
      "\n",
      "Epoch 02757: loss did not improve from -167.39326\n",
      "Epoch 2758/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.1331 - val_loss: -169.5265\n",
      "\n",
      "Epoch 02758: loss did not improve from -167.39326\n",
      "Epoch 2759/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.0689 - val_loss: -169.2120\n",
      "\n",
      "Epoch 02759: loss did not improve from -167.39326\n",
      "Epoch 2760/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.2219 - val_loss: -169.5091\n",
      "\n",
      "Epoch 02760: loss did not improve from -167.39326\n",
      "Epoch 2761/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.3308 - val_loss: -169.3504\n",
      "\n",
      "Epoch 02761: loss did not improve from -167.39326\n",
      "Epoch 2762/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.9200 - val_loss: -168.9182\n",
      "\n",
      "Epoch 02762: loss did not improve from -167.39326\n",
      "Epoch 2763/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.8718 - val_loss: -169.5464\n",
      "\n",
      "Epoch 02763: loss did not improve from -167.39326\n",
      "Epoch 2764/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.9457 - val_loss: -168.6036\n",
      "\n",
      "Epoch 02764: loss did not improve from -167.39326\n",
      "Epoch 2765/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.8822 - val_loss: -169.3261\n",
      "\n",
      "Epoch 02765: loss did not improve from -167.39326\n",
      "Epoch 2766/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.0924 - val_loss: -168.7010\n",
      "\n",
      "Epoch 02766: loss did not improve from -167.39326\n",
      "Epoch 2767/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.7663 - val_loss: -169.4519\n",
      "\n",
      "Epoch 02767: loss did not improve from -167.39326\n",
      "Epoch 2768/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.1740 - val_loss: -169.3378\n",
      "\n",
      "Epoch 02768: loss did not improve from -167.39326\n",
      "Epoch 2769/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.2611 - val_loss: -169.1508\n",
      "\n",
      "Epoch 02769: loss did not improve from -167.39326\n",
      "Epoch 2770/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.9108 - val_loss: -169.5563\n",
      "\n",
      "Epoch 02770: loss did not improve from -167.39326\n",
      "Epoch 2771/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.0320 - val_loss: -168.6817\n",
      "\n",
      "Epoch 02771: loss did not improve from -167.39326\n",
      "Epoch 2772/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.1462 - val_loss: -169.4418\n",
      "\n",
      "Epoch 02772: loss did not improve from -167.39326\n",
      "Epoch 2773/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.8987 - val_loss: -169.1424\n",
      "\n",
      "Epoch 02773: loss did not improve from -167.39326\n",
      "Epoch 2774/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.2595 - val_loss: -169.5780\n",
      "\n",
      "Epoch 02774: loss did not improve from -167.39326\n",
      "Epoch 2775/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.3401 - val_loss: -169.3616\n",
      "\n",
      "Epoch 02775: loss did not improve from -167.39326\n",
      "Epoch 2776/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.3141 - val_loss: -169.4763\n",
      "\n",
      "Epoch 02776: loss did not improve from -167.39326\n",
      "Epoch 2777/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.4947 - val_loss: -169.6589\n",
      "\n",
      "Epoch 02777: loss improved from -167.39326 to -167.49472, saving model to gendance.h5\n",
      "Epoch 2778/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.2193 - val_loss: -169.1505\n",
      "\n",
      "Epoch 02778: loss did not improve from -167.49472\n",
      "Epoch 2779/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.1726 - val_loss: -169.7692\n",
      "\n",
      "Epoch 02779: loss did not improve from -167.49472\n",
      "Epoch 2780/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.4445 - val_loss: -169.3673\n",
      "\n",
      "Epoch 02780: loss did not improve from -167.49472\n",
      "Epoch 2781/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.2584 - val_loss: -169.6599\n",
      "\n",
      "Epoch 02781: loss did not improve from -167.49472\n",
      "Epoch 2782/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.3966 - val_loss: -169.5712\n",
      "\n",
      "Epoch 02782: loss did not improve from -167.49472\n",
      "Epoch 2783/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.3299 - val_loss: -169.5253\n",
      "\n",
      "Epoch 02783: loss did not improve from -167.49472\n",
      "Epoch 2784/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.2436 - val_loss: -169.4613\n",
      "\n",
      "Epoch 02784: loss did not improve from -167.49472\n",
      "Epoch 2785/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.0147 - val_loss: -169.1210\n",
      "\n",
      "Epoch 02785: loss did not improve from -167.49472\n",
      "Epoch 2786/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.2595 - val_loss: -169.5383\n",
      "\n",
      "Epoch 02786: loss did not improve from -167.49472\n",
      "Epoch 2787/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.0394 - val_loss: -169.1778\n",
      "\n",
      "Epoch 02787: loss did not improve from -167.49472\n",
      "Epoch 2788/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.3663 - val_loss: -169.8035\n",
      "\n",
      "Epoch 02788: loss did not improve from -167.49472\n",
      "Epoch 2789/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.5377 - val_loss: -169.4580\n",
      "\n",
      "Epoch 02789: loss improved from -167.49472 to -167.53774, saving model to gendance.h5\n",
      "Epoch 2790/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.1437 - val_loss: -169.5762\n",
      "\n",
      "Epoch 02790: loss did not improve from -167.53774\n",
      "Epoch 2791/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.5023 - val_loss: -169.5564\n",
      "\n",
      "Epoch 02791: loss did not improve from -167.53774\n",
      "Epoch 2792/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.2320 - val_loss: -169.7397\n",
      "\n",
      "Epoch 02792: loss did not improve from -167.53774\n",
      "Epoch 2793/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.1533 - val_loss: -169.2635\n",
      "\n",
      "Epoch 02793: loss did not improve from -167.53774\n",
      "Epoch 2794/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.4340 - val_loss: -169.9956\n",
      "\n",
      "Epoch 02794: loss did not improve from -167.53774\n",
      "Epoch 2795/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.2716 - val_loss: -169.0573\n",
      "\n",
      "Epoch 02795: loss did not improve from -167.53774\n",
      "Epoch 2796/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.2466 - val_loss: -169.7035\n",
      "\n",
      "Epoch 02796: loss did not improve from -167.53774\n",
      "Epoch 2797/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.1803 - val_loss: -169.0121\n",
      "\n",
      "Epoch 02797: loss did not improve from -167.53774\n",
      "Epoch 2798/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.2543 - val_loss: -169.6725\n",
      "\n",
      "Epoch 02798: loss did not improve from -167.53774\n",
      "Epoch 2799/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.2963 - val_loss: -169.2614\n",
      "\n",
      "Epoch 02799: loss did not improve from -167.53774\n",
      "Epoch 2800/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.4125 - val_loss: -169.8132\n",
      "\n",
      "Epoch 02800: loss did not improve from -167.53774\n",
      "Epoch 2801/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.1550 - val_loss: -169.2470\n",
      "\n",
      "Epoch 02801: loss did not improve from -167.53774\n",
      "Epoch 2802/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.2697 - val_loss: -169.5355\n",
      "\n",
      "Epoch 02802: loss did not improve from -167.53774\n",
      "Epoch 2803/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.2560 - val_loss: -169.7237\n",
      "\n",
      "Epoch 02803: loss did not improve from -167.53774\n",
      "Epoch 2804/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.8440 - val_loss: -168.8253\n",
      "\n",
      "Epoch 02804: loss did not improve from -167.53774\n",
      "Epoch 2805/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.9198 - val_loss: -169.5045\n",
      "\n",
      "Epoch 02805: loss did not improve from -167.53774\n",
      "Epoch 2806/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.8265 - val_loss: -168.7722\n",
      "\n",
      "Epoch 02806: loss did not improve from -167.53774\n",
      "Epoch 2807/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.1535 - val_loss: -169.4553\n",
      "\n",
      "Epoch 02807: loss did not improve from -167.53774\n",
      "Epoch 2808/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.9717 - val_loss: -169.1110\n",
      "\n",
      "Epoch 02808: loss did not improve from -167.53774\n",
      "Epoch 2809/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.5129 - val_loss: -169.6414\n",
      "\n",
      "Epoch 02809: loss did not improve from -167.53774\n",
      "Epoch 2810/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.4061 - val_loss: -169.7652\n",
      "\n",
      "Epoch 02810: loss did not improve from -167.53774\n",
      "Epoch 2811/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.4281 - val_loss: -169.3125\n",
      "\n",
      "Epoch 02811: loss did not improve from -167.53774\n",
      "Epoch 2812/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.3070 - val_loss: -170.0309\n",
      "\n",
      "Epoch 02812: loss did not improve from -167.53774\n",
      "Epoch 2813/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.1758 - val_loss: -168.7591\n",
      "\n",
      "Epoch 02813: loss did not improve from -167.53774\n",
      "Epoch 2814/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.4209 - val_loss: -169.9393\n",
      "\n",
      "Epoch 02814: loss did not improve from -167.53774\n",
      "Epoch 2815/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.4250 - val_loss: -169.2106\n",
      "\n",
      "Epoch 02815: loss did not improve from -167.53774\n",
      "Epoch 2816/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.3751 - val_loss: -169.5980\n",
      "\n",
      "Epoch 02816: loss did not improve from -167.53774\n",
      "Epoch 2817/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.4918 - val_loss: -169.6627\n",
      "\n",
      "Epoch 02817: loss did not improve from -167.53774\n",
      "Epoch 2818/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.6245 - val_loss: -169.4555\n",
      "\n",
      "Epoch 02818: loss improved from -167.53774 to -167.62454, saving model to gendance.h5\n",
      "Epoch 2819/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.5517 - val_loss: -169.8863\n",
      "\n",
      "Epoch 02819: loss did not improve from -167.62454\n",
      "Epoch 2820/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.5680 - val_loss: -169.4269\n",
      "\n",
      "Epoch 02820: loss did not improve from -167.62454\n",
      "Epoch 2821/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -167.5274 - val_loss: -169.6950\n",
      "\n",
      "Epoch 02821: loss did not improve from -167.62454\n",
      "Epoch 2822/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.1480 - val_loss: -169.3383\n",
      "\n",
      "Epoch 02822: loss did not improve from -167.62454\n",
      "Epoch 2823/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.3619 - val_loss: -169.5818\n",
      "\n",
      "Epoch 02823: loss did not improve from -167.62454\n",
      "Epoch 2824/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.3316 - val_loss: -169.5694\n",
      "\n",
      "Epoch 02824: loss did not improve from -167.62454\n",
      "Epoch 2825/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.4148 - val_loss: -169.5306\n",
      "\n",
      "Epoch 02825: loss did not improve from -167.62454\n",
      "Epoch 2826/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.4814 - val_loss: -169.6255\n",
      "\n",
      "Epoch 02826: loss did not improve from -167.62454\n",
      "Epoch 2827/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.3256 - val_loss: -169.7956\n",
      "\n",
      "Epoch 02827: loss did not improve from -167.62454\n",
      "Epoch 2828/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.2279 - val_loss: -169.4143\n",
      "\n",
      "Epoch 02828: loss did not improve from -167.62454\n",
      "Epoch 2829/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.4038 - val_loss: -169.4543\n",
      "\n",
      "Epoch 02829: loss did not improve from -167.62454\n",
      "Epoch 2830/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.4494 - val_loss: -169.8788\n",
      "\n",
      "Epoch 02830: loss did not improve from -167.62454\n",
      "Epoch 2831/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.5637 - val_loss: -169.4220\n",
      "\n",
      "Epoch 02831: loss did not improve from -167.62454\n",
      "Epoch 2832/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.4499 - val_loss: -169.8422\n",
      "\n",
      "Epoch 02832: loss did not improve from -167.62454\n",
      "Epoch 2833/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -167.4448 - val_loss: -169.3793\n",
      "\n",
      "Epoch 02833: loss did not improve from -167.62454\n",
      "Epoch 2834/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.3227 - val_loss: -169.4714\n",
      "\n",
      "Epoch 02834: loss did not improve from -167.62454\n",
      "Epoch 2835/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.3254 - val_loss: -169.8595\n",
      "\n",
      "Epoch 02835: loss did not improve from -167.62454\n",
      "Epoch 2836/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -167.1034 - val_loss: -168.9167\n",
      "\n",
      "Epoch 02836: loss did not improve from -167.62454\n",
      "Epoch 2837/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.9559 - val_loss: -169.3949\n",
      "\n",
      "Epoch 02837: loss did not improve from -167.62454\n",
      "Epoch 2838/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.7602 - val_loss: -168.0011\n",
      "\n",
      "Epoch 02838: loss did not improve from -167.62454\n",
      "Epoch 2839/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.8801 - val_loss: -169.3313\n",
      "\n",
      "Epoch 02839: loss did not improve from -167.62454\n",
      "Epoch 2840/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.0788 - val_loss: -169.0846\n",
      "\n",
      "Epoch 02840: loss did not improve from -167.62454\n",
      "Epoch 2841/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.4282 - val_loss: -169.5454\n",
      "\n",
      "Epoch 02841: loss did not improve from -167.62454\n",
      "Epoch 2842/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.2767 - val_loss: -169.8280\n",
      "\n",
      "Epoch 02842: loss did not improve from -167.62454\n",
      "Epoch 2843/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.3978 - val_loss: -169.4086\n",
      "\n",
      "Epoch 02843: loss did not improve from -167.62454\n",
      "Epoch 2844/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.3265 - val_loss: -169.7175\n",
      "\n",
      "Epoch 02844: loss did not improve from -167.62454\n",
      "Epoch 2845/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.4435 - val_loss: -169.6223\n",
      "\n",
      "Epoch 02845: loss did not improve from -167.62454\n",
      "Epoch 2846/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.5239 - val_loss: -169.8923\n",
      "\n",
      "Epoch 02846: loss did not improve from -167.62454\n",
      "Epoch 2847/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.4954 - val_loss: -169.5844\n",
      "\n",
      "Epoch 02847: loss did not improve from -167.62454\n",
      "Epoch 2848/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.5146 - val_loss: -169.6083\n",
      "\n",
      "Epoch 02848: loss did not improve from -167.62454\n",
      "Epoch 2849/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.4086 - val_loss: -169.9127\n",
      "\n",
      "Epoch 02849: loss did not improve from -167.62454\n",
      "Epoch 2850/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.4428 - val_loss: -169.2894\n",
      "\n",
      "Epoch 02850: loss did not improve from -167.62454\n",
      "Epoch 2851/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.5406 - val_loss: -169.8262\n",
      "\n",
      "Epoch 02851: loss did not improve from -167.62454\n",
      "Epoch 2852/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -167.4817 - val_loss: -169.7432\n",
      "\n",
      "Epoch 02852: loss did not improve from -167.62454\n",
      "Epoch 2853/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.6225 - val_loss: -169.5748\n",
      "\n",
      "Epoch 02853: loss did not improve from -167.62454\n",
      "Epoch 2854/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.5776 - val_loss: -169.7527\n",
      "\n",
      "Epoch 02854: loss did not improve from -167.62454\n",
      "Epoch 2855/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.3982 - val_loss: -169.4398\n",
      "\n",
      "Epoch 02855: loss did not improve from -167.62454\n",
      "Epoch 2856/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.4013 - val_loss: -169.7304\n",
      "\n",
      "Epoch 02856: loss did not improve from -167.62454\n",
      "Epoch 2857/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.6036 - val_loss: -169.4800\n",
      "\n",
      "Epoch 02857: loss did not improve from -167.62454\n",
      "Epoch 2858/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.5587 - val_loss: -169.8755\n",
      "\n",
      "Epoch 02858: loss did not improve from -167.62454\n",
      "Epoch 2859/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.4391 - val_loss: -169.6274\n",
      "\n",
      "Epoch 02859: loss did not improve from -167.62454\n",
      "Epoch 2860/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.5659 - val_loss: -169.8404\n",
      "\n",
      "Epoch 02860: loss did not improve from -167.62454\n",
      "Epoch 2861/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.4722 - val_loss: -169.7016\n",
      "\n",
      "Epoch 02861: loss did not improve from -167.62454\n",
      "Epoch 2862/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.3534 - val_loss: -169.3107\n",
      "\n",
      "Epoch 02862: loss did not improve from -167.62454\n",
      "Epoch 2863/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.3380 - val_loss: -169.8726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 02863: loss did not improve from -167.62454\n",
      "Epoch 2864/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.2308 - val_loss: -168.9548\n",
      "\n",
      "Epoch 02864: loss did not improve from -167.62454\n",
      "Epoch 2865/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.4095 - val_loss: -169.8243\n",
      "\n",
      "Epoch 02865: loss did not improve from -167.62454\n",
      "Epoch 2866/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.5223 - val_loss: -169.6061\n",
      "\n",
      "Epoch 02866: loss did not improve from -167.62454\n",
      "Epoch 2867/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.7025 - val_loss: -169.9246\n",
      "\n",
      "Epoch 02867: loss improved from -167.62454 to -167.70253, saving model to gendance.h5\n",
      "Epoch 2868/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.6214 - val_loss: -169.9106\n",
      "\n",
      "Epoch 02868: loss did not improve from -167.70253\n",
      "Epoch 2869/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.6877 - val_loss: -169.9528\n",
      "\n",
      "Epoch 02869: loss did not improve from -167.70253\n",
      "Epoch 2870/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.7928 - val_loss: -169.6986\n",
      "\n",
      "Epoch 02870: loss improved from -167.70253 to -167.79279, saving model to gendance.h5\n",
      "Epoch 2871/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.7511 - val_loss: -169.9800\n",
      "\n",
      "Epoch 02871: loss did not improve from -167.79279\n",
      "Epoch 2872/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.6085 - val_loss: -169.5403\n",
      "\n",
      "Epoch 02872: loss did not improve from -167.79279\n",
      "Epoch 2873/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.6147 - val_loss: -169.9317\n",
      "\n",
      "Epoch 02873: loss did not improve from -167.79279\n",
      "Epoch 2874/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.6749 - val_loss: -169.9470\n",
      "\n",
      "Epoch 02874: loss did not improve from -167.79279\n",
      "Epoch 2875/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.6351 - val_loss: -169.4649\n",
      "\n",
      "Epoch 02875: loss did not improve from -167.79279\n",
      "Epoch 2876/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.5958 - val_loss: -169.8660\n",
      "\n",
      "Epoch 02876: loss did not improve from -167.79279\n",
      "Epoch 2877/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -167.4686 - val_loss: -168.9486\n",
      "\n",
      "Epoch 02877: loss did not improve from -167.79279\n",
      "Epoch 2878/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.5353 - val_loss: -169.7031\n",
      "\n",
      "Epoch 02878: loss did not improve from -167.79279\n",
      "Epoch 2879/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.3384 - val_loss: -168.7918\n",
      "\n",
      "Epoch 02879: loss did not improve from -167.79279\n",
      "Epoch 2880/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.3013 - val_loss: -169.6490\n",
      "\n",
      "Epoch 02880: loss did not improve from -167.79279\n",
      "Epoch 2881/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.2245 - val_loss: -169.2168\n",
      "\n",
      "Epoch 02881: loss did not improve from -167.79279\n",
      "Epoch 2882/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.0535 - val_loss: -169.2634\n",
      "\n",
      "Epoch 02882: loss did not improve from -167.79279\n",
      "Epoch 2883/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.0412 - val_loss: -169.8400\n",
      "\n",
      "Epoch 02883: loss did not improve from -167.79279\n",
      "Epoch 2884/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.0530 - val_loss: -168.9745\n",
      "\n",
      "Epoch 02884: loss did not improve from -167.79279\n",
      "Epoch 2885/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.2602 - val_loss: -169.9443\n",
      "\n",
      "Epoch 02885: loss did not improve from -167.79279\n",
      "Epoch 2886/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.6211 - val_loss: -169.4604\n",
      "\n",
      "Epoch 02886: loss did not improve from -167.79279\n",
      "Epoch 2887/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.6068 - val_loss: -170.0354\n",
      "\n",
      "Epoch 02887: loss did not improve from -167.79279\n",
      "Epoch 2888/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.5534 - val_loss: -169.6436\n",
      "\n",
      "Epoch 02888: loss did not improve from -167.79279\n",
      "Epoch 2889/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.5316 - val_loss: -170.0418\n",
      "\n",
      "Epoch 02889: loss did not improve from -167.79279\n",
      "Epoch 2890/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.7213 - val_loss: -169.8907\n",
      "\n",
      "Epoch 02890: loss did not improve from -167.79279\n",
      "Epoch 2891/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.5804 - val_loss: -169.8823\n",
      "\n",
      "Epoch 02891: loss did not improve from -167.79279\n",
      "Epoch 2892/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.6424 - val_loss: -169.9066\n",
      "\n",
      "Epoch 02892: loss did not improve from -167.79279\n",
      "Epoch 2893/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.6442 - val_loss: -169.9412\n",
      "\n",
      "Epoch 02893: loss did not improve from -167.79279\n",
      "Epoch 2894/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.5376 - val_loss: -169.7865\n",
      "\n",
      "Epoch 02894: loss did not improve from -167.79279\n",
      "Epoch 2895/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.6703 - val_loss: -169.8913\n",
      "\n",
      "Epoch 02895: loss did not improve from -167.79279\n",
      "Epoch 2896/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.6616 - val_loss: -170.0187\n",
      "\n",
      "Epoch 02896: loss did not improve from -167.79279\n",
      "Epoch 2897/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.6939 - val_loss: -169.8330\n",
      "\n",
      "Epoch 02897: loss did not improve from -167.79279\n",
      "Epoch 2898/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.5298 - val_loss: -169.7122\n",
      "\n",
      "Epoch 02898: loss did not improve from -167.79279\n",
      "Epoch 2899/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.6148 - val_loss: -169.9713\n",
      "\n",
      "Epoch 02899: loss did not improve from -167.79279\n",
      "Epoch 2900/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.4640 - val_loss: -169.5854\n",
      "\n",
      "Epoch 02900: loss did not improve from -167.79279\n",
      "Epoch 2901/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.4168 - val_loss: -169.9680\n",
      "\n",
      "Epoch 02901: loss did not improve from -167.79279\n",
      "Epoch 2902/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.5447 - val_loss: -169.5442\n",
      "\n",
      "Epoch 02902: loss did not improve from -167.79279\n",
      "Epoch 2903/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.7709 - val_loss: -170.0577\n",
      "\n",
      "Epoch 02903: loss did not improve from -167.79279\n",
      "Epoch 2904/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.8351 - val_loss: -169.9076\n",
      "\n",
      "Epoch 02904: loss improved from -167.79279 to -167.83508, saving model to gendance.h5\n",
      "Epoch 2905/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.8602 - val_loss: -170.0114\n",
      "\n",
      "Epoch 02905: loss improved from -167.83508 to -167.86017, saving model to gendance.h5\n",
      "Epoch 2906/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.7203 - val_loss: -169.8082\n",
      "\n",
      "Epoch 02906: loss did not improve from -167.86017\n",
      "Epoch 2907/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.7915 - val_loss: -170.1583\n",
      "\n",
      "Epoch 02907: loss did not improve from -167.86017\n",
      "Epoch 2908/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.7090 - val_loss: -169.7188\n",
      "\n",
      "Epoch 02908: loss did not improve from -167.86017\n",
      "Epoch 2909/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.6675 - val_loss: -169.8023\n",
      "\n",
      "Epoch 02909: loss did not improve from -167.86017\n",
      "Epoch 2910/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.7004 - val_loss: -169.8442\n",
      "\n",
      "Epoch 02910: loss did not improve from -167.86017\n",
      "Epoch 2911/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.8164 - val_loss: -169.7132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 02911: loss did not improve from -167.86017\n",
      "Epoch 2912/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.6063 - val_loss: -170.0623\n",
      "\n",
      "Epoch 02912: loss did not improve from -167.86017\n",
      "Epoch 2913/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.2574 - val_loss: -168.7668\n",
      "\n",
      "Epoch 02913: loss did not improve from -167.86017\n",
      "Epoch 2914/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -166.9932 - val_loss: -169.7788\n",
      "\n",
      "Epoch 02914: loss did not improve from -167.86017\n",
      "Epoch 2915/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.2398 - val_loss: -168.8093\n",
      "\n",
      "Epoch 02915: loss did not improve from -167.86017\n",
      "Epoch 2916/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.1954 - val_loss: -169.6022\n",
      "\n",
      "Epoch 02916: loss did not improve from -167.86017\n",
      "Epoch 2917/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.6228 - val_loss: -169.6871\n",
      "\n",
      "Epoch 02917: loss did not improve from -167.86017\n",
      "Epoch 2918/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.5760 - val_loss: -169.6203\n",
      "\n",
      "Epoch 02918: loss did not improve from -167.86017\n",
      "Epoch 2919/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.7528 - val_loss: -169.7624\n",
      "\n",
      "Epoch 02919: loss did not improve from -167.86017\n",
      "Epoch 2920/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -167.5389 - val_loss: -169.3765\n",
      "\n",
      "Epoch 02920: loss did not improve from -167.86017\n",
      "Epoch 2921/10000\n",
      "16167/16167 [==============================] - 1s 33us/step - loss: -167.4389 - val_loss: -169.8991\n",
      "\n",
      "Epoch 02921: loss did not improve from -167.86017\n",
      "Epoch 2922/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.3945 - val_loss: -169.3822\n",
      "\n",
      "Epoch 02922: loss did not improve from -167.86017\n",
      "Epoch 2923/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.2641 - val_loss: -169.7095\n",
      "\n",
      "Epoch 02923: loss did not improve from -167.86017\n",
      "Epoch 2924/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.5068 - val_loss: -169.4828\n",
      "\n",
      "Epoch 02924: loss did not improve from -167.86017\n",
      "Epoch 2925/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.4984 - val_loss: -169.8852\n",
      "\n",
      "Epoch 02925: loss did not improve from -167.86017\n",
      "Epoch 2926/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.6980 - val_loss: -169.7351\n",
      "\n",
      "Epoch 02926: loss did not improve from -167.86017\n",
      "Epoch 2927/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.5118 - val_loss: -169.4578\n",
      "\n",
      "Epoch 02927: loss did not improve from -167.86017\n",
      "Epoch 2928/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.5335 - val_loss: -170.0494\n",
      "\n",
      "Epoch 02928: loss did not improve from -167.86017\n",
      "Epoch 2929/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.5612 - val_loss: -169.3024\n",
      "\n",
      "Epoch 02929: loss did not improve from -167.86017\n",
      "Epoch 2930/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.6639 - val_loss: -169.8273\n",
      "\n",
      "Epoch 02930: loss did not improve from -167.86017\n",
      "Epoch 2931/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.5753 - val_loss: -169.8737\n",
      "\n",
      "Epoch 02931: loss did not improve from -167.86017\n",
      "Epoch 2932/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.6397 - val_loss: -169.8685\n",
      "\n",
      "Epoch 02932: loss did not improve from -167.86017\n",
      "Epoch 2933/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.7228 - val_loss: -170.0036\n",
      "\n",
      "Epoch 02933: loss did not improve from -167.86017\n",
      "Epoch 2934/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.5326 - val_loss: -169.3725\n",
      "\n",
      "Epoch 02934: loss did not improve from -167.86017\n",
      "Epoch 2935/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.5201 - val_loss: -169.5811\n",
      "\n",
      "Epoch 02935: loss did not improve from -167.86017\n",
      "Epoch 2936/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -167.1726 - val_loss: -169.2936\n",
      "\n",
      "Epoch 02936: loss did not improve from -167.86017\n",
      "Epoch 2937/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -167.4294 - val_loss: -169.9303\n",
      "\n",
      "Epoch 02937: loss did not improve from -167.86017\n",
      "Epoch 2938/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.5013 - val_loss: -169.5641\n",
      "\n",
      "Epoch 02938: loss did not improve from -167.86017\n",
      "Epoch 2939/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.7086 - val_loss: -170.2125\n",
      "\n",
      "Epoch 02939: loss did not improve from -167.86017\n",
      "Epoch 2940/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.7179 - val_loss: -169.9720\n",
      "\n",
      "Epoch 02940: loss did not improve from -167.86017\n",
      "Epoch 2941/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.9945 - val_loss: -169.9569\n",
      "\n",
      "Epoch 02941: loss improved from -167.86017 to -167.99450, saving model to gendance.h5\n",
      "Epoch 2942/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -167.9085 - val_loss: -170.2078\n",
      "\n",
      "Epoch 02942: loss did not improve from -167.99450\n",
      "Epoch 2943/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.8651 - val_loss: -169.9056\n",
      "\n",
      "Epoch 02943: loss did not improve from -167.99450\n",
      "Epoch 2944/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -168.1028 - val_loss: -169.9685\n",
      "\n",
      "Epoch 02944: loss improved from -167.99450 to -168.10279, saving model to gendance.h5\n",
      "Epoch 2945/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.0359 - val_loss: -169.9668\n",
      "\n",
      "Epoch 02945: loss did not improve from -168.10279\n",
      "Epoch 2946/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.8548 - val_loss: -169.9725\n",
      "\n",
      "Epoch 02946: loss did not improve from -168.10279\n",
      "Epoch 2947/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.8680 - val_loss: -169.8899\n",
      "\n",
      "Epoch 02947: loss did not improve from -168.10279\n",
      "Epoch 2948/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.7334 - val_loss: -170.1089\n",
      "\n",
      "Epoch 02948: loss did not improve from -168.10279\n",
      "Epoch 2949/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.9062 - val_loss: -170.0286\n",
      "\n",
      "Epoch 02949: loss did not improve from -168.10279\n",
      "Epoch 2950/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.9488 - val_loss: -170.0516\n",
      "\n",
      "Epoch 02950: loss did not improve from -168.10279\n",
      "Epoch 2951/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.9476 - val_loss: -170.1164\n",
      "\n",
      "Epoch 02951: loss did not improve from -168.10279\n",
      "Epoch 2952/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.7966 - val_loss: -169.8193\n",
      "\n",
      "Epoch 02952: loss did not improve from -168.10279\n",
      "Epoch 2953/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.9361 - val_loss: -170.2221\n",
      "\n",
      "Epoch 02953: loss did not improve from -168.10279\n",
      "Epoch 2954/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.7765 - val_loss: -169.2295\n",
      "\n",
      "Epoch 02954: loss did not improve from -168.10279\n",
      "Epoch 2955/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.6539 - val_loss: -170.0677\n",
      "\n",
      "Epoch 02955: loss did not improve from -168.10279\n",
      "Epoch 2956/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.7870 - val_loss: -169.6853\n",
      "\n",
      "Epoch 02956: loss did not improve from -168.10279\n",
      "Epoch 2957/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.5457 - val_loss: -169.6444\n",
      "\n",
      "Epoch 02957: loss did not improve from -168.10279\n",
      "Epoch 2958/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.4741 - val_loss: -169.9213\n",
      "\n",
      "Epoch 02958: loss did not improve from -168.10279\n",
      "Epoch 2959/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.3775 - val_loss: -169.0764\n",
      "\n",
      "Epoch 02959: loss did not improve from -168.10279\n",
      "Epoch 2960/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.0838 - val_loss: -169.6959\n",
      "\n",
      "Epoch 02960: loss did not improve from -168.10279\n",
      "Epoch 2961/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.3406 - val_loss: -169.0801\n",
      "\n",
      "Epoch 02961: loss did not improve from -168.10279\n",
      "Epoch 2962/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.5669 - val_loss: -169.9933\n",
      "\n",
      "Epoch 02962: loss did not improve from -168.10279\n",
      "Epoch 2963/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.6742 - val_loss: -169.7346\n",
      "\n",
      "Epoch 02963: loss did not improve from -168.10279\n",
      "Epoch 2964/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.8238 - val_loss: -170.1665\n",
      "\n",
      "Epoch 02964: loss did not improve from -168.10279\n",
      "Epoch 2965/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.7671 - val_loss: -170.1246\n",
      "\n",
      "Epoch 02965: loss did not improve from -168.10279\n",
      "Epoch 2966/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.0334 - val_loss: -169.9378\n",
      "\n",
      "Epoch 02966: loss did not improve from -168.10279\n",
      "Epoch 2967/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.7806 - val_loss: -170.2905\n",
      "\n",
      "Epoch 02967: loss did not improve from -168.10279\n",
      "Epoch 2968/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.8224 - val_loss: -169.7914\n",
      "\n",
      "Epoch 02968: loss did not improve from -168.10279\n",
      "Epoch 2969/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.7684 - val_loss: -170.2572\n",
      "\n",
      "Epoch 02969: loss did not improve from -168.10279\n",
      "Epoch 2970/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.7730 - val_loss: -169.9036\n",
      "\n",
      "Epoch 02970: loss did not improve from -168.10279\n",
      "Epoch 2971/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.7674 - val_loss: -169.9412\n",
      "\n",
      "Epoch 02971: loss did not improve from -168.10279\n",
      "Epoch 2972/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.7965 - val_loss: -170.1783\n",
      "\n",
      "Epoch 02972: loss did not improve from -168.10279\n",
      "Epoch 2973/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.0198 - val_loss: -170.2922\n",
      "\n",
      "Epoch 02973: loss did not improve from -168.10279\n",
      "Epoch 2974/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.9038 - val_loss: -170.2331\n",
      "\n",
      "Epoch 02974: loss did not improve from -168.10279\n",
      "Epoch 2975/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.0789 - val_loss: -169.9472\n",
      "\n",
      "Epoch 02975: loss did not improve from -168.10279\n",
      "Epoch 2976/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.0686 - val_loss: -170.2795\n",
      "\n",
      "Epoch 02976: loss did not improve from -168.10279\n",
      "Epoch 2977/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.2609 - val_loss: -170.2269\n",
      "\n",
      "Epoch 02977: loss improved from -168.10279 to -168.26095, saving model to gendance.h5\n",
      "Epoch 2978/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.0672 - val_loss: -169.9396\n",
      "\n",
      "Epoch 02978: loss did not improve from -168.26095\n",
      "Epoch 2979/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.0508 - val_loss: -170.3896\n",
      "\n",
      "Epoch 02979: loss did not improve from -168.26095\n",
      "Epoch 2980/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.0397 - val_loss: -169.9459\n",
      "\n",
      "Epoch 02980: loss did not improve from -168.26095\n",
      "Epoch 2981/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.9334 - val_loss: -170.1699\n",
      "\n",
      "Epoch 02981: loss did not improve from -168.26095\n",
      "Epoch 2982/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.9994 - val_loss: -170.1869\n",
      "\n",
      "Epoch 02982: loss did not improve from -168.26095\n",
      "Epoch 2983/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -168.0916 - val_loss: -170.1678\n",
      "\n",
      "Epoch 02983: loss did not improve from -168.26095\n",
      "Epoch 2984/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.9314 - val_loss: -170.1055\n",
      "\n",
      "Epoch 02984: loss did not improve from -168.26095\n",
      "Epoch 2985/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.0254 - val_loss: -169.9592\n",
      "\n",
      "Epoch 02985: loss did not improve from -168.26095\n",
      "Epoch 2986/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.8950 - val_loss: -170.1571\n",
      "\n",
      "Epoch 02986: loss did not improve from -168.26095\n",
      "Epoch 2987/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.8517 - val_loss: -169.9087\n",
      "\n",
      "Epoch 02987: loss did not improve from -168.26095\n",
      "Epoch 2988/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.7140 - val_loss: -170.0770\n",
      "\n",
      "Epoch 02988: loss did not improve from -168.26095\n",
      "Epoch 2989/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -167.7783 - val_loss: -169.8343\n",
      "\n",
      "Epoch 02989: loss did not improve from -168.26095\n",
      "Epoch 2990/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.7674 - val_loss: -169.9914\n",
      "\n",
      "Epoch 02990: loss did not improve from -168.26095\n",
      "Epoch 2991/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.7471 - val_loss: -169.6972\n",
      "\n",
      "Epoch 02991: loss did not improve from -168.26095\n",
      "Epoch 2992/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.9784 - val_loss: -170.3190\n",
      "\n",
      "Epoch 02992: loss did not improve from -168.26095\n",
      "Epoch 2993/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.7955 - val_loss: -169.5728\n",
      "\n",
      "Epoch 02993: loss did not improve from -168.26095\n",
      "Epoch 2994/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.8696 - val_loss: -170.2876\n",
      "\n",
      "Epoch 02994: loss did not improve from -168.26095\n",
      "Epoch 2995/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.7467 - val_loss: -169.5985\n",
      "\n",
      "Epoch 02995: loss did not improve from -168.26095\n",
      "Epoch 2996/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.7705 - val_loss: -169.8376\n",
      "\n",
      "Epoch 02996: loss did not improve from -168.26095\n",
      "Epoch 2997/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.8642 - val_loss: -170.2296\n",
      "\n",
      "Epoch 02997: loss did not improve from -168.26095\n",
      "Epoch 2998/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.5047 - val_loss: -169.3866\n",
      "\n",
      "Epoch 02998: loss did not improve from -168.26095\n",
      "Epoch 2999/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.4728 - val_loss: -169.9520\n",
      "\n",
      "Epoch 02999: loss did not improve from -168.26095\n",
      "Epoch 3000/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.4520 - val_loss: -169.2176\n",
      "\n",
      "Epoch 03000: loss did not improve from -168.26095\n",
      "Epoch 3001/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.5578 - val_loss: -169.8424\n",
      "\n",
      "Epoch 03001: loss did not improve from -168.26095\n",
      "Epoch 3002/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.6488 - val_loss: -169.4511\n",
      "\n",
      "Epoch 03002: loss did not improve from -168.26095\n",
      "Epoch 3003/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.0129 - val_loss: -170.2617\n",
      "\n",
      "Epoch 03003: loss did not improve from -168.26095\n",
      "Epoch 3004/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.9778 - val_loss: -170.0419\n",
      "\n",
      "Epoch 03004: loss did not improve from -168.26095\n",
      "Epoch 3005/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.1775 - val_loss: -169.8788\n",
      "\n",
      "Epoch 03005: loss did not improve from -168.26095\n",
      "Epoch 3006/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.9359 - val_loss: -170.3688\n",
      "\n",
      "Epoch 03006: loss did not improve from -168.26095\n",
      "Epoch 3007/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.9613 - val_loss: -169.7408\n",
      "\n",
      "Epoch 03007: loss did not improve from -168.26095\n",
      "Epoch 3008/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.7759 - val_loss: -170.0917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 03008: loss did not improve from -168.26095\n",
      "Epoch 3009/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.0773 - val_loss: -170.2285\n",
      "\n",
      "Epoch 03009: loss did not improve from -168.26095\n",
      "Epoch 3010/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.0175 - val_loss: -170.1253\n",
      "\n",
      "Epoch 03010: loss did not improve from -168.26095\n",
      "Epoch 3011/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.9259 - val_loss: -169.7718\n",
      "\n",
      "Epoch 03011: loss did not improve from -168.26095\n",
      "Epoch 3012/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.1805 - val_loss: -170.4642\n",
      "\n",
      "Epoch 03012: loss did not improve from -168.26095\n",
      "Epoch 3013/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.0796 - val_loss: -170.1080\n",
      "\n",
      "Epoch 03013: loss did not improve from -168.26095\n",
      "Epoch 3014/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.0025 - val_loss: -170.1176\n",
      "\n",
      "Epoch 03014: loss did not improve from -168.26095\n",
      "Epoch 3015/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.9113 - val_loss: -170.2314\n",
      "\n",
      "Epoch 03015: loss did not improve from -168.26095\n",
      "Epoch 3016/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.7884 - val_loss: -169.6331\n",
      "\n",
      "Epoch 03016: loss did not improve from -168.26095\n",
      "Epoch 3017/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.7735 - val_loss: -170.3074\n",
      "\n",
      "Epoch 03017: loss did not improve from -168.26095\n",
      "Epoch 3018/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -167.4385 - val_loss: -169.0313\n",
      "\n",
      "Epoch 03018: loss did not improve from -168.26095\n",
      "Epoch 3019/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.6640 - val_loss: -170.1409\n",
      "\n",
      "Epoch 03019: loss did not improve from -168.26095\n",
      "Epoch 3020/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.9348 - val_loss: -169.5188\n",
      "\n",
      "Epoch 03020: loss did not improve from -168.26095\n",
      "Epoch 3021/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.0068 - val_loss: -170.1174\n",
      "\n",
      "Epoch 03021: loss did not improve from -168.26095\n",
      "Epoch 3022/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.0791 - val_loss: -170.2485\n",
      "\n",
      "Epoch 03022: loss did not improve from -168.26095\n",
      "Epoch 3023/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.1738 - val_loss: -170.2132\n",
      "\n",
      "Epoch 03023: loss did not improve from -168.26095\n",
      "Epoch 3024/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.8152 - val_loss: -170.0390\n",
      "\n",
      "Epoch 03024: loss did not improve from -168.26095\n",
      "Epoch 3025/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.0057 - val_loss: -169.9448\n",
      "\n",
      "Epoch 03025: loss did not improve from -168.26095\n",
      "Epoch 3026/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.7439 - val_loss: -170.2948\n",
      "\n",
      "Epoch 03026: loss did not improve from -168.26095\n",
      "Epoch 3027/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.8104 - val_loss: -169.6515\n",
      "\n",
      "Epoch 03027: loss did not improve from -168.26095\n",
      "Epoch 3028/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.8857 - val_loss: -170.2329\n",
      "\n",
      "Epoch 03028: loss did not improve from -168.26095\n",
      "Epoch 3029/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.0812 - val_loss: -169.9115\n",
      "\n",
      "Epoch 03029: loss did not improve from -168.26095\n",
      "Epoch 3030/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.8959 - val_loss: -170.1942\n",
      "\n",
      "Epoch 03030: loss did not improve from -168.26095\n",
      "Epoch 3031/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.8938 - val_loss: -169.7900\n",
      "\n",
      "Epoch 03031: loss did not improve from -168.26095\n",
      "Epoch 3032/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.0331 - val_loss: -170.4780\n",
      "\n",
      "Epoch 03032: loss did not improve from -168.26095\n",
      "Epoch 3033/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.1678 - val_loss: -170.5122\n",
      "\n",
      "Epoch 03033: loss did not improve from -168.26095\n",
      "Epoch 3034/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.0817 - val_loss: -170.0821\n",
      "\n",
      "Epoch 03034: loss did not improve from -168.26095\n",
      "Epoch 3035/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.0110 - val_loss: -170.4176\n",
      "\n",
      "Epoch 03035: loss did not improve from -168.26095\n",
      "Epoch 3036/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.9697 - val_loss: -169.7698\n",
      "\n",
      "Epoch 03036: loss did not improve from -168.26095\n",
      "Epoch 3037/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.0726 - val_loss: -170.2679\n",
      "\n",
      "Epoch 03037: loss did not improve from -168.26095\n",
      "Epoch 3038/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.9919 - val_loss: -170.0175\n",
      "\n",
      "Epoch 03038: loss did not improve from -168.26095\n",
      "Epoch 3039/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.1035 - val_loss: -170.3443\n",
      "\n",
      "Epoch 03039: loss did not improve from -168.26095\n",
      "Epoch 3040/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.2192 - val_loss: -170.1372\n",
      "\n",
      "Epoch 03040: loss did not improve from -168.26095\n",
      "Epoch 3041/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.3645 - val_loss: -170.4747\n",
      "\n",
      "Epoch 03041: loss improved from -168.26095 to -168.36446, saving model to gendance.h5\n",
      "Epoch 3042/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.0940 - val_loss: -170.3033\n",
      "\n",
      "Epoch 03042: loss did not improve from -168.36446\n",
      "Epoch 3043/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.0745 - val_loss: -170.2787\n",
      "\n",
      "Epoch 03043: loss did not improve from -168.36446\n",
      "Epoch 3044/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.9689 - val_loss: -170.2447\n",
      "\n",
      "Epoch 03044: loss did not improve from -168.36446\n",
      "Epoch 3045/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.1461 - val_loss: -170.0267\n",
      "\n",
      "Epoch 03045: loss did not improve from -168.36446\n",
      "Epoch 3046/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.2435 - val_loss: -170.4250\n",
      "\n",
      "Epoch 03046: loss did not improve from -168.36446\n",
      "Epoch 3047/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.1359 - val_loss: -170.0483\n",
      "\n",
      "Epoch 03047: loss did not improve from -168.36446\n",
      "Epoch 3048/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.1655 - val_loss: -170.3857\n",
      "\n",
      "Epoch 03048: loss did not improve from -168.36446\n",
      "Epoch 3049/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.2787 - val_loss: -170.2391\n",
      "\n",
      "Epoch 03049: loss did not improve from -168.36446\n",
      "Epoch 3050/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.1311 - val_loss: -170.1954\n",
      "\n",
      "Epoch 03050: loss did not improve from -168.36446\n",
      "Epoch 3051/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.2348 - val_loss: -170.2473\n",
      "\n",
      "Epoch 03051: loss did not improve from -168.36446\n",
      "Epoch 3052/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.9749 - val_loss: -169.8647\n",
      "\n",
      "Epoch 03052: loss did not improve from -168.36446\n",
      "Epoch 3053/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -168.1254 - val_loss: -170.3581\n",
      "\n",
      "Epoch 03053: loss did not improve from -168.36446\n",
      "Epoch 3054/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.0938 - val_loss: -169.7539\n",
      "\n",
      "Epoch 03054: loss did not improve from -168.36446\n",
      "Epoch 3055/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.0558 - val_loss: -170.3122\n",
      "\n",
      "Epoch 03055: loss did not improve from -168.36446\n",
      "Epoch 3056/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.9420 - val_loss: -170.3428\n",
      "\n",
      "Epoch 03056: loss did not improve from -168.36446\n",
      "Epoch 3057/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.3223 - val_loss: -170.2664\n",
      "\n",
      "Epoch 03057: loss did not improve from -168.36446\n",
      "Epoch 3058/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.0011 - val_loss: -170.2844\n",
      "\n",
      "Epoch 03058: loss did not improve from -168.36446\n",
      "Epoch 3059/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.7655 - val_loss: -169.5995\n",
      "\n",
      "Epoch 03059: loss did not improve from -168.36446\n",
      "Epoch 3060/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -167.8252 - val_loss: -170.1892\n",
      "\n",
      "Epoch 03060: loss did not improve from -168.36446\n",
      "Epoch 3061/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.8955 - val_loss: -169.5626\n",
      "\n",
      "Epoch 03061: loss did not improve from -168.36446\n",
      "Epoch 3062/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.1427 - val_loss: -170.2132\n",
      "\n",
      "Epoch 03062: loss did not improve from -168.36446\n",
      "Epoch 3063/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.9751 - val_loss: -170.2573\n",
      "\n",
      "Epoch 03063: loss did not improve from -168.36446\n",
      "Epoch 3064/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.0058 - val_loss: -169.9160\n",
      "\n",
      "Epoch 03064: loss did not improve from -168.36446\n",
      "Epoch 3065/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.0675 - val_loss: -170.5265\n",
      "\n",
      "Epoch 03065: loss did not improve from -168.36446\n",
      "Epoch 3066/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.9379 - val_loss: -169.3545\n",
      "\n",
      "Epoch 03066: loss did not improve from -168.36446\n",
      "Epoch 3067/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.9611 - val_loss: -170.3030\n",
      "\n",
      "Epoch 03067: loss did not improve from -168.36446\n",
      "Epoch 3068/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.9805 - val_loss: -169.3926\n",
      "\n",
      "Epoch 03068: loss did not improve from -168.36446\n",
      "Epoch 3069/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.1105 - val_loss: -170.3088\n",
      "\n",
      "Epoch 03069: loss did not improve from -168.36446\n",
      "Epoch 3070/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.1170 - val_loss: -170.0739\n",
      "\n",
      "Epoch 03070: loss did not improve from -168.36446\n",
      "Epoch 3071/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.1224 - val_loss: -170.0949\n",
      "\n",
      "Epoch 03071: loss did not improve from -168.36446\n",
      "Epoch 3072/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.1213 - val_loss: -170.2369\n",
      "\n",
      "Epoch 03072: loss did not improve from -168.36446\n",
      "Epoch 3073/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.1515 - val_loss: -170.2134\n",
      "\n",
      "Epoch 03073: loss did not improve from -168.36446\n",
      "Epoch 3074/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.2347 - val_loss: -170.2830\n",
      "\n",
      "Epoch 03074: loss did not improve from -168.36446\n",
      "Epoch 3075/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.0972 - val_loss: -170.3885\n",
      "\n",
      "Epoch 03075: loss did not improve from -168.36446\n",
      "Epoch 3076/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.1249 - val_loss: -170.2339\n",
      "\n",
      "Epoch 03076: loss did not improve from -168.36446\n",
      "Epoch 3077/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.1644 - val_loss: -170.0073\n",
      "\n",
      "Epoch 03077: loss did not improve from -168.36446\n",
      "Epoch 3078/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.8815 - val_loss: -170.3888\n",
      "\n",
      "Epoch 03078: loss did not improve from -168.36446\n",
      "Epoch 3079/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.0855 - val_loss: -169.9081\n",
      "\n",
      "Epoch 03079: loss did not improve from -168.36446\n",
      "Epoch 3080/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.9707 - val_loss: -170.3380\n",
      "\n",
      "Epoch 03080: loss did not improve from -168.36446\n",
      "Epoch 3081/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.9593 - val_loss: -169.9037\n",
      "\n",
      "Epoch 03081: loss did not improve from -168.36446\n",
      "Epoch 3082/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.0903 - val_loss: -170.4456\n",
      "\n",
      "Epoch 03082: loss did not improve from -168.36446\n",
      "Epoch 3083/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.1760 - val_loss: -169.8167\n",
      "\n",
      "Epoch 03083: loss did not improve from -168.36446\n",
      "Epoch 3084/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.8550 - val_loss: -170.3897\n",
      "\n",
      "Epoch 03084: loss did not improve from -168.36446\n",
      "Epoch 3085/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.2637 - val_loss: -170.4012\n",
      "\n",
      "Epoch 03085: loss did not improve from -168.36446\n",
      "Epoch 3086/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.1933 - val_loss: -170.2297\n",
      "\n",
      "Epoch 03086: loss did not improve from -168.36446\n",
      "Epoch 3087/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.3586 - val_loss: -170.3926\n",
      "\n",
      "Epoch 03087: loss did not improve from -168.36446\n",
      "Epoch 3088/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.0937 - val_loss: -170.3384\n",
      "\n",
      "Epoch 03088: loss did not improve from -168.36446\n",
      "Epoch 3089/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.3849 - val_loss: -170.4430\n",
      "\n",
      "Epoch 03089: loss improved from -168.36446 to -168.38489, saving model to gendance.h5\n",
      "Epoch 3090/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -168.4744 - val_loss: -170.2961\n",
      "\n",
      "Epoch 03090: loss improved from -168.38489 to -168.47444, saving model to gendance.h5\n",
      "Epoch 3091/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.4261 - val_loss: -170.4678\n",
      "\n",
      "Epoch 03091: loss did not improve from -168.47444\n",
      "Epoch 3092/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.3780 - val_loss: -170.4441\n",
      "\n",
      "Epoch 03092: loss did not improve from -168.47444\n",
      "Epoch 3093/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.3699 - val_loss: -170.5405\n",
      "\n",
      "Epoch 03093: loss did not improve from -168.47444\n",
      "Epoch 3094/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -168.3194 - val_loss: -170.2824\n",
      "\n",
      "Epoch 03094: loss did not improve from -168.47444\n",
      "Epoch 3095/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.0655 - val_loss: -170.2844\n",
      "\n",
      "Epoch 03095: loss did not improve from -168.47444\n",
      "Epoch 3096/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.4022 - val_loss: -170.7065\n",
      "\n",
      "Epoch 03096: loss did not improve from -168.47444\n",
      "Epoch 3097/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.0287 - val_loss: -169.7934\n",
      "\n",
      "Epoch 03097: loss did not improve from -168.47444\n",
      "Epoch 3098/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -168.1210 - val_loss: -170.4398\n",
      "\n",
      "Epoch 03098: loss did not improve from -168.47444\n",
      "Epoch 3099/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.0288 - val_loss: -169.8582\n",
      "\n",
      "Epoch 03099: loss did not improve from -168.47444\n",
      "Epoch 3100/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.2949 - val_loss: -170.3560\n",
      "\n",
      "Epoch 03100: loss did not improve from -168.47444\n",
      "Epoch 3101/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.1682 - val_loss: -170.3126\n",
      "\n",
      "Epoch 03101: loss did not improve from -168.47444\n",
      "Epoch 3102/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.4750 - val_loss: -170.2818\n",
      "\n",
      "Epoch 03102: loss improved from -168.47444 to -168.47504, saving model to gendance.h5\n",
      "Epoch 3103/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.2015 - val_loss: -170.5291\n",
      "\n",
      "Epoch 03103: loss did not improve from -168.47504\n",
      "Epoch 3104/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.1389 - val_loss: -169.7684\n",
      "\n",
      "Epoch 03104: loss did not improve from -168.47504\n",
      "Epoch 3105/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.9819 - val_loss: -170.4581\n",
      "\n",
      "Epoch 03105: loss did not improve from -168.47504\n",
      "Epoch 3106/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.9871 - val_loss: -169.3209\n",
      "\n",
      "Epoch 03106: loss did not improve from -168.47504\n",
      "Epoch 3107/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.1696 - val_loss: -170.4884\n",
      "\n",
      "Epoch 03107: loss did not improve from -168.47504\n",
      "Epoch 3108/10000\n",
      "16167/16167 [==============================] - 1s 31us/step - loss: -168.1819 - val_loss: -170.1270\n",
      "\n",
      "Epoch 03108: loss did not improve from -168.47504\n",
      "Epoch 3109/10000\n",
      "16167/16167 [==============================] - 1s 32us/step - loss: -168.1518 - val_loss: -170.3077\n",
      "\n",
      "Epoch 03109: loss did not improve from -168.47504\n",
      "Epoch 3110/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.1023 - val_loss: -170.4371\n",
      "\n",
      "Epoch 03110: loss did not improve from -168.47504\n",
      "Epoch 3111/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.9131 - val_loss: -169.6705\n",
      "\n",
      "Epoch 03111: loss did not improve from -168.47504\n",
      "Epoch 3112/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.0563 - val_loss: -170.6238\n",
      "\n",
      "Epoch 03112: loss did not improve from -168.47504\n",
      "Epoch 3113/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.9314 - val_loss: -169.5469\n",
      "\n",
      "Epoch 03113: loss did not improve from -168.47504\n",
      "Epoch 3114/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.1257 - val_loss: -170.4303\n",
      "\n",
      "Epoch 03114: loss did not improve from -168.47504\n",
      "Epoch 3115/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.0390 - val_loss: -170.0508\n",
      "\n",
      "Epoch 03115: loss did not improve from -168.47504\n",
      "Epoch 3116/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -168.2213 - val_loss: -170.5759\n",
      "\n",
      "Epoch 03116: loss did not improve from -168.47504\n",
      "Epoch 3117/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.4738 - val_loss: -170.5328\n",
      "\n",
      "Epoch 03117: loss did not improve from -168.47504\n",
      "Epoch 3118/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.2134 - val_loss: -170.3755\n",
      "\n",
      "Epoch 03118: loss did not improve from -168.47504\n",
      "Epoch 3119/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.3473 - val_loss: -170.6117\n",
      "\n",
      "Epoch 03119: loss did not improve from -168.47504\n",
      "Epoch 3120/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.4540 - val_loss: -170.2992\n",
      "\n",
      "Epoch 03120: loss did not improve from -168.47504\n",
      "Epoch 3121/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.3294 - val_loss: -170.6662\n",
      "\n",
      "Epoch 03121: loss did not improve from -168.47504\n",
      "Epoch 3122/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.4273 - val_loss: -170.4101\n",
      "\n",
      "Epoch 03122: loss did not improve from -168.47504\n",
      "Epoch 3123/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.3936 - val_loss: -170.4113\n",
      "\n",
      "Epoch 03123: loss did not improve from -168.47504\n",
      "Epoch 3124/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.3374 - val_loss: -170.4093\n",
      "\n",
      "Epoch 03124: loss did not improve from -168.47504\n",
      "Epoch 3125/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.4290 - val_loss: -170.5964\n",
      "\n",
      "Epoch 03125: loss did not improve from -168.47504\n",
      "Epoch 3126/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.3270 - val_loss: -170.3960\n",
      "\n",
      "Epoch 03126: loss did not improve from -168.47504\n",
      "Epoch 3127/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.3541 - val_loss: -170.4563\n",
      "\n",
      "Epoch 03127: loss did not improve from -168.47504\n",
      "Epoch 3128/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.3577 - val_loss: -170.2701\n",
      "\n",
      "Epoch 03128: loss did not improve from -168.47504\n",
      "Epoch 3129/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.4861 - val_loss: -170.6548\n",
      "\n",
      "Epoch 03129: loss improved from -168.47504 to -168.48606, saving model to gendance.h5\n",
      "Epoch 3130/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.0721 - val_loss: -170.1347\n",
      "\n",
      "Epoch 03130: loss did not improve from -168.48606\n",
      "Epoch 3131/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.2836 - val_loss: -170.3752\n",
      "\n",
      "Epoch 03131: loss did not improve from -168.48606\n",
      "Epoch 3132/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.4045 - val_loss: -170.7347\n",
      "\n",
      "Epoch 03132: loss did not improve from -168.48606\n",
      "Epoch 3133/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.3709 - val_loss: -169.9174\n",
      "\n",
      "Epoch 03133: loss did not improve from -168.48606\n",
      "Epoch 3134/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.1197 - val_loss: -170.5578\n",
      "\n",
      "Epoch 03134: loss did not improve from -168.48606\n",
      "Epoch 3135/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.1973 - val_loss: -169.9432\n",
      "\n",
      "Epoch 03135: loss did not improve from -168.48606\n",
      "Epoch 3136/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.3819 - val_loss: -170.5490\n",
      "\n",
      "Epoch 03136: loss did not improve from -168.48606\n",
      "Epoch 3137/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.2148 - val_loss: -170.3104\n",
      "\n",
      "Epoch 03137: loss did not improve from -168.48606\n",
      "Epoch 3138/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.1492 - val_loss: -170.3834\n",
      "\n",
      "Epoch 03138: loss did not improve from -168.48606\n",
      "Epoch 3139/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.3709 - val_loss: -170.4963\n",
      "\n",
      "Epoch 03139: loss did not improve from -168.48606\n",
      "Epoch 3140/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.5451 - val_loss: -170.7960\n",
      "\n",
      "Epoch 03140: loss improved from -168.48606 to -168.54506, saving model to gendance.h5\n",
      "Epoch 3141/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.4953 - val_loss: -170.6662\n",
      "\n",
      "Epoch 03141: loss did not improve from -168.54506\n",
      "Epoch 3142/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.6017 - val_loss: -170.5982\n",
      "\n",
      "Epoch 03142: loss improved from -168.54506 to -168.60174, saving model to gendance.h5\n",
      "Epoch 3143/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -168.5233 - val_loss: -170.6262\n",
      "\n",
      "Epoch 03143: loss did not improve from -168.60174\n",
      "Epoch 3144/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.5130 - val_loss: -170.3749\n",
      "\n",
      "Epoch 03144: loss did not improve from -168.60174\n",
      "Epoch 3145/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -168.4678 - val_loss: -170.6590\n",
      "\n",
      "Epoch 03145: loss did not improve from -168.60174\n",
      "Epoch 3146/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.3032 - val_loss: -170.2292\n",
      "\n",
      "Epoch 03146: loss did not improve from -168.60174\n",
      "Epoch 3147/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.2032 - val_loss: -170.4948\n",
      "\n",
      "Epoch 03147: loss did not improve from -168.60174\n",
      "Epoch 3148/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.3866 - val_loss: -170.4980\n",
      "\n",
      "Epoch 03148: loss did not improve from -168.60174\n",
      "Epoch 3149/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.3202 - val_loss: -170.2673\n",
      "\n",
      "Epoch 03149: loss did not improve from -168.60174\n",
      "Epoch 3150/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.1270 - val_loss: -170.3556\n",
      "\n",
      "Epoch 03150: loss did not improve from -168.60174\n",
      "Epoch 3151/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -167.8478 - val_loss: -169.6097\n",
      "\n",
      "Epoch 03151: loss did not improve from -168.60174\n",
      "Epoch 3152/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.1055 - val_loss: -170.4595\n",
      "\n",
      "Epoch 03152: loss did not improve from -168.60174\n",
      "Epoch 3153/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.0184 - val_loss: -169.4813\n",
      "\n",
      "Epoch 03153: loss did not improve from -168.60174\n",
      "Epoch 3154/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.1297 - val_loss: -170.2544\n",
      "\n",
      "Epoch 03154: loss did not improve from -168.60174\n",
      "Epoch 3155/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.0591 - val_loss: -169.7972\n",
      "\n",
      "Epoch 03155: loss did not improve from -168.60174\n",
      "Epoch 3156/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.2787 - val_loss: -170.6198\n",
      "\n",
      "Epoch 03156: loss did not improve from -168.60174\n",
      "Epoch 3157/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.2753 - val_loss: -169.9523\n",
      "\n",
      "Epoch 03157: loss did not improve from -168.60174\n",
      "Epoch 3158/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.1939 - val_loss: -170.4608\n",
      "\n",
      "Epoch 03158: loss did not improve from -168.60174\n",
      "Epoch 3159/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.1140 - val_loss: -170.4643\n",
      "\n",
      "Epoch 03159: loss did not improve from -168.60174\n",
      "Epoch 3160/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.3842 - val_loss: -170.3109\n",
      "\n",
      "Epoch 03160: loss did not improve from -168.60174\n",
      "Epoch 3161/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.3136 - val_loss: -170.6641\n",
      "\n",
      "Epoch 03161: loss did not improve from -168.60174\n",
      "Epoch 3162/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.4518 - val_loss: -170.2031\n",
      "\n",
      "Epoch 03162: loss did not improve from -168.60174\n",
      "Epoch 3163/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.3864 - val_loss: -170.6749\n",
      "\n",
      "Epoch 03163: loss did not improve from -168.60174\n",
      "Epoch 3164/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.2414 - val_loss: -170.3273\n",
      "\n",
      "Epoch 03164: loss did not improve from -168.60174\n",
      "Epoch 3165/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.3589 - val_loss: -170.7690\n",
      "\n",
      "Epoch 03165: loss did not improve from -168.60174\n",
      "Epoch 3166/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.3743 - val_loss: -170.1027\n",
      "\n",
      "Epoch 03166: loss did not improve from -168.60174\n",
      "Epoch 3167/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.2292 - val_loss: -170.6418\n",
      "\n",
      "Epoch 03167: loss did not improve from -168.60174\n",
      "Epoch 3168/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.4512 - val_loss: -170.0178\n",
      "\n",
      "Epoch 03168: loss did not improve from -168.60174\n",
      "Epoch 3169/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.3689 - val_loss: -170.4637\n",
      "\n",
      "Epoch 03169: loss did not improve from -168.60174\n",
      "Epoch 3170/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.4272 - val_loss: -170.6489\n",
      "\n",
      "Epoch 03170: loss did not improve from -168.60174\n",
      "Epoch 3171/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.2451 - val_loss: -170.2810\n",
      "\n",
      "Epoch 03171: loss did not improve from -168.60174\n",
      "Epoch 3172/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.1562 - val_loss: -170.5853\n",
      "\n",
      "Epoch 03172: loss did not improve from -168.60174\n",
      "Epoch 3173/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.2955 - val_loss: -170.1687\n",
      "\n",
      "Epoch 03173: loss did not improve from -168.60174\n",
      "Epoch 3174/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.3467 - val_loss: -170.6385\n",
      "\n",
      "Epoch 03174: loss did not improve from -168.60174\n",
      "Epoch 3175/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.5779 - val_loss: -170.5135\n",
      "\n",
      "Epoch 03175: loss did not improve from -168.60174\n",
      "Epoch 3176/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.7422 - val_loss: -170.8323\n",
      "\n",
      "Epoch 03176: loss improved from -168.60174 to -168.74220, saving model to gendance.h5\n",
      "Epoch 3177/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.8247 - val_loss: -170.7082\n",
      "\n",
      "Epoch 03177: loss improved from -168.74220 to -168.82470, saving model to gendance.h5\n",
      "Epoch 3178/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -168.4095 - val_loss: -170.3490\n",
      "\n",
      "Epoch 03178: loss did not improve from -168.82470\n",
      "Epoch 3179/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.6857 - val_loss: -170.9440\n",
      "\n",
      "Epoch 03179: loss did not improve from -168.82470\n",
      "Epoch 3180/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.5413 - val_loss: -170.4151\n",
      "\n",
      "Epoch 03180: loss did not improve from -168.82470\n",
      "Epoch 3181/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.5433 - val_loss: -170.6138\n",
      "\n",
      "Epoch 03181: loss did not improve from -168.82470\n",
      "Epoch 3182/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.4303 - val_loss: -170.5099\n",
      "\n",
      "Epoch 03182: loss did not improve from -168.82470\n",
      "Epoch 3183/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.7970 - val_loss: -170.5809\n",
      "\n",
      "Epoch 03183: loss did not improve from -168.82470\n",
      "Epoch 3184/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.4830 - val_loss: -170.4836\n",
      "\n",
      "Epoch 03184: loss did not improve from -168.82470\n",
      "Epoch 3185/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.6190 - val_loss: -170.7402\n",
      "\n",
      "Epoch 03185: loss did not improve from -168.82470\n",
      "Epoch 3186/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.5808 - val_loss: -170.6893\n",
      "\n",
      "Epoch 03186: loss did not improve from -168.82470\n",
      "Epoch 3187/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.4198 - val_loss: -170.5040\n",
      "\n",
      "Epoch 03187: loss did not improve from -168.82470\n",
      "Epoch 3188/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.5982 - val_loss: -170.7486\n",
      "\n",
      "Epoch 03188: loss did not improve from -168.82470\n",
      "Epoch 3189/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.5142 - val_loss: -170.4336\n",
      "\n",
      "Epoch 03189: loss did not improve from -168.82470\n",
      "Epoch 3190/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.6464 - val_loss: -170.7264\n",
      "\n",
      "Epoch 03190: loss did not improve from -168.82470\n",
      "Epoch 3191/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.7478 - val_loss: -170.6306\n",
      "\n",
      "Epoch 03191: loss did not improve from -168.82470\n",
      "Epoch 3192/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.4805 - val_loss: -170.6853\n",
      "\n",
      "Epoch 03192: loss did not improve from -168.82470\n",
      "Epoch 3193/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.5834 - val_loss: -170.5248\n",
      "\n",
      "Epoch 03193: loss did not improve from -168.82470\n",
      "Epoch 3194/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.3982 - val_loss: -170.8477\n",
      "\n",
      "Epoch 03194: loss did not improve from -168.82470\n",
      "Epoch 3195/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.5491 - val_loss: -170.5592\n",
      "\n",
      "Epoch 03195: loss did not improve from -168.82470\n",
      "Epoch 3196/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.7213 - val_loss: -170.6119\n",
      "\n",
      "Epoch 03196: loss did not improve from -168.82470\n",
      "Epoch 3197/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.7887 - val_loss: -170.3879\n",
      "\n",
      "Epoch 03197: loss did not improve from -168.82470\n",
      "Epoch 3198/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.4637 - val_loss: -170.7435\n",
      "\n",
      "Epoch 03198: loss did not improve from -168.82470\n",
      "Epoch 3199/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.4926 - val_loss: -170.1630\n",
      "\n",
      "Epoch 03199: loss did not improve from -168.82470\n",
      "Epoch 3200/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.4541 - val_loss: -170.7342\n",
      "\n",
      "Epoch 03200: loss did not improve from -168.82470\n",
      "Epoch 3201/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.5036 - val_loss: -170.0177\n",
      "\n",
      "Epoch 03201: loss did not improve from -168.82470\n",
      "Epoch 3202/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.3134 - val_loss: -170.4790\n",
      "\n",
      "Epoch 03202: loss did not improve from -168.82470\n",
      "Epoch 3203/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.5567 - val_loss: -170.6110\n",
      "\n",
      "Epoch 03203: loss did not improve from -168.82470\n",
      "Epoch 3204/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.4553 - val_loss: -170.4037\n",
      "\n",
      "Epoch 03204: loss did not improve from -168.82470\n",
      "Epoch 3205/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.4881 - val_loss: -170.5322\n",
      "\n",
      "Epoch 03205: loss did not improve from -168.82470\n",
      "Epoch 3206/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.4647 - val_loss: -170.5642\n",
      "\n",
      "Epoch 03206: loss did not improve from -168.82470\n",
      "Epoch 3207/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.5696 - val_loss: -170.4359\n",
      "\n",
      "Epoch 03207: loss did not improve from -168.82470\n",
      "Epoch 3208/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.2805 - val_loss: -170.1945\n",
      "\n",
      "Epoch 03208: loss did not improve from -168.82470\n",
      "Epoch 3209/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.3639 - val_loss: -170.6148\n",
      "\n",
      "Epoch 03209: loss did not improve from -168.82470\n",
      "Epoch 3210/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.2419 - val_loss: -169.7499\n",
      "\n",
      "Epoch 03210: loss did not improve from -168.82470\n",
      "Epoch 3211/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.2160 - val_loss: -170.6555\n",
      "\n",
      "Epoch 03211: loss did not improve from -168.82470\n",
      "Epoch 3212/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.2050 - val_loss: -169.8450\n",
      "\n",
      "Epoch 03212: loss did not improve from -168.82470\n",
      "Epoch 3213/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.5332 - val_loss: -170.7787\n",
      "\n",
      "Epoch 03213: loss did not improve from -168.82470\n",
      "Epoch 3214/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.6781 - val_loss: -170.3940\n",
      "\n",
      "Epoch 03214: loss did not improve from -168.82470\n",
      "Epoch 3215/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.5289 - val_loss: -170.6196\n",
      "\n",
      "Epoch 03215: loss did not improve from -168.82470\n",
      "Epoch 3216/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -168.7646 - val_loss: -170.7223\n",
      "\n",
      "Epoch 03216: loss did not improve from -168.82470\n",
      "Epoch 3217/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.5477 - val_loss: -170.3469\n",
      "\n",
      "Epoch 03217: loss did not improve from -168.82470\n",
      "Epoch 3218/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.5232 - val_loss: -170.6522\n",
      "\n",
      "Epoch 03218: loss did not improve from -168.82470\n",
      "Epoch 3219/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.3652 - val_loss: -170.2686\n",
      "\n",
      "Epoch 03219: loss did not improve from -168.82470\n",
      "Epoch 3220/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.6921 - val_loss: -170.9131\n",
      "\n",
      "Epoch 03220: loss did not improve from -168.82470\n",
      "Epoch 3221/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.5257 - val_loss: -170.2864\n",
      "\n",
      "Epoch 03221: loss did not improve from -168.82470\n",
      "Epoch 3222/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.5018 - val_loss: -170.8499\n",
      "\n",
      "Epoch 03222: loss did not improve from -168.82470\n",
      "Epoch 3223/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.7549 - val_loss: -170.5919\n",
      "\n",
      "Epoch 03223: loss did not improve from -168.82470\n",
      "Epoch 3224/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.5327 - val_loss: -170.6450\n",
      "\n",
      "Epoch 03224: loss did not improve from -168.82470\n",
      "Epoch 3225/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.7269 - val_loss: -170.6782\n",
      "\n",
      "Epoch 03225: loss did not improve from -168.82470\n",
      "Epoch 3226/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.5981 - val_loss: -170.6630\n",
      "\n",
      "Epoch 03226: loss did not improve from -168.82470\n",
      "Epoch 3227/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.6969 - val_loss: -170.7131\n",
      "\n",
      "Epoch 03227: loss did not improve from -168.82470\n",
      "Epoch 3228/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.8243 - val_loss: -170.5931\n",
      "\n",
      "Epoch 03228: loss did not improve from -168.82470\n",
      "Epoch 3229/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.7638 - val_loss: -170.7967\n",
      "\n",
      "Epoch 03229: loss did not improve from -168.82470\n",
      "Epoch 3230/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.8138 - val_loss: -170.7658\n",
      "\n",
      "Epoch 03230: loss did not improve from -168.82470\n",
      "Epoch 3231/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.7988 - val_loss: -170.5501\n",
      "\n",
      "Epoch 03231: loss did not improve from -168.82470\n",
      "Epoch 3232/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.6247 - val_loss: -170.6155\n",
      "\n",
      "Epoch 03232: loss did not improve from -168.82470\n",
      "Epoch 3233/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.8301 - val_loss: -170.7185\n",
      "\n",
      "Epoch 03233: loss improved from -168.82470 to -168.83008, saving model to gendance.h5\n",
      "Epoch 3234/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.7978 - val_loss: -170.4797\n",
      "\n",
      "Epoch 03234: loss did not improve from -168.83008\n",
      "Epoch 3235/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.5265 - val_loss: -170.7303\n",
      "\n",
      "Epoch 03235: loss did not improve from -168.83008\n",
      "Epoch 3236/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.6018 - val_loss: -170.2689\n",
      "\n",
      "Epoch 03236: loss did not improve from -168.83008\n",
      "Epoch 3237/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.6770 - val_loss: -170.7840\n",
      "\n",
      "Epoch 03237: loss did not improve from -168.83008\n",
      "Epoch 3238/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.6862 - val_loss: -170.3717\n",
      "\n",
      "Epoch 03238: loss did not improve from -168.83008\n",
      "Epoch 3239/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.6517 - val_loss: -170.8597\n",
      "\n",
      "Epoch 03239: loss did not improve from -168.83008\n",
      "Epoch 3240/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.7467 - val_loss: -170.4753\n",
      "\n",
      "Epoch 03240: loss did not improve from -168.83008\n",
      "Epoch 3241/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.6427 - val_loss: -170.6569\n",
      "\n",
      "Epoch 03241: loss did not improve from -168.83008\n",
      "Epoch 3242/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.6295 - val_loss: -170.4821\n",
      "\n",
      "Epoch 03242: loss did not improve from -168.83008\n",
      "Epoch 3243/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.5003 - val_loss: -170.4606\n",
      "\n",
      "Epoch 03243: loss did not improve from -168.83008\n",
      "Epoch 3244/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.5508 - val_loss: -170.6919\n",
      "\n",
      "Epoch 03244: loss did not improve from -168.83008\n",
      "Epoch 3245/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.4711 - val_loss: -170.1855\n",
      "\n",
      "Epoch 03245: loss did not improve from -168.83008\n",
      "Epoch 3246/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.3293 - val_loss: -170.6171\n",
      "\n",
      "Epoch 03246: loss did not improve from -168.83008\n",
      "Epoch 3247/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.3785 - val_loss: -169.7375\n",
      "\n",
      "Epoch 03247: loss did not improve from -168.83008\n",
      "Epoch 3248/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.3857 - val_loss: -170.8240\n",
      "\n",
      "Epoch 03248: loss did not improve from -168.83008\n",
      "Epoch 3249/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.4353 - val_loss: -170.4885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 03249: loss did not improve from -168.83008\n",
      "Epoch 3250/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.4914 - val_loss: -170.5823\n",
      "\n",
      "Epoch 03250: loss did not improve from -168.83008\n",
      "Epoch 3251/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.5848 - val_loss: -170.9066\n",
      "\n",
      "Epoch 03251: loss did not improve from -168.83008\n",
      "Epoch 3252/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.5972 - val_loss: -170.2867\n",
      "\n",
      "Epoch 03252: loss did not improve from -168.83008\n",
      "Epoch 3253/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.4465 - val_loss: -170.6564\n",
      "\n",
      "Epoch 03253: loss did not improve from -168.83008\n",
      "Epoch 3254/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.5174 - val_loss: -170.2889\n",
      "\n",
      "Epoch 03254: loss did not improve from -168.83008\n",
      "Epoch 3255/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.6412 - val_loss: -170.9689\n",
      "\n",
      "Epoch 03255: loss did not improve from -168.83008\n",
      "Epoch 3256/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.5224 - val_loss: -170.2962\n",
      "\n",
      "Epoch 03256: loss did not improve from -168.83008\n",
      "Epoch 3257/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.5636 - val_loss: -170.8065\n",
      "\n",
      "Epoch 03257: loss did not improve from -168.83008\n",
      "Epoch 3258/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.2482 - val_loss: -170.0772\n",
      "\n",
      "Epoch 03258: loss did not improve from -168.83008\n",
      "Epoch 3259/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.8155 - val_loss: -170.8155\n",
      "\n",
      "Epoch 03259: loss did not improve from -168.83008\n",
      "Epoch 3260/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -168.7666 - val_loss: -170.8361\n",
      "\n",
      "Epoch 03260: loss did not improve from -168.83008\n",
      "Epoch 3261/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.9727 - val_loss: -170.9762\n",
      "\n",
      "Epoch 03261: loss improved from -168.83008 to -168.97275, saving model to gendance.h5\n",
      "Epoch 3262/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -168.9299 - val_loss: -170.9956\n",
      "\n",
      "Epoch 03262: loss did not improve from -168.97275\n",
      "Epoch 3263/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.8199 - val_loss: -170.6079\n",
      "\n",
      "Epoch 03263: loss did not improve from -168.97275\n",
      "Epoch 3264/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.6797 - val_loss: -171.0315\n",
      "\n",
      "Epoch 03264: loss did not improve from -168.97275\n",
      "Epoch 3265/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.7020 - val_loss: -170.4166\n",
      "\n",
      "Epoch 03265: loss did not improve from -168.97275\n",
      "Epoch 3266/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.6498 - val_loss: -170.8551\n",
      "\n",
      "Epoch 03266: loss did not improve from -168.97275\n",
      "Epoch 3267/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.6782 - val_loss: -170.5002\n",
      "\n",
      "Epoch 03267: loss did not improve from -168.97275\n",
      "Epoch 3268/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.6071 - val_loss: -170.9607\n",
      "\n",
      "Epoch 03268: loss did not improve from -168.97275\n",
      "Epoch 3269/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.4239 - val_loss: -170.0977\n",
      "\n",
      "Epoch 03269: loss did not improve from -168.97275\n",
      "Epoch 3270/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.5894 - val_loss: -170.7864\n",
      "\n",
      "Epoch 03270: loss did not improve from -168.97275\n",
      "Epoch 3271/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.5144 - val_loss: -170.3421\n",
      "\n",
      "Epoch 03271: loss did not improve from -168.97275\n",
      "Epoch 3272/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.6276 - val_loss: -170.9298\n",
      "\n",
      "Epoch 03272: loss did not improve from -168.97275\n",
      "Epoch 3273/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.8962 - val_loss: -170.7832\n",
      "\n",
      "Epoch 03273: loss did not improve from -168.97275\n",
      "Epoch 3274/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.8154 - val_loss: -170.6057\n",
      "\n",
      "Epoch 03274: loss did not improve from -168.97275\n",
      "Epoch 3275/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.7793 - val_loss: -170.9383\n",
      "\n",
      "Epoch 03275: loss did not improve from -168.97275\n",
      "Epoch 3276/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.7694 - val_loss: -170.5457\n",
      "\n",
      "Epoch 03276: loss did not improve from -168.97275\n",
      "Epoch 3277/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.8059 - val_loss: -171.0429\n",
      "\n",
      "Epoch 03277: loss did not improve from -168.97275\n",
      "Epoch 3278/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.8403 - val_loss: -170.3195\n",
      "\n",
      "Epoch 03278: loss did not improve from -168.97275\n",
      "Epoch 3279/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.9122 - val_loss: -171.0280\n",
      "\n",
      "Epoch 03279: loss did not improve from -168.97275\n",
      "Epoch 3280/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.8318 - val_loss: -170.7435\n",
      "\n",
      "Epoch 03280: loss did not improve from -168.97275\n",
      "Epoch 3281/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.7876 - val_loss: -170.6228\n",
      "\n",
      "Epoch 03281: loss did not improve from -168.97275\n",
      "Epoch 3282/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.8936 - val_loss: -171.0077\n",
      "\n",
      "Epoch 03282: loss did not improve from -168.97275\n",
      "Epoch 3283/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.8566 - val_loss: -170.7238\n",
      "\n",
      "Epoch 03283: loss did not improve from -168.97275\n",
      "Epoch 3284/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.8089 - val_loss: -171.0095\n",
      "\n",
      "Epoch 03284: loss did not improve from -168.97275\n",
      "Epoch 3285/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.9056 - val_loss: -170.8442\n",
      "\n",
      "Epoch 03285: loss did not improve from -168.97275\n",
      "Epoch 3286/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.8512 - val_loss: -170.9907\n",
      "\n",
      "Epoch 03286: loss did not improve from -168.97275\n",
      "Epoch 3287/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -168.8638 - val_loss: -170.8816\n",
      "\n",
      "Epoch 03287: loss did not improve from -168.97275\n",
      "Epoch 3288/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.8920 - val_loss: -170.6863\n",
      "\n",
      "Epoch 03288: loss did not improve from -168.97275\n",
      "Epoch 3289/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.7253 - val_loss: -170.8760\n",
      "\n",
      "Epoch 03289: loss did not improve from -168.97275\n",
      "Epoch 3290/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.6489 - val_loss: -170.4403\n",
      "\n",
      "Epoch 03290: loss did not improve from -168.97275\n",
      "Epoch 3291/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.7278 - val_loss: -171.0643\n",
      "\n",
      "Epoch 03291: loss did not improve from -168.97275\n",
      "Epoch 3292/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.8348 - val_loss: -170.4700\n",
      "\n",
      "Epoch 03292: loss did not improve from -168.97275\n",
      "Epoch 3293/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.7633 - val_loss: -171.0568\n",
      "\n",
      "Epoch 03293: loss did not improve from -168.97275\n",
      "Epoch 3294/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.7550 - val_loss: -170.5826\n",
      "\n",
      "Epoch 03294: loss did not improve from -168.97275\n",
      "Epoch 3295/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.7622 - val_loss: -170.9014\n",
      "\n",
      "Epoch 03295: loss did not improve from -168.97275\n",
      "Epoch 3296/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.8860 - val_loss: -170.8241\n",
      "\n",
      "Epoch 03296: loss did not improve from -168.97275\n",
      "Epoch 3297/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.9078 - val_loss: -170.6394\n",
      "\n",
      "Epoch 03297: loss did not improve from -168.97275\n",
      "Epoch 3298/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.7200 - val_loss: -171.0378\n",
      "\n",
      "Epoch 03298: loss did not improve from -168.97275\n",
      "Epoch 3299/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.6499 - val_loss: -169.9968\n",
      "\n",
      "Epoch 03299: loss did not improve from -168.97275\n",
      "Epoch 3300/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.5744 - val_loss: -170.8578\n",
      "\n",
      "Epoch 03300: loss did not improve from -168.97275\n",
      "Epoch 3301/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.3884 - val_loss: -170.3640\n",
      "\n",
      "Epoch 03301: loss did not improve from -168.97275\n",
      "Epoch 3302/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.6158 - val_loss: -170.7530\n",
      "\n",
      "Epoch 03302: loss did not improve from -168.97275\n",
      "Epoch 3303/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.8176 - val_loss: -170.8157\n",
      "\n",
      "Epoch 03303: loss did not improve from -168.97275\n",
      "Epoch 3304/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.7581 - val_loss: -170.7682\n",
      "\n",
      "Epoch 03304: loss did not improve from -168.97275\n",
      "Epoch 3305/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.7300 - val_loss: -171.0121\n",
      "\n",
      "Epoch 03305: loss did not improve from -168.97275\n",
      "Epoch 3306/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.8122 - val_loss: -170.5297\n",
      "\n",
      "Epoch 03306: loss did not improve from -168.97275\n",
      "Epoch 3307/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.5525 - val_loss: -170.7115\n",
      "\n",
      "Epoch 03307: loss did not improve from -168.97275\n",
      "Epoch 3308/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.6154 - val_loss: -170.5072\n",
      "\n",
      "Epoch 03308: loss did not improve from -168.97275\n",
      "Epoch 3309/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.8511 - val_loss: -170.8419\n",
      "\n",
      "Epoch 03309: loss did not improve from -168.97275\n",
      "Epoch 3310/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.7849 - val_loss: -170.5943\n",
      "\n",
      "Epoch 03310: loss did not improve from -168.97275\n",
      "Epoch 3311/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.8686 - val_loss: -171.1544\n",
      "\n",
      "Epoch 03311: loss did not improve from -168.97275\n",
      "Epoch 3312/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.7484 - val_loss: -170.7256\n",
      "\n",
      "Epoch 03312: loss did not improve from -168.97275\n",
      "Epoch 3313/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.9913 - val_loss: -170.9840\n",
      "\n",
      "Epoch 03313: loss improved from -168.97275 to -168.99128, saving model to gendance.h5\n",
      "Epoch 3314/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.9228 - val_loss: -170.7972\n",
      "\n",
      "Epoch 03314: loss did not improve from -168.99128\n",
      "Epoch 3315/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.9316 - val_loss: -170.9779\n",
      "\n",
      "Epoch 03315: loss did not improve from -168.99128\n",
      "Epoch 3316/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.8467 - val_loss: -170.9264\n",
      "\n",
      "Epoch 03316: loss did not improve from -168.99128\n",
      "Epoch 3317/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.9289 - val_loss: -170.7605\n",
      "\n",
      "Epoch 03317: loss did not improve from -168.99128\n",
      "Epoch 3318/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.6997 - val_loss: -171.1513\n",
      "\n",
      "Epoch 03318: loss did not improve from -168.99128\n",
      "Epoch 3319/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.5677 - val_loss: -170.2555\n",
      "\n",
      "Epoch 03319: loss did not improve from -168.99128\n",
      "Epoch 3320/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.5448 - val_loss: -170.8238\n",
      "\n",
      "Epoch 03320: loss did not improve from -168.99128\n",
      "Epoch 3321/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.2583 - val_loss: -169.9274\n",
      "\n",
      "Epoch 03321: loss did not improve from -168.99128\n",
      "Epoch 3322/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.8959 - val_loss: -170.9145\n",
      "\n",
      "Epoch 03322: loss did not improve from -168.99128\n",
      "Epoch 3323/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.8068 - val_loss: -170.6574\n",
      "\n",
      "Epoch 03323: loss did not improve from -168.99128\n",
      "Epoch 3324/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -168.7653 - val_loss: -171.0434\n",
      "\n",
      "Epoch 03324: loss did not improve from -168.99128\n",
      "Epoch 3325/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.7733 - val_loss: -170.8327\n",
      "\n",
      "Epoch 03325: loss did not improve from -168.99128\n",
      "Epoch 3326/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.5635 - val_loss: -170.5364\n",
      "\n",
      "Epoch 03326: loss did not improve from -168.99128\n",
      "Epoch 3327/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.2963 - val_loss: -171.1270\n",
      "\n",
      "Epoch 03327: loss did not improve from -168.99128\n",
      "Epoch 3328/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.6074 - val_loss: -169.8458\n",
      "\n",
      "Epoch 03328: loss did not improve from -168.99128\n",
      "Epoch 3329/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.6035 - val_loss: -171.1554\n",
      "\n",
      "Epoch 03329: loss did not improve from -168.99128\n",
      "Epoch 3330/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.6004 - val_loss: -170.6725\n",
      "\n",
      "Epoch 03330: loss did not improve from -168.99128\n",
      "Epoch 3331/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.9086 - val_loss: -171.1329\n",
      "\n",
      "Epoch 03331: loss did not improve from -168.99128\n",
      "Epoch 3332/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.9651 - val_loss: -170.7467\n",
      "\n",
      "Epoch 03332: loss did not improve from -168.99128\n",
      "Epoch 3333/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.8986 - val_loss: -171.1207\n",
      "\n",
      "Epoch 03333: loss did not improve from -168.99128\n",
      "Epoch 3334/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.9469 - val_loss: -171.0118\n",
      "\n",
      "Epoch 03334: loss did not improve from -168.99128\n",
      "Epoch 3335/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.2473 - val_loss: -171.1291\n",
      "\n",
      "Epoch 03335: loss improved from -168.99128 to -169.24730, saving model to gendance.h5\n",
      "Epoch 3336/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.1599 - val_loss: -171.2484\n",
      "\n",
      "Epoch 03336: loss did not improve from -169.24730\n",
      "Epoch 3337/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.9150 - val_loss: -170.9353\n",
      "\n",
      "Epoch 03337: loss did not improve from -169.24730\n",
      "Epoch 3338/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.0455 - val_loss: -171.1708\n",
      "\n",
      "Epoch 03338: loss did not improve from -169.24730\n",
      "Epoch 3339/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.9675 - val_loss: -171.1329\n",
      "\n",
      "Epoch 03339: loss did not improve from -169.24730\n",
      "Epoch 3340/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.0966 - val_loss: -170.9715\n",
      "\n",
      "Epoch 03340: loss did not improve from -169.24730\n",
      "Epoch 3341/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.0182 - val_loss: -171.1948\n",
      "\n",
      "Epoch 03341: loss did not improve from -169.24730\n",
      "Epoch 3342/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.0037 - val_loss: -170.9118\n",
      "\n",
      "Epoch 03342: loss did not improve from -169.24730\n",
      "Epoch 3343/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.0653 - val_loss: -170.9782\n",
      "\n",
      "Epoch 03343: loss did not improve from -169.24730\n",
      "Epoch 3344/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.9170 - val_loss: -171.1188\n",
      "\n",
      "Epoch 03344: loss did not improve from -169.24730\n",
      "Epoch 3345/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.0508 - val_loss: -170.9252\n",
      "\n",
      "Epoch 03345: loss did not improve from -169.24730\n",
      "Epoch 3346/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.0593 - val_loss: -171.0703\n",
      "\n",
      "Epoch 03346: loss did not improve from -169.24730\n",
      "Epoch 3347/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.9362 - val_loss: -170.7191\n",
      "\n",
      "Epoch 03347: loss did not improve from -169.24730\n",
      "Epoch 3348/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.0209 - val_loss: -171.0731\n",
      "\n",
      "Epoch 03348: loss did not improve from -169.24730\n",
      "Epoch 3349/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.0878 - val_loss: -171.0476\n",
      "\n",
      "Epoch 03349: loss did not improve from -169.24730\n",
      "Epoch 3350/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.8578 - val_loss: -171.0793\n",
      "\n",
      "Epoch 03350: loss did not improve from -169.24730\n",
      "Epoch 3351/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.8529 - val_loss: -170.9090\n",
      "\n",
      "Epoch 03351: loss did not improve from -169.24730\n",
      "Epoch 3352/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.7960 - val_loss: -170.9485\n",
      "\n",
      "Epoch 03352: loss did not improve from -169.24730\n",
      "Epoch 3353/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.9725 - val_loss: -170.9356\n",
      "\n",
      "Epoch 03353: loss did not improve from -169.24730\n",
      "Epoch 3354/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.8941 - val_loss: -170.6091\n",
      "\n",
      "Epoch 03354: loss did not improve from -169.24730\n",
      "Epoch 3355/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.0482 - val_loss: -171.2106\n",
      "\n",
      "Epoch 03355: loss did not improve from -169.24730\n",
      "Epoch 3356/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.0133 - val_loss: -170.7539\n",
      "\n",
      "Epoch 03356: loss did not improve from -169.24730\n",
      "Epoch 3357/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.1244 - val_loss: -170.8662\n",
      "\n",
      "Epoch 03357: loss did not improve from -169.24730\n",
      "Epoch 3358/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.0228 - val_loss: -170.9726\n",
      "\n",
      "Epoch 03358: loss did not improve from -169.24730\n",
      "Epoch 3359/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.7806 - val_loss: -170.7153\n",
      "\n",
      "Epoch 03359: loss did not improve from -169.24730\n",
      "Epoch 3360/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.7143 - val_loss: -171.0301\n",
      "\n",
      "Epoch 03360: loss did not improve from -169.24730\n",
      "Epoch 3361/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.7957 - val_loss: -170.4334\n",
      "\n",
      "Epoch 03361: loss did not improve from -169.24730\n",
      "Epoch 3362/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.6891 - val_loss: -171.0966\n",
      "\n",
      "Epoch 03362: loss did not improve from -169.24730\n",
      "Epoch 3363/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.7702 - val_loss: -170.5613\n",
      "\n",
      "Epoch 03363: loss did not improve from -169.24730\n",
      "Epoch 3364/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.9194 - val_loss: -171.1380\n",
      "\n",
      "Epoch 03364: loss did not improve from -169.24730\n",
      "Epoch 3365/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.0290 - val_loss: -170.4789\n",
      "\n",
      "Epoch 03365: loss did not improve from -169.24730\n",
      "Epoch 3366/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.1586 - val_loss: -171.2845\n",
      "\n",
      "Epoch 03366: loss did not improve from -169.24730\n",
      "Epoch 3367/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.0429 - val_loss: -170.7470\n",
      "\n",
      "Epoch 03367: loss did not improve from -169.24730\n",
      "Epoch 3368/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.0178 - val_loss: -170.9293\n",
      "\n",
      "Epoch 03368: loss did not improve from -169.24730\n",
      "Epoch 3369/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.9492 - val_loss: -170.9522\n",
      "\n",
      "Epoch 03369: loss did not improve from -169.24730\n",
      "Epoch 3370/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.7014 - val_loss: -170.9924\n",
      "\n",
      "Epoch 03370: loss did not improve from -169.24730\n",
      "Epoch 3371/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.8190 - val_loss: -171.0324\n",
      "\n",
      "Epoch 03371: loss did not improve from -169.24730\n",
      "Epoch 3372/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.8330 - val_loss: -170.6320\n",
      "\n",
      "Epoch 03372: loss did not improve from -169.24730\n",
      "Epoch 3373/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.7701 - val_loss: -170.9224\n",
      "\n",
      "Epoch 03373: loss did not improve from -169.24730\n",
      "Epoch 3374/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.5862 - val_loss: -170.5251\n",
      "\n",
      "Epoch 03374: loss did not improve from -169.24730\n",
      "Epoch 3375/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.0299 - val_loss: -171.1662\n",
      "\n",
      "Epoch 03375: loss did not improve from -169.24730\n",
      "Epoch 3376/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.0076 - val_loss: -170.6642\n",
      "\n",
      "Epoch 03376: loss did not improve from -169.24730\n",
      "Epoch 3377/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.0841 - val_loss: -171.1095\n",
      "\n",
      "Epoch 03377: loss did not improve from -169.24730\n",
      "Epoch 3378/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.9841 - val_loss: -171.1895\n",
      "\n",
      "Epoch 03378: loss did not improve from -169.24730\n",
      "Epoch 3379/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.2545 - val_loss: -170.8856\n",
      "\n",
      "Epoch 03379: loss improved from -169.24730 to -169.25450, saving model to gendance.h5\n",
      "Epoch 3380/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.9788 - val_loss: -171.1856\n",
      "\n",
      "Epoch 03380: loss did not improve from -169.25450\n",
      "Epoch 3381/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.0655 - val_loss: -170.7324\n",
      "\n",
      "Epoch 03381: loss did not improve from -169.25450\n",
      "Epoch 3382/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.0264 - val_loss: -170.9774\n",
      "\n",
      "Epoch 03382: loss did not improve from -169.25450\n",
      "Epoch 3383/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.9291 - val_loss: -171.0159\n",
      "\n",
      "Epoch 03383: loss did not improve from -169.25450\n",
      "Epoch 3384/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.9516 - val_loss: -170.8893\n",
      "\n",
      "Epoch 03384: loss did not improve from -169.25450\n",
      "Epoch 3385/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.1881 - val_loss: -171.1205\n",
      "\n",
      "Epoch 03385: loss did not improve from -169.25450\n",
      "Epoch 3386/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.0171 - val_loss: -171.0171\n",
      "\n",
      "Epoch 03386: loss did not improve from -169.25450\n",
      "Epoch 3387/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.9067 - val_loss: -170.9398\n",
      "\n",
      "Epoch 03387: loss did not improve from -169.25450\n",
      "Epoch 3388/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.1185 - val_loss: -170.9384\n",
      "\n",
      "Epoch 03388: loss did not improve from -169.25450\n",
      "Epoch 3389/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.0580 - val_loss: -171.2110\n",
      "\n",
      "Epoch 03389: loss did not improve from -169.25450\n",
      "Epoch 3390/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.1085 - val_loss: -170.9457\n",
      "\n",
      "Epoch 03390: loss did not improve from -169.25450\n",
      "Epoch 3391/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.0680 - val_loss: -171.2488\n",
      "\n",
      "Epoch 03391: loss did not improve from -169.25450\n",
      "Epoch 3392/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.0662 - val_loss: -171.2128\n",
      "\n",
      "Epoch 03392: loss did not improve from -169.25450\n",
      "Epoch 3393/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.3282 - val_loss: -171.2476\n",
      "\n",
      "Epoch 03393: loss improved from -169.25450 to -169.32816, saving model to gendance.h5\n",
      "Epoch 3394/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.0300 - val_loss: -171.1610\n",
      "\n",
      "Epoch 03394: loss did not improve from -169.32816\n",
      "Epoch 3395/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.9864 - val_loss: -171.0211\n",
      "\n",
      "Epoch 03395: loss did not improve from -169.32816\n",
      "Epoch 3396/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.0294 - val_loss: -171.0461\n",
      "\n",
      "Epoch 03396: loss did not improve from -169.32816\n",
      "Epoch 3397/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.9623 - val_loss: -171.1081\n",
      "\n",
      "Epoch 03397: loss did not improve from -169.32816\n",
      "Epoch 3398/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.0387 - val_loss: -171.0566\n",
      "\n",
      "Epoch 03398: loss did not improve from -169.32816\n",
      "Epoch 3399/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.9150 - val_loss: -170.9867\n",
      "\n",
      "Epoch 03399: loss did not improve from -169.32816\n",
      "Epoch 3400/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.0994 - val_loss: -170.7353\n",
      "\n",
      "Epoch 03400: loss did not improve from -169.32816\n",
      "Epoch 3401/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.9729 - val_loss: -171.0269\n",
      "\n",
      "Epoch 03401: loss did not improve from -169.32816\n",
      "Epoch 3402/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.0281 - val_loss: -170.7506\n",
      "\n",
      "Epoch 03402: loss did not improve from -169.32816\n",
      "Epoch 3403/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -168.9922 - val_loss: -170.9699\n",
      "\n",
      "Epoch 03403: loss did not improve from -169.32816\n",
      "Epoch 3404/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.0508 - val_loss: -171.0773\n",
      "\n",
      "Epoch 03404: loss did not improve from -169.32816\n",
      "Epoch 3405/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.9832 - val_loss: -171.0501\n",
      "\n",
      "Epoch 03405: loss did not improve from -169.32816\n",
      "Epoch 3406/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -168.9372 - val_loss: -170.6486\n",
      "\n",
      "Epoch 03406: loss did not improve from -169.32816\n",
      "Epoch 3407/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.0295 - val_loss: -171.1723\n",
      "\n",
      "Epoch 03407: loss did not improve from -169.32816\n",
      "Epoch 3408/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.9779 - val_loss: -170.9654\n",
      "\n",
      "Epoch 03408: loss did not improve from -169.32816\n",
      "Epoch 3409/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -169.2291 - val_loss: -171.1074\n",
      "\n",
      "Epoch 03409: loss did not improve from -169.32816\n",
      "Epoch 3410/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.1416 - val_loss: -171.0204\n",
      "\n",
      "Epoch 03410: loss did not improve from -169.32816\n",
      "Epoch 3411/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.0453 - val_loss: -171.2152\n",
      "\n",
      "Epoch 03411: loss did not improve from -169.32816\n",
      "Epoch 3412/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.8027 - val_loss: -170.5413\n",
      "\n",
      "Epoch 03412: loss did not improve from -169.32816\n",
      "Epoch 3413/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.1713 - val_loss: -171.3445\n",
      "\n",
      "Epoch 03413: loss did not improve from -169.32816\n",
      "Epoch 3414/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.1524 - val_loss: -170.7843\n",
      "\n",
      "Epoch 03414: loss did not improve from -169.32816\n",
      "Epoch 3415/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.8759 - val_loss: -170.9789\n",
      "\n",
      "Epoch 03415: loss did not improve from -169.32816\n",
      "Epoch 3416/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.9593 - val_loss: -171.2288\n",
      "\n",
      "Epoch 03416: loss did not improve from -169.32816\n",
      "Epoch 3417/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.0731 - val_loss: -170.8175\n",
      "\n",
      "Epoch 03417: loss did not improve from -169.32816\n",
      "Epoch 3418/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.9266 - val_loss: -171.2944\n",
      "\n",
      "Epoch 03418: loss did not improve from -169.32816\n",
      "Epoch 3419/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.9045 - val_loss: -170.6857\n",
      "\n",
      "Epoch 03419: loss did not improve from -169.32816\n",
      "Epoch 3420/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.8003 - val_loss: -171.2031\n",
      "\n",
      "Epoch 03420: loss did not improve from -169.32816\n",
      "Epoch 3421/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.7749 - val_loss: -170.5272\n",
      "\n",
      "Epoch 03421: loss did not improve from -169.32816\n",
      "Epoch 3422/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.0079 - val_loss: -171.0321\n",
      "\n",
      "Epoch 03422: loss did not improve from -169.32816\n",
      "Epoch 3423/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.0227 - val_loss: -170.8727\n",
      "\n",
      "Epoch 03423: loss did not improve from -169.32816\n",
      "Epoch 3424/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -168.9315 - val_loss: -171.0714\n",
      "\n",
      "Epoch 03424: loss did not improve from -169.32816\n",
      "Epoch 3425/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.0241 - val_loss: -171.0847\n",
      "\n",
      "Epoch 03425: loss did not improve from -169.32816\n",
      "Epoch 3426/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.1881 - val_loss: -171.0901\n",
      "\n",
      "Epoch 03426: loss did not improve from -169.32816\n",
      "Epoch 3427/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.2418 - val_loss: -171.0784\n",
      "\n",
      "Epoch 03427: loss did not improve from -169.32816\n",
      "Epoch 3428/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.9406 - val_loss: -171.0325\n",
      "\n",
      "Epoch 03428: loss did not improve from -169.32816\n",
      "Epoch 3429/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.0205 - val_loss: -171.1572\n",
      "\n",
      "Epoch 03429: loss did not improve from -169.32816\n",
      "Epoch 3430/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.0568 - val_loss: -171.0913\n",
      "\n",
      "Epoch 03430: loss did not improve from -169.32816\n",
      "Epoch 3431/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.3125 - val_loss: -171.1841\n",
      "\n",
      "Epoch 03431: loss did not improve from -169.32816\n",
      "Epoch 3432/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.1797 - val_loss: -170.8789\n",
      "\n",
      "Epoch 03432: loss did not improve from -169.32816\n",
      "Epoch 3433/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.1802 - val_loss: -171.3181\n",
      "\n",
      "Epoch 03433: loss did not improve from -169.32816\n",
      "Epoch 3434/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.0832 - val_loss: -170.8728\n",
      "\n",
      "Epoch 03434: loss did not improve from -169.32816\n",
      "Epoch 3435/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.2766 - val_loss: -171.3776\n",
      "\n",
      "Epoch 03435: loss did not improve from -169.32816\n",
      "Epoch 3436/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.1934 - val_loss: -170.7883\n",
      "\n",
      "Epoch 03436: loss did not improve from -169.32816\n",
      "Epoch 3437/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.1364 - val_loss: -171.0490\n",
      "\n",
      "Epoch 03437: loss did not improve from -169.32816\n",
      "Epoch 3438/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.9070 - val_loss: -170.9030\n",
      "\n",
      "Epoch 03438: loss did not improve from -169.32816\n",
      "Epoch 3439/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.6398 - val_loss: -170.3941\n",
      "\n",
      "Epoch 03439: loss did not improve from -169.32816\n",
      "Epoch 3440/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.8673 - val_loss: -171.2640\n",
      "\n",
      "Epoch 03440: loss did not improve from -169.32816\n",
      "Epoch 3441/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.9002 - val_loss: -170.5158\n",
      "\n",
      "Epoch 03441: loss did not improve from -169.32816\n",
      "Epoch 3442/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.9178 - val_loss: -171.1770\n",
      "\n",
      "Epoch 03442: loss did not improve from -169.32816\n",
      "Epoch 3443/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.8845 - val_loss: -170.5052\n",
      "\n",
      "Epoch 03443: loss did not improve from -169.32816\n",
      "Epoch 3444/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.9275 - val_loss: -171.3323\n",
      "\n",
      "Epoch 03444: loss did not improve from -169.32816\n",
      "Epoch 3445/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.9817 - val_loss: -170.9437\n",
      "\n",
      "Epoch 03445: loss did not improve from -169.32816\n",
      "Epoch 3446/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.2235 - val_loss: -171.4180\n",
      "\n",
      "Epoch 03446: loss did not improve from -169.32816\n",
      "Epoch 3447/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.4465 - val_loss: -171.4968\n",
      "\n",
      "Epoch 03447: loss improved from -169.32816 to -169.44651, saving model to gendance.h5\n",
      "Epoch 3448/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.4423 - val_loss: -171.1423\n",
      "\n",
      "Epoch 03448: loss did not improve from -169.44651\n",
      "Epoch 3449/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.2188 - val_loss: -171.4131\n",
      "\n",
      "Epoch 03449: loss did not improve from -169.44651\n",
      "Epoch 3450/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.3676 - val_loss: -171.2196\n",
      "\n",
      "Epoch 03450: loss did not improve from -169.44651\n",
      "Epoch 3451/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.2544 - val_loss: -171.1802\n",
      "\n",
      "Epoch 03451: loss did not improve from -169.44651\n",
      "Epoch 3452/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.1781 - val_loss: -171.2826\n",
      "\n",
      "Epoch 03452: loss did not improve from -169.44651\n",
      "Epoch 3453/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.4183 - val_loss: -171.2951\n",
      "\n",
      "Epoch 03453: loss did not improve from -169.44651\n",
      "Epoch 3454/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.1426 - val_loss: -171.2846\n",
      "\n",
      "Epoch 03454: loss did not improve from -169.44651\n",
      "Epoch 3455/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.2087 - val_loss: -171.2411\n",
      "\n",
      "Epoch 03455: loss did not improve from -169.44651\n",
      "Epoch 3456/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.3896 - val_loss: -171.1598\n",
      "\n",
      "Epoch 03456: loss did not improve from -169.44651\n",
      "Epoch 3457/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.4331 - val_loss: -171.4118\n",
      "\n",
      "Epoch 03457: loss did not improve from -169.44651\n",
      "Epoch 3458/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.0786 - val_loss: -171.1796\n",
      "\n",
      "Epoch 03458: loss did not improve from -169.44651\n",
      "Epoch 3459/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.1271 - val_loss: -170.9739\n",
      "\n",
      "Epoch 03459: loss did not improve from -169.44651\n",
      "Epoch 3460/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.1944 - val_loss: -171.3580\n",
      "\n",
      "Epoch 03460: loss did not improve from -169.44651\n",
      "Epoch 3461/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.1740 - val_loss: -170.9300\n",
      "\n",
      "Epoch 03461: loss did not improve from -169.44651\n",
      "Epoch 3462/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.1164 - val_loss: -171.2650\n",
      "\n",
      "Epoch 03462: loss did not improve from -169.44651\n",
      "Epoch 3463/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.2659 - val_loss: -170.9078\n",
      "\n",
      "Epoch 03463: loss did not improve from -169.44651\n",
      "Epoch 3464/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -169.1707 - val_loss: -171.1333\n",
      "\n",
      "Epoch 03464: loss did not improve from -169.44651\n",
      "Epoch 3465/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.2091 - val_loss: -170.8784\n",
      "\n",
      "Epoch 03465: loss did not improve from -169.44651\n",
      "Epoch 3466/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.2444 - val_loss: -171.1732\n",
      "\n",
      "Epoch 03466: loss did not improve from -169.44651\n",
      "Epoch 3467/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.1460 - val_loss: -171.1338\n",
      "\n",
      "Epoch 03467: loss did not improve from -169.44651\n",
      "Epoch 3468/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.8930 - val_loss: -170.8026\n",
      "\n",
      "Epoch 03468: loss did not improve from -169.44651\n",
      "Epoch 3469/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.0663 - val_loss: -171.2692\n",
      "\n",
      "Epoch 03469: loss did not improve from -169.44651\n",
      "Epoch 3470/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.0261 - val_loss: -170.7993\n",
      "\n",
      "Epoch 03470: loss did not improve from -169.44651\n",
      "Epoch 3471/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.1293 - val_loss: -171.3036\n",
      "\n",
      "Epoch 03471: loss did not improve from -169.44651\n",
      "Epoch 3472/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.9553 - val_loss: -170.6633\n",
      "\n",
      "Epoch 03472: loss did not improve from -169.44651\n",
      "Epoch 3473/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.9159 - val_loss: -171.2519\n",
      "\n",
      "Epoch 03473: loss did not improve from -169.44651\n",
      "Epoch 3474/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.2460 - val_loss: -170.8687\n",
      "\n",
      "Epoch 03474: loss did not improve from -169.44651\n",
      "Epoch 3475/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.3472 - val_loss: -171.3169\n",
      "\n",
      "Epoch 03475: loss did not improve from -169.44651\n",
      "Epoch 3476/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.1773 - val_loss: -171.4193\n",
      "\n",
      "Epoch 03476: loss did not improve from -169.44651\n",
      "Epoch 3477/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.3299 - val_loss: -171.2429\n",
      "\n",
      "Epoch 03477: loss did not improve from -169.44651\n",
      "Epoch 3478/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.2684 - val_loss: -171.2370\n",
      "\n",
      "Epoch 03478: loss did not improve from -169.44651\n",
      "Epoch 3479/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.2373 - val_loss: -171.3872\n",
      "\n",
      "Epoch 03479: loss did not improve from -169.44651\n",
      "Epoch 3480/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.3250 - val_loss: -171.3106\n",
      "\n",
      "Epoch 03480: loss did not improve from -169.44651\n",
      "Epoch 3481/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.3572 - val_loss: -171.4242\n",
      "\n",
      "Epoch 03481: loss did not improve from -169.44651\n",
      "Epoch 3482/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.2244 - val_loss: -171.0986\n",
      "\n",
      "Epoch 03482: loss did not improve from -169.44651\n",
      "Epoch 3483/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.4239 - val_loss: -171.3147\n",
      "\n",
      "Epoch 03483: loss did not improve from -169.44651\n",
      "Epoch 3484/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.7103 - val_loss: -171.4713\n",
      "\n",
      "Epoch 03484: loss improved from -169.44651 to -169.71031, saving model to gendance.h5\n",
      "Epoch 3485/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.2236 - val_loss: -171.2949\n",
      "\n",
      "Epoch 03485: loss did not improve from -169.71031\n",
      "Epoch 3486/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.1020 - val_loss: -171.4726\n",
      "\n",
      "Epoch 03486: loss did not improve from -169.71031\n",
      "Epoch 3487/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.1528 - val_loss: -171.0423\n",
      "\n",
      "Epoch 03487: loss did not improve from -169.71031\n",
      "Epoch 3488/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.0534 - val_loss: -171.2301\n",
      "\n",
      "Epoch 03488: loss did not improve from -169.71031\n",
      "Epoch 3489/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.1527 - val_loss: -170.7300\n",
      "\n",
      "Epoch 03489: loss did not improve from -169.71031\n",
      "Epoch 3490/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.0328 - val_loss: -171.3539\n",
      "\n",
      "Epoch 03490: loss did not improve from -169.71031\n",
      "Epoch 3491/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.2929 - val_loss: -170.8696\n",
      "\n",
      "Epoch 03491: loss did not improve from -169.71031\n",
      "Epoch 3492/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.3365 - val_loss: -171.1147\n",
      "\n",
      "Epoch 03492: loss did not improve from -169.71031\n",
      "Epoch 3493/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.3947 - val_loss: -171.3819\n",
      "\n",
      "Epoch 03493: loss did not improve from -169.71031\n",
      "Epoch 3494/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.3124 - val_loss: -170.9755\n",
      "\n",
      "Epoch 03494: loss did not improve from -169.71031\n",
      "Epoch 3495/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.4660 - val_loss: -171.4168\n",
      "\n",
      "Epoch 03495: loss did not improve from -169.71031\n",
      "Epoch 3496/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.2765 - val_loss: -171.0854\n",
      "\n",
      "Epoch 03496: loss did not improve from -169.71031\n",
      "Epoch 3497/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.1027 - val_loss: -171.2681\n",
      "\n",
      "Epoch 03497: loss did not improve from -169.71031\n",
      "Epoch 3498/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.4206 - val_loss: -171.3473\n",
      "\n",
      "Epoch 03498: loss did not improve from -169.71031\n",
      "Epoch 3499/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.3925 - val_loss: -171.3784\n",
      "\n",
      "Epoch 03499: loss did not improve from -169.71031\n",
      "Epoch 3500/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.4347 - val_loss: -171.3072\n",
      "\n",
      "Epoch 03500: loss did not improve from -169.71031\n",
      "Epoch 3501/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.3636 - val_loss: -171.4024\n",
      "\n",
      "Epoch 03501: loss did not improve from -169.71031\n",
      "Epoch 3502/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.2584 - val_loss: -170.9438\n",
      "\n",
      "Epoch 03502: loss did not improve from -169.71031\n",
      "Epoch 3503/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.1947 - val_loss: -171.3926\n",
      "\n",
      "Epoch 03503: loss did not improve from -169.71031\n",
      "Epoch 3504/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.3292 - val_loss: -170.8162\n",
      "\n",
      "Epoch 03504: loss did not improve from -169.71031\n",
      "Epoch 3505/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.0064 - val_loss: -171.4260\n",
      "\n",
      "Epoch 03505: loss did not improve from -169.71031\n",
      "Epoch 3506/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.2773 - val_loss: -170.7509\n",
      "\n",
      "Epoch 03506: loss did not improve from -169.71031\n",
      "Epoch 3507/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.3930 - val_loss: -171.4981\n",
      "\n",
      "Epoch 03507: loss did not improve from -169.71031\n",
      "Epoch 3508/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.2212 - val_loss: -170.9450\n",
      "\n",
      "Epoch 03508: loss did not improve from -169.71031\n",
      "Epoch 3509/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.3621 - val_loss: -171.3216\n",
      "\n",
      "Epoch 03509: loss did not improve from -169.71031\n",
      "Epoch 3510/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.1023 - val_loss: -171.3242\n",
      "\n",
      "Epoch 03510: loss did not improve from -169.71031\n",
      "Epoch 3511/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.4278 - val_loss: -171.0299\n",
      "\n",
      "Epoch 03511: loss did not improve from -169.71031\n",
      "Epoch 3512/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.1614 - val_loss: -171.5698\n",
      "\n",
      "Epoch 03512: loss did not improve from -169.71031\n",
      "Epoch 3513/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.1955 - val_loss: -170.9223\n",
      "\n",
      "Epoch 03513: loss did not improve from -169.71031\n",
      "Epoch 3514/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.2879 - val_loss: -171.2736\n",
      "\n",
      "Epoch 03514: loss did not improve from -169.71031\n",
      "Epoch 3515/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.1319 - val_loss: -170.7887\n",
      "\n",
      "Epoch 03515: loss did not improve from -169.71031\n",
      "Epoch 3516/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.5306 - val_loss: -171.3865\n",
      "\n",
      "Epoch 03516: loss did not improve from -169.71031\n",
      "Epoch 3517/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.1784 - val_loss: -171.0338\n",
      "\n",
      "Epoch 03517: loss did not improve from -169.71031\n",
      "Epoch 3518/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.4506 - val_loss: -171.3620\n",
      "\n",
      "Epoch 03518: loss did not improve from -169.71031\n",
      "Epoch 3519/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.5660 - val_loss: -171.4556\n",
      "\n",
      "Epoch 03519: loss did not improve from -169.71031\n",
      "Epoch 3520/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.2636 - val_loss: -171.1552\n",
      "\n",
      "Epoch 03520: loss did not improve from -169.71031\n",
      "Epoch 3521/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.3334 - val_loss: -171.4260\n",
      "\n",
      "Epoch 03521: loss did not improve from -169.71031\n",
      "Epoch 3522/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.5321 - val_loss: -171.1453\n",
      "\n",
      "Epoch 03522: loss did not improve from -169.71031\n",
      "Epoch 3523/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.4559 - val_loss: -171.5394\n",
      "\n",
      "Epoch 03523: loss did not improve from -169.71031\n",
      "Epoch 3524/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.4243 - val_loss: -171.0307\n",
      "\n",
      "Epoch 03524: loss did not improve from -169.71031\n",
      "Epoch 3525/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.2989 - val_loss: -171.4125\n",
      "\n",
      "Epoch 03525: loss did not improve from -169.71031\n",
      "Epoch 3526/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.3863 - val_loss: -171.1681\n",
      "\n",
      "Epoch 03526: loss did not improve from -169.71031\n",
      "Epoch 3527/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.4189 - val_loss: -171.5412\n",
      "\n",
      "Epoch 03527: loss did not improve from -169.71031\n",
      "Epoch 3528/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.3409 - val_loss: -171.3075\n",
      "\n",
      "Epoch 03528: loss did not improve from -169.71031\n",
      "Epoch 3529/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.1230 - val_loss: -171.2005\n",
      "\n",
      "Epoch 03529: loss did not improve from -169.71031\n",
      "Epoch 3530/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.4075 - val_loss: -171.2756\n",
      "\n",
      "Epoch 03530: loss did not improve from -169.71031\n",
      "Epoch 3531/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.6045 - val_loss: -171.3200\n",
      "\n",
      "Epoch 03531: loss did not improve from -169.71031\n",
      "Epoch 3532/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.5051 - val_loss: -171.5045\n",
      "\n",
      "Epoch 03532: loss did not improve from -169.71031\n",
      "Epoch 3533/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.3402 - val_loss: -171.1172\n",
      "\n",
      "Epoch 03533: loss did not improve from -169.71031\n",
      "Epoch 3534/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.3486 - val_loss: -171.6793\n",
      "\n",
      "Epoch 03534: loss did not improve from -169.71031\n",
      "Epoch 3535/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.3442 - val_loss: -171.3980\n",
      "\n",
      "Epoch 03535: loss did not improve from -169.71031\n",
      "Epoch 3536/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.5040 - val_loss: -171.5531\n",
      "\n",
      "Epoch 03536: loss did not improve from -169.71031\n",
      "Epoch 3537/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.6030 - val_loss: -171.1723\n",
      "\n",
      "Epoch 03537: loss did not improve from -169.71031\n",
      "Epoch 3538/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.4105 - val_loss: -171.4217\n",
      "\n",
      "Epoch 03538: loss did not improve from -169.71031\n",
      "Epoch 3539/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.3982 - val_loss: -171.3828\n",
      "\n",
      "Epoch 03539: loss did not improve from -169.71031\n",
      "Epoch 3540/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.3341 - val_loss: -171.0976\n",
      "\n",
      "Epoch 03540: loss did not improve from -169.71031\n",
      "Epoch 3541/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.1699 - val_loss: -171.4259\n",
      "\n",
      "Epoch 03541: loss did not improve from -169.71031\n",
      "Epoch 3542/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.9540 - val_loss: -170.7159\n",
      "\n",
      "Epoch 03542: loss did not improve from -169.71031\n",
      "Epoch 3543/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.2953 - val_loss: -171.4192\n",
      "\n",
      "Epoch 03543: loss did not improve from -169.71031\n",
      "Epoch 3544/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.4200 - val_loss: -170.7494\n",
      "\n",
      "Epoch 03544: loss did not improve from -169.71031\n",
      "Epoch 3545/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.3642 - val_loss: -171.2426\n",
      "\n",
      "Epoch 03545: loss did not improve from -169.71031\n",
      "Epoch 3546/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.3475 - val_loss: -170.7538\n",
      "\n",
      "Epoch 03546: loss did not improve from -169.71031\n",
      "Epoch 3547/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.3636 - val_loss: -171.3974\n",
      "\n",
      "Epoch 03547: loss did not improve from -169.71031\n",
      "Epoch 3548/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.7045 - val_loss: -171.4242\n",
      "\n",
      "Epoch 03548: loss did not improve from -169.71031\n",
      "Epoch 3549/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.6625 - val_loss: -171.2548\n",
      "\n",
      "Epoch 03549: loss did not improve from -169.71031\n",
      "Epoch 3550/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.5912 - val_loss: -171.5655\n",
      "\n",
      "Epoch 03550: loss did not improve from -169.71031\n",
      "Epoch 3551/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.6116 - val_loss: -171.4175\n",
      "\n",
      "Epoch 03551: loss did not improve from -169.71031\n",
      "Epoch 3552/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.5229 - val_loss: -171.2505\n",
      "\n",
      "Epoch 03552: loss did not improve from -169.71031\n",
      "Epoch 3553/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.4194 - val_loss: -171.1664\n",
      "\n",
      "Epoch 03553: loss did not improve from -169.71031\n",
      "Epoch 3554/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.5608 - val_loss: -171.5522\n",
      "\n",
      "Epoch 03554: loss did not improve from -169.71031\n",
      "Epoch 3555/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.5603 - val_loss: -171.2490\n",
      "\n",
      "Epoch 03555: loss did not improve from -169.71031\n",
      "Epoch 3556/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.5691 - val_loss: -171.4856\n",
      "\n",
      "Epoch 03556: loss did not improve from -169.71031\n",
      "Epoch 3557/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.4466 - val_loss: -171.4143\n",
      "\n",
      "Epoch 03557: loss did not improve from -169.71031\n",
      "Epoch 3558/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.3801 - val_loss: -171.4237\n",
      "\n",
      "Epoch 03558: loss did not improve from -169.71031\n",
      "Epoch 3559/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.7760 - val_loss: -171.7150\n",
      "\n",
      "Epoch 03559: loss improved from -169.71031 to -169.77601, saving model to gendance.h5\n",
      "Epoch 3560/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -169.3343 - val_loss: -171.0136\n",
      "\n",
      "Epoch 03560: loss did not improve from -169.77601\n",
      "Epoch 3561/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.4281 - val_loss: -171.4760\n",
      "\n",
      "Epoch 03561: loss did not improve from -169.77601\n",
      "Epoch 3562/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.3547 - val_loss: -171.1824\n",
      "\n",
      "Epoch 03562: loss did not improve from -169.77601\n",
      "Epoch 3563/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.1247 - val_loss: -171.2127\n",
      "\n",
      "Epoch 03563: loss did not improve from -169.77601\n",
      "Epoch 3564/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.1763 - val_loss: -171.3421\n",
      "\n",
      "Epoch 03564: loss did not improve from -169.77601\n",
      "Epoch 3565/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.1181 - val_loss: -170.8905\n",
      "\n",
      "Epoch 03565: loss did not improve from -169.77601\n",
      "Epoch 3566/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.0433 - val_loss: -171.4268\n",
      "\n",
      "Epoch 03566: loss did not improve from -169.77601\n",
      "Epoch 3567/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.9891 - val_loss: -170.4066\n",
      "\n",
      "Epoch 03567: loss did not improve from -169.77601\n",
      "Epoch 3568/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -168.9406 - val_loss: -171.4569\n",
      "\n",
      "Epoch 03568: loss did not improve from -169.77601\n",
      "Epoch 3569/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.1241 - val_loss: -170.9850\n",
      "\n",
      "Epoch 03569: loss did not improve from -169.77601\n",
      "Epoch 3570/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.0400 - val_loss: -171.4059\n",
      "\n",
      "Epoch 03570: loss did not improve from -169.77601\n",
      "Epoch 3571/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.4177 - val_loss: -171.3927\n",
      "\n",
      "Epoch 03571: loss did not improve from -169.77601\n",
      "Epoch 3572/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.3550 - val_loss: -171.5477\n",
      "\n",
      "Epoch 03572: loss did not improve from -169.77601\n",
      "Epoch 3573/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.6795 - val_loss: -171.3507\n",
      "\n",
      "Epoch 03573: loss did not improve from -169.77601\n",
      "Epoch 3574/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.3633 - val_loss: -171.5762\n",
      "\n",
      "Epoch 03574: loss did not improve from -169.77601\n",
      "Epoch 3575/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.5151 - val_loss: -171.3048\n",
      "\n",
      "Epoch 03575: loss did not improve from -169.77601\n",
      "Epoch 3576/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.7012 - val_loss: -171.5517\n",
      "\n",
      "Epoch 03576: loss did not improve from -169.77601\n",
      "Epoch 3577/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.5989 - val_loss: -171.4075\n",
      "\n",
      "Epoch 03577: loss did not improve from -169.77601\n",
      "Epoch 3578/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.6269 - val_loss: -171.3689\n",
      "\n",
      "Epoch 03578: loss did not improve from -169.77601\n",
      "Epoch 3579/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.4491 - val_loss: -171.5833\n",
      "\n",
      "Epoch 03579: loss did not improve from -169.77601\n",
      "Epoch 3580/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.6447 - val_loss: -171.4006\n",
      "\n",
      "Epoch 03580: loss did not improve from -169.77601\n",
      "Epoch 3581/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.5584 - val_loss: -171.5632\n",
      "\n",
      "Epoch 03581: loss did not improve from -169.77601\n",
      "Epoch 3582/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.4355 - val_loss: -171.3951\n",
      "\n",
      "Epoch 03582: loss did not improve from -169.77601\n",
      "Epoch 3583/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.5325 - val_loss: -171.5683\n",
      "\n",
      "Epoch 03583: loss did not improve from -169.77601\n",
      "Epoch 3584/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.6531 - val_loss: -171.4490\n",
      "\n",
      "Epoch 03584: loss did not improve from -169.77601\n",
      "Epoch 3585/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.6434 - val_loss: -171.4196\n",
      "\n",
      "Epoch 03585: loss did not improve from -169.77601\n",
      "Epoch 3586/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.5664 - val_loss: -171.5180\n",
      "\n",
      "Epoch 03586: loss did not improve from -169.77601\n",
      "Epoch 3587/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.5140 - val_loss: -171.4015\n",
      "\n",
      "Epoch 03587: loss did not improve from -169.77601\n",
      "Epoch 3588/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.4764 - val_loss: -171.3572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 03588: loss did not improve from -169.77601\n",
      "Epoch 3589/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.6366 - val_loss: -171.8518\n",
      "\n",
      "Epoch 03589: loss did not improve from -169.77601\n",
      "Epoch 3590/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.2186 - val_loss: -170.6846\n",
      "\n",
      "Epoch 03590: loss did not improve from -169.77601\n",
      "Epoch 3591/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.3855 - val_loss: -171.3751\n",
      "\n",
      "Epoch 03591: loss did not improve from -169.77601\n",
      "Epoch 3592/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.4160 - val_loss: -171.0884\n",
      "\n",
      "Epoch 03592: loss did not improve from -169.77601\n",
      "Epoch 3593/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.5156 - val_loss: -171.5320\n",
      "\n",
      "Epoch 03593: loss did not improve from -169.77601\n",
      "Epoch 3594/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.6682 - val_loss: -171.3639\n",
      "\n",
      "Epoch 03594: loss did not improve from -169.77601\n",
      "Epoch 3595/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -169.4217 - val_loss: -171.3271\n",
      "\n",
      "Epoch 03595: loss did not improve from -169.77601\n",
      "Epoch 3596/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.4565 - val_loss: -171.3929\n",
      "\n",
      "Epoch 03596: loss did not improve from -169.77601\n",
      "Epoch 3597/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.4463 - val_loss: -171.3061\n",
      "\n",
      "Epoch 03597: loss did not improve from -169.77601\n",
      "Epoch 3598/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.5950 - val_loss: -171.6554\n",
      "\n",
      "Epoch 03598: loss did not improve from -169.77601\n",
      "Epoch 3599/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -169.6670 - val_loss: -171.2584\n",
      "\n",
      "Epoch 03599: loss did not improve from -169.77601\n",
      "Epoch 3600/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.3536 - val_loss: -171.5097\n",
      "\n",
      "Epoch 03600: loss did not improve from -169.77601\n",
      "Epoch 3601/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.4755 - val_loss: -170.8691\n",
      "\n",
      "Epoch 03601: loss did not improve from -169.77601\n",
      "Epoch 3602/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.4259 - val_loss: -171.3854\n",
      "\n",
      "Epoch 03602: loss did not improve from -169.77601\n",
      "Epoch 3603/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.3703 - val_loss: -170.9174\n",
      "\n",
      "Epoch 03603: loss did not improve from -169.77601\n",
      "Epoch 3604/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.6269 - val_loss: -171.6938\n",
      "\n",
      "Epoch 03604: loss did not improve from -169.77601\n",
      "Epoch 3605/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.4203 - val_loss: -171.0768\n",
      "\n",
      "Epoch 03605: loss did not improve from -169.77601\n",
      "Epoch 3606/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.6861 - val_loss: -171.7493\n",
      "\n",
      "Epoch 03606: loss did not improve from -169.77601\n",
      "Epoch 3607/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.5803 - val_loss: -171.2643\n",
      "\n",
      "Epoch 03607: loss did not improve from -169.77601\n",
      "Epoch 3608/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.5759 - val_loss: -171.4711\n",
      "\n",
      "Epoch 03608: loss did not improve from -169.77601\n",
      "Epoch 3609/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.6518 - val_loss: -171.8219\n",
      "\n",
      "Epoch 03609: loss did not improve from -169.77601\n",
      "Epoch 3610/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.6071 - val_loss: -171.3234\n",
      "\n",
      "Epoch 03610: loss did not improve from -169.77601\n",
      "Epoch 3611/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.2937 - val_loss: -171.6562\n",
      "\n",
      "Epoch 03611: loss did not improve from -169.77601\n",
      "Epoch 3612/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.6137 - val_loss: -171.3746\n",
      "\n",
      "Epoch 03612: loss did not improve from -169.77601\n",
      "Epoch 3613/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.6202 - val_loss: -171.6397\n",
      "\n",
      "Epoch 03613: loss did not improve from -169.77601\n",
      "Epoch 3614/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.6129 - val_loss: -171.3128\n",
      "\n",
      "Epoch 03614: loss did not improve from -169.77601\n",
      "Epoch 3615/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.4795 - val_loss: -171.3981\n",
      "\n",
      "Epoch 03615: loss did not improve from -169.77601\n",
      "Epoch 3616/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.6589 - val_loss: -170.9412\n",
      "\n",
      "Epoch 03616: loss did not improve from -169.77601\n",
      "Epoch 3617/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.5386 - val_loss: -171.4923\n",
      "\n",
      "Epoch 03617: loss did not improve from -169.77601\n",
      "Epoch 3618/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.5981 - val_loss: -171.3737\n",
      "\n",
      "Epoch 03618: loss did not improve from -169.77601\n",
      "Epoch 3619/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.4859 - val_loss: -171.3544\n",
      "\n",
      "Epoch 03619: loss did not improve from -169.77601\n",
      "Epoch 3620/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.3741 - val_loss: -171.4424\n",
      "\n",
      "Epoch 03620: loss did not improve from -169.77601\n",
      "Epoch 3621/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.5714 - val_loss: -171.4957\n",
      "\n",
      "Epoch 03621: loss did not improve from -169.77601\n",
      "Epoch 3622/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.7436 - val_loss: -171.7925\n",
      "\n",
      "Epoch 03622: loss did not improve from -169.77601\n",
      "Epoch 3623/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.5054 - val_loss: -171.3624\n",
      "\n",
      "Epoch 03623: loss did not improve from -169.77601\n",
      "Epoch 3624/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.8428 - val_loss: -171.8888\n",
      "\n",
      "Epoch 03624: loss improved from -169.77601 to -169.84282, saving model to gendance.h5\n",
      "Epoch 3625/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.5046 - val_loss: -171.4730\n",
      "\n",
      "Epoch 03625: loss did not improve from -169.84282\n",
      "Epoch 3626/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.8547 - val_loss: -171.7939\n",
      "\n",
      "Epoch 03626: loss improved from -169.84282 to -169.85469, saving model to gendance.h5\n",
      "Epoch 3627/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.7221 - val_loss: -171.2231\n",
      "\n",
      "Epoch 03627: loss did not improve from -169.85469\n",
      "Epoch 3628/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.2958 - val_loss: -171.5120\n",
      "\n",
      "Epoch 03628: loss did not improve from -169.85469\n",
      "Epoch 3629/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.5812 - val_loss: -171.3924\n",
      "\n",
      "Epoch 03629: loss did not improve from -169.85469\n",
      "Epoch 3630/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.4351 - val_loss: -171.3801\n",
      "\n",
      "Epoch 03630: loss did not improve from -169.85469\n",
      "Epoch 3631/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.4863 - val_loss: -171.7953\n",
      "\n",
      "Epoch 03631: loss did not improve from -169.85469\n",
      "Epoch 3632/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.4903 - val_loss: -171.1541\n",
      "\n",
      "Epoch 03632: loss did not improve from -169.85469\n",
      "Epoch 3633/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.4224 - val_loss: -171.6126\n",
      "\n",
      "Epoch 03633: loss did not improve from -169.85469\n",
      "Epoch 3634/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.4948 - val_loss: -171.2845\n",
      "\n",
      "Epoch 03634: loss did not improve from -169.85469\n",
      "Epoch 3635/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.7646 - val_loss: -171.6715\n",
      "\n",
      "Epoch 03635: loss did not improve from -169.85469\n",
      "Epoch 3636/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.7996 - val_loss: -171.6443\n",
      "\n",
      "Epoch 03636: loss did not improve from -169.85469\n",
      "Epoch 3637/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.6736 - val_loss: -171.4842\n",
      "\n",
      "Epoch 03637: loss did not improve from -169.85469\n",
      "Epoch 3638/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.5648 - val_loss: -171.3674\n",
      "\n",
      "Epoch 03638: loss did not improve from -169.85469\n",
      "Epoch 3639/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.7536 - val_loss: -171.7433\n",
      "\n",
      "Epoch 03639: loss did not improve from -169.85469\n",
      "Epoch 3640/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.4539 - val_loss: -171.3578\n",
      "\n",
      "Epoch 03640: loss did not improve from -169.85469\n",
      "Epoch 3641/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.4329 - val_loss: -171.7475\n",
      "\n",
      "Epoch 03641: loss did not improve from -169.85469\n",
      "Epoch 3642/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.4742 - val_loss: -170.9945\n",
      "\n",
      "Epoch 03642: loss did not improve from -169.85469\n",
      "Epoch 3643/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.3365 - val_loss: -171.5875\n",
      "\n",
      "Epoch 03643: loss did not improve from -169.85469\n",
      "Epoch 3644/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.6175 - val_loss: -170.9253\n",
      "\n",
      "Epoch 03644: loss did not improve from -169.85469\n",
      "Epoch 3645/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.6171 - val_loss: -171.8065\n",
      "\n",
      "Epoch 03645: loss did not improve from -169.85469\n",
      "Epoch 3646/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.8539 - val_loss: -171.5163\n",
      "\n",
      "Epoch 03646: loss did not improve from -169.85469\n",
      "Epoch 3647/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.7968 - val_loss: -171.3840\n",
      "\n",
      "Epoch 03647: loss did not improve from -169.85469\n",
      "Epoch 3648/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.8175 - val_loss: -171.8025\n",
      "\n",
      "Epoch 03648: loss did not improve from -169.85469\n",
      "Epoch 3649/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.7762 - val_loss: -171.2097\n",
      "\n",
      "Epoch 03649: loss did not improve from -169.85469\n",
      "Epoch 3650/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.6384 - val_loss: -171.8371\n",
      "\n",
      "Epoch 03650: loss did not improve from -169.85469\n",
      "Epoch 3651/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.6601 - val_loss: -171.5043\n",
      "\n",
      "Epoch 03651: loss did not improve from -169.85469\n",
      "Epoch 3652/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.7159 - val_loss: -171.7717\n",
      "\n",
      "Epoch 03652: loss did not improve from -169.85469\n",
      "Epoch 3653/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.8550 - val_loss: -171.6126\n",
      "\n",
      "Epoch 03653: loss improved from -169.85469 to -169.85496, saving model to gendance.h5\n",
      "Epoch 3654/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.7034 - val_loss: -171.6907\n",
      "\n",
      "Epoch 03654: loss did not improve from -169.85496\n",
      "Epoch 3655/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.7557 - val_loss: -171.7137\n",
      "\n",
      "Epoch 03655: loss did not improve from -169.85496\n",
      "Epoch 3656/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.5500 - val_loss: -171.1080\n",
      "\n",
      "Epoch 03656: loss did not improve from -169.85496\n",
      "Epoch 3657/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.6589 - val_loss: -171.7269\n",
      "\n",
      "Epoch 03657: loss did not improve from -169.85496\n",
      "Epoch 3658/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.4494 - val_loss: -170.8574\n",
      "\n",
      "Epoch 03658: loss did not improve from -169.85496\n",
      "Epoch 3659/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.6802 - val_loss: -171.5956\n",
      "\n",
      "Epoch 03659: loss did not improve from -169.85496\n",
      "Epoch 3660/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.6076 - val_loss: -171.4571\n",
      "\n",
      "Epoch 03660: loss did not improve from -169.85496\n",
      "Epoch 3661/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.3741 - val_loss: -171.2910\n",
      "\n",
      "Epoch 03661: loss did not improve from -169.85496\n",
      "Epoch 3662/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.4998 - val_loss: -171.6125\n",
      "\n",
      "Epoch 03662: loss did not improve from -169.85496\n",
      "Epoch 3663/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.2761 - val_loss: -171.0239\n",
      "\n",
      "Epoch 03663: loss did not improve from -169.85496\n",
      "Epoch 3664/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.4002 - val_loss: -171.6805\n",
      "\n",
      "Epoch 03664: loss did not improve from -169.85496\n",
      "Epoch 3665/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.7429 - val_loss: -171.0601\n",
      "\n",
      "Epoch 03665: loss did not improve from -169.85496\n",
      "Epoch 3666/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.6640 - val_loss: -171.6592\n",
      "\n",
      "Epoch 03666: loss did not improve from -169.85496\n",
      "Epoch 3667/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.6117 - val_loss: -171.1991\n",
      "\n",
      "Epoch 03667: loss did not improve from -169.85496\n",
      "Epoch 3668/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.6687 - val_loss: -171.7864\n",
      "\n",
      "Epoch 03668: loss did not improve from -169.85496\n",
      "Epoch 3669/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.6627 - val_loss: -171.5836\n",
      "\n",
      "Epoch 03669: loss did not improve from -169.85496\n",
      "Epoch 3670/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.8348 - val_loss: -171.7270\n",
      "\n",
      "Epoch 03670: loss did not improve from -169.85496\n",
      "Epoch 3671/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.9247 - val_loss: -171.6867\n",
      "\n",
      "Epoch 03671: loss improved from -169.85496 to -169.92467, saving model to gendance.h5\n",
      "Epoch 3672/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.6262 - val_loss: -171.6794\n",
      "\n",
      "Epoch 03672: loss did not improve from -169.92467\n",
      "Epoch 3673/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.6585 - val_loss: -171.5146\n",
      "\n",
      "Epoch 03673: loss did not improve from -169.92467\n",
      "Epoch 3674/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.8486 - val_loss: -171.8463\n",
      "\n",
      "Epoch 03674: loss did not improve from -169.92467\n",
      "Epoch 3675/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.8658 - val_loss: -171.5441\n",
      "\n",
      "Epoch 03675: loss did not improve from -169.92467\n",
      "Epoch 3676/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.7970 - val_loss: -171.6210\n",
      "\n",
      "Epoch 03676: loss did not improve from -169.92467\n",
      "Epoch 3677/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.7871 - val_loss: -171.4450\n",
      "\n",
      "Epoch 03677: loss did not improve from -169.92467\n",
      "Epoch 3678/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.9570 - val_loss: -171.7644\n",
      "\n",
      "Epoch 03678: loss improved from -169.92467 to -169.95701, saving model to gendance.h5\n",
      "Epoch 3679/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.8103 - val_loss: -171.4300\n",
      "\n",
      "Epoch 03679: loss did not improve from -169.95701\n",
      "Epoch 3680/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -169.5673 - val_loss: -171.3350\n",
      "\n",
      "Epoch 03680: loss did not improve from -169.95701\n",
      "Epoch 3681/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.7819 - val_loss: -171.7806\n",
      "\n",
      "Epoch 03681: loss did not improve from -169.95701\n",
      "Epoch 3682/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.8158 - val_loss: -171.4539\n",
      "\n",
      "Epoch 03682: loss did not improve from -169.95701\n",
      "Epoch 3683/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.7195 - val_loss: -171.8118\n",
      "\n",
      "Epoch 03683: loss did not improve from -169.95701\n",
      "Epoch 3684/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.8379 - val_loss: -171.4026\n",
      "\n",
      "Epoch 03684: loss did not improve from -169.95701\n",
      "Epoch 3685/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.7626 - val_loss: -171.8377\n",
      "\n",
      "Epoch 03685: loss did not improve from -169.95701\n",
      "Epoch 3686/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.7869 - val_loss: -171.3499\n",
      "\n",
      "Epoch 03686: loss did not improve from -169.95701\n",
      "Epoch 3687/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.7423 - val_loss: -171.8102\n",
      "\n",
      "Epoch 03687: loss did not improve from -169.95701\n",
      "Epoch 3688/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.6912 - val_loss: -171.2234\n",
      "\n",
      "Epoch 03688: loss did not improve from -169.95701\n",
      "Epoch 3689/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.7681 - val_loss: -171.4185\n",
      "\n",
      "Epoch 03689: loss did not improve from -169.95701\n",
      "Epoch 3690/10000\n",
      "16167/16167 [==============================] - 1s 31us/step - loss: -169.5546 - val_loss: -171.5747\n",
      "\n",
      "Epoch 03690: loss did not improve from -169.95701\n",
      "Epoch 3691/10000\n",
      "16167/16167 [==============================] - 1s 32us/step - loss: -169.5965 - val_loss: -171.4392\n",
      "\n",
      "Epoch 03691: loss did not improve from -169.95701\n",
      "Epoch 3692/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.4850 - val_loss: -171.5193\n",
      "\n",
      "Epoch 03692: loss did not improve from -169.95701\n",
      "Epoch 3693/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.6911 - val_loss: -171.3598\n",
      "\n",
      "Epoch 03693: loss did not improve from -169.95701\n",
      "Epoch 3694/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.6686 - val_loss: -171.7091\n",
      "\n",
      "Epoch 03694: loss did not improve from -169.95701\n",
      "Epoch 3695/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.7655 - val_loss: -171.3021\n",
      "\n",
      "Epoch 03695: loss did not improve from -169.95701\n",
      "Epoch 3696/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.6968 - val_loss: -171.6877\n",
      "\n",
      "Epoch 03696: loss did not improve from -169.95701\n",
      "Epoch 3697/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.9530 - val_loss: -171.5051\n",
      "\n",
      "Epoch 03697: loss did not improve from -169.95701\n",
      "Epoch 3698/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -169.8898 - val_loss: -171.9632\n",
      "\n",
      "Epoch 03698: loss did not improve from -169.95701\n",
      "Epoch 3699/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.7904 - val_loss: -171.4624\n",
      "\n",
      "Epoch 03699: loss did not improve from -169.95701\n",
      "Epoch 3700/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.9344 - val_loss: -171.8400\n",
      "\n",
      "Epoch 03700: loss did not improve from -169.95701\n",
      "Epoch 3701/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.8604 - val_loss: -171.4988\n",
      "\n",
      "Epoch 03701: loss did not improve from -169.95701\n",
      "Epoch 3702/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.6618 - val_loss: -171.5027\n",
      "\n",
      "Epoch 03702: loss did not improve from -169.95701\n",
      "Epoch 3703/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.0642 - val_loss: -171.9112\n",
      "\n",
      "Epoch 03703: loss improved from -169.95701 to -170.06417, saving model to gendance.h5\n",
      "Epoch 3704/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.0325 - val_loss: -171.6343\n",
      "\n",
      "Epoch 03704: loss did not improve from -170.06417\n",
      "Epoch 3705/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.9094 - val_loss: -171.8106\n",
      "\n",
      "Epoch 03705: loss did not improve from -170.06417\n",
      "Epoch 3706/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.7916 - val_loss: -171.6502\n",
      "\n",
      "Epoch 03706: loss did not improve from -170.06417\n",
      "Epoch 3707/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.1841 - val_loss: -171.9057\n",
      "\n",
      "Epoch 03707: loss improved from -170.06417 to -170.18407, saving model to gendance.h5\n",
      "Epoch 3708/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.9776 - val_loss: -171.4022\n",
      "\n",
      "Epoch 03708: loss did not improve from -170.18407\n",
      "Epoch 3709/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -169.9593 - val_loss: -171.7953\n",
      "\n",
      "Epoch 03709: loss did not improve from -170.18407\n",
      "Epoch 3710/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.6397 - val_loss: -171.3325\n",
      "\n",
      "Epoch 03710: loss did not improve from -170.18407\n",
      "Epoch 3711/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.6693 - val_loss: -171.5541\n",
      "\n",
      "Epoch 03711: loss did not improve from -170.18407\n",
      "Epoch 3712/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.6076 - val_loss: -171.5169\n",
      "\n",
      "Epoch 03712: loss did not improve from -170.18407\n",
      "Epoch 3713/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.4957 - val_loss: -171.1668\n",
      "\n",
      "Epoch 03713: loss did not improve from -170.18407\n",
      "Epoch 3714/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.4650 - val_loss: -171.6741\n",
      "\n",
      "Epoch 03714: loss did not improve from -170.18407\n",
      "Epoch 3715/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.5377 - val_loss: -171.1327\n",
      "\n",
      "Epoch 03715: loss did not improve from -170.18407\n",
      "Epoch 3716/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.7224 - val_loss: -171.7073\n",
      "\n",
      "Epoch 03716: loss did not improve from -170.18407\n",
      "Epoch 3717/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.6848 - val_loss: -171.4607\n",
      "\n",
      "Epoch 03717: loss did not improve from -170.18407\n",
      "Epoch 3718/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.8920 - val_loss: -171.8376\n",
      "\n",
      "Epoch 03718: loss did not improve from -170.18407\n",
      "Epoch 3719/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.8223 - val_loss: -171.5693\n",
      "\n",
      "Epoch 03719: loss did not improve from -170.18407\n",
      "Epoch 3720/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.8821 - val_loss: -171.8920\n",
      "\n",
      "Epoch 03720: loss did not improve from -170.18407\n",
      "Epoch 3721/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.6789 - val_loss: -171.3092\n",
      "\n",
      "Epoch 03721: loss did not improve from -170.18407\n",
      "Epoch 3722/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.9776 - val_loss: -171.7917\n",
      "\n",
      "Epoch 03722: loss did not improve from -170.18407\n",
      "Epoch 3723/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.0170 - val_loss: -171.5557\n",
      "\n",
      "Epoch 03723: loss did not improve from -170.18407\n",
      "Epoch 3724/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.8916 - val_loss: -171.9644\n",
      "\n",
      "Epoch 03724: loss did not improve from -170.18407\n",
      "Epoch 3725/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.1230 - val_loss: -171.7647\n",
      "\n",
      "Epoch 03725: loss did not improve from -170.18407\n",
      "Epoch 3726/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.8374 - val_loss: -171.8166\n",
      "\n",
      "Epoch 03726: loss did not improve from -170.18407\n",
      "Epoch 3727/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.9663 - val_loss: -171.8185\n",
      "\n",
      "Epoch 03727: loss did not improve from -170.18407\n",
      "Epoch 3728/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.9052 - val_loss: -171.6969\n",
      "\n",
      "Epoch 03728: loss did not improve from -170.18407\n",
      "Epoch 3729/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.0587 - val_loss: -171.9272\n",
      "\n",
      "Epoch 03729: loss did not improve from -170.18407\n",
      "Epoch 3730/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.0367 - val_loss: -171.7027\n",
      "\n",
      "Epoch 03730: loss did not improve from -170.18407\n",
      "Epoch 3731/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.8772 - val_loss: -171.7628\n",
      "\n",
      "Epoch 03731: loss did not improve from -170.18407\n",
      "Epoch 3732/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.9923 - val_loss: -171.8508\n",
      "\n",
      "Epoch 03732: loss did not improve from -170.18407\n",
      "Epoch 3733/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.0634 - val_loss: -171.7824\n",
      "\n",
      "Epoch 03733: loss did not improve from -170.18407\n",
      "Epoch 3734/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.9309 - val_loss: -171.7977\n",
      "\n",
      "Epoch 03734: loss did not improve from -170.18407\n",
      "Epoch 3735/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.9495 - val_loss: -171.7830\n",
      "\n",
      "Epoch 03735: loss did not improve from -170.18407\n",
      "Epoch 3736/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.8820 - val_loss: -171.3362\n",
      "\n",
      "Epoch 03736: loss did not improve from -170.18407\n",
      "Epoch 3737/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.7565 - val_loss: -171.8068\n",
      "\n",
      "Epoch 03737: loss did not improve from -170.18407\n",
      "Epoch 3738/10000\n",
      "16167/16167 [==============================] - 1s 32us/step - loss: -169.7754 - val_loss: -170.8679\n",
      "\n",
      "Epoch 03738: loss did not improve from -170.18407\n",
      "Epoch 3739/10000\n",
      "16167/16167 [==============================] - 1s 32us/step - loss: -169.9664 - val_loss: -171.7626\n",
      "\n",
      "Epoch 03739: loss did not improve from -170.18407\n",
      "Epoch 3740/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.6847 - val_loss: -171.2052\n",
      "\n",
      "Epoch 03740: loss did not improve from -170.18407\n",
      "Epoch 3741/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.6242 - val_loss: -171.6731\n",
      "\n",
      "Epoch 03741: loss did not improve from -170.18407\n",
      "Epoch 3742/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.8498 - val_loss: -171.7410\n",
      "\n",
      "Epoch 03742: loss did not improve from -170.18407\n",
      "Epoch 3743/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.7897 - val_loss: -171.5143\n",
      "\n",
      "Epoch 03743: loss did not improve from -170.18407\n",
      "Epoch 3744/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.9513 - val_loss: -171.9024\n",
      "\n",
      "Epoch 03744: loss did not improve from -170.18407\n",
      "Epoch 3745/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.6181 - val_loss: -171.2755\n",
      "\n",
      "Epoch 03745: loss did not improve from -170.18407\n",
      "Epoch 3746/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.0214 - val_loss: -171.9958\n",
      "\n",
      "Epoch 03746: loss did not improve from -170.18407\n",
      "Epoch 3747/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.7028 - val_loss: -171.0889\n",
      "\n",
      "Epoch 03747: loss did not improve from -170.18407\n",
      "Epoch 3748/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.8867 - val_loss: -171.9724\n",
      "\n",
      "Epoch 03748: loss did not improve from -170.18407\n",
      "Epoch 3749/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.0354 - val_loss: -171.7632\n",
      "\n",
      "Epoch 03749: loss did not improve from -170.18407\n",
      "Epoch 3750/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.9439 - val_loss: -171.7639\n",
      "\n",
      "Epoch 03750: loss did not improve from -170.18407\n",
      "Epoch 3751/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.9962 - val_loss: -171.8928\n",
      "\n",
      "Epoch 03751: loss did not improve from -170.18407\n",
      "Epoch 3752/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.0552 - val_loss: -171.7049\n",
      "\n",
      "Epoch 03752: loss did not improve from -170.18407\n",
      "Epoch 3753/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.1918 - val_loss: -171.8308\n",
      "\n",
      "Epoch 03753: loss improved from -170.18407 to -170.19177, saving model to gendance.h5\n",
      "Epoch 3754/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.0382 - val_loss: -171.8028\n",
      "\n",
      "Epoch 03754: loss did not improve from -170.19177\n",
      "Epoch 3755/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.9927 - val_loss: -171.6759\n",
      "\n",
      "Epoch 03755: loss did not improve from -170.19177\n",
      "Epoch 3756/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.9152 - val_loss: -171.9608\n",
      "\n",
      "Epoch 03756: loss did not improve from -170.19177\n",
      "Epoch 3757/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.9723 - val_loss: -171.6756\n",
      "\n",
      "Epoch 03757: loss did not improve from -170.19177\n",
      "Epoch 3758/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.8902 - val_loss: -171.9163\n",
      "\n",
      "Epoch 03758: loss did not improve from -170.19177\n",
      "Epoch 3759/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.9357 - val_loss: -171.5104\n",
      "\n",
      "Epoch 03759: loss did not improve from -170.19177\n",
      "Epoch 3760/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.8892 - val_loss: -171.9216\n",
      "\n",
      "Epoch 03760: loss did not improve from -170.19177\n",
      "Epoch 3761/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.0302 - val_loss: -171.6935\n",
      "\n",
      "Epoch 03761: loss did not improve from -170.19177\n",
      "Epoch 3762/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.8747 - val_loss: -171.6776\n",
      "\n",
      "Epoch 03762: loss did not improve from -170.19177\n",
      "Epoch 3763/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.9565 - val_loss: -172.0779\n",
      "\n",
      "Epoch 03763: loss did not improve from -170.19177\n",
      "Epoch 3764/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.8924 - val_loss: -171.8312\n",
      "\n",
      "Epoch 03764: loss did not improve from -170.19177\n",
      "Epoch 3765/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.0550 - val_loss: -171.9150\n",
      "\n",
      "Epoch 03765: loss did not improve from -170.19177\n",
      "Epoch 3766/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -169.8097 - val_loss: -171.5625\n",
      "\n",
      "Epoch 03766: loss did not improve from -170.19177\n",
      "Epoch 3767/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.9637 - val_loss: -171.8927\n",
      "\n",
      "Epoch 03767: loss did not improve from -170.19177\n",
      "Epoch 3768/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.9742 - val_loss: -171.9467\n",
      "\n",
      "Epoch 03768: loss did not improve from -170.19177\n",
      "Epoch 3769/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.1189 - val_loss: -171.8605\n",
      "\n",
      "Epoch 03769: loss did not improve from -170.19177\n",
      "Epoch 3770/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.0793 - val_loss: -171.7874\n",
      "\n",
      "Epoch 03770: loss did not improve from -170.19177\n",
      "Epoch 3771/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.2977 - val_loss: -172.1129\n",
      "\n",
      "Epoch 03771: loss improved from -170.19177 to -170.29769, saving model to gendance.h5\n",
      "Epoch 3772/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -170.0342 - val_loss: -171.6341\n",
      "\n",
      "Epoch 03772: loss did not improve from -170.29769\n",
      "Epoch 3773/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.1944 - val_loss: -172.1654\n",
      "\n",
      "Epoch 03773: loss did not improve from -170.29769\n",
      "Epoch 3774/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.3096 - val_loss: -171.8142\n",
      "\n",
      "Epoch 03774: loss improved from -170.29769 to -170.30955, saving model to gendance.h5\n",
      "Epoch 3775/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.0328 - val_loss: -171.7479\n",
      "\n",
      "Epoch 03775: loss did not improve from -170.30955\n",
      "Epoch 3776/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.9201 - val_loss: -171.8468\n",
      "\n",
      "Epoch 03776: loss did not improve from -170.30955\n",
      "Epoch 3777/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.0395 - val_loss: -171.7684\n",
      "\n",
      "Epoch 03777: loss did not improve from -170.30955\n",
      "Epoch 3778/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.7892 - val_loss: -171.8169\n",
      "\n",
      "Epoch 03778: loss did not improve from -170.30955\n",
      "Epoch 3779/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.9447 - val_loss: -171.6803\n",
      "\n",
      "Epoch 03779: loss did not improve from -170.30955\n",
      "Epoch 3780/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -169.9390 - val_loss: -171.8118\n",
      "\n",
      "Epoch 03780: loss did not improve from -170.30955\n",
      "Epoch 3781/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.8778 - val_loss: -171.3038\n",
      "\n",
      "Epoch 03781: loss did not improve from -170.30955\n",
      "Epoch 3782/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.7930 - val_loss: -171.9032\n",
      "\n",
      "Epoch 03782: loss did not improve from -170.30955\n",
      "Epoch 3783/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.6501 - val_loss: -170.8200\n",
      "\n",
      "Epoch 03783: loss did not improve from -170.30955\n",
      "Epoch 3784/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.6254 - val_loss: -171.7388\n",
      "\n",
      "Epoch 03784: loss did not improve from -170.30955\n",
      "Epoch 3785/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.8534 - val_loss: -171.4153\n",
      "\n",
      "Epoch 03785: loss did not improve from -170.30955\n",
      "Epoch 3786/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.0286 - val_loss: -171.9431\n",
      "\n",
      "Epoch 03786: loss did not improve from -170.30955\n",
      "Epoch 3787/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.8957 - val_loss: -171.6004\n",
      "\n",
      "Epoch 03787: loss did not improve from -170.30955\n",
      "Epoch 3788/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.0425 - val_loss: -171.8723\n",
      "\n",
      "Epoch 03788: loss did not improve from -170.30955\n",
      "Epoch 3789/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.9188 - val_loss: -171.7790\n",
      "\n",
      "Epoch 03789: loss did not improve from -170.30955\n",
      "Epoch 3790/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.9707 - val_loss: -171.6308\n",
      "\n",
      "Epoch 03790: loss did not improve from -170.30955\n",
      "Epoch 3791/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.6031 - val_loss: -171.9086\n",
      "\n",
      "Epoch 03791: loss did not improve from -170.30955\n",
      "Epoch 3792/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.6842 - val_loss: -171.3154\n",
      "\n",
      "Epoch 03792: loss did not improve from -170.30955\n",
      "Epoch 3793/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.8252 - val_loss: -172.0617\n",
      "\n",
      "Epoch 03793: loss did not improve from -170.30955\n",
      "Epoch 3794/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.8330 - val_loss: -171.3438\n",
      "\n",
      "Epoch 03794: loss did not improve from -170.30955\n",
      "Epoch 3795/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.9570 - val_loss: -171.9768\n",
      "\n",
      "Epoch 03795: loss did not improve from -170.30955\n",
      "Epoch 3796/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.8894 - val_loss: -171.4235\n",
      "\n",
      "Epoch 03796: loss did not improve from -170.30955\n",
      "Epoch 3797/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.9986 - val_loss: -171.8855\n",
      "\n",
      "Epoch 03797: loss did not improve from -170.30955\n",
      "Epoch 3798/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.9128 - val_loss: -171.4948\n",
      "\n",
      "Epoch 03798: loss did not improve from -170.30955\n",
      "Epoch 3799/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.0643 - val_loss: -171.9667\n",
      "\n",
      "Epoch 03799: loss did not improve from -170.30955\n",
      "Epoch 3800/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.8839 - val_loss: -171.7486\n",
      "\n",
      "Epoch 03800: loss did not improve from -170.30955\n",
      "Epoch 3801/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.7763 - val_loss: -171.6445\n",
      "\n",
      "Epoch 03801: loss did not improve from -170.30955\n",
      "Epoch 3802/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.7655 - val_loss: -171.8810\n",
      "\n",
      "Epoch 03802: loss did not improve from -170.30955\n",
      "Epoch 3803/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.8804 - val_loss: -171.3205\n",
      "\n",
      "Epoch 03803: loss did not improve from -170.30955\n",
      "Epoch 3804/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.7946 - val_loss: -172.1034\n",
      "\n",
      "Epoch 03804: loss did not improve from -170.30955\n",
      "Epoch 3805/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.7410 - val_loss: -171.4890\n",
      "\n",
      "Epoch 03805: loss did not improve from -170.30955\n",
      "Epoch 3806/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.8288 - val_loss: -172.0371\n",
      "\n",
      "Epoch 03806: loss did not improve from -170.30955\n",
      "Epoch 3807/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.0222 - val_loss: -171.6331\n",
      "\n",
      "Epoch 03807: loss did not improve from -170.30955\n",
      "Epoch 3808/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.9321 - val_loss: -171.9619\n",
      "\n",
      "Epoch 03808: loss did not improve from -170.30955\n",
      "Epoch 3809/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.0028 - val_loss: -171.8801\n",
      "\n",
      "Epoch 03809: loss did not improve from -170.30955\n",
      "Epoch 3810/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.3419 - val_loss: -172.1214\n",
      "\n",
      "Epoch 03810: loss improved from -170.30955 to -170.34190, saving model to gendance.h5\n",
      "Epoch 3811/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.8989 - val_loss: -171.6526\n",
      "\n",
      "Epoch 03811: loss did not improve from -170.34190\n",
      "Epoch 3812/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.9874 - val_loss: -171.9879\n",
      "\n",
      "Epoch 03812: loss did not improve from -170.34190\n",
      "Epoch 3813/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -169.8519 - val_loss: -171.8412\n",
      "\n",
      "Epoch 03813: loss did not improve from -170.34190\n",
      "Epoch 3814/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.1538 - val_loss: -171.8830\n",
      "\n",
      "Epoch 03814: loss did not improve from -170.34190\n",
      "Epoch 3815/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.0914 - val_loss: -172.1287\n",
      "\n",
      "Epoch 03815: loss did not improve from -170.34190\n",
      "Epoch 3816/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.8663 - val_loss: -171.5633\n",
      "\n",
      "Epoch 03816: loss did not improve from -170.34190\n",
      "Epoch 3817/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.7292 - val_loss: -171.9540\n",
      "\n",
      "Epoch 03817: loss did not improve from -170.34190\n",
      "Epoch 3818/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.0243 - val_loss: -171.5980\n",
      "\n",
      "Epoch 03818: loss did not improve from -170.34190\n",
      "Epoch 3819/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.1612 - val_loss: -171.8835\n",
      "\n",
      "Epoch 03819: loss did not improve from -170.34190\n",
      "Epoch 3820/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -170.1113 - val_loss: -171.7287\n",
      "\n",
      "Epoch 03820: loss did not improve from -170.34190\n",
      "Epoch 3821/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.0403 - val_loss: -172.0060\n",
      "\n",
      "Epoch 03821: loss did not improve from -170.34190\n",
      "Epoch 3822/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.0023 - val_loss: -171.4824\n",
      "\n",
      "Epoch 03822: loss did not improve from -170.34190\n",
      "Epoch 3823/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.9399 - val_loss: -171.8976\n",
      "\n",
      "Epoch 03823: loss did not improve from -170.34190\n",
      "Epoch 3824/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.1338 - val_loss: -171.7621\n",
      "\n",
      "Epoch 03824: loss did not improve from -170.34190\n",
      "Epoch 3825/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.1906 - val_loss: -171.9344\n",
      "\n",
      "Epoch 03825: loss did not improve from -170.34190\n",
      "Epoch 3826/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.0542 - val_loss: -171.7825\n",
      "\n",
      "Epoch 03826: loss did not improve from -170.34190\n",
      "Epoch 3827/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.1502 - val_loss: -171.9675\n",
      "\n",
      "Epoch 03827: loss did not improve from -170.34190\n",
      "Epoch 3828/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.0907 - val_loss: -171.9478\n",
      "\n",
      "Epoch 03828: loss did not improve from -170.34190\n",
      "Epoch 3829/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.2687 - val_loss: -172.0653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 03829: loss did not improve from -170.34190\n",
      "Epoch 3830/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.1538 - val_loss: -171.7918\n",
      "\n",
      "Epoch 03830: loss did not improve from -170.34190\n",
      "Epoch 3831/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.2729 - val_loss: -172.0169\n",
      "\n",
      "Epoch 03831: loss did not improve from -170.34190\n",
      "Epoch 3832/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.2774 - val_loss: -171.9807\n",
      "\n",
      "Epoch 03832: loss did not improve from -170.34190\n",
      "Epoch 3833/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.0763 - val_loss: -171.7394\n",
      "\n",
      "Epoch 03833: loss did not improve from -170.34190\n",
      "Epoch 3834/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.9730 - val_loss: -172.1103\n",
      "\n",
      "Epoch 03834: loss did not improve from -170.34190\n",
      "Epoch 3835/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.0264 - val_loss: -171.7010\n",
      "\n",
      "Epoch 03835: loss did not improve from -170.34190\n",
      "Epoch 3836/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.0453 - val_loss: -171.9635\n",
      "\n",
      "Epoch 03836: loss did not improve from -170.34190\n",
      "Epoch 3837/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.1363 - val_loss: -171.6205\n",
      "\n",
      "Epoch 03837: loss did not improve from -170.34190\n",
      "Epoch 3838/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.0047 - val_loss: -172.0548\n",
      "\n",
      "Epoch 03838: loss did not improve from -170.34190\n",
      "Epoch 3839/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.0964 - val_loss: -171.6791\n",
      "\n",
      "Epoch 03839: loss did not improve from -170.34190\n",
      "Epoch 3840/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.0939 - val_loss: -172.0902\n",
      "\n",
      "Epoch 03840: loss did not improve from -170.34190\n",
      "Epoch 3841/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.3009 - val_loss: -171.6947\n",
      "\n",
      "Epoch 03841: loss did not improve from -170.34190\n",
      "Epoch 3842/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.2253 - val_loss: -171.9241\n",
      "\n",
      "Epoch 03842: loss did not improve from -170.34190\n",
      "Epoch 3843/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.0767 - val_loss: -171.7394\n",
      "\n",
      "Epoch 03843: loss did not improve from -170.34190\n",
      "Epoch 3844/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.1446 - val_loss: -171.9760\n",
      "\n",
      "Epoch 03844: loss did not improve from -170.34190\n",
      "Epoch 3845/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.3308 - val_loss: -172.0555\n",
      "\n",
      "Epoch 03845: loss did not improve from -170.34190\n",
      "Epoch 3846/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.0139 - val_loss: -171.8576\n",
      "\n",
      "Epoch 03846: loss did not improve from -170.34190\n",
      "Epoch 3847/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.4541 - val_loss: -171.9565\n",
      "\n",
      "Epoch 03847: loss improved from -170.34190 to -170.45414, saving model to gendance.h5\n",
      "Epoch 3848/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.2839 - val_loss: -172.0814\n",
      "\n",
      "Epoch 03848: loss did not improve from -170.45414\n",
      "Epoch 3849/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.3826 - val_loss: -171.9431\n",
      "\n",
      "Epoch 03849: loss did not improve from -170.45414\n",
      "Epoch 3850/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.1220 - val_loss: -172.0091\n",
      "\n",
      "Epoch 03850: loss did not improve from -170.45414\n",
      "Epoch 3851/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.1201 - val_loss: -171.8519\n",
      "\n",
      "Epoch 03851: loss did not improve from -170.45414\n",
      "Epoch 3852/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.9158 - val_loss: -171.6715\n",
      "\n",
      "Epoch 03852: loss did not improve from -170.45414\n",
      "Epoch 3853/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.0933 - val_loss: -171.8493\n",
      "\n",
      "Epoch 03853: loss did not improve from -170.45414\n",
      "Epoch 3854/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.1187 - val_loss: -171.9950\n",
      "\n",
      "Epoch 03854: loss did not improve from -170.45414\n",
      "Epoch 3855/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.9908 - val_loss: -171.2873\n",
      "\n",
      "Epoch 03855: loss did not improve from -170.45414\n",
      "Epoch 3856/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.8243 - val_loss: -171.9779\n",
      "\n",
      "Epoch 03856: loss did not improve from -170.45414\n",
      "Epoch 3857/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.7026 - val_loss: -171.1682\n",
      "\n",
      "Epoch 03857: loss did not improve from -170.45414\n",
      "Epoch 3858/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.8011 - val_loss: -171.9695\n",
      "\n",
      "Epoch 03858: loss did not improve from -170.45414\n",
      "Epoch 3859/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.0014 - val_loss: -171.3665\n",
      "\n",
      "Epoch 03859: loss did not improve from -170.45414\n",
      "Epoch 3860/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.8937 - val_loss: -172.0102\n",
      "\n",
      "Epoch 03860: loss did not improve from -170.45414\n",
      "Epoch 3861/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.1325 - val_loss: -171.5917\n",
      "\n",
      "Epoch 03861: loss did not improve from -170.45414\n",
      "Epoch 3862/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.2802 - val_loss: -172.1028\n",
      "\n",
      "Epoch 03862: loss did not improve from -170.45414\n",
      "Epoch 3863/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.3116 - val_loss: -172.0180\n",
      "\n",
      "Epoch 03863: loss did not improve from -170.45414\n",
      "Epoch 3864/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.3080 - val_loss: -172.0601\n",
      "\n",
      "Epoch 03864: loss did not improve from -170.45414\n",
      "Epoch 3865/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.1556 - val_loss: -171.8987\n",
      "\n",
      "Epoch 03865: loss did not improve from -170.45414\n",
      "Epoch 3866/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.0939 - val_loss: -171.8778\n",
      "\n",
      "Epoch 03866: loss did not improve from -170.45414\n",
      "Epoch 3867/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.1366 - val_loss: -172.0993\n",
      "\n",
      "Epoch 03867: loss did not improve from -170.45414\n",
      "Epoch 3868/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.1975 - val_loss: -171.9771\n",
      "\n",
      "Epoch 03868: loss did not improve from -170.45414\n",
      "Epoch 3869/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.2212 - val_loss: -172.1100\n",
      "\n",
      "Epoch 03869: loss did not improve from -170.45414\n",
      "Epoch 3870/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.2670 - val_loss: -171.6064\n",
      "\n",
      "Epoch 03870: loss did not improve from -170.45414\n",
      "Epoch 3871/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.1919 - val_loss: -172.0663\n",
      "\n",
      "Epoch 03871: loss did not improve from -170.45414\n",
      "Epoch 3872/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.9199 - val_loss: -171.5978\n",
      "\n",
      "Epoch 03872: loss did not improve from -170.45414\n",
      "Epoch 3873/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.9084 - val_loss: -171.8817\n",
      "\n",
      "Epoch 03873: loss did not improve from -170.45414\n",
      "Epoch 3874/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.8691 - val_loss: -172.0718\n",
      "\n",
      "Epoch 03874: loss did not improve from -170.45414\n",
      "Epoch 3875/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.8796 - val_loss: -171.0511\n",
      "\n",
      "Epoch 03875: loss did not improve from -170.45414\n",
      "Epoch 3876/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.7394 - val_loss: -172.0355\n",
      "\n",
      "Epoch 03876: loss did not improve from -170.45414\n",
      "Epoch 3877/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.8425 - val_loss: -171.3491\n",
      "\n",
      "Epoch 03877: loss did not improve from -170.45414\n",
      "Epoch 3878/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.2070 - val_loss: -172.2013\n",
      "\n",
      "Epoch 03878: loss did not improve from -170.45414\n",
      "Epoch 3879/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -170.2548 - val_loss: -171.8440\n",
      "\n",
      "Epoch 03879: loss did not improve from -170.45414\n",
      "Epoch 3880/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.1145 - val_loss: -172.0174\n",
      "\n",
      "Epoch 03880: loss did not improve from -170.45414\n",
      "Epoch 3881/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.2843 - val_loss: -171.8460\n",
      "\n",
      "Epoch 03881: loss did not improve from -170.45414\n",
      "Epoch 3882/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.2754 - val_loss: -172.0192\n",
      "\n",
      "Epoch 03882: loss did not improve from -170.45414\n",
      "Epoch 3883/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.1968 - val_loss: -172.0522\n",
      "\n",
      "Epoch 03883: loss did not improve from -170.45414\n",
      "Epoch 3884/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.3413 - val_loss: -171.9526\n",
      "\n",
      "Epoch 03884: loss did not improve from -170.45414\n",
      "Epoch 3885/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.2024 - val_loss: -172.0917\n",
      "\n",
      "Epoch 03885: loss did not improve from -170.45414\n",
      "Epoch 3886/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.2814 - val_loss: -172.1568\n",
      "\n",
      "Epoch 03886: loss did not improve from -170.45414\n",
      "Epoch 3887/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.3186 - val_loss: -171.9782\n",
      "\n",
      "Epoch 03887: loss did not improve from -170.45414\n",
      "Epoch 3888/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.3135 - val_loss: -172.1006\n",
      "\n",
      "Epoch 03888: loss did not improve from -170.45414\n",
      "Epoch 3889/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.2439 - val_loss: -172.1414\n",
      "\n",
      "Epoch 03889: loss did not improve from -170.45414\n",
      "Epoch 3890/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.3211 - val_loss: -172.0092\n",
      "\n",
      "Epoch 03890: loss did not improve from -170.45414\n",
      "Epoch 3891/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.3658 - val_loss: -171.9879\n",
      "\n",
      "Epoch 03891: loss did not improve from -170.45414\n",
      "Epoch 3892/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.2570 - val_loss: -171.7805\n",
      "\n",
      "Epoch 03892: loss did not improve from -170.45414\n",
      "Epoch 3893/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.2201 - val_loss: -172.0903\n",
      "\n",
      "Epoch 03893: loss did not improve from -170.45414\n",
      "Epoch 3894/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.1917 - val_loss: -171.8597\n",
      "\n",
      "Epoch 03894: loss did not improve from -170.45414\n",
      "Epoch 3895/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.1978 - val_loss: -171.9281\n",
      "\n",
      "Epoch 03895: loss did not improve from -170.45414\n",
      "Epoch 3896/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.2611 - val_loss: -171.9966\n",
      "\n",
      "Epoch 03896: loss did not improve from -170.45414\n",
      "Epoch 3897/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.4390 - val_loss: -172.2194\n",
      "\n",
      "Epoch 03897: loss did not improve from -170.45414\n",
      "Epoch 3898/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.2978 - val_loss: -171.9415\n",
      "\n",
      "Epoch 03898: loss did not improve from -170.45414\n",
      "Epoch 3899/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.3090 - val_loss: -171.9275\n",
      "\n",
      "Epoch 03899: loss did not improve from -170.45414\n",
      "Epoch 3900/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.2792 - val_loss: -171.9733\n",
      "\n",
      "Epoch 03900: loss did not improve from -170.45414\n",
      "Epoch 3901/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.2861 - val_loss: -171.9422\n",
      "\n",
      "Epoch 03901: loss did not improve from -170.45414\n",
      "Epoch 3902/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.2069 - val_loss: -172.0404\n",
      "\n",
      "Epoch 03902: loss did not improve from -170.45414\n",
      "Epoch 3903/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.2869 - val_loss: -171.9189\n",
      "\n",
      "Epoch 03903: loss did not improve from -170.45414\n",
      "Epoch 3904/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.3737 - val_loss: -172.1670\n",
      "\n",
      "Epoch 03904: loss did not improve from -170.45414\n",
      "Epoch 3905/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.1498 - val_loss: -171.9430\n",
      "\n",
      "Epoch 03905: loss did not improve from -170.45414\n",
      "Epoch 3906/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.1182 - val_loss: -171.9417\n",
      "\n",
      "Epoch 03906: loss did not improve from -170.45414\n",
      "Epoch 3907/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.1335 - val_loss: -172.0788\n",
      "\n",
      "Epoch 03907: loss did not improve from -170.45414\n",
      "Epoch 3908/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.9019 - val_loss: -171.2780\n",
      "\n",
      "Epoch 03908: loss did not improve from -170.45414\n",
      "Epoch 3909/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.8280 - val_loss: -171.8928\n",
      "\n",
      "Epoch 03909: loss did not improve from -170.45414\n",
      "Epoch 3910/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.8441 - val_loss: -171.0510\n",
      "\n",
      "Epoch 03910: loss did not improve from -170.45414\n",
      "Epoch 3911/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.9429 - val_loss: -172.1906\n",
      "\n",
      "Epoch 03911: loss did not improve from -170.45414\n",
      "Epoch 3912/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.1205 - val_loss: -171.6485\n",
      "\n",
      "Epoch 03912: loss did not improve from -170.45414\n",
      "Epoch 3913/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.3025 - val_loss: -172.2774\n",
      "\n",
      "Epoch 03913: loss did not improve from -170.45414\n",
      "Epoch 3914/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.1664 - val_loss: -171.9962\n",
      "\n",
      "Epoch 03914: loss did not improve from -170.45414\n",
      "Epoch 3915/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.2516 - val_loss: -172.1556\n",
      "\n",
      "Epoch 03915: loss did not improve from -170.45414\n",
      "Epoch 3916/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.4174 - val_loss: -172.2121\n",
      "\n",
      "Epoch 03916: loss did not improve from -170.45414\n",
      "Epoch 3917/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.2407 - val_loss: -171.9517\n",
      "\n",
      "Epoch 03917: loss did not improve from -170.45414\n",
      "Epoch 3918/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.2688 - val_loss: -172.3800\n",
      "\n",
      "Epoch 03918: loss did not improve from -170.45414\n",
      "Epoch 3919/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.2530 - val_loss: -171.8396\n",
      "\n",
      "Epoch 03919: loss did not improve from -170.45414\n",
      "Epoch 3920/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.2915 - val_loss: -172.1067\n",
      "\n",
      "Epoch 03920: loss did not improve from -170.45414\n",
      "Epoch 3921/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.4824 - val_loss: -171.9444\n",
      "\n",
      "Epoch 03921: loss improved from -170.45414 to -170.48238, saving model to gendance.h5\n",
      "Epoch 3922/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.2517 - val_loss: -172.1592\n",
      "\n",
      "Epoch 03922: loss did not improve from -170.48238\n",
      "Epoch 3923/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.2860 - val_loss: -172.0058\n",
      "\n",
      "Epoch 03923: loss did not improve from -170.48238\n",
      "Epoch 3924/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.5414 - val_loss: -172.2515\n",
      "\n",
      "Epoch 03924: loss improved from -170.48238 to -170.54143, saving model to gendance.h5\n",
      "Epoch 3925/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.2163 - val_loss: -172.0075\n",
      "\n",
      "Epoch 03925: loss did not improve from -170.54143\n",
      "Epoch 3926/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.2739 - val_loss: -172.0692\n",
      "\n",
      "Epoch 03926: loss did not improve from -170.54143\n",
      "Epoch 3927/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.3193 - val_loss: -172.0547\n",
      "\n",
      "Epoch 03927: loss did not improve from -170.54143\n",
      "Epoch 3928/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.3229 - val_loss: -172.0614\n",
      "\n",
      "Epoch 03928: loss did not improve from -170.54143\n",
      "Epoch 3929/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.5675 - val_loss: -172.0688\n",
      "\n",
      "Epoch 03929: loss improved from -170.54143 to -170.56747, saving model to gendance.h5\n",
      "Epoch 3930/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.3716 - val_loss: -172.0607\n",
      "\n",
      "Epoch 03930: loss did not improve from -170.56747\n",
      "Epoch 3931/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.3332 - val_loss: -171.7896\n",
      "\n",
      "Epoch 03931: loss did not improve from -170.56747\n",
      "Epoch 3932/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.2893 - val_loss: -172.1498\n",
      "\n",
      "Epoch 03932: loss did not improve from -170.56747\n",
      "Epoch 3933/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.2338 - val_loss: -171.8852\n",
      "\n",
      "Epoch 03933: loss did not improve from -170.56747\n",
      "Epoch 3934/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.0153 - val_loss: -171.7678\n",
      "\n",
      "Epoch 03934: loss did not improve from -170.56747\n",
      "Epoch 3935/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.0194 - val_loss: -172.1052\n",
      "\n",
      "Epoch 03935: loss did not improve from -170.56747\n",
      "Epoch 3936/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.3279 - val_loss: -171.8484\n",
      "\n",
      "Epoch 03936: loss did not improve from -170.56747\n",
      "Epoch 3937/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.4781 - val_loss: -172.2701\n",
      "\n",
      "Epoch 03937: loss did not improve from -170.56747\n",
      "Epoch 3938/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.1482 - val_loss: -171.9157\n",
      "\n",
      "Epoch 03938: loss did not improve from -170.56747\n",
      "Epoch 3939/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.1307 - val_loss: -172.2269\n",
      "\n",
      "Epoch 03939: loss did not improve from -170.56747\n",
      "Epoch 3940/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.0763 - val_loss: -171.3844\n",
      "\n",
      "Epoch 03940: loss did not improve from -170.56747\n",
      "Epoch 3941/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.2344 - val_loss: -172.1827\n",
      "\n",
      "Epoch 03941: loss did not improve from -170.56747\n",
      "Epoch 3942/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.2832 - val_loss: -171.4468\n",
      "\n",
      "Epoch 03942: loss did not improve from -170.56747\n",
      "Epoch 3943/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.3681 - val_loss: -172.0682\n",
      "\n",
      "Epoch 03943: loss did not improve from -170.56747\n",
      "Epoch 3944/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.3154 - val_loss: -172.0496\n",
      "\n",
      "Epoch 03944: loss did not improve from -170.56747\n",
      "Epoch 3945/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.2763 - val_loss: -172.0556\n",
      "\n",
      "Epoch 03945: loss did not improve from -170.56747\n",
      "Epoch 3946/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.2774 - val_loss: -172.2455\n",
      "\n",
      "Epoch 03946: loss did not improve from -170.56747\n",
      "Epoch 3947/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.3681 - val_loss: -171.9715\n",
      "\n",
      "Epoch 03947: loss did not improve from -170.56747\n",
      "Epoch 3948/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.4048 - val_loss: -172.3030\n",
      "\n",
      "Epoch 03948: loss did not improve from -170.56747\n",
      "Epoch 3949/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.1634 - val_loss: -171.7467\n",
      "\n",
      "Epoch 03949: loss did not improve from -170.56747\n",
      "Epoch 3950/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.3774 - val_loss: -172.2393\n",
      "\n",
      "Epoch 03950: loss did not improve from -170.56747\n",
      "Epoch 3951/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.4683 - val_loss: -171.9407\n",
      "\n",
      "Epoch 03951: loss did not improve from -170.56747\n",
      "Epoch 3952/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.3546 - val_loss: -172.2239\n",
      "\n",
      "Epoch 03952: loss did not improve from -170.56747\n",
      "Epoch 3953/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.3964 - val_loss: -171.9411\n",
      "\n",
      "Epoch 03953: loss did not improve from -170.56747\n",
      "Epoch 3954/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.3280 - val_loss: -172.3506\n",
      "\n",
      "Epoch 03954: loss did not improve from -170.56747\n",
      "Epoch 3955/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.3861 - val_loss: -171.9893\n",
      "\n",
      "Epoch 03955: loss did not improve from -170.56747\n",
      "Epoch 3956/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.4706 - val_loss: -172.0964\n",
      "\n",
      "Epoch 03956: loss did not improve from -170.56747\n",
      "Epoch 3957/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.3772 - val_loss: -172.2243\n",
      "\n",
      "Epoch 03957: loss did not improve from -170.56747\n",
      "Epoch 3958/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.4430 - val_loss: -172.0690\n",
      "\n",
      "Epoch 03958: loss did not improve from -170.56747\n",
      "Epoch 3959/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.5864 - val_loss: -172.3458\n",
      "\n",
      "Epoch 03959: loss improved from -170.56747 to -170.58643, saving model to gendance.h5\n",
      "Epoch 3960/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.3726 - val_loss: -171.8953\n",
      "\n",
      "Epoch 03960: loss did not improve from -170.58643\n",
      "Epoch 3961/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.3919 - val_loss: -172.3856\n",
      "\n",
      "Epoch 03961: loss did not improve from -170.58643\n",
      "Epoch 3962/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.4952 - val_loss: -171.8138\n",
      "\n",
      "Epoch 03962: loss did not improve from -170.58643\n",
      "Epoch 3963/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.3041 - val_loss: -172.2164\n",
      "\n",
      "Epoch 03963: loss did not improve from -170.58643\n",
      "Epoch 3964/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.2783 - val_loss: -171.9187\n",
      "\n",
      "Epoch 03964: loss did not improve from -170.58643\n",
      "Epoch 3965/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.5194 - val_loss: -172.2746\n",
      "\n",
      "Epoch 03965: loss did not improve from -170.58643\n",
      "Epoch 3966/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.4635 - val_loss: -172.0701\n",
      "\n",
      "Epoch 03966: loss did not improve from -170.58643\n",
      "Epoch 3967/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.5268 - val_loss: -172.2560\n",
      "\n",
      "Epoch 03967: loss did not improve from -170.58643\n",
      "Epoch 3968/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.4681 - val_loss: -171.9937\n",
      "\n",
      "Epoch 03968: loss did not improve from -170.58643\n",
      "Epoch 3969/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.4146 - val_loss: -172.1355\n",
      "\n",
      "Epoch 03969: loss did not improve from -170.58643\n",
      "Epoch 3970/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.1654 - val_loss: -172.2182\n",
      "\n",
      "Epoch 03970: loss did not improve from -170.58643\n",
      "Epoch 3971/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.4405 - val_loss: -171.8193\n",
      "\n",
      "Epoch 03971: loss did not improve from -170.58643\n",
      "Epoch 3972/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.5295 - val_loss: -172.3089\n",
      "\n",
      "Epoch 03972: loss did not improve from -170.58643\n",
      "Epoch 3973/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.2294 - val_loss: -171.5859\n",
      "\n",
      "Epoch 03973: loss did not improve from -170.58643\n",
      "Epoch 3974/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.2200 - val_loss: -172.3879\n",
      "\n",
      "Epoch 03974: loss did not improve from -170.58643\n",
      "Epoch 3975/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.2315 - val_loss: -171.8746\n",
      "\n",
      "Epoch 03975: loss did not improve from -170.58643\n",
      "Epoch 3976/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.4051 - val_loss: -172.2137\n",
      "\n",
      "Epoch 03976: loss did not improve from -170.58643\n",
      "Epoch 3977/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.4979 - val_loss: -171.8499\n",
      "\n",
      "Epoch 03977: loss did not improve from -170.58643\n",
      "Epoch 3978/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.5161 - val_loss: -172.4136\n",
      "\n",
      "Epoch 03978: loss did not improve from -170.58643\n",
      "Epoch 3979/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.5404 - val_loss: -172.0044\n",
      "\n",
      "Epoch 03979: loss did not improve from -170.58643\n",
      "Epoch 3980/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.3758 - val_loss: -172.0236\n",
      "\n",
      "Epoch 03980: loss did not improve from -170.58643\n",
      "Epoch 3981/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.5221 - val_loss: -172.3687\n",
      "\n",
      "Epoch 03981: loss did not improve from -170.58643\n",
      "Epoch 3982/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.6473 - val_loss: -172.0477\n",
      "\n",
      "Epoch 03982: loss improved from -170.58643 to -170.64732, saving model to gendance.h5\n",
      "Epoch 3983/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.5764 - val_loss: -172.4346\n",
      "\n",
      "Epoch 03983: loss did not improve from -170.64732\n",
      "Epoch 3984/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.3426 - val_loss: -171.8788\n",
      "\n",
      "Epoch 03984: loss did not improve from -170.64732\n",
      "Epoch 3985/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.4256 - val_loss: -172.3364\n",
      "\n",
      "Epoch 03985: loss did not improve from -170.64732\n",
      "Epoch 3986/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.2122 - val_loss: -171.9724\n",
      "\n",
      "Epoch 03986: loss did not improve from -170.64732\n",
      "Epoch 3987/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.4428 - val_loss: -172.1604\n",
      "\n",
      "Epoch 03987: loss did not improve from -170.64732\n",
      "Epoch 3988/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.3808 - val_loss: -171.8782\n",
      "\n",
      "Epoch 03988: loss did not improve from -170.64732\n",
      "Epoch 3989/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.3948 - val_loss: -172.2959\n",
      "\n",
      "Epoch 03989: loss did not improve from -170.64732\n",
      "Epoch 3990/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.5141 - val_loss: -172.1081\n",
      "\n",
      "Epoch 03990: loss did not improve from -170.64732\n",
      "Epoch 3991/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.7048 - val_loss: -172.2723\n",
      "\n",
      "Epoch 03991: loss improved from -170.64732 to -170.70481, saving model to gendance.h5\n",
      "Epoch 3992/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -170.7225 - val_loss: -172.4291\n",
      "\n",
      "Epoch 03992: loss improved from -170.70481 to -170.72253, saving model to gendance.h5\n",
      "Epoch 3993/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.6283 - val_loss: -172.2340\n",
      "\n",
      "Epoch 03993: loss did not improve from -170.72253\n",
      "Epoch 3994/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.6345 - val_loss: -172.3332\n",
      "\n",
      "Epoch 03994: loss did not improve from -170.72253\n",
      "Epoch 3995/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.4442 - val_loss: -172.0897\n",
      "\n",
      "Epoch 03995: loss did not improve from -170.72253\n",
      "Epoch 3996/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -170.5202 - val_loss: -172.2947\n",
      "\n",
      "Epoch 03996: loss did not improve from -170.72253\n",
      "Epoch 3997/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.5802 - val_loss: -172.1107\n",
      "\n",
      "Epoch 03997: loss did not improve from -170.72253\n",
      "Epoch 3998/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.2802 - val_loss: -172.2111\n",
      "\n",
      "Epoch 03998: loss did not improve from -170.72253\n",
      "Epoch 3999/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.1630 - val_loss: -171.7695\n",
      "\n",
      "Epoch 03999: loss did not improve from -170.72253\n",
      "Epoch 4000/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.3261 - val_loss: -172.3703\n",
      "\n",
      "Epoch 04000: loss did not improve from -170.72253\n",
      "Epoch 4001/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.2739 - val_loss: -171.8421\n",
      "\n",
      "Epoch 04001: loss did not improve from -170.72253\n",
      "Epoch 4002/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.2971 - val_loss: -172.2182\n",
      "\n",
      "Epoch 04002: loss did not improve from -170.72253\n",
      "Epoch 4003/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.6101 - val_loss: -171.8710\n",
      "\n",
      "Epoch 04003: loss did not improve from -170.72253\n",
      "Epoch 4004/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -170.4756 - val_loss: -172.4874\n",
      "\n",
      "Epoch 04004: loss did not improve from -170.72253\n",
      "Epoch 4005/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.3865 - val_loss: -171.9560\n",
      "\n",
      "Epoch 04005: loss did not improve from -170.72253\n",
      "Epoch 4006/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.5756 - val_loss: -172.2077\n",
      "\n",
      "Epoch 04006: loss did not improve from -170.72253\n",
      "Epoch 4007/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.4677 - val_loss: -172.1982\n",
      "\n",
      "Epoch 04007: loss did not improve from -170.72253\n",
      "Epoch 4008/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.4941 - val_loss: -172.0201\n",
      "\n",
      "Epoch 04008: loss did not improve from -170.72253\n",
      "Epoch 4009/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.3319 - val_loss: -172.2061\n",
      "\n",
      "Epoch 04009: loss did not improve from -170.72253\n",
      "Epoch 4010/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.4735 - val_loss: -171.7923\n",
      "\n",
      "Epoch 04010: loss did not improve from -170.72253\n",
      "Epoch 4011/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.1289 - val_loss: -172.2328\n",
      "\n",
      "Epoch 04011: loss did not improve from -170.72253\n",
      "Epoch 4012/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.3320 - val_loss: -171.6101\n",
      "\n",
      "Epoch 04012: loss did not improve from -170.72253\n",
      "Epoch 4013/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.1575 - val_loss: -172.0654\n",
      "\n",
      "Epoch 04013: loss did not improve from -170.72253\n",
      "Epoch 4014/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -169.9815 - val_loss: -171.7112\n",
      "\n",
      "Epoch 04014: loss did not improve from -170.72253\n",
      "Epoch 4015/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.3898 - val_loss: -172.0758\n",
      "\n",
      "Epoch 04015: loss did not improve from -170.72253\n",
      "Epoch 4016/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.4159 - val_loss: -172.0380\n",
      "\n",
      "Epoch 04016: loss did not improve from -170.72253\n",
      "Epoch 4017/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -170.4801 - val_loss: -172.2755\n",
      "\n",
      "Epoch 04017: loss did not improve from -170.72253\n",
      "Epoch 4018/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.6610 - val_loss: -172.1930\n",
      "\n",
      "Epoch 04018: loss did not improve from -170.72253\n",
      "Epoch 4019/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.5615 - val_loss: -172.4171\n",
      "\n",
      "Epoch 04019: loss did not improve from -170.72253\n",
      "Epoch 4020/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.7356 - val_loss: -172.0114\n",
      "\n",
      "Epoch 04020: loss improved from -170.72253 to -170.73558, saving model to gendance.h5\n",
      "Epoch 4021/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.6276 - val_loss: -172.3791\n",
      "\n",
      "Epoch 04021: loss did not improve from -170.73558\n",
      "Epoch 4022/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.6123 - val_loss: -172.4356\n",
      "\n",
      "Epoch 04022: loss did not improve from -170.73558\n",
      "Epoch 4023/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.4527 - val_loss: -172.0290\n",
      "\n",
      "Epoch 04023: loss did not improve from -170.73558\n",
      "Epoch 4024/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.4313 - val_loss: -172.2619\n",
      "\n",
      "Epoch 04024: loss did not improve from -170.73558\n",
      "Epoch 4025/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.5635 - val_loss: -171.9483\n",
      "\n",
      "Epoch 04025: loss did not improve from -170.73558\n",
      "Epoch 4026/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.5482 - val_loss: -172.3998\n",
      "\n",
      "Epoch 04026: loss did not improve from -170.73558\n",
      "Epoch 4027/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.4581 - val_loss: -172.1881\n",
      "\n",
      "Epoch 04027: loss did not improve from -170.73558\n",
      "Epoch 4028/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.4708 - val_loss: -172.2114\n",
      "\n",
      "Epoch 04028: loss did not improve from -170.73558\n",
      "Epoch 4029/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.6565 - val_loss: -172.4286\n",
      "\n",
      "Epoch 04029: loss did not improve from -170.73558\n",
      "Epoch 4030/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.6049 - val_loss: -172.2039\n",
      "\n",
      "Epoch 04030: loss did not improve from -170.73558\n",
      "Epoch 4031/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.5967 - val_loss: -172.3118\n",
      "\n",
      "Epoch 04031: loss did not improve from -170.73558\n",
      "Epoch 4032/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.6114 - val_loss: -172.0907\n",
      "\n",
      "Epoch 04032: loss did not improve from -170.73558\n",
      "Epoch 4033/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.6725 - val_loss: -172.4618\n",
      "\n",
      "Epoch 04033: loss did not improve from -170.73558\n",
      "Epoch 4034/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.5966 - val_loss: -171.9091\n",
      "\n",
      "Epoch 04034: loss did not improve from -170.73558\n",
      "Epoch 4035/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.4245 - val_loss: -172.3366\n",
      "\n",
      "Epoch 04035: loss did not improve from -170.73558\n",
      "Epoch 4036/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.4094 - val_loss: -171.8558\n",
      "\n",
      "Epoch 04036: loss did not improve from -170.73558\n",
      "Epoch 4037/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.7163 - val_loss: -172.2712\n",
      "\n",
      "Epoch 04037: loss did not improve from -170.73558\n",
      "Epoch 4038/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.6756 - val_loss: -172.2350\n",
      "\n",
      "Epoch 04038: loss did not improve from -170.73558\n",
      "Epoch 4039/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.4416 - val_loss: -172.3454\n",
      "\n",
      "Epoch 04039: loss did not improve from -170.73558\n",
      "Epoch 4040/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.3900 - val_loss: -172.2356\n",
      "\n",
      "Epoch 04040: loss did not improve from -170.73558\n",
      "Epoch 4041/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.4236 - val_loss: -172.3956\n",
      "\n",
      "Epoch 04041: loss did not improve from -170.73558\n",
      "Epoch 4042/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.7863 - val_loss: -172.2901\n",
      "\n",
      "Epoch 04042: loss improved from -170.73558 to -170.78626, saving model to gendance.h5\n",
      "Epoch 4043/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.4882 - val_loss: -172.2383\n",
      "\n",
      "Epoch 04043: loss did not improve from -170.78626\n",
      "Epoch 4044/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.6456 - val_loss: -172.3147\n",
      "\n",
      "Epoch 04044: loss did not improve from -170.78626\n",
      "Epoch 4045/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.5147 - val_loss: -172.3373\n",
      "\n",
      "Epoch 04045: loss did not improve from -170.78626\n",
      "Epoch 4046/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.7246 - val_loss: -172.3351\n",
      "\n",
      "Epoch 04046: loss did not improve from -170.78626\n",
      "Epoch 4047/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.4231 - val_loss: -172.2572\n",
      "\n",
      "Epoch 04047: loss did not improve from -170.78626\n",
      "Epoch 4048/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.4256 - val_loss: -172.0924\n",
      "\n",
      "Epoch 04048: loss did not improve from -170.78626\n",
      "Epoch 4049/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.2554 - val_loss: -172.2541\n",
      "\n",
      "Epoch 04049: loss did not improve from -170.78626\n",
      "Epoch 4050/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.5389 - val_loss: -172.2901\n",
      "\n",
      "Epoch 04050: loss did not improve from -170.78626\n",
      "Epoch 4051/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.4772 - val_loss: -172.1544\n",
      "\n",
      "Epoch 04051: loss did not improve from -170.78626\n",
      "Epoch 4052/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.6539 - val_loss: -172.4111\n",
      "\n",
      "Epoch 04052: loss did not improve from -170.78626\n",
      "Epoch 4053/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.3269 - val_loss: -171.9568\n",
      "\n",
      "Epoch 04053: loss did not improve from -170.78626\n",
      "Epoch 4054/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.5194 - val_loss: -172.3512\n",
      "\n",
      "Epoch 04054: loss did not improve from -170.78626\n",
      "Epoch 4055/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.1415 - val_loss: -171.6260\n",
      "\n",
      "Epoch 04055: loss did not improve from -170.78626\n",
      "Epoch 4056/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.4461 - val_loss: -172.2778\n",
      "\n",
      "Epoch 04056: loss did not improve from -170.78626\n",
      "Epoch 4057/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.6770 - val_loss: -172.0882\n",
      "\n",
      "Epoch 04057: loss did not improve from -170.78626\n",
      "Epoch 4058/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.7786 - val_loss: -172.4198\n",
      "\n",
      "Epoch 04058: loss did not improve from -170.78626\n",
      "Epoch 4059/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.5803 - val_loss: -171.9736\n",
      "\n",
      "Epoch 04059: loss did not improve from -170.78626\n",
      "Epoch 4060/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.7510 - val_loss: -172.5851\n",
      "\n",
      "Epoch 04060: loss did not improve from -170.78626\n",
      "Epoch 4061/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -170.4471 - val_loss: -171.9462\n",
      "\n",
      "Epoch 04061: loss did not improve from -170.78626\n",
      "Epoch 4062/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.3958 - val_loss: -172.1913\n",
      "\n",
      "Epoch 04062: loss did not improve from -170.78626\n",
      "Epoch 4063/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.7578 - val_loss: -172.3996\n",
      "\n",
      "Epoch 04063: loss did not improve from -170.78626\n",
      "Epoch 4064/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.5777 - val_loss: -172.0651\n",
      "\n",
      "Epoch 04064: loss did not improve from -170.78626\n",
      "Epoch 4065/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.5132 - val_loss: -172.3437\n",
      "\n",
      "Epoch 04065: loss did not improve from -170.78626\n",
      "Epoch 4066/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.4082 - val_loss: -172.1674\n",
      "\n",
      "Epoch 04066: loss did not improve from -170.78626\n",
      "Epoch 4067/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.6047 - val_loss: -172.3565\n",
      "\n",
      "Epoch 04067: loss did not improve from -170.78626\n",
      "Epoch 4068/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.5674 - val_loss: -171.7615\n",
      "\n",
      "Epoch 04068: loss did not improve from -170.78626\n",
      "Epoch 4069/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.2904 - val_loss: -172.4164\n",
      "\n",
      "Epoch 04069: loss did not improve from -170.78626\n",
      "Epoch 4070/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -170.5539 - val_loss: -171.7413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 04070: loss did not improve from -170.78626\n",
      "Epoch 4071/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.3979 - val_loss: -172.4779\n",
      "\n",
      "Epoch 04071: loss did not improve from -170.78626\n",
      "Epoch 4072/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.6116 - val_loss: -172.1479\n",
      "\n",
      "Epoch 04072: loss did not improve from -170.78626\n",
      "Epoch 4073/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.5781 - val_loss: -172.2102\n",
      "\n",
      "Epoch 04073: loss did not improve from -170.78626\n",
      "Epoch 4074/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.5687 - val_loss: -172.5500\n",
      "\n",
      "Epoch 04074: loss did not improve from -170.78626\n",
      "Epoch 4075/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.6841 - val_loss: -172.1835\n",
      "\n",
      "Epoch 04075: loss did not improve from -170.78626\n",
      "Epoch 4076/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.6258 - val_loss: -172.3626\n",
      "\n",
      "Epoch 04076: loss did not improve from -170.78626\n",
      "Epoch 4077/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.4405 - val_loss: -172.2570\n",
      "\n",
      "Epoch 04077: loss did not improve from -170.78626\n",
      "Epoch 4078/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.5861 - val_loss: -172.4130\n",
      "\n",
      "Epoch 04078: loss did not improve from -170.78626\n",
      "Epoch 4079/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.6212 - val_loss: -172.1359\n",
      "\n",
      "Epoch 04079: loss did not improve from -170.78626\n",
      "Epoch 4080/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.5562 - val_loss: -172.3431\n",
      "\n",
      "Epoch 04080: loss did not improve from -170.78626\n",
      "Epoch 4081/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.7110 - val_loss: -172.1641\n",
      "\n",
      "Epoch 04081: loss did not improve from -170.78626\n",
      "Epoch 4082/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.4965 - val_loss: -172.4948\n",
      "\n",
      "Epoch 04082: loss did not improve from -170.78626\n",
      "Epoch 4083/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.3516 - val_loss: -172.1852\n",
      "\n",
      "Epoch 04083: loss did not improve from -170.78626\n",
      "Epoch 4084/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.7079 - val_loss: -172.2738\n",
      "\n",
      "Epoch 04084: loss did not improve from -170.78626\n",
      "Epoch 4085/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.5936 - val_loss: -172.1908\n",
      "\n",
      "Epoch 04085: loss did not improve from -170.78626\n",
      "Epoch 4086/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.5559 - val_loss: -172.3142\n",
      "\n",
      "Epoch 04086: loss did not improve from -170.78626\n",
      "Epoch 4087/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.7929 - val_loss: -172.1778\n",
      "\n",
      "Epoch 04087: loss improved from -170.78626 to -170.79293, saving model to gendance.h5\n",
      "Epoch 4088/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.5250 - val_loss: -172.2143\n",
      "\n",
      "Epoch 04088: loss did not improve from -170.79293\n",
      "Epoch 4089/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.5962 - val_loss: -171.8969\n",
      "\n",
      "Epoch 04089: loss did not improve from -170.79293\n",
      "Epoch 4090/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.5636 - val_loss: -172.3251\n",
      "\n",
      "Epoch 04090: loss did not improve from -170.79293\n",
      "Epoch 4091/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.5553 - val_loss: -171.9807\n",
      "\n",
      "Epoch 04091: loss did not improve from -170.79293\n",
      "Epoch 4092/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.6652 - val_loss: -172.3831\n",
      "\n",
      "Epoch 04092: loss did not improve from -170.79293\n",
      "Epoch 4093/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.7247 - val_loss: -172.0579\n",
      "\n",
      "Epoch 04093: loss did not improve from -170.79293\n",
      "Epoch 4094/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.5995 - val_loss: -172.2180\n",
      "\n",
      "Epoch 04094: loss did not improve from -170.79293\n",
      "Epoch 4095/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9282 - val_loss: -172.3363\n",
      "\n",
      "Epoch 04095: loss improved from -170.79293 to -170.92821, saving model to gendance.h5\n",
      "Epoch 4096/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.7741 - val_loss: -172.3389\n",
      "\n",
      "Epoch 04096: loss did not improve from -170.92821\n",
      "Epoch 4097/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.6083 - val_loss: -172.4666\n",
      "\n",
      "Epoch 04097: loss did not improve from -170.92821\n",
      "Epoch 4098/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.6966 - val_loss: -172.2975\n",
      "\n",
      "Epoch 04098: loss did not improve from -170.92821\n",
      "Epoch 4099/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.6752 - val_loss: -172.3596\n",
      "\n",
      "Epoch 04099: loss did not improve from -170.92821\n",
      "Epoch 4100/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.4932 - val_loss: -172.2230\n",
      "\n",
      "Epoch 04100: loss did not improve from -170.92821\n",
      "Epoch 4101/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.7861 - val_loss: -172.4687\n",
      "\n",
      "Epoch 04101: loss did not improve from -170.92821\n",
      "Epoch 4102/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.4841 - val_loss: -172.0367\n",
      "\n",
      "Epoch 04102: loss did not improve from -170.92821\n",
      "Epoch 4103/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.5720 - val_loss: -172.2927\n",
      "\n",
      "Epoch 04103: loss did not improve from -170.92821\n",
      "Epoch 4104/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.6877 - val_loss: -172.2654\n",
      "\n",
      "Epoch 04104: loss did not improve from -170.92821\n",
      "Epoch 4105/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.7750 - val_loss: -172.5122\n",
      "\n",
      "Epoch 04105: loss did not improve from -170.92821\n",
      "Epoch 4106/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.6330 - val_loss: -172.1540\n",
      "\n",
      "Epoch 04106: loss did not improve from -170.92821\n",
      "Epoch 4107/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.6934 - val_loss: -172.3123\n",
      "\n",
      "Epoch 04107: loss did not improve from -170.92821\n",
      "Epoch 4108/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.6121 - val_loss: -172.1795\n",
      "\n",
      "Epoch 04108: loss did not improve from -170.92821\n",
      "Epoch 4109/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.6678 - val_loss: -172.3077\n",
      "\n",
      "Epoch 04109: loss did not improve from -170.92821\n",
      "Epoch 4110/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.7311 - val_loss: -172.3020\n",
      "\n",
      "Epoch 04110: loss did not improve from -170.92821\n",
      "Epoch 4111/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.6734 - val_loss: -172.1955\n",
      "\n",
      "Epoch 04111: loss did not improve from -170.92821\n",
      "Epoch 4112/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.4794 - val_loss: -172.4099\n",
      "\n",
      "Epoch 04112: loss did not improve from -170.92821\n",
      "Epoch 4113/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.3557 - val_loss: -171.8278\n",
      "\n",
      "Epoch 04113: loss did not improve from -170.92821\n",
      "Epoch 4114/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.2428 - val_loss: -172.2303\n",
      "\n",
      "Epoch 04114: loss did not improve from -170.92821\n",
      "Epoch 4115/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.1436 - val_loss: -171.4008\n",
      "\n",
      "Epoch 04115: loss did not improve from -170.92821\n",
      "Epoch 4116/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.3870 - val_loss: -172.3856\n",
      "\n",
      "Epoch 04116: loss did not improve from -170.92821\n",
      "Epoch 4117/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.5186 - val_loss: -171.8920\n",
      "\n",
      "Epoch 04117: loss did not improve from -170.92821\n",
      "Epoch 4118/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.8461 - val_loss: -172.6143\n",
      "\n",
      "Epoch 04118: loss did not improve from -170.92821\n",
      "Epoch 4119/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.7656 - val_loss: -172.2517\n",
      "\n",
      "Epoch 04119: loss did not improve from -170.92821\n",
      "Epoch 4120/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9731 - val_loss: -172.4956\n",
      "\n",
      "Epoch 04120: loss improved from -170.92821 to -170.97309, saving model to gendance.h5\n",
      "Epoch 4121/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.8456 - val_loss: -172.3993\n",
      "\n",
      "Epoch 04121: loss did not improve from -170.97309\n",
      "Epoch 4122/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.7948 - val_loss: -172.3287\n",
      "\n",
      "Epoch 04122: loss did not improve from -170.97309\n",
      "Epoch 4123/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.7309 - val_loss: -172.4683\n",
      "\n",
      "Epoch 04123: loss did not improve from -170.97309\n",
      "Epoch 4124/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.6736 - val_loss: -172.1964\n",
      "\n",
      "Epoch 04124: loss did not improve from -170.97309\n",
      "Epoch 4125/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.7163 - val_loss: -172.4420\n",
      "\n",
      "Epoch 04125: loss did not improve from -170.97309\n",
      "Epoch 4126/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.5411 - val_loss: -172.4700\n",
      "\n",
      "Epoch 04126: loss did not improve from -170.97309\n",
      "Epoch 4127/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.8316 - val_loss: -172.3473\n",
      "\n",
      "Epoch 04127: loss did not improve from -170.97309\n",
      "Epoch 4128/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9593 - val_loss: -172.2611\n",
      "\n",
      "Epoch 04128: loss did not improve from -170.97309\n",
      "Epoch 4129/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.7286 - val_loss: -172.4398\n",
      "\n",
      "Epoch 04129: loss did not improve from -170.97309\n",
      "Epoch 4130/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.7159 - val_loss: -172.2286\n",
      "\n",
      "Epoch 04130: loss did not improve from -170.97309\n",
      "Epoch 4131/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.7387 - val_loss: -172.5155\n",
      "\n",
      "Epoch 04131: loss did not improve from -170.97309\n",
      "Epoch 4132/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.8776 - val_loss: -172.5203\n",
      "\n",
      "Epoch 04132: loss did not improve from -170.97309\n",
      "Epoch 4133/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.8721 - val_loss: -172.4788\n",
      "\n",
      "Epoch 04133: loss did not improve from -170.97309\n",
      "Epoch 4134/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -170.7916 - val_loss: -172.5391\n",
      "\n",
      "Epoch 04134: loss did not improve from -170.97309\n",
      "Epoch 4135/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9375 - val_loss: -172.3924\n",
      "\n",
      "Epoch 04135: loss did not improve from -170.97309\n",
      "Epoch 4136/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.8002 - val_loss: -172.5096\n",
      "\n",
      "Epoch 04136: loss did not improve from -170.97309\n",
      "Epoch 4137/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.7555 - val_loss: -172.4195\n",
      "\n",
      "Epoch 04137: loss did not improve from -170.97309\n",
      "Epoch 4138/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.8251 - val_loss: -172.3870\n",
      "\n",
      "Epoch 04138: loss did not improve from -170.97309\n",
      "Epoch 4139/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.8192 - val_loss: -172.3456\n",
      "\n",
      "Epoch 04139: loss did not improve from -170.97309\n",
      "Epoch 4140/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.6943 - val_loss: -172.4483\n",
      "\n",
      "Epoch 04140: loss did not improve from -170.97309\n",
      "Epoch 4141/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9349 - val_loss: -172.6518\n",
      "\n",
      "Epoch 04141: loss did not improve from -170.97309\n",
      "Epoch 4142/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.8066 - val_loss: -172.3456\n",
      "\n",
      "Epoch 04142: loss did not improve from -170.97309\n",
      "Epoch 4143/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9938 - val_loss: -172.5002\n",
      "\n",
      "Epoch 04143: loss improved from -170.97309 to -170.99384, saving model to gendance.h5\n",
      "Epoch 4144/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9209 - val_loss: -172.3196\n",
      "\n",
      "Epoch 04144: loss did not improve from -170.99384\n",
      "Epoch 4145/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9011 - val_loss: -172.5140\n",
      "\n",
      "Epoch 04145: loss did not improve from -170.99384\n",
      "Epoch 4146/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9138 - val_loss: -172.0052\n",
      "\n",
      "Epoch 04146: loss did not improve from -170.99384\n",
      "Epoch 4147/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.5811 - val_loss: -172.4463\n",
      "\n",
      "Epoch 04147: loss did not improve from -170.99384\n",
      "Epoch 4148/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.8212 - val_loss: -172.3455\n",
      "\n",
      "Epoch 04148: loss did not improve from -170.99384\n",
      "Epoch 4149/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.5988 - val_loss: -172.2184\n",
      "\n",
      "Epoch 04149: loss did not improve from -170.99384\n",
      "Epoch 4150/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.6442 - val_loss: -172.4544\n",
      "\n",
      "Epoch 04150: loss did not improve from -170.99384\n",
      "Epoch 4151/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.5629 - val_loss: -171.9300\n",
      "\n",
      "Epoch 04151: loss did not improve from -170.99384\n",
      "Epoch 4152/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.6136 - val_loss: -172.4385\n",
      "\n",
      "Epoch 04152: loss did not improve from -170.99384\n",
      "Epoch 4153/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.3605 - val_loss: -172.0200\n",
      "\n",
      "Epoch 04153: loss did not improve from -170.99384\n",
      "Epoch 4154/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.6699 - val_loss: -172.4971\n",
      "\n",
      "Epoch 04154: loss did not improve from -170.99384\n",
      "Epoch 4155/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.6978 - val_loss: -171.9097\n",
      "\n",
      "Epoch 04155: loss did not improve from -170.99384\n",
      "Epoch 4156/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.7624 - val_loss: -172.5271\n",
      "\n",
      "Epoch 04156: loss did not improve from -170.99384\n",
      "Epoch 4157/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.8883 - val_loss: -172.3014\n",
      "\n",
      "Epoch 04157: loss did not improve from -170.99384\n",
      "Epoch 4158/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.7229 - val_loss: -172.2117\n",
      "\n",
      "Epoch 04158: loss did not improve from -170.99384\n",
      "Epoch 4159/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.7312 - val_loss: -172.4584\n",
      "\n",
      "Epoch 04159: loss did not improve from -170.99384\n",
      "Epoch 4160/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9776 - val_loss: -172.4433\n",
      "\n",
      "Epoch 04160: loss did not improve from -170.99384\n",
      "Epoch 4161/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.6767 - val_loss: -172.0470\n",
      "\n",
      "Epoch 04161: loss did not improve from -170.99384\n",
      "Epoch 4162/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.5475 - val_loss: -172.4317\n",
      "\n",
      "Epoch 04162: loss did not improve from -170.99384\n",
      "Epoch 4163/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.6304 - val_loss: -171.6485\n",
      "\n",
      "Epoch 04163: loss did not improve from -170.99384\n",
      "Epoch 4164/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.6958 - val_loss: -172.4933\n",
      "\n",
      "Epoch 04164: loss did not improve from -170.99384\n",
      "Epoch 4165/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.5589 - val_loss: -171.6186\n",
      "\n",
      "Epoch 04165: loss did not improve from -170.99384\n",
      "Epoch 4166/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.6635 - val_loss: -172.4273\n",
      "\n",
      "Epoch 04166: loss did not improve from -170.99384\n",
      "Epoch 4167/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.8368 - val_loss: -172.2337\n",
      "\n",
      "Epoch 04167: loss did not improve from -170.99384\n",
      "Epoch 4168/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.7569 - val_loss: -172.3506\n",
      "\n",
      "Epoch 04168: loss did not improve from -170.99384\n",
      "Epoch 4169/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9605 - val_loss: -172.5136\n",
      "\n",
      "Epoch 04169: loss did not improve from -170.99384\n",
      "Epoch 4170/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.8044 - val_loss: -172.3095\n",
      "\n",
      "Epoch 04170: loss did not improve from -170.99384\n",
      "Epoch 4171/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -170.5900 - val_loss: -172.3367\n",
      "\n",
      "Epoch 04171: loss did not improve from -170.99384\n",
      "Epoch 4172/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.7468 - val_loss: -172.4169\n",
      "\n",
      "Epoch 04172: loss did not improve from -170.99384\n",
      "Epoch 4173/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9296 - val_loss: -172.4287\n",
      "\n",
      "Epoch 04173: loss did not improve from -170.99384\n",
      "Epoch 4174/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.8862 - val_loss: -172.4041\n",
      "\n",
      "Epoch 04174: loss did not improve from -170.99384\n",
      "Epoch 4175/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.8002 - val_loss: -172.5027\n",
      "\n",
      "Epoch 04175: loss did not improve from -170.99384\n",
      "Epoch 4176/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.6459 - val_loss: -172.3840\n",
      "\n",
      "Epoch 04176: loss did not improve from -170.99384\n",
      "Epoch 4177/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.8921 - val_loss: -172.5662\n",
      "\n",
      "Epoch 04177: loss did not improve from -170.99384\n",
      "Epoch 4178/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.6762 - val_loss: -172.1302\n",
      "\n",
      "Epoch 04178: loss did not improve from -170.99384\n",
      "Epoch 4179/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.8368 - val_loss: -172.4491\n",
      "\n",
      "Epoch 04179: loss did not improve from -170.99384\n",
      "Epoch 4180/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9181 - val_loss: -172.3799\n",
      "\n",
      "Epoch 04180: loss did not improve from -170.99384\n",
      "Epoch 4181/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -170.9433 - val_loss: -172.5426\n",
      "\n",
      "Epoch 04181: loss did not improve from -170.99384\n",
      "Epoch 4182/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9796 - val_loss: -172.2908\n",
      "\n",
      "Epoch 04182: loss did not improve from -170.99384\n",
      "Epoch 4183/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9446 - val_loss: -172.5326\n",
      "\n",
      "Epoch 04183: loss did not improve from -170.99384\n",
      "Epoch 4184/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.7878 - val_loss: -172.2833\n",
      "\n",
      "Epoch 04184: loss did not improve from -170.99384\n",
      "Epoch 4185/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.7314 - val_loss: -172.4720\n",
      "\n",
      "Epoch 04185: loss did not improve from -170.99384\n",
      "Epoch 4186/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.8675 - val_loss: -172.5655\n",
      "\n",
      "Epoch 04186: loss did not improve from -170.99384\n",
      "Epoch 4187/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9144 - val_loss: -172.3804\n",
      "\n",
      "Epoch 04187: loss did not improve from -170.99384\n",
      "Epoch 4188/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.8646 - val_loss: -172.5330\n",
      "\n",
      "Epoch 04188: loss did not improve from -170.99384\n",
      "Epoch 4189/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.7119 - val_loss: -171.9746\n",
      "\n",
      "Epoch 04189: loss did not improve from -170.99384\n",
      "Epoch 4190/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.7176 - val_loss: -172.4354\n",
      "\n",
      "Epoch 04190: loss did not improve from -170.99384\n",
      "Epoch 4191/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.6404 - val_loss: -171.9921\n",
      "\n",
      "Epoch 04191: loss did not improve from -170.99384\n",
      "Epoch 4192/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.7909 - val_loss: -172.3689\n",
      "\n",
      "Epoch 04192: loss did not improve from -170.99384\n",
      "Epoch 4193/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9550 - val_loss: -172.2672\n",
      "\n",
      "Epoch 04193: loss did not improve from -170.99384\n",
      "Epoch 4194/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.8819 - val_loss: -172.5016\n",
      "\n",
      "Epoch 04194: loss did not improve from -170.99384\n",
      "Epoch 4195/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.8938 - val_loss: -172.1149\n",
      "\n",
      "Epoch 04195: loss did not improve from -170.99384\n",
      "Epoch 4196/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.8370 - val_loss: -172.4180\n",
      "\n",
      "Epoch 04196: loss did not improve from -170.99384\n",
      "Epoch 4197/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.6046 - val_loss: -172.4173\n",
      "\n",
      "Epoch 04197: loss did not improve from -170.99384\n",
      "Epoch 4198/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.8504 - val_loss: -172.0720\n",
      "\n",
      "Epoch 04198: loss did not improve from -170.99384\n",
      "Epoch 4199/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.7369 - val_loss: -172.3636\n",
      "\n",
      "Epoch 04199: loss did not improve from -170.99384\n",
      "Epoch 4200/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.8474 - val_loss: -172.2824\n",
      "\n",
      "Epoch 04200: loss did not improve from -170.99384\n",
      "Epoch 4201/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.0290 - val_loss: -172.7172\n",
      "\n",
      "Epoch 04201: loss improved from -170.99384 to -171.02897, saving model to gendance.h5\n",
      "Epoch 4202/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.8642 - val_loss: -172.2455\n",
      "\n",
      "Epoch 04202: loss did not improve from -171.02897\n",
      "Epoch 4203/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.0216 - val_loss: -172.5605\n",
      "\n",
      "Epoch 04203: loss did not improve from -171.02897\n",
      "Epoch 4204/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9277 - val_loss: -172.4560\n",
      "\n",
      "Epoch 04204: loss did not improve from -171.02897\n",
      "Epoch 4205/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9033 - val_loss: -172.5446\n",
      "\n",
      "Epoch 04205: loss did not improve from -171.02897\n",
      "Epoch 4206/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.8824 - val_loss: -172.4683\n",
      "\n",
      "Epoch 04206: loss did not improve from -171.02897\n",
      "Epoch 4207/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.8543 - val_loss: -172.1829\n",
      "\n",
      "Epoch 04207: loss did not improve from -171.02897\n",
      "Epoch 4208/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.7927 - val_loss: -172.5517\n",
      "\n",
      "Epoch 04208: loss did not improve from -171.02897\n",
      "Epoch 4209/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9081 - val_loss: -172.1973\n",
      "\n",
      "Epoch 04209: loss did not improve from -171.02897\n",
      "Epoch 4210/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2195 - val_loss: -172.6573\n",
      "\n",
      "Epoch 04210: loss improved from -171.02897 to -171.21954, saving model to gendance.h5\n",
      "Epoch 4211/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9404 - val_loss: -172.2832\n",
      "\n",
      "Epoch 04211: loss did not improve from -171.21954\n",
      "Epoch 4212/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9084 - val_loss: -172.6371\n",
      "\n",
      "Epoch 04212: loss did not improve from -171.21954\n",
      "Epoch 4213/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.0453 - val_loss: -172.2530\n",
      "\n",
      "Epoch 04213: loss did not improve from -171.21954\n",
      "Epoch 4214/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.1458 - val_loss: -172.6384\n",
      "\n",
      "Epoch 04214: loss did not improve from -171.21954\n",
      "Epoch 4215/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.0507 - val_loss: -172.3399\n",
      "\n",
      "Epoch 04215: loss did not improve from -171.21954\n",
      "Epoch 4216/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.8708 - val_loss: -172.5682\n",
      "\n",
      "Epoch 04216: loss did not improve from -171.21954\n",
      "Epoch 4217/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.8864 - val_loss: -172.4754\n",
      "\n",
      "Epoch 04217: loss did not improve from -171.21954\n",
      "Epoch 4218/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.8630 - val_loss: -172.5894\n",
      "\n",
      "Epoch 04218: loss did not improve from -171.21954\n",
      "Epoch 4219/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.0838 - val_loss: -172.4348\n",
      "\n",
      "Epoch 04219: loss did not improve from -171.21954\n",
      "Epoch 4220/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9373 - val_loss: -172.4649\n",
      "\n",
      "Epoch 04220: loss did not improve from -171.21954\n",
      "Epoch 4221/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9180 - val_loss: -172.3079\n",
      "\n",
      "Epoch 04221: loss did not improve from -171.21954\n",
      "Epoch 4222/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.6393 - val_loss: -172.3494\n",
      "\n",
      "Epoch 04222: loss did not improve from -171.21954\n",
      "Epoch 4223/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.6118 - val_loss: -172.3553\n",
      "\n",
      "Epoch 04223: loss did not improve from -171.21954\n",
      "Epoch 4224/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.4404 - val_loss: -172.0347\n",
      "\n",
      "Epoch 04224: loss did not improve from -171.21954\n",
      "Epoch 4225/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.5948 - val_loss: -172.4016\n",
      "\n",
      "Epoch 04225: loss did not improve from -171.21954\n",
      "Epoch 4226/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.5385 - val_loss: -171.9553\n",
      "\n",
      "Epoch 04226: loss did not improve from -171.21954\n",
      "Epoch 4227/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.4816 - val_loss: -172.6354\n",
      "\n",
      "Epoch 04227: loss did not improve from -171.21954\n",
      "Epoch 4228/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.5656 - val_loss: -171.6186\n",
      "\n",
      "Epoch 04228: loss did not improve from -171.21954\n",
      "Epoch 4229/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.7926 - val_loss: -172.4966\n",
      "\n",
      "Epoch 04229: loss did not improve from -171.21954\n",
      "Epoch 4230/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.7380 - val_loss: -172.0757\n",
      "\n",
      "Epoch 04230: loss did not improve from -171.21954\n",
      "Epoch 4231/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9444 - val_loss: -172.6717\n",
      "\n",
      "Epoch 04231: loss did not improve from -171.21954\n",
      "Epoch 4232/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.0807 - val_loss: -172.3068\n",
      "\n",
      "Epoch 04232: loss did not improve from -171.21954\n",
      "Epoch 4233/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9065 - val_loss: -172.4601\n",
      "\n",
      "Epoch 04233: loss did not improve from -171.21954\n",
      "Epoch 4234/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.0937 - val_loss: -172.4632\n",
      "\n",
      "Epoch 04234: loss did not improve from -171.21954\n",
      "Epoch 4235/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9698 - val_loss: -172.5035\n",
      "\n",
      "Epoch 04235: loss did not improve from -171.21954\n",
      "Epoch 4236/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.8392 - val_loss: -172.4779\n",
      "\n",
      "Epoch 04236: loss did not improve from -171.21954\n",
      "Epoch 4237/10000\n",
      "16167/16167 [==============================] - 1s 33us/step - loss: -170.9664 - val_loss: -172.2700\n",
      "\n",
      "Epoch 04237: loss did not improve from -171.21954\n",
      "Epoch 4238/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.0032 - val_loss: -172.4913\n",
      "\n",
      "Epoch 04238: loss did not improve from -171.21954\n",
      "Epoch 4239/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.0089 - val_loss: -172.3751\n",
      "\n",
      "Epoch 04239: loss did not improve from -171.21954\n",
      "Epoch 4240/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9014 - val_loss: -172.5667\n",
      "\n",
      "Epoch 04240: loss did not improve from -171.21954\n",
      "Epoch 4241/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9161 - val_loss: -172.3444\n",
      "\n",
      "Epoch 04241: loss did not improve from -171.21954\n",
      "Epoch 4242/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9490 - val_loss: -172.5491\n",
      "\n",
      "Epoch 04242: loss did not improve from -171.21954\n",
      "Epoch 4243/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.0012 - val_loss: -172.4287\n",
      "\n",
      "Epoch 04243: loss did not improve from -171.21954\n",
      "Epoch 4244/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.1704 - val_loss: -172.5712\n",
      "\n",
      "Epoch 04244: loss did not improve from -171.21954\n",
      "Epoch 4245/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.0298 - val_loss: -172.6031\n",
      "\n",
      "Epoch 04245: loss did not improve from -171.21954\n",
      "Epoch 4246/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2387 - val_loss: -172.6125\n",
      "\n",
      "Epoch 04246: loss improved from -171.21954 to -171.23868, saving model to gendance.h5\n",
      "Epoch 4247/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2306 - val_loss: -172.6498\n",
      "\n",
      "Epoch 04247: loss did not improve from -171.23868\n",
      "Epoch 4248/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.7886 - val_loss: -172.4932\n",
      "\n",
      "Epoch 04248: loss did not improve from -171.23868\n",
      "Epoch 4249/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9854 - val_loss: -172.3275\n",
      "\n",
      "Epoch 04249: loss did not improve from -171.23868\n",
      "Epoch 4250/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2532 - val_loss: -172.6216\n",
      "\n",
      "Epoch 04250: loss improved from -171.23868 to -171.25316, saving model to gendance.h5\n",
      "Epoch 4251/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.8773 - val_loss: -172.5147\n",
      "\n",
      "Epoch 04251: loss did not improve from -171.25316\n",
      "Epoch 4252/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.6779 - val_loss: -171.9215\n",
      "\n",
      "Epoch 04252: loss did not improve from -171.25316\n",
      "Epoch 4253/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.8663 - val_loss: -172.6765\n",
      "\n",
      "Epoch 04253: loss did not improve from -171.25316\n",
      "Epoch 4254/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9276 - val_loss: -172.1548\n",
      "\n",
      "Epoch 04254: loss did not improve from -171.25316\n",
      "Epoch 4255/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9325 - val_loss: -172.7001\n",
      "\n",
      "Epoch 04255: loss did not improve from -171.25316\n",
      "Epoch 4256/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.0841 - val_loss: -172.3807\n",
      "\n",
      "Epoch 04256: loss did not improve from -171.25316\n",
      "Epoch 4257/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.0386 - val_loss: -172.6818\n",
      "\n",
      "Epoch 04257: loss did not improve from -171.25316\n",
      "Epoch 4258/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.1283 - val_loss: -172.3409\n",
      "\n",
      "Epoch 04258: loss did not improve from -171.25316\n",
      "Epoch 4259/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9964 - val_loss: -172.6772\n",
      "\n",
      "Epoch 04259: loss did not improve from -171.25316\n",
      "Epoch 4260/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.7966 - val_loss: -172.4059\n",
      "\n",
      "Epoch 04260: loss did not improve from -171.25316\n",
      "Epoch 4261/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9971 - val_loss: -172.1925\n",
      "\n",
      "Epoch 04261: loss did not improve from -171.25316\n",
      "Epoch 4262/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.7385 - val_loss: -172.4538\n",
      "\n",
      "Epoch 04262: loss did not improve from -171.25316\n",
      "Epoch 4263/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.8202 - val_loss: -172.2408\n",
      "\n",
      "Epoch 04263: loss did not improve from -171.25316\n",
      "Epoch 4264/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.0105 - val_loss: -172.6749\n",
      "\n",
      "Epoch 04264: loss did not improve from -171.25316\n",
      "Epoch 4265/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.6285 - val_loss: -172.1160\n",
      "\n",
      "Epoch 04265: loss did not improve from -171.25316\n",
      "Epoch 4266/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9936 - val_loss: -172.5644\n",
      "\n",
      "Epoch 04266: loss did not improve from -171.25316\n",
      "Epoch 4267/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9732 - val_loss: -172.1686\n",
      "\n",
      "Epoch 04267: loss did not improve from -171.25316\n",
      "Epoch 4268/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.0198 - val_loss: -172.5987\n",
      "\n",
      "Epoch 04268: loss did not improve from -171.25316\n",
      "Epoch 4269/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9914 - val_loss: -172.5391\n",
      "\n",
      "Epoch 04269: loss did not improve from -171.25316\n",
      "Epoch 4270/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.1782 - val_loss: -172.6959\n",
      "\n",
      "Epoch 04270: loss did not improve from -171.25316\n",
      "Epoch 4271/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9621 - val_loss: -172.5222\n",
      "\n",
      "Epoch 04271: loss did not improve from -171.25316\n",
      "Epoch 4272/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2821 - val_loss: -172.6987\n",
      "\n",
      "Epoch 04272: loss improved from -171.25316 to -171.28210, saving model to gendance.h5\n",
      "Epoch 4273/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.0234 - val_loss: -172.5818\n",
      "\n",
      "Epoch 04273: loss did not improve from -171.28210\n",
      "Epoch 4274/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.0717 - val_loss: -172.4668\n",
      "\n",
      "Epoch 04274: loss did not improve from -171.28210\n",
      "Epoch 4275/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.3425 - val_loss: -172.8134\n",
      "\n",
      "Epoch 04275: loss improved from -171.28210 to -171.34255, saving model to gendance.h5\n",
      "Epoch 4276/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.1779 - val_loss: -172.5947\n",
      "\n",
      "Epoch 04276: loss did not improve from -171.34255\n",
      "Epoch 4277/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.3160 - val_loss: -172.7473\n",
      "\n",
      "Epoch 04277: loss did not improve from -171.34255\n",
      "Epoch 4278/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2958 - val_loss: -172.7945\n",
      "\n",
      "Epoch 04278: loss did not improve from -171.34255\n",
      "Epoch 4279/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.0044 - val_loss: -172.5423\n",
      "\n",
      "Epoch 04279: loss did not improve from -171.34255\n",
      "Epoch 4280/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.0833 - val_loss: -172.7819\n",
      "\n",
      "Epoch 04280: loss did not improve from -171.34255\n",
      "Epoch 4281/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.0921 - val_loss: -172.4940\n",
      "\n",
      "Epoch 04281: loss did not improve from -171.34255\n",
      "Epoch 4282/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.0159 - val_loss: -172.5858\n",
      "\n",
      "Epoch 04282: loss did not improve from -171.34255\n",
      "Epoch 4283/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.0320 - val_loss: -172.6906\n",
      "\n",
      "Epoch 04283: loss did not improve from -171.34255\n",
      "Epoch 4284/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.0438 - val_loss: -172.3647\n",
      "\n",
      "Epoch 04284: loss did not improve from -171.34255\n",
      "Epoch 4285/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9560 - val_loss: -172.6533\n",
      "\n",
      "Epoch 04285: loss did not improve from -171.34255\n",
      "Epoch 4286/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.1565 - val_loss: -172.4292\n",
      "\n",
      "Epoch 04286: loss did not improve from -171.34255\n",
      "Epoch 4287/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9776 - val_loss: -172.6066\n",
      "\n",
      "Epoch 04287: loss did not improve from -171.34255\n",
      "Epoch 4288/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.8587 - val_loss: -172.3779\n",
      "\n",
      "Epoch 04288: loss did not improve from -171.34255\n",
      "Epoch 4289/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.8658 - val_loss: -172.5561\n",
      "\n",
      "Epoch 04289: loss did not improve from -171.34255\n",
      "Epoch 4290/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9410 - val_loss: -172.4596\n",
      "\n",
      "Epoch 04290: loss did not improve from -171.34255\n",
      "Epoch 4291/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9252 - val_loss: -172.6324\n",
      "\n",
      "Epoch 04291: loss did not improve from -171.34255\n",
      "Epoch 4292/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9066 - val_loss: -172.4615\n",
      "\n",
      "Epoch 04292: loss did not improve from -171.34255\n",
      "Epoch 4293/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.1054 - val_loss: -172.6348\n",
      "\n",
      "Epoch 04293: loss did not improve from -171.34255\n",
      "Epoch 4294/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.0851 - val_loss: -172.5521\n",
      "\n",
      "Epoch 04294: loss did not improve from -171.34255\n",
      "Epoch 4295/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.3730 - val_loss: -172.8082\n",
      "\n",
      "Epoch 04295: loss improved from -171.34255 to -171.37305, saving model to gendance.h5\n",
      "Epoch 4296/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.1855 - val_loss: -172.6845\n",
      "\n",
      "Epoch 04296: loss did not improve from -171.37305\n",
      "Epoch 4297/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.0777 - val_loss: -172.6021\n",
      "\n",
      "Epoch 04297: loss did not improve from -171.37305\n",
      "Epoch 4298/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.0933 - val_loss: -172.7293\n",
      "\n",
      "Epoch 04298: loss did not improve from -171.37305\n",
      "Epoch 4299/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2282 - val_loss: -172.5788\n",
      "\n",
      "Epoch 04299: loss did not improve from -171.37305\n",
      "Epoch 4300/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.0664 - val_loss: -172.5847\n",
      "\n",
      "Epoch 04300: loss did not improve from -171.37305\n",
      "Epoch 4301/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2920 - val_loss: -172.5996\n",
      "\n",
      "Epoch 04301: loss did not improve from -171.37305\n",
      "Epoch 4302/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -171.0775 - val_loss: -172.5786\n",
      "\n",
      "Epoch 04302: loss did not improve from -171.37305\n",
      "Epoch 4303/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.1038 - val_loss: -172.6132\n",
      "\n",
      "Epoch 04303: loss did not improve from -171.37305\n",
      "Epoch 4304/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.1935 - val_loss: -172.6202\n",
      "\n",
      "Epoch 04304: loss did not improve from -171.37305\n",
      "Epoch 4305/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.1327 - val_loss: -172.6722\n",
      "\n",
      "Epoch 04305: loss did not improve from -171.37305\n",
      "Epoch 4306/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.1862 - val_loss: -172.5515\n",
      "\n",
      "Epoch 04306: loss did not improve from -171.37305\n",
      "Epoch 4307/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9633 - val_loss: -172.6684\n",
      "\n",
      "Epoch 04307: loss did not improve from -171.37305\n",
      "Epoch 4308/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.8855 - val_loss: -172.4773\n",
      "\n",
      "Epoch 04308: loss did not improve from -171.37305\n",
      "Epoch 4309/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.1349 - val_loss: -172.8513\n",
      "\n",
      "Epoch 04309: loss did not improve from -171.37305\n",
      "Epoch 4310/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.0932 - val_loss: -172.2558\n",
      "\n",
      "Epoch 04310: loss did not improve from -171.37305\n",
      "Epoch 4311/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9969 - val_loss: -172.6778\n",
      "\n",
      "Epoch 04311: loss did not improve from -171.37305\n",
      "Epoch 4312/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9800 - val_loss: -172.2861\n",
      "\n",
      "Epoch 04312: loss did not improve from -171.37305\n",
      "Epoch 4313/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.8954 - val_loss: -172.5578\n",
      "\n",
      "Epoch 04313: loss did not improve from -171.37305\n",
      "Epoch 4314/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.1084 - val_loss: -172.0578\n",
      "\n",
      "Epoch 04314: loss did not improve from -171.37305\n",
      "Epoch 4315/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.0765 - val_loss: -172.4556\n",
      "\n",
      "Epoch 04315: loss did not improve from -171.37305\n",
      "Epoch 4316/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.8180 - val_loss: -171.9186\n",
      "\n",
      "Epoch 04316: loss did not improve from -171.37305\n",
      "Epoch 4317/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9802 - val_loss: -172.7904\n",
      "\n",
      "Epoch 04317: loss did not improve from -171.37305\n",
      "Epoch 4318/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.1255 - val_loss: -172.7261\n",
      "\n",
      "Epoch 04318: loss did not improve from -171.37305\n",
      "Epoch 4319/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9788 - val_loss: -172.6795\n",
      "\n",
      "Epoch 04319: loss did not improve from -171.37305\n",
      "Epoch 4320/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2339 - val_loss: -172.8731\n",
      "\n",
      "Epoch 04320: loss did not improve from -171.37305\n",
      "Epoch 4321/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2874 - val_loss: -172.5419\n",
      "\n",
      "Epoch 04321: loss did not improve from -171.37305\n",
      "Epoch 4322/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2157 - val_loss: -172.6848\n",
      "\n",
      "Epoch 04322: loss did not improve from -171.37305\n",
      "Epoch 4323/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.1903 - val_loss: -172.5367\n",
      "\n",
      "Epoch 04323: loss did not improve from -171.37305\n",
      "Epoch 4324/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.1727 - val_loss: -172.8124\n",
      "\n",
      "Epoch 04324: loss did not improve from -171.37305\n",
      "Epoch 4325/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.3059 - val_loss: -172.6933\n",
      "\n",
      "Epoch 04325: loss did not improve from -171.37305\n",
      "Epoch 4326/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9429 - val_loss: -172.6707\n",
      "\n",
      "Epoch 04326: loss did not improve from -171.37305\n",
      "Epoch 4327/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.1958 - val_loss: -172.5457\n",
      "\n",
      "Epoch 04327: loss did not improve from -171.37305\n",
      "Epoch 4328/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.0713 - val_loss: -172.4947\n",
      "\n",
      "Epoch 04328: loss did not improve from -171.37305\n",
      "Epoch 4329/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2114 - val_loss: -172.6914\n",
      "\n",
      "Epoch 04329: loss did not improve from -171.37305\n",
      "Epoch 4330/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.1856 - val_loss: -172.8523\n",
      "\n",
      "Epoch 04330: loss did not improve from -171.37305\n",
      "Epoch 4331/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4421 - val_loss: -172.7734\n",
      "\n",
      "Epoch 04331: loss improved from -171.37305 to -171.44206, saving model to gendance.h5\n",
      "Epoch 4332/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.3502 - val_loss: -172.6856\n",
      "\n",
      "Epoch 04332: loss did not improve from -171.44206\n",
      "Epoch 4333/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.1827 - val_loss: -172.4513\n",
      "\n",
      "Epoch 04333: loss did not improve from -171.44206\n",
      "Epoch 4334/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.0995 - val_loss: -172.8072\n",
      "\n",
      "Epoch 04334: loss did not improve from -171.44206\n",
      "Epoch 4335/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4499 - val_loss: -172.6668\n",
      "\n",
      "Epoch 04335: loss improved from -171.44206 to -171.44993, saving model to gendance.h5\n",
      "Epoch 4336/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2156 - val_loss: -172.7532\n",
      "\n",
      "Epoch 04336: loss did not improve from -171.44993\n",
      "Epoch 4337/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.0303 - val_loss: -172.5394\n",
      "\n",
      "Epoch 04337: loss did not improve from -171.44993\n",
      "Epoch 4338/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.0360 - val_loss: -172.5487\n",
      "\n",
      "Epoch 04338: loss did not improve from -171.44993\n",
      "Epoch 4339/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.0536 - val_loss: -172.6662\n",
      "\n",
      "Epoch 04339: loss did not improve from -171.44993\n",
      "Epoch 4340/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9716 - val_loss: -172.2291\n",
      "\n",
      "Epoch 04340: loss did not improve from -171.44993\n",
      "Epoch 4341/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.8566 - val_loss: -172.7092\n",
      "\n",
      "Epoch 04341: loss did not improve from -171.44993\n",
      "Epoch 4342/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9758 - val_loss: -172.0402\n",
      "\n",
      "Epoch 04342: loss did not improve from -171.44993\n",
      "Epoch 4343/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9184 - val_loss: -172.7569\n",
      "\n",
      "Epoch 04343: loss did not improve from -171.44993\n",
      "Epoch 4344/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.8592 - val_loss: -172.0059\n",
      "\n",
      "Epoch 04344: loss did not improve from -171.44993\n",
      "Epoch 4345/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.0327 - val_loss: -172.6760\n",
      "\n",
      "Epoch 04345: loss did not improve from -171.44993\n",
      "Epoch 4346/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.1519 - val_loss: -172.3783\n",
      "\n",
      "Epoch 04346: loss did not improve from -171.44993\n",
      "Epoch 4347/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2140 - val_loss: -172.6193\n",
      "\n",
      "Epoch 04347: loss did not improve from -171.44993\n",
      "Epoch 4348/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.1745 - val_loss: -172.6875\n",
      "\n",
      "Epoch 04348: loss did not improve from -171.44993\n",
      "Epoch 4349/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.3178 - val_loss: -172.4765\n",
      "\n",
      "Epoch 04349: loss did not improve from -171.44993\n",
      "Epoch 4350/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4329 - val_loss: -172.8840\n",
      "\n",
      "Epoch 04350: loss did not improve from -171.44993\n",
      "Epoch 4351/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.0553 - val_loss: -172.5200\n",
      "\n",
      "Epoch 04351: loss did not improve from -171.44993\n",
      "Epoch 4352/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2521 - val_loss: -172.6271\n",
      "\n",
      "Epoch 04352: loss did not improve from -171.44993\n",
      "Epoch 4353/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.3248 - val_loss: -172.6026\n",
      "\n",
      "Epoch 04353: loss did not improve from -171.44993\n",
      "Epoch 4354/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.0474 - val_loss: -172.4878\n",
      "\n",
      "Epoch 04354: loss did not improve from -171.44993\n",
      "Epoch 4355/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.1471 - val_loss: -172.6255\n",
      "\n",
      "Epoch 04355: loss did not improve from -171.44993\n",
      "Epoch 4356/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.1840 - val_loss: -172.6224\n",
      "\n",
      "Epoch 04356: loss did not improve from -171.44993\n",
      "Epoch 4357/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.1926 - val_loss: -172.6288\n",
      "\n",
      "Epoch 04357: loss did not improve from -171.44993\n",
      "Epoch 4358/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.1304 - val_loss: -172.2040\n",
      "\n",
      "Epoch 04358: loss did not improve from -171.44993\n",
      "Epoch 4359/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.0912 - val_loss: -172.6786\n",
      "\n",
      "Epoch 04359: loss did not improve from -171.44993\n",
      "Epoch 4360/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2738 - val_loss: -172.3567\n",
      "\n",
      "Epoch 04360: loss did not improve from -171.44993\n",
      "Epoch 4361/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9140 - val_loss: -172.7753\n",
      "\n",
      "Epoch 04361: loss did not improve from -171.44993\n",
      "Epoch 4362/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.1888 - val_loss: -172.5666\n",
      "\n",
      "Epoch 04362: loss did not improve from -171.44993\n",
      "Epoch 4363/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4922 - val_loss: -172.8196\n",
      "\n",
      "Epoch 04363: loss improved from -171.44993 to -171.49220, saving model to gendance.h5\n",
      "Epoch 4364/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.1996 - val_loss: -172.5518\n",
      "\n",
      "Epoch 04364: loss did not improve from -171.49220\n",
      "Epoch 4365/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.1755 - val_loss: -172.6796\n",
      "\n",
      "Epoch 04365: loss did not improve from -171.49220\n",
      "Epoch 4366/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2414 - val_loss: -172.5816\n",
      "\n",
      "Epoch 04366: loss did not improve from -171.49220\n",
      "Epoch 4367/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.3104 - val_loss: -172.7112\n",
      "\n",
      "Epoch 04367: loss did not improve from -171.49220\n",
      "Epoch 4368/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.1965 - val_loss: -172.2562\n",
      "\n",
      "Epoch 04368: loss did not improve from -171.49220\n",
      "Epoch 4369/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.1767 - val_loss: -172.7868\n",
      "\n",
      "Epoch 04369: loss did not improve from -171.49220\n",
      "Epoch 4370/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.0904 - val_loss: -172.3202\n",
      "\n",
      "Epoch 04370: loss did not improve from -171.49220\n",
      "Epoch 4371/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.1117 - val_loss: -172.6857\n",
      "\n",
      "Epoch 04371: loss did not improve from -171.49220\n",
      "Epoch 4372/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.1052 - val_loss: -172.3197\n",
      "\n",
      "Epoch 04372: loss did not improve from -171.49220\n",
      "Epoch 4373/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.3552 - val_loss: -172.7565\n",
      "\n",
      "Epoch 04373: loss did not improve from -171.49220\n",
      "Epoch 4374/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2336 - val_loss: -172.4509\n",
      "\n",
      "Epoch 04374: loss did not improve from -171.49220\n",
      "Epoch 4375/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4091 - val_loss: -172.6759\n",
      "\n",
      "Epoch 04375: loss did not improve from -171.49220\n",
      "Epoch 4376/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.3723 - val_loss: -172.6925\n",
      "\n",
      "Epoch 04376: loss did not improve from -171.49220\n",
      "Epoch 4377/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.3269 - val_loss: -172.8046\n",
      "\n",
      "Epoch 04377: loss did not improve from -171.49220\n",
      "Epoch 4378/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.3838 - val_loss: -172.6626\n",
      "\n",
      "Epoch 04378: loss did not improve from -171.49220\n",
      "Epoch 4379/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2952 - val_loss: -172.7279\n",
      "\n",
      "Epoch 04379: loss did not improve from -171.49220\n",
      "Epoch 4380/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2374 - val_loss: -172.7498\n",
      "\n",
      "Epoch 04380: loss did not improve from -171.49220\n",
      "Epoch 4381/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2628 - val_loss: -172.5995\n",
      "\n",
      "Epoch 04381: loss did not improve from -171.49220\n",
      "Epoch 4382/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4070 - val_loss: -172.7601\n",
      "\n",
      "Epoch 04382: loss did not improve from -171.49220\n",
      "Epoch 4383/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2256 - val_loss: -172.4335\n",
      "\n",
      "Epoch 04383: loss did not improve from -171.49220\n",
      "Epoch 4384/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.1023 - val_loss: -172.6713\n",
      "\n",
      "Epoch 04384: loss did not improve from -171.49220\n",
      "Epoch 4385/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.1467 - val_loss: -172.4405\n",
      "\n",
      "Epoch 04385: loss did not improve from -171.49220\n",
      "Epoch 4386/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2610 - val_loss: -172.6794\n",
      "\n",
      "Epoch 04386: loss did not improve from -171.49220\n",
      "Epoch 4387/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9926 - val_loss: -172.3877\n",
      "\n",
      "Epoch 04387: loss did not improve from -171.49220\n",
      "Epoch 4388/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.1164 - val_loss: -172.7062\n",
      "\n",
      "Epoch 04388: loss did not improve from -171.49220\n",
      "Epoch 4389/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.3560 - val_loss: -172.3878\n",
      "\n",
      "Epoch 04389: loss did not improve from -171.49220\n",
      "Epoch 4390/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.1643 - val_loss: -172.7367\n",
      "\n",
      "Epoch 04390: loss did not improve from -171.49220\n",
      "Epoch 4391/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2056 - val_loss: -172.1656\n",
      "\n",
      "Epoch 04391: loss did not improve from -171.49220\n",
      "Epoch 4392/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.1054 - val_loss: -172.7819\n",
      "\n",
      "Epoch 04392: loss did not improve from -171.49220\n",
      "Epoch 4393/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2758 - val_loss: -172.4208\n",
      "\n",
      "Epoch 04393: loss did not improve from -171.49220\n",
      "Epoch 4394/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2785 - val_loss: -172.7009\n",
      "\n",
      "Epoch 04394: loss did not improve from -171.49220\n",
      "Epoch 4395/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.3775 - val_loss: -172.8452\n",
      "\n",
      "Epoch 04395: loss did not improve from -171.49220\n",
      "Epoch 4396/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.1333 - val_loss: -172.5218\n",
      "\n",
      "Epoch 04396: loss did not improve from -171.49220\n",
      "Epoch 4397/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.0851 - val_loss: -172.7457\n",
      "\n",
      "Epoch 04397: loss did not improve from -171.49220\n",
      "Epoch 4398/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.1108 - val_loss: -172.2544\n",
      "\n",
      "Epoch 04398: loss did not improve from -171.49220\n",
      "Epoch 4399/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2156 - val_loss: -172.7513\n",
      "\n",
      "Epoch 04399: loss did not improve from -171.49220\n",
      "Epoch 4400/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.1655 - val_loss: -172.1650\n",
      "\n",
      "Epoch 04400: loss did not improve from -171.49220\n",
      "Epoch 4401/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.0835 - val_loss: -172.7427\n",
      "\n",
      "Epoch 04401: loss did not improve from -171.49220\n",
      "Epoch 4402/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.0006 - val_loss: -172.2108\n",
      "\n",
      "Epoch 04402: loss did not improve from -171.49220\n",
      "Epoch 4403/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.3627 - val_loss: -172.7296\n",
      "\n",
      "Epoch 04403: loss did not improve from -171.49220\n",
      "Epoch 4404/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.0921 - val_loss: -172.4130\n",
      "\n",
      "Epoch 04404: loss did not improve from -171.49220\n",
      "Epoch 4405/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2609 - val_loss: -172.7669\n",
      "\n",
      "Epoch 04405: loss did not improve from -171.49220\n",
      "Epoch 4406/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2057 - val_loss: -172.6315\n",
      "\n",
      "Epoch 04406: loss did not improve from -171.49220\n",
      "Epoch 4407/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2046 - val_loss: -172.4129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 04407: loss did not improve from -171.49220\n",
      "Epoch 4408/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2307 - val_loss: -172.8092\n",
      "\n",
      "Epoch 04408: loss did not improve from -171.49220\n",
      "Epoch 4409/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.0938 - val_loss: -172.5242\n",
      "\n",
      "Epoch 04409: loss did not improve from -171.49220\n",
      "Epoch 4410/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.3144 - val_loss: -172.7059\n",
      "\n",
      "Epoch 04410: loss did not improve from -171.49220\n",
      "Epoch 4411/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2886 - val_loss: -172.6018\n",
      "\n",
      "Epoch 04411: loss did not improve from -171.49220\n",
      "Epoch 4412/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.3530 - val_loss: -172.8931\n",
      "\n",
      "Epoch 04412: loss did not improve from -171.49220\n",
      "Epoch 4413/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4568 - val_loss: -172.5722\n",
      "\n",
      "Epoch 04413: loss did not improve from -171.49220\n",
      "Epoch 4414/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2215 - val_loss: -172.6832\n",
      "\n",
      "Epoch 04414: loss did not improve from -171.49220\n",
      "Epoch 4415/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2901 - val_loss: -172.7559\n",
      "\n",
      "Epoch 04415: loss did not improve from -171.49220\n",
      "Epoch 4416/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.3171 - val_loss: -172.6988\n",
      "\n",
      "Epoch 04416: loss did not improve from -171.49220\n",
      "Epoch 4417/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.3907 - val_loss: -172.8665\n",
      "\n",
      "Epoch 04417: loss did not improve from -171.49220\n",
      "Epoch 4418/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.3431 - val_loss: -172.6843\n",
      "\n",
      "Epoch 04418: loss did not improve from -171.49220\n",
      "Epoch 4419/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4053 - val_loss: -172.8260\n",
      "\n",
      "Epoch 04419: loss did not improve from -171.49220\n",
      "Epoch 4420/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4513 - val_loss: -172.6108\n",
      "\n",
      "Epoch 04420: loss did not improve from -171.49220\n",
      "Epoch 4421/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2984 - val_loss: -172.8706\n",
      "\n",
      "Epoch 04421: loss did not improve from -171.49220\n",
      "Epoch 4422/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.1048 - val_loss: -172.4380\n",
      "\n",
      "Epoch 04422: loss did not improve from -171.49220\n",
      "Epoch 4423/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2501 - val_loss: -172.7956\n",
      "\n",
      "Epoch 04423: loss did not improve from -171.49220\n",
      "Epoch 4424/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2410 - val_loss: -172.6127\n",
      "\n",
      "Epoch 04424: loss did not improve from -171.49220\n",
      "Epoch 4425/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.3709 - val_loss: -172.6915\n",
      "\n",
      "Epoch 04425: loss did not improve from -171.49220\n",
      "Epoch 4426/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.3577 - val_loss: -172.8121\n",
      "\n",
      "Epoch 04426: loss did not improve from -171.49220\n",
      "Epoch 4427/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4173 - val_loss: -172.6321\n",
      "\n",
      "Epoch 04427: loss did not improve from -171.49220\n",
      "Epoch 4428/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.5272 - val_loss: -172.9691\n",
      "\n",
      "Epoch 04428: loss improved from -171.49220 to -171.52724, saving model to gendance.h5\n",
      "Epoch 4429/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4167 - val_loss: -172.6550\n",
      "\n",
      "Epoch 04429: loss did not improve from -171.52724\n",
      "Epoch 4430/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -171.4376 - val_loss: -172.7771\n",
      "\n",
      "Epoch 04430: loss did not improve from -171.52724\n",
      "Epoch 4431/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2765 - val_loss: -172.6711\n",
      "\n",
      "Epoch 04431: loss did not improve from -171.52724\n",
      "Epoch 4432/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.1714 - val_loss: -172.7429\n",
      "\n",
      "Epoch 04432: loss did not improve from -171.52724\n",
      "Epoch 4433/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.3642 - val_loss: -172.4798\n",
      "\n",
      "Epoch 04433: loss did not improve from -171.52724\n",
      "Epoch 4434/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.0255 - val_loss: -172.7340\n",
      "\n",
      "Epoch 04434: loss did not improve from -171.52724\n",
      "Epoch 4435/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2833 - val_loss: -172.4137\n",
      "\n",
      "Epoch 04435: loss did not improve from -171.52724\n",
      "Epoch 4436/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2420 - val_loss: -172.7237\n",
      "\n",
      "Epoch 04436: loss did not improve from -171.52724\n",
      "Epoch 4437/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.1501 - val_loss: -172.2221\n",
      "\n",
      "Epoch 04437: loss did not improve from -171.52724\n",
      "Epoch 4438/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.3445 - val_loss: -172.8371\n",
      "\n",
      "Epoch 04438: loss did not improve from -171.52724\n",
      "Epoch 4439/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.0501 - val_loss: -172.0583\n",
      "\n",
      "Epoch 04439: loss did not improve from -171.52724\n",
      "Epoch 4440/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2652 - val_loss: -172.8321\n",
      "\n",
      "Epoch 04440: loss did not improve from -171.52724\n",
      "Epoch 4441/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4557 - val_loss: -172.6337\n",
      "\n",
      "Epoch 04441: loss did not improve from -171.52724\n",
      "Epoch 4442/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -171.3763 - val_loss: -172.6844\n",
      "\n",
      "Epoch 04442: loss did not improve from -171.52724\n",
      "Epoch 4443/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.3705 - val_loss: -172.7819\n",
      "\n",
      "Epoch 04443: loss did not improve from -171.52724\n",
      "Epoch 4444/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4427 - val_loss: -172.6396\n",
      "\n",
      "Epoch 04444: loss did not improve from -171.52724\n",
      "Epoch 4445/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.3179 - val_loss: -172.8097\n",
      "\n",
      "Epoch 04445: loss did not improve from -171.52724\n",
      "Epoch 4446/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2182 - val_loss: -172.5319\n",
      "\n",
      "Epoch 04446: loss did not improve from -171.52724\n",
      "Epoch 4447/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4919 - val_loss: -172.9769\n",
      "\n",
      "Epoch 04447: loss did not improve from -171.52724\n",
      "Epoch 4448/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4796 - val_loss: -172.7799\n",
      "\n",
      "Epoch 04448: loss did not improve from -171.52724\n",
      "Epoch 4449/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4771 - val_loss: -172.5646\n",
      "\n",
      "Epoch 04449: loss did not improve from -171.52724\n",
      "Epoch 4450/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.3405 - val_loss: -172.8226\n",
      "\n",
      "Epoch 04450: loss did not improve from -171.52724\n",
      "Epoch 4451/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.3089 - val_loss: -172.7049\n",
      "\n",
      "Epoch 04451: loss did not improve from -171.52724\n",
      "Epoch 4452/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4318 - val_loss: -172.6713\n",
      "\n",
      "Epoch 04452: loss did not improve from -171.52724\n",
      "Epoch 4453/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4621 - val_loss: -172.8098\n",
      "\n",
      "Epoch 04453: loss did not improve from -171.52724\n",
      "Epoch 4454/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2471 - val_loss: -172.4595\n",
      "\n",
      "Epoch 04454: loss did not improve from -171.52724\n",
      "Epoch 4455/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2984 - val_loss: -172.6830\n",
      "\n",
      "Epoch 04455: loss did not improve from -171.52724\n",
      "Epoch 4456/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4388 - val_loss: -172.7694\n",
      "\n",
      "Epoch 04456: loss did not improve from -171.52724\n",
      "Epoch 4457/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2601 - val_loss: -172.5472\n",
      "\n",
      "Epoch 04457: loss did not improve from -171.52724\n",
      "Epoch 4458/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -170.7204 - val_loss: -172.3884\n",
      "\n",
      "Epoch 04458: loss did not improve from -171.52724\n",
      "Epoch 4459/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.8939 - val_loss: -172.2153\n",
      "\n",
      "Epoch 04459: loss did not improve from -171.52724\n",
      "Epoch 4460/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.8255 - val_loss: -172.5117\n",
      "\n",
      "Epoch 04460: loss did not improve from -171.52724\n",
      "Epoch 4461/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.6247 - val_loss: -171.8868\n",
      "\n",
      "Epoch 04461: loss did not improve from -171.52724\n",
      "Epoch 4462/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9548 - val_loss: -172.7331\n",
      "\n",
      "Epoch 04462: loss did not improve from -171.52724\n",
      "Epoch 4463/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2354 - val_loss: -172.3064\n",
      "\n",
      "Epoch 04463: loss did not improve from -171.52724\n",
      "Epoch 4464/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.3920 - val_loss: -172.9385\n",
      "\n",
      "Epoch 04464: loss did not improve from -171.52724\n",
      "Epoch 4465/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4303 - val_loss: -172.4661\n",
      "\n",
      "Epoch 04465: loss did not improve from -171.52724\n",
      "Epoch 4466/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4835 - val_loss: -172.9119\n",
      "\n",
      "Epoch 04466: loss did not improve from -171.52724\n",
      "Epoch 4467/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.1842 - val_loss: -172.6403\n",
      "\n",
      "Epoch 04467: loss did not improve from -171.52724\n",
      "Epoch 4468/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2237 - val_loss: -172.7082\n",
      "\n",
      "Epoch 04468: loss did not improve from -171.52724\n",
      "Epoch 4469/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4481 - val_loss: -172.9615\n",
      "\n",
      "Epoch 04469: loss did not improve from -171.52724\n",
      "Epoch 4470/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4276 - val_loss: -172.8510\n",
      "\n",
      "Epoch 04470: loss did not improve from -171.52724\n",
      "Epoch 4471/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.5778 - val_loss: -172.8935\n",
      "\n",
      "Epoch 04471: loss improved from -171.52724 to -171.57775, saving model to gendance.h5\n",
      "Epoch 4472/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4162 - val_loss: -172.8216\n",
      "\n",
      "Epoch 04472: loss did not improve from -171.57775\n",
      "Epoch 4473/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4391 - val_loss: -172.8349\n",
      "\n",
      "Epoch 04473: loss did not improve from -171.57775\n",
      "Epoch 4474/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2821 - val_loss: -172.8625\n",
      "\n",
      "Epoch 04474: loss did not improve from -171.57775\n",
      "Epoch 4475/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.3219 - val_loss: -172.8863\n",
      "\n",
      "Epoch 04475: loss did not improve from -171.57775\n",
      "Epoch 4476/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.3302 - val_loss: -172.8086\n",
      "\n",
      "Epoch 04476: loss did not improve from -171.57775\n",
      "Epoch 4477/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4733 - val_loss: -172.9189\n",
      "\n",
      "Epoch 04477: loss did not improve from -171.57775\n",
      "Epoch 4478/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4606 - val_loss: -172.7097\n",
      "\n",
      "Epoch 04478: loss did not improve from -171.57775\n",
      "Epoch 4479/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.3579 - val_loss: -172.8290\n",
      "\n",
      "Epoch 04479: loss did not improve from -171.57775\n",
      "Epoch 4480/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.3550 - val_loss: -172.6818\n",
      "\n",
      "Epoch 04480: loss did not improve from -171.57775\n",
      "Epoch 4481/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2546 - val_loss: -172.8421\n",
      "\n",
      "Epoch 04481: loss did not improve from -171.57775\n",
      "Epoch 4482/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.3241 - val_loss: -172.6052\n",
      "\n",
      "Epoch 04482: loss did not improve from -171.57775\n",
      "Epoch 4483/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4597 - val_loss: -172.9508\n",
      "\n",
      "Epoch 04483: loss did not improve from -171.57775\n",
      "Epoch 4484/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2593 - val_loss: -172.8812\n",
      "\n",
      "Epoch 04484: loss did not improve from -171.57775\n",
      "Epoch 4485/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2622 - val_loss: -172.3994\n",
      "\n",
      "Epoch 04485: loss did not improve from -171.57775\n",
      "Epoch 4486/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2333 - val_loss: -173.0034\n",
      "\n",
      "Epoch 04486: loss did not improve from -171.57775\n",
      "Epoch 4487/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2007 - val_loss: -172.5119\n",
      "\n",
      "Epoch 04487: loss did not improve from -171.57775\n",
      "Epoch 4488/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2782 - val_loss: -172.8296\n",
      "\n",
      "Epoch 04488: loss did not improve from -171.57775\n",
      "Epoch 4489/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.3841 - val_loss: -172.6199\n",
      "\n",
      "Epoch 04489: loss did not improve from -171.57775\n",
      "Epoch 4490/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.5343 - val_loss: -172.9517\n",
      "\n",
      "Epoch 04490: loss did not improve from -171.57775\n",
      "Epoch 4491/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.3409 - val_loss: -172.6187\n",
      "\n",
      "Epoch 04491: loss did not improve from -171.57775\n",
      "Epoch 4492/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4605 - val_loss: -172.9424\n",
      "\n",
      "Epoch 04492: loss did not improve from -171.57775\n",
      "Epoch 4493/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.5045 - val_loss: -172.8454\n",
      "\n",
      "Epoch 04493: loss did not improve from -171.57775\n",
      "Epoch 4494/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.5475 - val_loss: -172.9005\n",
      "\n",
      "Epoch 04494: loss did not improve from -171.57775\n",
      "Epoch 4495/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.5073 - val_loss: -172.6344\n",
      "\n",
      "Epoch 04495: loss did not improve from -171.57775\n",
      "Epoch 4496/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4397 - val_loss: -173.0398\n",
      "\n",
      "Epoch 04496: loss did not improve from -171.57775\n",
      "Epoch 4497/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.5301 - val_loss: -172.8709\n",
      "\n",
      "Epoch 04497: loss did not improve from -171.57775\n",
      "Epoch 4498/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -171.3715 - val_loss: -172.8212\n",
      "\n",
      "Epoch 04498: loss did not improve from -171.57775\n",
      "Epoch 4499/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4933 - val_loss: -172.8488\n",
      "\n",
      "Epoch 04499: loss did not improve from -171.57775\n",
      "Epoch 4500/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2967 - val_loss: -172.5113\n",
      "\n",
      "Epoch 04500: loss did not improve from -171.57775\n",
      "Epoch 4501/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.3431 - val_loss: -172.9672\n",
      "\n",
      "Epoch 04501: loss did not improve from -171.57775\n",
      "Epoch 4502/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2997 - val_loss: -172.6216\n",
      "\n",
      "Epoch 04502: loss did not improve from -171.57775\n",
      "Epoch 4503/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4307 - val_loss: -172.7228\n",
      "\n",
      "Epoch 04503: loss did not improve from -171.57775\n",
      "Epoch 4504/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.7096 - val_loss: -172.9310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 04504: loss improved from -171.57775 to -171.70964, saving model to gendance.h5\n",
      "Epoch 4505/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.5564 - val_loss: -172.7333\n",
      "\n",
      "Epoch 04505: loss did not improve from -171.70964\n",
      "Epoch 4506/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.6754 - val_loss: -173.0798\n",
      "\n",
      "Epoch 04506: loss did not improve from -171.70964\n",
      "Epoch 4507/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.8790 - val_loss: -172.8865\n",
      "\n",
      "Epoch 04507: loss improved from -171.70964 to -171.87899, saving model to gendance.h5\n",
      "Epoch 4508/10000\n",
      "16167/16167 [==============================] - 1s 32us/step - loss: -171.6453 - val_loss: -172.8800\n",
      "\n",
      "Epoch 04508: loss did not improve from -171.87899\n",
      "Epoch 4509/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.5277 - val_loss: -172.9298\n",
      "\n",
      "Epoch 04509: loss did not improve from -171.87899\n",
      "Epoch 4510/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.6109 - val_loss: -172.9460\n",
      "\n",
      "Epoch 04510: loss did not improve from -171.87899\n",
      "Epoch 4511/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.3881 - val_loss: -172.9827\n",
      "\n",
      "Epoch 04511: loss did not improve from -171.87899\n",
      "Epoch 4512/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.3775 - val_loss: -172.7202\n",
      "\n",
      "Epoch 04512: loss did not improve from -171.87899\n",
      "Epoch 4513/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.3788 - val_loss: -172.8473\n",
      "\n",
      "Epoch 04513: loss did not improve from -171.87899\n",
      "Epoch 4514/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.5520 - val_loss: -172.9984\n",
      "\n",
      "Epoch 04514: loss did not improve from -171.87899\n",
      "Epoch 4515/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4196 - val_loss: -173.0134\n",
      "\n",
      "Epoch 04515: loss did not improve from -171.87899\n",
      "Epoch 4516/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.6219 - val_loss: -172.9158\n",
      "\n",
      "Epoch 04516: loss did not improve from -171.87899\n",
      "Epoch 4517/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4922 - val_loss: -172.8799\n",
      "\n",
      "Epoch 04517: loss did not improve from -171.87899\n",
      "Epoch 4518/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.6831 - val_loss: -172.8947\n",
      "\n",
      "Epoch 04518: loss did not improve from -171.87899\n",
      "Epoch 4519/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.3182 - val_loss: -172.9695\n",
      "\n",
      "Epoch 04519: loss did not improve from -171.87899\n",
      "Epoch 4520/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.6577 - val_loss: -172.7061\n",
      "\n",
      "Epoch 04520: loss did not improve from -171.87899\n",
      "Epoch 4521/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4190 - val_loss: -172.7888\n",
      "\n",
      "Epoch 04521: loss did not improve from -171.87899\n",
      "Epoch 4522/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2936 - val_loss: -172.5952\n",
      "\n",
      "Epoch 04522: loss did not improve from -171.87899\n",
      "Epoch 4523/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.3277 - val_loss: -172.7652\n",
      "\n",
      "Epoch 04523: loss did not improve from -171.87899\n",
      "Epoch 4524/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.9595 - val_loss: -172.6931\n",
      "\n",
      "Epoch 04524: loss did not improve from -171.87899\n",
      "Epoch 4525/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.1172 - val_loss: -172.3989\n",
      "\n",
      "Epoch 04525: loss did not improve from -171.87899\n",
      "Epoch 4526/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -170.7288 - val_loss: -172.6894\n",
      "\n",
      "Epoch 04526: loss did not improve from -171.87899\n",
      "Epoch 4527/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.0010 - val_loss: -172.2728\n",
      "\n",
      "Epoch 04527: loss did not improve from -171.87899\n",
      "Epoch 4528/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.1461 - val_loss: -172.9311\n",
      "\n",
      "Epoch 04528: loss did not improve from -171.87899\n",
      "Epoch 4529/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2747 - val_loss: -172.2875\n",
      "\n",
      "Epoch 04529: loss did not improve from -171.87899\n",
      "Epoch 4530/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2690 - val_loss: -173.0541\n",
      "\n",
      "Epoch 04530: loss did not improve from -171.87899\n",
      "Epoch 4531/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4700 - val_loss: -172.8915\n",
      "\n",
      "Epoch 04531: loss did not improve from -171.87899\n",
      "Epoch 4532/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.7363 - val_loss: -173.0385\n",
      "\n",
      "Epoch 04532: loss did not improve from -171.87899\n",
      "Epoch 4533/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.5463 - val_loss: -173.0763\n",
      "\n",
      "Epoch 04533: loss did not improve from -171.87899\n",
      "Epoch 4534/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.5769 - val_loss: -173.0768\n",
      "\n",
      "Epoch 04534: loss did not improve from -171.87899\n",
      "Epoch 4535/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.6091 - val_loss: -172.9871\n",
      "\n",
      "Epoch 04535: loss did not improve from -171.87899\n",
      "Epoch 4536/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4595 - val_loss: -172.8975\n",
      "\n",
      "Epoch 04536: loss did not improve from -171.87899\n",
      "Epoch 4537/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4212 - val_loss: -172.9760\n",
      "\n",
      "Epoch 04537: loss did not improve from -171.87899\n",
      "Epoch 4538/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.5898 - val_loss: -173.0100\n",
      "\n",
      "Epoch 04538: loss did not improve from -171.87899\n",
      "Epoch 4539/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.6345 - val_loss: -172.9069\n",
      "\n",
      "Epoch 04539: loss did not improve from -171.87899\n",
      "Epoch 4540/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4354 - val_loss: -172.9110\n",
      "\n",
      "Epoch 04540: loss did not improve from -171.87899\n",
      "Epoch 4541/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2181 - val_loss: -172.7737\n",
      "\n",
      "Epoch 04541: loss did not improve from -171.87899\n",
      "Epoch 4542/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.6062 - val_loss: -172.9828\n",
      "\n",
      "Epoch 04542: loss did not improve from -171.87899\n",
      "Epoch 4543/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.5771 - val_loss: -172.8674\n",
      "\n",
      "Epoch 04543: loss did not improve from -171.87899\n",
      "Epoch 4544/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.6482 - val_loss: -172.9838\n",
      "\n",
      "Epoch 04544: loss did not improve from -171.87899\n",
      "Epoch 4545/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.7371 - val_loss: -172.8956\n",
      "\n",
      "Epoch 04545: loss did not improve from -171.87899\n",
      "Epoch 4546/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.5430 - val_loss: -172.9385\n",
      "\n",
      "Epoch 04546: loss did not improve from -171.87899\n",
      "Epoch 4547/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.3979 - val_loss: -172.4465\n",
      "\n",
      "Epoch 04547: loss did not improve from -171.87899\n",
      "Epoch 4548/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.5044 - val_loss: -173.0717\n",
      "\n",
      "Epoch 04548: loss did not improve from -171.87899\n",
      "Epoch 4549/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.6308 - val_loss: -172.7665\n",
      "\n",
      "Epoch 04549: loss did not improve from -171.87899\n",
      "Epoch 4550/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.6521 - val_loss: -172.9523\n",
      "\n",
      "Epoch 04550: loss did not improve from -171.87899\n",
      "Epoch 4551/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.7407 - val_loss: -172.5517\n",
      "\n",
      "Epoch 04551: loss did not improve from -171.87899\n",
      "Epoch 4552/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.6788 - val_loss: -173.0287\n",
      "\n",
      "Epoch 04552: loss did not improve from -171.87899\n",
      "Epoch 4553/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.6332 - val_loss: -172.8764\n",
      "\n",
      "Epoch 04553: loss did not improve from -171.87899\n",
      "Epoch 4554/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4808 - val_loss: -172.8805\n",
      "\n",
      "Epoch 04554: loss did not improve from -171.87899\n",
      "Epoch 4555/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.6271 - val_loss: -173.0077\n",
      "\n",
      "Epoch 04555: loss did not improve from -171.87899\n",
      "Epoch 4556/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4704 - val_loss: -172.7090\n",
      "\n",
      "Epoch 04556: loss did not improve from -171.87899\n",
      "Epoch 4557/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.5592 - val_loss: -172.9780\n",
      "\n",
      "Epoch 04557: loss did not improve from -171.87899\n",
      "Epoch 4558/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.5528 - val_loss: -172.7012\n",
      "\n",
      "Epoch 04558: loss did not improve from -171.87899\n",
      "Epoch 4559/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.7106 - val_loss: -173.2596\n",
      "\n",
      "Epoch 04559: loss did not improve from -171.87899\n",
      "Epoch 4560/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4873 - val_loss: -172.6152\n",
      "\n",
      "Epoch 04560: loss did not improve from -171.87899\n",
      "Epoch 4561/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4485 - val_loss: -173.0035\n",
      "\n",
      "Epoch 04561: loss did not improve from -171.87899\n",
      "Epoch 4562/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4963 - val_loss: -172.6299\n",
      "\n",
      "Epoch 04562: loss did not improve from -171.87899\n",
      "Epoch 4563/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.6229 - val_loss: -172.9928\n",
      "\n",
      "Epoch 04563: loss did not improve from -171.87899\n",
      "Epoch 4564/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.6205 - val_loss: -172.7469\n",
      "\n",
      "Epoch 04564: loss did not improve from -171.87899\n",
      "Epoch 4565/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.5692 - val_loss: -173.0189\n",
      "\n",
      "Epoch 04565: loss did not improve from -171.87899\n",
      "Epoch 4566/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.7183 - val_loss: -172.7772\n",
      "\n",
      "Epoch 04566: loss did not improve from -171.87899\n",
      "Epoch 4567/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.5971 - val_loss: -172.7479\n",
      "\n",
      "Epoch 04567: loss did not improve from -171.87899\n",
      "Epoch 4568/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.6533 - val_loss: -172.8722\n",
      "\n",
      "Epoch 04568: loss did not improve from -171.87899\n",
      "Epoch 4569/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.5684 - val_loss: -172.8451\n",
      "\n",
      "Epoch 04569: loss did not improve from -171.87899\n",
      "Epoch 4570/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.3962 - val_loss: -172.8234\n",
      "\n",
      "Epoch 04570: loss did not improve from -171.87899\n",
      "Epoch 4571/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.5302 - val_loss: -172.9592\n",
      "\n",
      "Epoch 04571: loss did not improve from -171.87899\n",
      "Epoch 4572/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.6034 - val_loss: -172.8441\n",
      "\n",
      "Epoch 04572: loss did not improve from -171.87899\n",
      "Epoch 4573/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.3579 - val_loss: -172.6104\n",
      "\n",
      "Epoch 04573: loss did not improve from -171.87899\n",
      "Epoch 4574/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4177 - val_loss: -173.0929\n",
      "\n",
      "Epoch 04574: loss did not improve from -171.87899\n",
      "Epoch 4575/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.3293 - val_loss: -172.3416\n",
      "\n",
      "Epoch 04575: loss did not improve from -171.87899\n",
      "Epoch 4576/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.2172 - val_loss: -172.9554\n",
      "\n",
      "Epoch 04576: loss did not improve from -171.87899\n",
      "Epoch 4577/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4536 - val_loss: -172.5317\n",
      "\n",
      "Epoch 04577: loss did not improve from -171.87899\n",
      "Epoch 4578/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.3447 - val_loss: -173.0583\n",
      "\n",
      "Epoch 04578: loss did not improve from -171.87899\n",
      "Epoch 4579/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4008 - val_loss: -172.6456\n",
      "\n",
      "Epoch 04579: loss did not improve from -171.87899\n",
      "Epoch 4580/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.3250 - val_loss: -172.9158\n",
      "\n",
      "Epoch 04580: loss did not improve from -171.87899\n",
      "Epoch 4581/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4404 - val_loss: -172.5996\n",
      "\n",
      "Epoch 04581: loss did not improve from -171.87899\n",
      "Epoch 4582/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.5124 - val_loss: -172.9843\n",
      "\n",
      "Epoch 04582: loss did not improve from -171.87899\n",
      "Epoch 4583/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4702 - val_loss: -172.8580\n",
      "\n",
      "Epoch 04583: loss did not improve from -171.87899\n",
      "Epoch 4584/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.5901 - val_loss: -172.9739\n",
      "\n",
      "Epoch 04584: loss did not improve from -171.87899\n",
      "Epoch 4585/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4769 - val_loss: -172.9602\n",
      "\n",
      "Epoch 04585: loss did not improve from -171.87899\n",
      "Epoch 4586/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.6649 - val_loss: -172.9441\n",
      "\n",
      "Epoch 04586: loss did not improve from -171.87899\n",
      "Epoch 4587/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.6486 - val_loss: -173.0810\n",
      "\n",
      "Epoch 04587: loss did not improve from -171.87899\n",
      "Epoch 4588/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.7009 - val_loss: -172.9198\n",
      "\n",
      "Epoch 04588: loss did not improve from -171.87899\n",
      "Epoch 4589/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.6775 - val_loss: -172.9553\n",
      "\n",
      "Epoch 04589: loss did not improve from -171.87899\n",
      "Epoch 4590/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.7681 - val_loss: -172.6636\n",
      "\n",
      "Epoch 04590: loss did not improve from -171.87899\n",
      "Epoch 4591/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.6981 - val_loss: -172.9311\n",
      "\n",
      "Epoch 04591: loss did not improve from -171.87899\n",
      "Epoch 4592/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.5881 - val_loss: -172.5877\n",
      "\n",
      "Epoch 04592: loss did not improve from -171.87899\n",
      "Epoch 4593/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.6318 - val_loss: -172.9812\n",
      "\n",
      "Epoch 04593: loss did not improve from -171.87899\n",
      "Epoch 4594/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.7082 - val_loss: -172.7983\n",
      "\n",
      "Epoch 04594: loss did not improve from -171.87899\n",
      "Epoch 4595/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -171.6238 - val_loss: -173.1093\n",
      "\n",
      "Epoch 04595: loss did not improve from -171.87899\n",
      "Epoch 4596/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.7874 - val_loss: -172.9902\n",
      "\n",
      "Epoch 04596: loss did not improve from -171.87899\n",
      "Epoch 4597/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.8432 - val_loss: -173.1086\n",
      "\n",
      "Epoch 04597: loss did not improve from -171.87899\n",
      "Epoch 4598/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.7485 - val_loss: -173.0222\n",
      "\n",
      "Epoch 04598: loss did not improve from -171.87899\n",
      "Epoch 4599/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.7197 - val_loss: -173.0557\n",
      "\n",
      "Epoch 04599: loss did not improve from -171.87899\n",
      "Epoch 4600/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.7905 - val_loss: -173.1056\n",
      "\n",
      "Epoch 04600: loss did not improve from -171.87899\n",
      "Epoch 4601/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.7969 - val_loss: -172.9791\n",
      "\n",
      "Epoch 04601: loss did not improve from -171.87899\n",
      "Epoch 4602/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.7597 - val_loss: -173.0934\n",
      "\n",
      "Epoch 04602: loss did not improve from -171.87899\n",
      "Epoch 4603/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.7529 - val_loss: -172.9130\n",
      "\n",
      "Epoch 04603: loss did not improve from -171.87899\n",
      "Epoch 4604/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.7551 - val_loss: -173.0562\n",
      "\n",
      "Epoch 04604: loss did not improve from -171.87899\n",
      "Epoch 4605/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.8766 - val_loss: -173.1616\n",
      "\n",
      "Epoch 04605: loss did not improve from -171.87899\n",
      "Epoch 4606/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.7059 - val_loss: -172.9664\n",
      "\n",
      "Epoch 04606: loss did not improve from -171.87899\n",
      "Epoch 4607/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.5633 - val_loss: -172.7689\n",
      "\n",
      "Epoch 04607: loss did not improve from -171.87899\n",
      "Epoch 4608/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.7445 - val_loss: -173.1433\n",
      "\n",
      "Epoch 04608: loss did not improve from -171.87899\n",
      "Epoch 4609/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.7337 - val_loss: -172.8565\n",
      "\n",
      "Epoch 04609: loss did not improve from -171.87899\n",
      "Epoch 4610/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.8969 - val_loss: -173.1381\n",
      "\n",
      "Epoch 04610: loss improved from -171.87899 to -171.89692, saving model to gendance.h5\n",
      "Epoch 4611/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.6402 - val_loss: -172.7974\n",
      "\n",
      "Epoch 04611: loss did not improve from -171.89692\n",
      "Epoch 4612/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.6566 - val_loss: -173.1225\n",
      "\n",
      "Epoch 04612: loss did not improve from -171.89692\n",
      "Epoch 4613/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.8548 - val_loss: -172.9808\n",
      "\n",
      "Epoch 04613: loss did not improve from -171.89692\n",
      "Epoch 4614/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.6817 - val_loss: -172.8149\n",
      "\n",
      "Epoch 04614: loss did not improve from -171.89692\n",
      "Epoch 4615/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.5142 - val_loss: -172.9386\n",
      "\n",
      "Epoch 04615: loss did not improve from -171.89692\n",
      "Epoch 4616/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.6602 - val_loss: -172.7824\n",
      "\n",
      "Epoch 04616: loss did not improve from -171.89692\n",
      "Epoch 4617/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4585 - val_loss: -173.0954\n",
      "\n",
      "Epoch 04617: loss did not improve from -171.89692\n",
      "Epoch 4618/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.5010 - val_loss: -172.7124\n",
      "\n",
      "Epoch 04618: loss did not improve from -171.89692\n",
      "Epoch 4619/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.6772 - val_loss: -173.0931\n",
      "\n",
      "Epoch 04619: loss did not improve from -171.89692\n",
      "Epoch 4620/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.6469 - val_loss: -172.6385\n",
      "\n",
      "Epoch 04620: loss did not improve from -171.89692\n",
      "Epoch 4621/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4800 - val_loss: -173.0401\n",
      "\n",
      "Epoch 04621: loss did not improve from -171.89692\n",
      "Epoch 4622/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.7032 - val_loss: -172.5215\n",
      "\n",
      "Epoch 04622: loss did not improve from -171.89692\n",
      "Epoch 4623/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.6332 - val_loss: -172.9310\n",
      "\n",
      "Epoch 04623: loss did not improve from -171.89692\n",
      "Epoch 4624/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.5422 - val_loss: -172.5074\n",
      "\n",
      "Epoch 04624: loss did not improve from -171.89692\n",
      "Epoch 4625/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.6441 - val_loss: -173.0632\n",
      "\n",
      "Epoch 04625: loss did not improve from -171.89692\n",
      "Epoch 4626/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.5621 - val_loss: -172.6712\n",
      "\n",
      "Epoch 04626: loss did not improve from -171.89692\n",
      "Epoch 4627/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.6299 - val_loss: -173.1270\n",
      "\n",
      "Epoch 04627: loss did not improve from -171.89692\n",
      "Epoch 4628/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.5767 - val_loss: -172.9736\n",
      "\n",
      "Epoch 04628: loss did not improve from -171.89692\n",
      "Epoch 4629/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.6806 - val_loss: -172.8940\n",
      "\n",
      "Epoch 04629: loss did not improve from -171.89692\n",
      "Epoch 4630/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.6749 - val_loss: -173.1036\n",
      "\n",
      "Epoch 04630: loss did not improve from -171.89692\n",
      "Epoch 4631/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4980 - val_loss: -172.7244\n",
      "\n",
      "Epoch 04631: loss did not improve from -171.89692\n",
      "Epoch 4632/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.8053 - val_loss: -173.1322\n",
      "\n",
      "Epoch 04632: loss did not improve from -171.89692\n",
      "Epoch 4633/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.7262 - val_loss: -172.6441\n",
      "\n",
      "Epoch 04633: loss did not improve from -171.89692\n",
      "Epoch 4634/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.5480 - val_loss: -173.0267\n",
      "\n",
      "Epoch 04634: loss did not improve from -171.89692\n",
      "Epoch 4635/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.5409 - val_loss: -172.7624\n",
      "\n",
      "Epoch 04635: loss did not improve from -171.89692\n",
      "Epoch 4636/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.7196 - val_loss: -172.9405\n",
      "\n",
      "Epoch 04636: loss did not improve from -171.89692\n",
      "Epoch 4637/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.7367 - val_loss: -172.8942\n",
      "\n",
      "Epoch 04637: loss did not improve from -171.89692\n",
      "Epoch 4638/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.6502 - val_loss: -173.0356\n",
      "\n",
      "Epoch 04638: loss did not improve from -171.89692\n",
      "Epoch 4639/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.7662 - val_loss: -172.9051\n",
      "\n",
      "Epoch 04639: loss did not improve from -171.89692\n",
      "Epoch 4640/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.7861 - val_loss: -173.0396\n",
      "\n",
      "Epoch 04640: loss did not improve from -171.89692\n",
      "Epoch 4641/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.9450 - val_loss: -173.0547\n",
      "\n",
      "Epoch 04641: loss improved from -171.89692 to -171.94503, saving model to gendance.h5\n",
      "Epoch 4642/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -171.8440 - val_loss: -173.1515\n",
      "\n",
      "Epoch 04642: loss did not improve from -171.94503\n",
      "Epoch 4643/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.6649 - val_loss: -172.8934\n",
      "\n",
      "Epoch 04643: loss did not improve from -171.94503\n",
      "Epoch 4644/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -171.7548 - val_loss: -173.1171\n",
      "\n",
      "Epoch 04644: loss did not improve from -171.94503\n",
      "Epoch 4645/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.5859 - val_loss: -172.8811\n",
      "\n",
      "Epoch 04645: loss did not improve from -171.94503\n",
      "Epoch 4646/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.9214 - val_loss: -173.2121\n",
      "\n",
      "Epoch 04646: loss did not improve from -171.94503\n",
      "Epoch 4647/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.8067 - val_loss: -172.7660\n",
      "\n",
      "Epoch 04647: loss did not improve from -171.94503\n",
      "Epoch 4648/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.7116 - val_loss: -173.0207\n",
      "\n",
      "Epoch 04648: loss did not improve from -171.94503\n",
      "Epoch 4649/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.7082 - val_loss: -172.8340\n",
      "\n",
      "Epoch 04649: loss did not improve from -171.94503\n",
      "Epoch 4650/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.7919 - val_loss: -173.0106\n",
      "\n",
      "Epoch 04650: loss did not improve from -171.94503\n",
      "Epoch 4651/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4701 - val_loss: -172.9185\n",
      "\n",
      "Epoch 04651: loss did not improve from -171.94503\n",
      "Epoch 4652/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.8278 - val_loss: -172.9670\n",
      "\n",
      "Epoch 04652: loss did not improve from -171.94503\n",
      "Epoch 4653/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.6466 - val_loss: -173.0398\n",
      "\n",
      "Epoch 04653: loss did not improve from -171.94503\n",
      "Epoch 4654/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.6977 - val_loss: -172.5725\n",
      "\n",
      "Epoch 04654: loss did not improve from -171.94503\n",
      "Epoch 4655/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.5016 - val_loss: -172.9967\n",
      "\n",
      "Epoch 04655: loss did not improve from -171.94503\n",
      "Epoch 4656/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4283 - val_loss: -172.5661\n",
      "\n",
      "Epoch 04656: loss did not improve from -171.94503\n",
      "Epoch 4657/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.6042 - val_loss: -173.0938\n",
      "\n",
      "Epoch 04657: loss did not improve from -171.94503\n",
      "Epoch 4658/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.7266 - val_loss: -172.7264\n",
      "\n",
      "Epoch 04658: loss did not improve from -171.94503\n",
      "Epoch 4659/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.6699 - val_loss: -173.0630\n",
      "\n",
      "Epoch 04659: loss did not improve from -171.94503\n",
      "Epoch 4660/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.0039 - val_loss: -173.0613\n",
      "\n",
      "Epoch 04660: loss improved from -171.94503 to -172.00388, saving model to gendance.h5\n",
      "Epoch 4661/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.7365 - val_loss: -173.0688\n",
      "\n",
      "Epoch 04661: loss did not improve from -172.00388\n",
      "Epoch 4662/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.7341 - val_loss: -173.0418\n",
      "\n",
      "Epoch 04662: loss did not improve from -172.00388\n",
      "Epoch 4663/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.8902 - val_loss: -172.9671\n",
      "\n",
      "Epoch 04663: loss did not improve from -172.00388\n",
      "Epoch 4664/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.8876 - val_loss: -173.1123\n",
      "\n",
      "Epoch 04664: loss did not improve from -172.00388\n",
      "Epoch 4665/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.6687 - val_loss: -172.9614\n",
      "\n",
      "Epoch 04665: loss did not improve from -172.00388\n",
      "Epoch 4666/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.8458 - val_loss: -173.0501\n",
      "\n",
      "Epoch 04666: loss did not improve from -172.00388\n",
      "Epoch 4667/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.9746 - val_loss: -172.8264\n",
      "\n",
      "Epoch 04667: loss did not improve from -172.00388\n",
      "Epoch 4668/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.8010 - val_loss: -173.0732\n",
      "\n",
      "Epoch 04668: loss did not improve from -172.00388\n",
      "Epoch 4669/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.9717 - val_loss: -172.9885\n",
      "\n",
      "Epoch 04669: loss did not improve from -172.00388\n",
      "Epoch 4670/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.8654 - val_loss: -173.2020\n",
      "\n",
      "Epoch 04670: loss did not improve from -172.00388\n",
      "Epoch 4671/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.8492 - val_loss: -172.7420\n",
      "\n",
      "Epoch 04671: loss did not improve from -172.00388\n",
      "Epoch 4672/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.7718 - val_loss: -173.1981\n",
      "\n",
      "Epoch 04672: loss did not improve from -172.00388\n",
      "Epoch 4673/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.6628 - val_loss: -172.6476\n",
      "\n",
      "Epoch 04673: loss did not improve from -172.00388\n",
      "Epoch 4674/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.5643 - val_loss: -172.9865\n",
      "\n",
      "Epoch 04674: loss did not improve from -172.00388\n",
      "Epoch 4675/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.6323 - val_loss: -172.9330\n",
      "\n",
      "Epoch 04675: loss did not improve from -172.00388\n",
      "Epoch 4676/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.5937 - val_loss: -172.7583\n",
      "\n",
      "Epoch 04676: loss did not improve from -172.00388\n",
      "Epoch 4677/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.5927 - val_loss: -172.9174\n",
      "\n",
      "Epoch 04677: loss did not improve from -172.00388\n",
      "Epoch 4678/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4757 - val_loss: -172.7053\n",
      "\n",
      "Epoch 04678: loss did not improve from -172.00388\n",
      "Epoch 4679/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4727 - val_loss: -173.0449\n",
      "\n",
      "Epoch 04679: loss did not improve from -172.00388\n",
      "Epoch 4680/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.4832 - val_loss: -172.4746\n",
      "\n",
      "Epoch 04680: loss did not improve from -172.00388\n",
      "Epoch 4681/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.5160 - val_loss: -172.9996\n",
      "\n",
      "Epoch 04681: loss did not improve from -172.00388\n",
      "Epoch 4682/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.5790 - val_loss: -172.4860\n",
      "\n",
      "Epoch 04682: loss did not improve from -172.00388\n",
      "Epoch 4683/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.5960 - val_loss: -173.0849\n",
      "\n",
      "Epoch 04683: loss did not improve from -172.00388\n",
      "Epoch 4684/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.8502 - val_loss: -172.8753\n",
      "\n",
      "Epoch 04684: loss did not improve from -172.00388\n",
      "Epoch 4685/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.0500 - val_loss: -173.1980\n",
      "\n",
      "Epoch 04685: loss improved from -172.00388 to -172.05003, saving model to gendance.h5\n",
      "Epoch 4686/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.7044 - val_loss: -172.6810\n",
      "\n",
      "Epoch 04686: loss did not improve from -172.05003\n",
      "Epoch 4687/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.9866 - val_loss: -173.2348\n",
      "\n",
      "Epoch 04687: loss did not improve from -172.05003\n",
      "Epoch 4688/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.0771 - val_loss: -173.0870\n",
      "\n",
      "Epoch 04688: loss improved from -172.05003 to -172.07711, saving model to gendance.h5\n",
      "Epoch 4689/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.1188 - val_loss: -173.1925\n",
      "\n",
      "Epoch 04689: loss improved from -172.07711 to -172.11880, saving model to gendance.h5\n",
      "Epoch 4690/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.8834 - val_loss: -173.2133\n",
      "\n",
      "Epoch 04690: loss did not improve from -172.11880\n",
      "Epoch 4691/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.0016 - val_loss: -172.9453\n",
      "\n",
      "Epoch 04691: loss did not improve from -172.11880\n",
      "Epoch 4692/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.7368 - val_loss: -173.1652\n",
      "\n",
      "Epoch 04692: loss did not improve from -172.11880\n",
      "Epoch 4693/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.6983 - val_loss: -173.0275\n",
      "\n",
      "Epoch 04693: loss did not improve from -172.11880\n",
      "Epoch 4694/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.6088 - val_loss: -173.0041\n",
      "\n",
      "Epoch 04694: loss did not improve from -172.11880\n",
      "Epoch 4695/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.6961 - val_loss: -172.8052\n",
      "\n",
      "Epoch 04695: loss did not improve from -172.11880\n",
      "Epoch 4696/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.7487 - val_loss: -173.2405\n",
      "\n",
      "Epoch 04696: loss did not improve from -172.11880\n",
      "Epoch 4697/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.9141 - val_loss: -172.9715\n",
      "\n",
      "Epoch 04697: loss did not improve from -172.11880\n",
      "Epoch 4698/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.0899 - val_loss: -173.1580\n",
      "\n",
      "Epoch 04698: loss did not improve from -172.11880\n",
      "Epoch 4699/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.8492 - val_loss: -173.1111\n",
      "\n",
      "Epoch 04699: loss did not improve from -172.11880\n",
      "Epoch 4700/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.8579 - val_loss: -173.1456\n",
      "\n",
      "Epoch 04700: loss did not improve from -172.11880\n",
      "Epoch 4701/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.9159 - val_loss: -172.9650\n",
      "\n",
      "Epoch 04701: loss did not improve from -172.11880\n",
      "Epoch 4702/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.8931 - val_loss: -173.1885\n",
      "\n",
      "Epoch 04702: loss did not improve from -172.11880\n",
      "Epoch 4703/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.7143 - val_loss: -173.0597\n",
      "\n",
      "Epoch 04703: loss did not improve from -172.11880\n",
      "Epoch 4704/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.7613 - val_loss: -173.0708\n",
      "\n",
      "Epoch 04704: loss did not improve from -172.11880\n",
      "Epoch 4705/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.9227 - val_loss: -173.2085\n",
      "\n",
      "Epoch 04705: loss did not improve from -172.11880\n",
      "Epoch 4706/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.6327 - val_loss: -172.9316\n",
      "\n",
      "Epoch 04706: loss did not improve from -172.11880\n",
      "Epoch 4707/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.7989 - val_loss: -173.1385\n",
      "\n",
      "Epoch 04707: loss did not improve from -172.11880\n",
      "Epoch 4708/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.6216 - val_loss: -172.7325\n",
      "\n",
      "Epoch 04708: loss did not improve from -172.11880\n",
      "Epoch 4709/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.9091 - val_loss: -173.3156\n",
      "\n",
      "Epoch 04709: loss did not improve from -172.11880\n",
      "Epoch 4710/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -171.9199 - val_loss: -172.5646\n",
      "\n",
      "Epoch 04710: loss did not improve from -172.11880\n",
      "Epoch 4711/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.7908 - val_loss: -173.2502\n",
      "\n",
      "Epoch 04711: loss did not improve from -172.11880\n",
      "Epoch 4712/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.8095 - val_loss: -172.8604\n",
      "\n",
      "Epoch 04712: loss did not improve from -172.11880\n",
      "Epoch 4713/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.8684 - val_loss: -173.1338\n",
      "\n",
      "Epoch 04713: loss did not improve from -172.11880\n",
      "Epoch 4714/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.8790 - val_loss: -173.2745\n",
      "\n",
      "Epoch 04714: loss did not improve from -172.11880\n",
      "Epoch 4715/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.7910 - val_loss: -173.1210\n",
      "\n",
      "Epoch 04715: loss did not improve from -172.11880\n",
      "Epoch 4716/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.9889 - val_loss: -173.2861\n",
      "\n",
      "Epoch 04716: loss did not improve from -172.11880\n",
      "Epoch 4717/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.9202 - val_loss: -173.1407\n",
      "\n",
      "Epoch 04717: loss did not improve from -172.11880\n",
      "Epoch 4718/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.0163 - val_loss: -173.2415\n",
      "\n",
      "Epoch 04718: loss did not improve from -172.11880\n",
      "Epoch 4719/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.9360 - val_loss: -173.0692\n",
      "\n",
      "Epoch 04719: loss did not improve from -172.11880\n",
      "Epoch 4720/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.8999 - val_loss: -173.1584\n",
      "\n",
      "Epoch 04720: loss did not improve from -172.11880\n",
      "Epoch 4721/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.0534 - val_loss: -173.0350\n",
      "\n",
      "Epoch 04721: loss did not improve from -172.11880\n",
      "Epoch 4722/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -171.9671 - val_loss: -173.1742\n",
      "\n",
      "Epoch 04722: loss did not improve from -172.11880\n",
      "Epoch 4723/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.7228 - val_loss: -172.7021\n",
      "\n",
      "Epoch 04723: loss did not improve from -172.11880\n",
      "Epoch 4724/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.9504 - val_loss: -173.2299\n",
      "\n",
      "Epoch 04724: loss did not improve from -172.11880\n",
      "Epoch 4725/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.1446 - val_loss: -173.2085\n",
      "\n",
      "Epoch 04725: loss improved from -172.11880 to -172.14463, saving model to gendance.h5\n",
      "Epoch 4726/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.8787 - val_loss: -173.0283\n",
      "\n",
      "Epoch 04726: loss did not improve from -172.14463\n",
      "Epoch 4727/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.9609 - val_loss: -173.2170\n",
      "\n",
      "Epoch 04727: loss did not improve from -172.14463\n",
      "Epoch 4728/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.8700 - val_loss: -172.9208\n",
      "\n",
      "Epoch 04728: loss did not improve from -172.14463\n",
      "Epoch 4729/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.8771 - val_loss: -173.1167\n",
      "\n",
      "Epoch 04729: loss did not improve from -172.14463\n",
      "Epoch 4730/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.0487 - val_loss: -172.8880\n",
      "\n",
      "Epoch 04730: loss did not improve from -172.14463\n",
      "Epoch 4731/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.8660 - val_loss: -173.0013\n",
      "\n",
      "Epoch 04731: loss did not improve from -172.14463\n",
      "Epoch 4732/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.7495 - val_loss: -172.8983\n",
      "\n",
      "Epoch 04732: loss did not improve from -172.14463\n",
      "Epoch 4733/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.9697 - val_loss: -173.1498\n",
      "\n",
      "Epoch 04733: loss did not improve from -172.14463\n",
      "Epoch 4734/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.0617 - val_loss: -173.1891\n",
      "\n",
      "Epoch 04734: loss did not improve from -172.14463\n",
      "Epoch 4735/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.8255 - val_loss: -173.1566\n",
      "\n",
      "Epoch 04735: loss did not improve from -172.14463\n",
      "Epoch 4736/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.9730 - val_loss: -173.0963\n",
      "\n",
      "Epoch 04736: loss did not improve from -172.14463\n",
      "Epoch 4737/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.9637 - val_loss: -173.1827\n",
      "\n",
      "Epoch 04737: loss did not improve from -172.14463\n",
      "Epoch 4738/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.8920 - val_loss: -173.1334\n",
      "\n",
      "Epoch 04738: loss did not improve from -172.14463\n",
      "Epoch 4739/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.6920 - val_loss: -172.9816\n",
      "\n",
      "Epoch 04739: loss did not improve from -172.14463\n",
      "Epoch 4740/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.8032 - val_loss: -173.1831\n",
      "\n",
      "Epoch 04740: loss did not improve from -172.14463\n",
      "Epoch 4741/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.1099 - val_loss: -173.1848\n",
      "\n",
      "Epoch 04741: loss did not improve from -172.14463\n",
      "Epoch 4742/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.7434 - val_loss: -173.1075\n",
      "\n",
      "Epoch 04742: loss did not improve from -172.14463\n",
      "Epoch 4743/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.9490 - val_loss: -172.8863\n",
      "\n",
      "Epoch 04743: loss did not improve from -172.14463\n",
      "Epoch 4744/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.9143 - val_loss: -173.2687\n",
      "\n",
      "Epoch 04744: loss did not improve from -172.14463\n",
      "Epoch 4745/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.0702 - val_loss: -173.0015\n",
      "\n",
      "Epoch 04745: loss did not improve from -172.14463\n",
      "Epoch 4746/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.9406 - val_loss: -173.2478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 04746: loss did not improve from -172.14463\n",
      "Epoch 4747/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.8430 - val_loss: -172.9605\n",
      "\n",
      "Epoch 04747: loss did not improve from -172.14463\n",
      "Epoch 4748/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -171.9613 - val_loss: -172.9741\n",
      "\n",
      "Epoch 04748: loss did not improve from -172.14463\n",
      "Epoch 4749/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -171.8485 - val_loss: -173.2835\n",
      "\n",
      "Epoch 04749: loss did not improve from -172.14463\n",
      "Epoch 4750/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.8669 - val_loss: -172.8195\n",
      "\n",
      "Epoch 04750: loss did not improve from -172.14463\n",
      "Epoch 4751/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.6287 - val_loss: -173.2205\n",
      "\n",
      "Epoch 04751: loss did not improve from -172.14463\n",
      "Epoch 4752/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.7257 - val_loss: -172.4248\n",
      "\n",
      "Epoch 04752: loss did not improve from -172.14463\n",
      "Epoch 4753/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.6041 - val_loss: -173.1156\n",
      "\n",
      "Epoch 04753: loss did not improve from -172.14463\n",
      "Epoch 4754/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.7002 - val_loss: -172.3700\n",
      "\n",
      "Epoch 04754: loss did not improve from -172.14463\n",
      "Epoch 4755/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.7241 - val_loss: -173.3210\n",
      "\n",
      "Epoch 04755: loss did not improve from -172.14463\n",
      "Epoch 4756/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.7243 - val_loss: -172.8935\n",
      "\n",
      "Epoch 04756: loss did not improve from -172.14463\n",
      "Epoch 4757/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.9970 - val_loss: -173.1214\n",
      "\n",
      "Epoch 04757: loss did not improve from -172.14463\n",
      "Epoch 4758/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.8350 - val_loss: -172.8743\n",
      "\n",
      "Epoch 04758: loss did not improve from -172.14463\n",
      "Epoch 4759/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.9542 - val_loss: -173.1364\n",
      "\n",
      "Epoch 04759: loss did not improve from -172.14463\n",
      "Epoch 4760/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.9127 - val_loss: -173.1730\n",
      "\n",
      "Epoch 04760: loss did not improve from -172.14463\n",
      "Epoch 4761/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.6672 - val_loss: -172.7620\n",
      "\n",
      "Epoch 04761: loss did not improve from -172.14463\n",
      "Epoch 4762/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.7436 - val_loss: -173.3838\n",
      "\n",
      "Epoch 04762: loss did not improve from -172.14463\n",
      "Epoch 4763/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.5711 - val_loss: -172.4944\n",
      "\n",
      "Epoch 04763: loss did not improve from -172.14463\n",
      "Epoch 4764/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.8947 - val_loss: -173.3195\n",
      "\n",
      "Epoch 04764: loss did not improve from -172.14463\n",
      "Epoch 4765/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.8198 - val_loss: -172.9146\n",
      "\n",
      "Epoch 04765: loss did not improve from -172.14463\n",
      "Epoch 4766/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.8248 - val_loss: -173.2073\n",
      "\n",
      "Epoch 04766: loss did not improve from -172.14463\n",
      "Epoch 4767/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.9400 - val_loss: -173.0673\n",
      "\n",
      "Epoch 04767: loss did not improve from -172.14463\n",
      "Epoch 4768/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.8893 - val_loss: -173.2053\n",
      "\n",
      "Epoch 04768: loss did not improve from -172.14463\n",
      "Epoch 4769/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.0149 - val_loss: -173.1561\n",
      "\n",
      "Epoch 04769: loss did not improve from -172.14463\n",
      "Epoch 4770/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.8191 - val_loss: -173.1050\n",
      "\n",
      "Epoch 04770: loss did not improve from -172.14463\n",
      "Epoch 4771/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.8550 - val_loss: -173.0868\n",
      "\n",
      "Epoch 04771: loss did not improve from -172.14463\n",
      "Epoch 4772/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.0113 - val_loss: -173.1473\n",
      "\n",
      "Epoch 04772: loss did not improve from -172.14463\n",
      "Epoch 4773/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2768 - val_loss: -173.3033\n",
      "\n",
      "Epoch 04773: loss improved from -172.14463 to -172.27684, saving model to gendance.h5\n",
      "Epoch 4774/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.1557 - val_loss: -172.9748\n",
      "\n",
      "Epoch 04774: loss did not improve from -172.27684\n",
      "Epoch 4775/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.9688 - val_loss: -173.3090\n",
      "\n",
      "Epoch 04775: loss did not improve from -172.27684\n",
      "Epoch 4776/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.9759 - val_loss: -172.9261\n",
      "\n",
      "Epoch 04776: loss did not improve from -172.27684\n",
      "Epoch 4777/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.9059 - val_loss: -173.2457\n",
      "\n",
      "Epoch 04777: loss did not improve from -172.27684\n",
      "Epoch 4778/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.8903 - val_loss: -172.9960\n",
      "\n",
      "Epoch 04778: loss did not improve from -172.27684\n",
      "Epoch 4779/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.8670 - val_loss: -173.3076\n",
      "\n",
      "Epoch 04779: loss did not improve from -172.27684\n",
      "Epoch 4780/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.7403 - val_loss: -172.8711\n",
      "\n",
      "Epoch 04780: loss did not improve from -172.27684\n",
      "Epoch 4781/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.8292 - val_loss: -173.2646\n",
      "\n",
      "Epoch 04781: loss did not improve from -172.27684\n",
      "Epoch 4782/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.9306 - val_loss: -173.1217\n",
      "\n",
      "Epoch 04782: loss did not improve from -172.27684\n",
      "Epoch 4783/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.0944 - val_loss: -173.2684\n",
      "\n",
      "Epoch 04783: loss did not improve from -172.27684\n",
      "Epoch 4784/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.8640 - val_loss: -173.1024\n",
      "\n",
      "Epoch 04784: loss did not improve from -172.27684\n",
      "Epoch 4785/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.0856 - val_loss: -173.2093\n",
      "\n",
      "Epoch 04785: loss did not improve from -172.27684\n",
      "Epoch 4786/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -172.0905 - val_loss: -173.3139\n",
      "\n",
      "Epoch 04786: loss did not improve from -172.27684\n",
      "Epoch 4787/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.0937 - val_loss: -173.2896\n",
      "\n",
      "Epoch 04787: loss did not improve from -172.27684\n",
      "Epoch 4788/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.8659 - val_loss: -172.9273\n",
      "\n",
      "Epoch 04788: loss did not improve from -172.27684\n",
      "Epoch 4789/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.9374 - val_loss: -173.3233\n",
      "\n",
      "Epoch 04789: loss did not improve from -172.27684\n",
      "Epoch 4790/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.8936 - val_loss: -172.8850\n",
      "\n",
      "Epoch 04790: loss did not improve from -172.27684\n",
      "Epoch 4791/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.0496 - val_loss: -173.3305\n",
      "\n",
      "Epoch 04791: loss did not improve from -172.27684\n",
      "Epoch 4792/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.9866 - val_loss: -173.0770\n",
      "\n",
      "Epoch 04792: loss did not improve from -172.27684\n",
      "Epoch 4793/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.0327 - val_loss: -173.4091\n",
      "\n",
      "Epoch 04793: loss did not improve from -172.27684\n",
      "Epoch 4794/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.0746 - val_loss: -173.3638\n",
      "\n",
      "Epoch 04794: loss did not improve from -172.27684\n",
      "Epoch 4795/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.0025 - val_loss: -172.9702\n",
      "\n",
      "Epoch 04795: loss did not improve from -172.27684\n",
      "Epoch 4796/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.8927 - val_loss: -173.3577\n",
      "\n",
      "Epoch 04796: loss did not improve from -172.27684\n",
      "Epoch 4797/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.1164 - val_loss: -173.0826\n",
      "\n",
      "Epoch 04797: loss did not improve from -172.27684\n",
      "Epoch 4798/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2101 - val_loss: -173.3223\n",
      "\n",
      "Epoch 04798: loss did not improve from -172.27684\n",
      "Epoch 4799/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2049 - val_loss: -173.2584\n",
      "\n",
      "Epoch 04799: loss did not improve from -172.27684\n",
      "Epoch 4800/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.1527 - val_loss: -173.1754\n",
      "\n",
      "Epoch 04800: loss did not improve from -172.27684\n",
      "Epoch 4801/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.9844 - val_loss: -173.2061\n",
      "\n",
      "Epoch 04801: loss did not improve from -172.27684\n",
      "Epoch 4802/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.1811 - val_loss: -173.0743\n",
      "\n",
      "Epoch 04802: loss did not improve from -172.27684\n",
      "Epoch 4803/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.1569 - val_loss: -173.3898\n",
      "\n",
      "Epoch 04803: loss did not improve from -172.27684\n",
      "Epoch 4804/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2761 - val_loss: -173.2121\n",
      "\n",
      "Epoch 04804: loss did not improve from -172.27684\n",
      "Epoch 4805/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.1234 - val_loss: -173.0762\n",
      "\n",
      "Epoch 04805: loss did not improve from -172.27684\n",
      "Epoch 4806/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.9759 - val_loss: -173.2942\n",
      "\n",
      "Epoch 04806: loss did not improve from -172.27684\n",
      "Epoch 4807/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.1711 - val_loss: -173.1976\n",
      "\n",
      "Epoch 04807: loss did not improve from -172.27684\n",
      "Epoch 4808/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2493 - val_loss: -173.3732\n",
      "\n",
      "Epoch 04808: loss did not improve from -172.27684\n",
      "Epoch 4809/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2219 - val_loss: -173.1236\n",
      "\n",
      "Epoch 04809: loss did not improve from -172.27684\n",
      "Epoch 4810/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2207 - val_loss: -173.5373\n",
      "\n",
      "Epoch 04810: loss did not improve from -172.27684\n",
      "Epoch 4811/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.1270 - val_loss: -173.2710\n",
      "\n",
      "Epoch 04811: loss did not improve from -172.27684\n",
      "Epoch 4812/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -172.2367 - val_loss: -173.2506\n",
      "\n",
      "Epoch 04812: loss did not improve from -172.27684\n",
      "Epoch 4813/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2801 - val_loss: -173.4363\n",
      "\n",
      "Epoch 04813: loss improved from -172.27684 to -172.28013, saving model to gendance.h5\n",
      "Epoch 4814/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -172.2399 - val_loss: -173.0709\n",
      "\n",
      "Epoch 04814: loss did not improve from -172.28013\n",
      "Epoch 4815/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.0930 - val_loss: -173.4646\n",
      "\n",
      "Epoch 04815: loss did not improve from -172.28013\n",
      "Epoch 4816/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.9188 - val_loss: -172.5801\n",
      "\n",
      "Epoch 04816: loss did not improve from -172.28013\n",
      "Epoch 4817/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.8289 - val_loss: -173.1272\n",
      "\n",
      "Epoch 04817: loss did not improve from -172.28013\n",
      "Epoch 4818/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.9555 - val_loss: -172.9187\n",
      "\n",
      "Epoch 04818: loss did not improve from -172.28013\n",
      "Epoch 4819/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.9620 - val_loss: -173.2093\n",
      "\n",
      "Epoch 04819: loss did not improve from -172.28013\n",
      "Epoch 4820/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.7247 - val_loss: -173.2193\n",
      "\n",
      "Epoch 04820: loss did not improve from -172.28013\n",
      "Epoch 4821/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.6005 - val_loss: -172.7607\n",
      "\n",
      "Epoch 04821: loss did not improve from -172.28013\n",
      "Epoch 4822/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.6513 - val_loss: -173.3659\n",
      "\n",
      "Epoch 04822: loss did not improve from -172.28013\n",
      "Epoch 4823/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.5800 - val_loss: -172.7744\n",
      "\n",
      "Epoch 04823: loss did not improve from -172.28013\n",
      "Epoch 4824/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -171.7399 - val_loss: -173.2704\n",
      "\n",
      "Epoch 04824: loss did not improve from -172.28013\n",
      "Epoch 4825/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.8634 - val_loss: -172.9033\n",
      "\n",
      "Epoch 04825: loss did not improve from -172.28013\n",
      "Epoch 4826/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.0173 - val_loss: -173.3508\n",
      "\n",
      "Epoch 04826: loss did not improve from -172.28013\n",
      "Epoch 4827/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.8794 - val_loss: -172.9080\n",
      "\n",
      "Epoch 04827: loss did not improve from -172.28013\n",
      "Epoch 4828/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2485 - val_loss: -173.5387\n",
      "\n",
      "Epoch 04828: loss did not improve from -172.28013\n",
      "Epoch 4829/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.0607 - val_loss: -173.0705\n",
      "\n",
      "Epoch 04829: loss did not improve from -172.28013\n",
      "Epoch 4830/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2142 - val_loss: -173.2955\n",
      "\n",
      "Epoch 04830: loss did not improve from -172.28013\n",
      "Epoch 4831/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.1515 - val_loss: -173.2068\n",
      "\n",
      "Epoch 04831: loss did not improve from -172.28013\n",
      "Epoch 4832/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.1036 - val_loss: -173.2683\n",
      "\n",
      "Epoch 04832: loss did not improve from -172.28013\n",
      "Epoch 4833/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.0954 - val_loss: -173.2253\n",
      "\n",
      "Epoch 04833: loss did not improve from -172.28013\n",
      "Epoch 4834/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.1208 - val_loss: -173.2424\n",
      "\n",
      "Epoch 04834: loss did not improve from -172.28013\n",
      "Epoch 4835/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.9732 - val_loss: -173.2415\n",
      "\n",
      "Epoch 04835: loss did not improve from -172.28013\n",
      "Epoch 4836/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.1165 - val_loss: -173.2044\n",
      "\n",
      "Epoch 04836: loss did not improve from -172.28013\n",
      "Epoch 4837/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.0667 - val_loss: -173.2759\n",
      "\n",
      "Epoch 04837: loss did not improve from -172.28013\n",
      "Epoch 4838/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.0602 - val_loss: -173.0756\n",
      "\n",
      "Epoch 04838: loss did not improve from -172.28013\n",
      "Epoch 4839/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.0700 - val_loss: -173.3439\n",
      "\n",
      "Epoch 04839: loss did not improve from -172.28013\n",
      "Epoch 4840/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.0874 - val_loss: -173.2606\n",
      "\n",
      "Epoch 04840: loss did not improve from -172.28013\n",
      "Epoch 4841/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.1023 - val_loss: -173.3325\n",
      "\n",
      "Epoch 04841: loss did not improve from -172.28013\n",
      "Epoch 4842/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.0498 - val_loss: -173.3761\n",
      "\n",
      "Epoch 04842: loss did not improve from -172.28013\n",
      "Epoch 4843/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2648 - val_loss: -173.4851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 04843: loss did not improve from -172.28013\n",
      "Epoch 4844/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.1223 - val_loss: -173.1120\n",
      "\n",
      "Epoch 04844: loss did not improve from -172.28013\n",
      "Epoch 4845/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2143 - val_loss: -173.3830\n",
      "\n",
      "Epoch 04845: loss did not improve from -172.28013\n",
      "Epoch 4846/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2308 - val_loss: -173.1992\n",
      "\n",
      "Epoch 04846: loss did not improve from -172.28013\n",
      "Epoch 4847/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2933 - val_loss: -173.3368\n",
      "\n",
      "Epoch 04847: loss improved from -172.28013 to -172.29330, saving model to gendance.h5\n",
      "Epoch 4848/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.0545 - val_loss: -173.1609\n",
      "\n",
      "Epoch 04848: loss did not improve from -172.29330\n",
      "Epoch 4849/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.3033 - val_loss: -173.1336\n",
      "\n",
      "Epoch 04849: loss improved from -172.29330 to -172.30333, saving model to gendance.h5\n",
      "Epoch 4850/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2279 - val_loss: -173.4515\n",
      "\n",
      "Epoch 04850: loss did not improve from -172.30333\n",
      "Epoch 4851/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.3013 - val_loss: -173.3911\n",
      "\n",
      "Epoch 04851: loss did not improve from -172.30333\n",
      "Epoch 4852/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5106 - val_loss: -173.3311\n",
      "\n",
      "Epoch 04852: loss improved from -172.30333 to -172.51061, saving model to gendance.h5\n",
      "Epoch 4853/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -172.1988 - val_loss: -173.2561\n",
      "\n",
      "Epoch 04853: loss did not improve from -172.51061\n",
      "Epoch 4854/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.3814 - val_loss: -173.3978\n",
      "\n",
      "Epoch 04854: loss did not improve from -172.51061\n",
      "Epoch 4855/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.1703 - val_loss: -173.2991\n",
      "\n",
      "Epoch 04855: loss did not improve from -172.51061\n",
      "Epoch 4856/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.3347 - val_loss: -173.4723\n",
      "\n",
      "Epoch 04856: loss did not improve from -172.51061\n",
      "Epoch 4857/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.1618 - val_loss: -173.2500\n",
      "\n",
      "Epoch 04857: loss did not improve from -172.51061\n",
      "Epoch 4858/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.3737 - val_loss: -173.4723\n",
      "\n",
      "Epoch 04858: loss did not improve from -172.51061\n",
      "Epoch 4859/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.1544 - val_loss: -173.2887\n",
      "\n",
      "Epoch 04859: loss did not improve from -172.51061\n",
      "Epoch 4860/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.3481 - val_loss: -173.0577\n",
      "\n",
      "Epoch 04860: loss did not improve from -172.51061\n",
      "Epoch 4861/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2153 - val_loss: -173.4372\n",
      "\n",
      "Epoch 04861: loss did not improve from -172.51061\n",
      "Epoch 4862/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.3091 - val_loss: -173.0751\n",
      "\n",
      "Epoch 04862: loss did not improve from -172.51061\n",
      "Epoch 4863/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.0567 - val_loss: -173.3599\n",
      "\n",
      "Epoch 04863: loss did not improve from -172.51061\n",
      "Epoch 4864/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2947 - val_loss: -172.9355\n",
      "\n",
      "Epoch 04864: loss did not improve from -172.51061\n",
      "Epoch 4865/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.0292 - val_loss: -173.2257\n",
      "\n",
      "Epoch 04865: loss did not improve from -172.51061\n",
      "Epoch 4866/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.1143 - val_loss: -173.2133\n",
      "\n",
      "Epoch 04866: loss did not improve from -172.51061\n",
      "Epoch 4867/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2839 - val_loss: -173.2907\n",
      "\n",
      "Epoch 04867: loss did not improve from -172.51061\n",
      "Epoch 4868/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2771 - val_loss: -173.3870\n",
      "\n",
      "Epoch 04868: loss did not improve from -172.51061\n",
      "Epoch 4869/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2024 - val_loss: -173.2790\n",
      "\n",
      "Epoch 04869: loss did not improve from -172.51061\n",
      "Epoch 4870/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.4154 - val_loss: -173.4999\n",
      "\n",
      "Epoch 04870: loss did not improve from -172.51061\n",
      "Epoch 4871/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2152 - val_loss: -173.3503\n",
      "\n",
      "Epoch 04871: loss did not improve from -172.51061\n",
      "Epoch 4872/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -172.3232 - val_loss: -173.4183\n",
      "\n",
      "Epoch 04872: loss did not improve from -172.51061\n",
      "Epoch 4873/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.1075 - val_loss: -173.1627\n",
      "\n",
      "Epoch 04873: loss did not improve from -172.51061\n",
      "Epoch 4874/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.1123 - val_loss: -173.3603\n",
      "\n",
      "Epoch 04874: loss did not improve from -172.51061\n",
      "Epoch 4875/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.0871 - val_loss: -172.9745\n",
      "\n",
      "Epoch 04875: loss did not improve from -172.51061\n",
      "Epoch 4876/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.1664 - val_loss: -173.3903\n",
      "\n",
      "Epoch 04876: loss did not improve from -172.51061\n",
      "Epoch 4877/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.1458 - val_loss: -173.2028\n",
      "\n",
      "Epoch 04877: loss did not improve from -172.51061\n",
      "Epoch 4878/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -172.3919 - val_loss: -173.4422\n",
      "\n",
      "Epoch 04878: loss did not improve from -172.51061\n",
      "Epoch 4879/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.0658 - val_loss: -173.1603\n",
      "\n",
      "Epoch 04879: loss did not improve from -172.51061\n",
      "Epoch 4880/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.3289 - val_loss: -173.3619\n",
      "\n",
      "Epoch 04880: loss did not improve from -172.51061\n",
      "Epoch 4881/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2735 - val_loss: -173.4231\n",
      "\n",
      "Epoch 04881: loss did not improve from -172.51061\n",
      "Epoch 4882/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.3440 - val_loss: -173.3386\n",
      "\n",
      "Epoch 04882: loss did not improve from -172.51061\n",
      "Epoch 4883/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.0865 - val_loss: -173.4398\n",
      "\n",
      "Epoch 04883: loss did not improve from -172.51061\n",
      "Epoch 4884/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -172.1628 - val_loss: -173.3553\n",
      "\n",
      "Epoch 04884: loss did not improve from -172.51061\n",
      "Epoch 4885/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.1669 - val_loss: -173.2850\n",
      "\n",
      "Epoch 04885: loss did not improve from -172.51061\n",
      "Epoch 4886/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.0347 - val_loss: -173.2009\n",
      "\n",
      "Epoch 04886: loss did not improve from -172.51061\n",
      "Epoch 4887/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.1700 - val_loss: -173.0373\n",
      "\n",
      "Epoch 04887: loss did not improve from -172.51061\n",
      "Epoch 4888/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.9925 - val_loss: -173.3909\n",
      "\n",
      "Epoch 04888: loss did not improve from -172.51061\n",
      "Epoch 4889/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -171.9406 - val_loss: -172.8432\n",
      "\n",
      "Epoch 04889: loss did not improve from -172.51061\n",
      "Epoch 4890/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.1773 - val_loss: -173.3397\n",
      "\n",
      "Epoch 04890: loss did not improve from -172.51061\n",
      "Epoch 4891/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2859 - val_loss: -172.9195\n",
      "\n",
      "Epoch 04891: loss did not improve from -172.51061\n",
      "Epoch 4892/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 31us/step - loss: -172.1872 - val_loss: -173.4377\n",
      "\n",
      "Epoch 04892: loss did not improve from -172.51061\n",
      "Epoch 4893/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.1091 - val_loss: -173.0639\n",
      "\n",
      "Epoch 04893: loss did not improve from -172.51061\n",
      "Epoch 4894/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2886 - val_loss: -173.4450\n",
      "\n",
      "Epoch 04894: loss did not improve from -172.51061\n",
      "Epoch 4895/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2303 - val_loss: -173.1686\n",
      "\n",
      "Epoch 04895: loss did not improve from -172.51061\n",
      "Epoch 4896/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2951 - val_loss: -173.3085\n",
      "\n",
      "Epoch 04896: loss did not improve from -172.51061\n",
      "Epoch 4897/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2783 - val_loss: -173.4013\n",
      "\n",
      "Epoch 04897: loss did not improve from -172.51061\n",
      "Epoch 4898/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.4488 - val_loss: -173.5582\n",
      "\n",
      "Epoch 04898: loss did not improve from -172.51061\n",
      "Epoch 4899/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.3020 - val_loss: -173.2603\n",
      "\n",
      "Epoch 04899: loss did not improve from -172.51061\n",
      "Epoch 4900/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.3526 - val_loss: -173.4146\n",
      "\n",
      "Epoch 04900: loss did not improve from -172.51061\n",
      "Epoch 4901/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.3390 - val_loss: -173.2195\n",
      "\n",
      "Epoch 04901: loss did not improve from -172.51061\n",
      "Epoch 4902/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2195 - val_loss: -173.3160\n",
      "\n",
      "Epoch 04902: loss did not improve from -172.51061\n",
      "Epoch 4903/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.0986 - val_loss: -173.2361\n",
      "\n",
      "Epoch 04903: loss did not improve from -172.51061\n",
      "Epoch 4904/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.3279 - val_loss: -173.2937\n",
      "\n",
      "Epoch 04904: loss did not improve from -172.51061\n",
      "Epoch 4905/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2438 - val_loss: -173.4858\n",
      "\n",
      "Epoch 04905: loss did not improve from -172.51061\n",
      "Epoch 4906/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.4365 - val_loss: -173.0306\n",
      "\n",
      "Epoch 04906: loss did not improve from -172.51061\n",
      "Epoch 4907/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.1227 - val_loss: -173.4606\n",
      "\n",
      "Epoch 04907: loss did not improve from -172.51061\n",
      "Epoch 4908/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -172.3168 - val_loss: -173.0959\n",
      "\n",
      "Epoch 04908: loss did not improve from -172.51061\n",
      "Epoch 4909/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2559 - val_loss: -173.3109\n",
      "\n",
      "Epoch 04909: loss did not improve from -172.51061\n",
      "Epoch 4910/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.0387 - val_loss: -173.1919\n",
      "\n",
      "Epoch 04910: loss did not improve from -172.51061\n",
      "Epoch 4911/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2650 - val_loss: -173.1950\n",
      "\n",
      "Epoch 04911: loss did not improve from -172.51061\n",
      "Epoch 4912/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2971 - val_loss: -173.3880\n",
      "\n",
      "Epoch 04912: loss did not improve from -172.51061\n",
      "Epoch 4913/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.1851 - val_loss: -173.1306\n",
      "\n",
      "Epoch 04913: loss did not improve from -172.51061\n",
      "Epoch 4914/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2376 - val_loss: -173.3460\n",
      "\n",
      "Epoch 04914: loss did not improve from -172.51061\n",
      "Epoch 4915/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.0441 - val_loss: -173.1656\n",
      "\n",
      "Epoch 04915: loss did not improve from -172.51061\n",
      "Epoch 4916/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2379 - val_loss: -173.4602\n",
      "\n",
      "Epoch 04916: loss did not improve from -172.51061\n",
      "Epoch 4917/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.1010 - val_loss: -173.0058\n",
      "\n",
      "Epoch 04917: loss did not improve from -172.51061\n",
      "Epoch 4918/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.1740 - val_loss: -173.5038\n",
      "\n",
      "Epoch 04918: loss did not improve from -172.51061\n",
      "Epoch 4919/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2123 - val_loss: -172.8033\n",
      "\n",
      "Epoch 04919: loss did not improve from -172.51061\n",
      "Epoch 4920/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.1442 - val_loss: -173.3868\n",
      "\n",
      "Epoch 04920: loss did not improve from -172.51061\n",
      "Epoch 4921/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.3343 - val_loss: -173.1544\n",
      "\n",
      "Epoch 04921: loss did not improve from -172.51061\n",
      "Epoch 4922/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.3149 - val_loss: -173.4047\n",
      "\n",
      "Epoch 04922: loss did not improve from -172.51061\n",
      "Epoch 4923/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.4535 - val_loss: -173.4848\n",
      "\n",
      "Epoch 04923: loss did not improve from -172.51061\n",
      "Epoch 4924/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2663 - val_loss: -173.2052\n",
      "\n",
      "Epoch 04924: loss did not improve from -172.51061\n",
      "Epoch 4925/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.3287 - val_loss: -173.5267\n",
      "\n",
      "Epoch 04925: loss did not improve from -172.51061\n",
      "Epoch 4926/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2715 - val_loss: -173.3030\n",
      "\n",
      "Epoch 04926: loss did not improve from -172.51061\n",
      "Epoch 4927/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.3439 - val_loss: -173.4699\n",
      "\n",
      "Epoch 04927: loss did not improve from -172.51061\n",
      "Epoch 4928/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.3248 - val_loss: -173.1963\n",
      "\n",
      "Epoch 04928: loss did not improve from -172.51061\n",
      "Epoch 4929/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2370 - val_loss: -173.4341\n",
      "\n",
      "Epoch 04929: loss did not improve from -172.51061\n",
      "Epoch 4930/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2592 - val_loss: -173.3605\n",
      "\n",
      "Epoch 04930: loss did not improve from -172.51061\n",
      "Epoch 4931/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.4329 - val_loss: -173.4176\n",
      "\n",
      "Epoch 04931: loss did not improve from -172.51061\n",
      "Epoch 4932/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2993 - val_loss: -173.4473\n",
      "\n",
      "Epoch 04932: loss did not improve from -172.51061\n",
      "Epoch 4933/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2783 - val_loss: -173.5519\n",
      "\n",
      "Epoch 04933: loss did not improve from -172.51061\n",
      "Epoch 4934/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.3184 - val_loss: -173.2892\n",
      "\n",
      "Epoch 04934: loss did not improve from -172.51061\n",
      "Epoch 4935/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2494 - val_loss: -173.3755\n",
      "\n",
      "Epoch 04935: loss did not improve from -172.51061\n",
      "Epoch 4936/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -172.2388 - val_loss: -173.2448\n",
      "\n",
      "Epoch 04936: loss did not improve from -172.51061\n",
      "Epoch 4937/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2370 - val_loss: -173.4633\n",
      "\n",
      "Epoch 04937: loss did not improve from -172.51061\n",
      "Epoch 4938/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2011 - val_loss: -173.2261\n",
      "\n",
      "Epoch 04938: loss did not improve from -172.51061\n",
      "Epoch 4939/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2778 - val_loss: -173.5334\n",
      "\n",
      "Epoch 04939: loss did not improve from -172.51061\n",
      "Epoch 4940/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.3456 - val_loss: -173.2977\n",
      "\n",
      "Epoch 04940: loss did not improve from -172.51061\n",
      "Epoch 4941/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 31us/step - loss: -172.4708 - val_loss: -173.6213\n",
      "\n",
      "Epoch 04941: loss did not improve from -172.51061\n",
      "Epoch 4942/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2705 - val_loss: -173.0607\n",
      "\n",
      "Epoch 04942: loss did not improve from -172.51061\n",
      "Epoch 4943/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.3282 - val_loss: -173.4122\n",
      "\n",
      "Epoch 04943: loss did not improve from -172.51061\n",
      "Epoch 4944/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.0991 - val_loss: -173.0508\n",
      "\n",
      "Epoch 04944: loss did not improve from -172.51061\n",
      "Epoch 4945/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2598 - val_loss: -173.4737\n",
      "\n",
      "Epoch 04945: loss did not improve from -172.51061\n",
      "Epoch 4946/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2963 - val_loss: -173.4036\n",
      "\n",
      "Epoch 04946: loss did not improve from -172.51061\n",
      "Epoch 4947/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.1300 - val_loss: -173.4639\n",
      "\n",
      "Epoch 04947: loss did not improve from -172.51061\n",
      "Epoch 4948/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.3611 - val_loss: -173.4210\n",
      "\n",
      "Epoch 04948: loss did not improve from -172.51061\n",
      "Epoch 4949/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2136 - val_loss: -173.1952\n",
      "\n",
      "Epoch 04949: loss did not improve from -172.51061\n",
      "Epoch 4950/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.1606 - val_loss: -173.5336\n",
      "\n",
      "Epoch 04950: loss did not improve from -172.51061\n",
      "Epoch 4951/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.1622 - val_loss: -172.9364\n",
      "\n",
      "Epoch 04951: loss did not improve from -172.51061\n",
      "Epoch 4952/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.1352 - val_loss: -173.4102\n",
      "\n",
      "Epoch 04952: loss did not improve from -172.51061\n",
      "Epoch 4953/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.3377 - val_loss: -173.1868\n",
      "\n",
      "Epoch 04953: loss did not improve from -172.51061\n",
      "Epoch 4954/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.1023 - val_loss: -173.3037\n",
      "\n",
      "Epoch 04954: loss did not improve from -172.51061\n",
      "Epoch 4955/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -172.1449 - val_loss: -172.9711\n",
      "\n",
      "Epoch 04955: loss did not improve from -172.51061\n",
      "Epoch 4956/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.3322 - val_loss: -173.5291\n",
      "\n",
      "Epoch 04956: loss did not improve from -172.51061\n",
      "Epoch 4957/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.4347 - val_loss: -173.2928\n",
      "\n",
      "Epoch 04957: loss did not improve from -172.51061\n",
      "Epoch 4958/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.3530 - val_loss: -173.3538\n",
      "\n",
      "Epoch 04958: loss did not improve from -172.51061\n",
      "Epoch 4959/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.4199 - val_loss: -173.2739\n",
      "\n",
      "Epoch 04959: loss did not improve from -172.51061\n",
      "Epoch 4960/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.3423 - val_loss: -173.4495\n",
      "\n",
      "Epoch 04960: loss did not improve from -172.51061\n",
      "Epoch 4961/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.4485 - val_loss: -173.4457\n",
      "\n",
      "Epoch 04961: loss did not improve from -172.51061\n",
      "Epoch 4962/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5053 - val_loss: -173.4428\n",
      "\n",
      "Epoch 04962: loss did not improve from -172.51061\n",
      "Epoch 4963/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5690 - val_loss: -173.4832\n",
      "\n",
      "Epoch 04963: loss improved from -172.51061 to -172.56902, saving model to gendance.h5\n",
      "Epoch 4964/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.3979 - val_loss: -173.5515\n",
      "\n",
      "Epoch 04964: loss did not improve from -172.56902\n",
      "Epoch 4965/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.4198 - val_loss: -173.3757\n",
      "\n",
      "Epoch 04965: loss did not improve from -172.56902\n",
      "Epoch 4966/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.3234 - val_loss: -173.5600\n",
      "\n",
      "Epoch 04966: loss did not improve from -172.56902\n",
      "Epoch 4967/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5129 - val_loss: -173.4805\n",
      "\n",
      "Epoch 04967: loss did not improve from -172.56902\n",
      "Epoch 4968/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2666 - val_loss: -173.3445\n",
      "\n",
      "Epoch 04968: loss did not improve from -172.56902\n",
      "Epoch 4969/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.1283 - val_loss: -173.3990\n",
      "\n",
      "Epoch 04969: loss did not improve from -172.56902\n",
      "Epoch 4970/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5570 - val_loss: -173.3820\n",
      "\n",
      "Epoch 04970: loss did not improve from -172.56902\n",
      "Epoch 4971/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5385 - val_loss: -173.5110\n",
      "\n",
      "Epoch 04971: loss did not improve from -172.56902\n",
      "Epoch 4972/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.4438 - val_loss: -173.3936\n",
      "\n",
      "Epoch 04972: loss did not improve from -172.56902\n",
      "Epoch 4973/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.4494 - val_loss: -173.4820\n",
      "\n",
      "Epoch 04973: loss did not improve from -172.56902\n",
      "Epoch 4974/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.3674 - val_loss: -173.4316\n",
      "\n",
      "Epoch 04974: loss did not improve from -172.56902\n",
      "Epoch 4975/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2414 - val_loss: -173.4187\n",
      "\n",
      "Epoch 04975: loss did not improve from -172.56902\n",
      "Epoch 4976/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.3330 - val_loss: -173.4313\n",
      "\n",
      "Epoch 04976: loss did not improve from -172.56902\n",
      "Epoch 4977/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.4337 - val_loss: -173.4787\n",
      "\n",
      "Epoch 04977: loss did not improve from -172.56902\n",
      "Epoch 4978/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.4474 - val_loss: -173.1751\n",
      "\n",
      "Epoch 04978: loss did not improve from -172.56902\n",
      "Epoch 4979/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.3920 - val_loss: -173.6125\n",
      "\n",
      "Epoch 04979: loss did not improve from -172.56902\n",
      "Epoch 4980/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.3734 - val_loss: -173.3736\n",
      "\n",
      "Epoch 04980: loss did not improve from -172.56902\n",
      "Epoch 4981/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5398 - val_loss: -173.7687\n",
      "\n",
      "Epoch 04981: loss did not improve from -172.56902\n",
      "Epoch 4982/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.3830 - val_loss: -173.3218\n",
      "\n",
      "Epoch 04982: loss did not improve from -172.56902\n",
      "Epoch 4983/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5321 - val_loss: -173.5805\n",
      "\n",
      "Epoch 04983: loss did not improve from -172.56902\n",
      "Epoch 4984/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.4443 - val_loss: -173.5254\n",
      "\n",
      "Epoch 04984: loss did not improve from -172.56902\n",
      "Epoch 4985/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6930 - val_loss: -173.3745\n",
      "\n",
      "Epoch 04985: loss improved from -172.56902 to -172.69298, saving model to gendance.h5\n",
      "Epoch 4986/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.3301 - val_loss: -173.5002\n",
      "\n",
      "Epoch 04986: loss did not improve from -172.69298\n",
      "Epoch 4987/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.4324 - val_loss: -173.3004\n",
      "\n",
      "Epoch 04987: loss did not improve from -172.69298\n",
      "Epoch 4988/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.1943 - val_loss: -173.4357\n",
      "\n",
      "Epoch 04988: loss did not improve from -172.69298\n",
      "Epoch 4989/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2551 - val_loss: -173.0665\n",
      "\n",
      "Epoch 04989: loss did not improve from -172.69298\n",
      "Epoch 4990/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.4703 - val_loss: -173.5323\n",
      "\n",
      "Epoch 04990: loss did not improve from -172.69298\n",
      "Epoch 4991/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.3114 - val_loss: -173.1697\n",
      "\n",
      "Epoch 04991: loss did not improve from -172.69298\n",
      "Epoch 4992/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.3250 - val_loss: -173.3906\n",
      "\n",
      "Epoch 04992: loss did not improve from -172.69298\n",
      "Epoch 4993/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.3346 - val_loss: -173.4179\n",
      "\n",
      "Epoch 04993: loss did not improve from -172.69298\n",
      "Epoch 4994/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2542 - val_loss: -173.3283\n",
      "\n",
      "Epoch 04994: loss did not improve from -172.69298\n",
      "Epoch 4995/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5233 - val_loss: -173.6138\n",
      "\n",
      "Epoch 04995: loss did not improve from -172.69298\n",
      "Epoch 4996/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -172.5126 - val_loss: -173.2851\n",
      "\n",
      "Epoch 04996: loss did not improve from -172.69298\n",
      "Epoch 4997/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.3356 - val_loss: -173.4950\n",
      "\n",
      "Epoch 04997: loss did not improve from -172.69298\n",
      "Epoch 4998/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2574 - val_loss: -173.2441\n",
      "\n",
      "Epoch 04998: loss did not improve from -172.69298\n",
      "Epoch 4999/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.4503 - val_loss: -173.5523\n",
      "\n",
      "Epoch 04999: loss did not improve from -172.69298\n",
      "Epoch 5000/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5462 - val_loss: -173.4169\n",
      "\n",
      "Epoch 05000: loss did not improve from -172.69298\n",
      "Epoch 5001/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2585 - val_loss: -173.4330\n",
      "\n",
      "Epoch 05001: loss did not improve from -172.69298\n",
      "Epoch 5002/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.3673 - val_loss: -173.3980\n",
      "\n",
      "Epoch 05002: loss did not improve from -172.69298\n",
      "Epoch 5003/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.3947 - val_loss: -173.3880\n",
      "\n",
      "Epoch 05003: loss did not improve from -172.69298\n",
      "Epoch 5004/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.4201 - val_loss: -173.4847\n",
      "\n",
      "Epoch 05004: loss did not improve from -172.69298\n",
      "Epoch 5005/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.1827 - val_loss: -173.4093\n",
      "\n",
      "Epoch 05005: loss did not improve from -172.69298\n",
      "Epoch 5006/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5078 - val_loss: -173.4968\n",
      "\n",
      "Epoch 05006: loss did not improve from -172.69298\n",
      "Epoch 5007/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5538 - val_loss: -173.6405\n",
      "\n",
      "Epoch 05007: loss did not improve from -172.69298\n",
      "Epoch 5008/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.4245 - val_loss: -173.4402\n",
      "\n",
      "Epoch 05008: loss did not improve from -172.69298\n",
      "Epoch 5009/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.4679 - val_loss: -173.5328\n",
      "\n",
      "Epoch 05009: loss did not improve from -172.69298\n",
      "Epoch 5010/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.4361 - val_loss: -173.6723\n",
      "\n",
      "Epoch 05010: loss did not improve from -172.69298\n",
      "Epoch 5011/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.4144 - val_loss: -173.1993\n",
      "\n",
      "Epoch 05011: loss did not improve from -172.69298\n",
      "Epoch 5012/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5821 - val_loss: -173.5280\n",
      "\n",
      "Epoch 05012: loss did not improve from -172.69298\n",
      "Epoch 5013/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.4968 - val_loss: -173.3021\n",
      "\n",
      "Epoch 05013: loss did not improve from -172.69298\n",
      "Epoch 5014/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.3270 - val_loss: -173.4507\n",
      "\n",
      "Epoch 05014: loss did not improve from -172.69298\n",
      "Epoch 5015/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.3847 - val_loss: -173.3195\n",
      "\n",
      "Epoch 05015: loss did not improve from -172.69298\n",
      "Epoch 5016/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2677 - val_loss: -173.3228\n",
      "\n",
      "Epoch 05016: loss did not improve from -172.69298\n",
      "Epoch 5017/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2801 - val_loss: -173.4576\n",
      "\n",
      "Epoch 05017: loss did not improve from -172.69298\n",
      "Epoch 5018/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.3208 - val_loss: -173.0275\n",
      "\n",
      "Epoch 05018: loss did not improve from -172.69298\n",
      "Epoch 5019/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.4856 - val_loss: -173.5507\n",
      "\n",
      "Epoch 05019: loss did not improve from -172.69298\n",
      "Epoch 5020/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5503 - val_loss: -173.2568\n",
      "\n",
      "Epoch 05020: loss did not improve from -172.69298\n",
      "Epoch 5021/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.4964 - val_loss: -173.7318\n",
      "\n",
      "Epoch 05021: loss did not improve from -172.69298\n",
      "Epoch 5022/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6036 - val_loss: -173.2959\n",
      "\n",
      "Epoch 05022: loss did not improve from -172.69298\n",
      "Epoch 5023/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5852 - val_loss: -173.5356\n",
      "\n",
      "Epoch 05023: loss did not improve from -172.69298\n",
      "Epoch 5024/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.4518 - val_loss: -173.3853\n",
      "\n",
      "Epoch 05024: loss did not improve from -172.69298\n",
      "Epoch 5025/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.3465 - val_loss: -173.5429\n",
      "\n",
      "Epoch 05025: loss did not improve from -172.69298\n",
      "Epoch 5026/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2752 - val_loss: -173.5264\n",
      "\n",
      "Epoch 05026: loss did not improve from -172.69298\n",
      "Epoch 5027/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2375 - val_loss: -173.3752\n",
      "\n",
      "Epoch 05027: loss did not improve from -172.69298\n",
      "Epoch 5028/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -172.5064 - val_loss: -173.5972\n",
      "\n",
      "Epoch 05028: loss did not improve from -172.69298\n",
      "Epoch 5029/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -172.6352 - val_loss: -173.4368\n",
      "\n",
      "Epoch 05029: loss did not improve from -172.69298\n",
      "Epoch 5030/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2682 - val_loss: -173.5305\n",
      "\n",
      "Epoch 05030: loss did not improve from -172.69298\n",
      "Epoch 5031/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.4249 - val_loss: -173.2295\n",
      "\n",
      "Epoch 05031: loss did not improve from -172.69298\n",
      "Epoch 5032/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5590 - val_loss: -173.7996\n",
      "\n",
      "Epoch 05032: loss did not improve from -172.69298\n",
      "Epoch 5033/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5012 - val_loss: -173.1378\n",
      "\n",
      "Epoch 05033: loss did not improve from -172.69298\n",
      "Epoch 5034/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5849 - val_loss: -173.5947\n",
      "\n",
      "Epoch 05034: loss did not improve from -172.69298\n",
      "Epoch 5035/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.4438 - val_loss: -173.3746\n",
      "\n",
      "Epoch 05035: loss did not improve from -172.69298\n",
      "Epoch 5036/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5448 - val_loss: -173.5818\n",
      "\n",
      "Epoch 05036: loss did not improve from -172.69298\n",
      "Epoch 5037/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6919 - val_loss: -173.4214\n",
      "\n",
      "Epoch 05037: loss did not improve from -172.69298\n",
      "Epoch 5038/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.4828 - val_loss: -173.6735\n",
      "\n",
      "Epoch 05038: loss did not improve from -172.69298\n",
      "Epoch 5039/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6347 - val_loss: -173.4814\n",
      "\n",
      "Epoch 05039: loss did not improve from -172.69298\n",
      "Epoch 5040/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6817 - val_loss: -173.6197\n",
      "\n",
      "Epoch 05040: loss did not improve from -172.69298\n",
      "Epoch 5041/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6186 - val_loss: -173.4845\n",
      "\n",
      "Epoch 05041: loss did not improve from -172.69298\n",
      "Epoch 5042/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.4077 - val_loss: -173.5315\n",
      "\n",
      "Epoch 05042: loss did not improve from -172.69298\n",
      "Epoch 5043/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.4867 - val_loss: -173.5709\n",
      "\n",
      "Epoch 05043: loss did not improve from -172.69298\n",
      "Epoch 5044/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5106 - val_loss: -173.5033\n",
      "\n",
      "Epoch 05044: loss did not improve from -172.69298\n",
      "Epoch 5045/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.4163 - val_loss: -173.5837\n",
      "\n",
      "Epoch 05045: loss did not improve from -172.69298\n",
      "Epoch 5046/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.4527 - val_loss: -173.4081\n",
      "\n",
      "Epoch 05046: loss did not improve from -172.69298\n",
      "Epoch 5047/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.3802 - val_loss: -173.5789\n",
      "\n",
      "Epoch 05047: loss did not improve from -172.69298\n",
      "Epoch 5048/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.4800 - val_loss: -173.3267\n",
      "\n",
      "Epoch 05048: loss did not improve from -172.69298\n",
      "Epoch 5049/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.4346 - val_loss: -173.5652\n",
      "\n",
      "Epoch 05049: loss did not improve from -172.69298\n",
      "Epoch 5050/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.4536 - val_loss: -173.1860\n",
      "\n",
      "Epoch 05050: loss did not improve from -172.69298\n",
      "Epoch 5051/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.4237 - val_loss: -173.6021\n",
      "\n",
      "Epoch 05051: loss did not improve from -172.69298\n",
      "Epoch 5052/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6035 - val_loss: -173.5507\n",
      "\n",
      "Epoch 05052: loss did not improve from -172.69298\n",
      "Epoch 5053/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5977 - val_loss: -173.5683\n",
      "\n",
      "Epoch 05053: loss did not improve from -172.69298\n",
      "Epoch 5054/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6661 - val_loss: -173.5578\n",
      "\n",
      "Epoch 05054: loss did not improve from -172.69298\n",
      "Epoch 5055/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7053 - val_loss: -173.5213\n",
      "\n",
      "Epoch 05055: loss improved from -172.69298 to -172.70531, saving model to gendance.h5\n",
      "Epoch 5056/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -172.6706 - val_loss: -173.6671\n",
      "\n",
      "Epoch 05056: loss did not improve from -172.70531\n",
      "Epoch 5057/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6679 - val_loss: -173.4346\n",
      "\n",
      "Epoch 05057: loss did not improve from -172.70531\n",
      "Epoch 5058/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.3897 - val_loss: -173.4765\n",
      "\n",
      "Epoch 05058: loss did not improve from -172.70531\n",
      "Epoch 5059/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.4251 - val_loss: -173.5713\n",
      "\n",
      "Epoch 05059: loss did not improve from -172.70531\n",
      "Epoch 5060/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7298 - val_loss: -173.5864\n",
      "\n",
      "Epoch 05060: loss improved from -172.70531 to -172.72977, saving model to gendance.h5\n",
      "Epoch 5061/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8084 - val_loss: -173.7537\n",
      "\n",
      "Epoch 05061: loss improved from -172.72977 to -172.80839, saving model to gendance.h5\n",
      "Epoch 5062/10000\n",
      "16167/16167 [==============================] - 1s 31us/step - loss: -172.4111 - val_loss: -173.4176\n",
      "\n",
      "Epoch 05062: loss did not improve from -172.80839\n",
      "Epoch 5063/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6142 - val_loss: -173.6510\n",
      "\n",
      "Epoch 05063: loss did not improve from -172.80839\n",
      "Epoch 5064/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6852 - val_loss: -173.4663\n",
      "\n",
      "Epoch 05064: loss did not improve from -172.80839\n",
      "Epoch 5065/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5613 - val_loss: -173.5818\n",
      "\n",
      "Epoch 05065: loss did not improve from -172.80839\n",
      "Epoch 5066/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5222 - val_loss: -173.5302\n",
      "\n",
      "Epoch 05066: loss did not improve from -172.80839\n",
      "Epoch 5067/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -172.5138 - val_loss: -173.4623\n",
      "\n",
      "Epoch 05067: loss did not improve from -172.80839\n",
      "Epoch 5068/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6310 - val_loss: -173.6602\n",
      "\n",
      "Epoch 05068: loss did not improve from -172.80839\n",
      "Epoch 5069/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.4492 - val_loss: -173.5301\n",
      "\n",
      "Epoch 05069: loss did not improve from -172.80839\n",
      "Epoch 5070/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5975 - val_loss: -173.6585\n",
      "\n",
      "Epoch 05070: loss did not improve from -172.80839\n",
      "Epoch 5071/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6064 - val_loss: -173.2414\n",
      "\n",
      "Epoch 05071: loss did not improve from -172.80839\n",
      "Epoch 5072/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5686 - val_loss: -173.3605\n",
      "\n",
      "Epoch 05072: loss did not improve from -172.80839\n",
      "Epoch 5073/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.1740 - val_loss: -173.4470\n",
      "\n",
      "Epoch 05073: loss did not improve from -172.80839\n",
      "Epoch 5074/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.0373 - val_loss: -172.7058\n",
      "\n",
      "Epoch 05074: loss did not improve from -172.80839\n",
      "Epoch 5075/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.1762 - val_loss: -173.5670\n",
      "\n",
      "Epoch 05075: loss did not improve from -172.80839\n",
      "Epoch 5076/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.1236 - val_loss: -172.7727\n",
      "\n",
      "Epoch 05076: loss did not improve from -172.80839\n",
      "Epoch 5077/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2028 - val_loss: -173.6035\n",
      "\n",
      "Epoch 05077: loss did not improve from -172.80839\n",
      "Epoch 5078/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5343 - val_loss: -173.2578\n",
      "\n",
      "Epoch 05078: loss did not improve from -172.80839\n",
      "Epoch 5079/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.3230 - val_loss: -173.6202\n",
      "\n",
      "Epoch 05079: loss did not improve from -172.80839\n",
      "Epoch 5080/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -172.5028 - val_loss: -173.3950\n",
      "\n",
      "Epoch 05080: loss did not improve from -172.80839\n",
      "Epoch 5081/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.4966 - val_loss: -173.5881\n",
      "\n",
      "Epoch 05081: loss did not improve from -172.80839\n",
      "Epoch 5082/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -172.4068 - val_loss: -173.5297\n",
      "\n",
      "Epoch 05082: loss did not improve from -172.80839\n",
      "Epoch 5083/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.3734 - val_loss: -173.5900\n",
      "\n",
      "Epoch 05083: loss did not improve from -172.80839\n",
      "Epoch 5084/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5084 - val_loss: -173.6375\n",
      "\n",
      "Epoch 05084: loss did not improve from -172.80839\n",
      "Epoch 5085/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5135 - val_loss: -173.5973\n",
      "\n",
      "Epoch 05085: loss did not improve from -172.80839\n",
      "Epoch 5086/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.3929 - val_loss: -173.7286\n",
      "\n",
      "Epoch 05086: loss did not improve from -172.80839\n",
      "Epoch 5087/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7202 - val_loss: -173.3760\n",
      "\n",
      "Epoch 05087: loss did not improve from -172.80839\n",
      "Epoch 5088/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5941 - val_loss: -173.7985\n",
      "\n",
      "Epoch 05088: loss did not improve from -172.80839\n",
      "Epoch 5089/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5107 - val_loss: -173.3978\n",
      "\n",
      "Epoch 05089: loss did not improve from -172.80839\n",
      "Epoch 5090/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6987 - val_loss: -173.7933\n",
      "\n",
      "Epoch 05090: loss did not improve from -172.80839\n",
      "Epoch 5091/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6838 - val_loss: -173.6249\n",
      "\n",
      "Epoch 05091: loss did not improve from -172.80839\n",
      "Epoch 5092/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5852 - val_loss: -173.6435\n",
      "\n",
      "Epoch 05092: loss did not improve from -172.80839\n",
      "Epoch 5093/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6710 - val_loss: -173.5204\n",
      "\n",
      "Epoch 05093: loss did not improve from -172.80839\n",
      "Epoch 5094/10000\n",
      "16167/16167 [==============================] - 1s 31us/step - loss: -172.8964 - val_loss: -173.6212\n",
      "\n",
      "Epoch 05094: loss improved from -172.80839 to -172.89639, saving model to gendance.h5\n",
      "Epoch 5095/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6956 - val_loss: -173.6274\n",
      "\n",
      "Epoch 05095: loss did not improve from -172.89639\n",
      "Epoch 5096/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6587 - val_loss: -173.6172\n",
      "\n",
      "Epoch 05096: loss did not improve from -172.89639\n",
      "Epoch 5097/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6178 - val_loss: -173.7292\n",
      "\n",
      "Epoch 05097: loss did not improve from -172.89639\n",
      "Epoch 5098/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6394 - val_loss: -173.4216\n",
      "\n",
      "Epoch 05098: loss did not improve from -172.89639\n",
      "Epoch 5099/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.4404 - val_loss: -173.5335\n",
      "\n",
      "Epoch 05099: loss did not improve from -172.89639\n",
      "Epoch 5100/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7039 - val_loss: -173.7059\n",
      "\n",
      "Epoch 05100: loss did not improve from -172.89639\n",
      "Epoch 5101/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7189 - val_loss: -173.8274\n",
      "\n",
      "Epoch 05101: loss did not improve from -172.89639\n",
      "Epoch 5102/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6496 - val_loss: -173.3404\n",
      "\n",
      "Epoch 05102: loss did not improve from -172.89639\n",
      "Epoch 5103/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6755 - val_loss: -173.7744\n",
      "\n",
      "Epoch 05103: loss did not improve from -172.89639\n",
      "Epoch 5104/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7299 - val_loss: -173.5078\n",
      "\n",
      "Epoch 05104: loss did not improve from -172.89639\n",
      "Epoch 5105/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7149 - val_loss: -173.6332\n",
      "\n",
      "Epoch 05105: loss did not improve from -172.89639\n",
      "Epoch 5106/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5628 - val_loss: -173.2727\n",
      "\n",
      "Epoch 05106: loss did not improve from -172.89639\n",
      "Epoch 5107/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6164 - val_loss: -173.6800\n",
      "\n",
      "Epoch 05107: loss did not improve from -172.89639\n",
      "Epoch 5108/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5005 - val_loss: -173.4079\n",
      "\n",
      "Epoch 05108: loss did not improve from -172.89639\n",
      "Epoch 5109/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.4979 - val_loss: -173.3131\n",
      "\n",
      "Epoch 05109: loss did not improve from -172.89639\n",
      "Epoch 5110/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.3740 - val_loss: -173.5732\n",
      "\n",
      "Epoch 05110: loss did not improve from -172.89639\n",
      "Epoch 5111/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.1942 - val_loss: -173.2096\n",
      "\n",
      "Epoch 05111: loss did not improve from -172.89639\n",
      "Epoch 5112/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.3658 - val_loss: -173.5875\n",
      "\n",
      "Epoch 05112: loss did not improve from -172.89639\n",
      "Epoch 5113/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.3371 - val_loss: -172.7076\n",
      "\n",
      "Epoch 05113: loss did not improve from -172.89639\n",
      "Epoch 5114/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.1820 - val_loss: -173.6425\n",
      "\n",
      "Epoch 05114: loss did not improve from -172.89639\n",
      "Epoch 5115/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.4229 - val_loss: -173.0820\n",
      "\n",
      "Epoch 05115: loss did not improve from -172.89639\n",
      "Epoch 5116/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6121 - val_loss: -173.6676\n",
      "\n",
      "Epoch 05116: loss did not improve from -172.89639\n",
      "Epoch 5117/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5138 - val_loss: -173.4004\n",
      "\n",
      "Epoch 05117: loss did not improve from -172.89639\n",
      "Epoch 5118/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6110 - val_loss: -173.4391\n",
      "\n",
      "Epoch 05118: loss did not improve from -172.89639\n",
      "Epoch 5119/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6452 - val_loss: -173.6151\n",
      "\n",
      "Epoch 05119: loss did not improve from -172.89639\n",
      "Epoch 5120/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.9914 - val_loss: -173.5933\n",
      "\n",
      "Epoch 05120: loss improved from -172.89639 to -172.99139, saving model to gendance.h5\n",
      "Epoch 5121/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6048 - val_loss: -173.6397\n",
      "\n",
      "Epoch 05121: loss did not improve from -172.99139\n",
      "Epoch 5122/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5011 - val_loss: -173.5931\n",
      "\n",
      "Epoch 05122: loss did not improve from -172.99139\n",
      "Epoch 5123/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6219 - val_loss: -173.7267\n",
      "\n",
      "Epoch 05123: loss did not improve from -172.99139\n",
      "Epoch 5124/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5552 - val_loss: -173.2967\n",
      "\n",
      "Epoch 05124: loss did not improve from -172.99139\n",
      "Epoch 5125/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5587 - val_loss: -173.5759\n",
      "\n",
      "Epoch 05125: loss did not improve from -172.99139\n",
      "Epoch 5126/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5586 - val_loss: -173.5249\n",
      "\n",
      "Epoch 05126: loss did not improve from -172.99139\n",
      "Epoch 5127/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6924 - val_loss: -173.7202\n",
      "\n",
      "Epoch 05127: loss did not improve from -172.99139\n",
      "Epoch 5128/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8322 - val_loss: -173.5238\n",
      "\n",
      "Epoch 05128: loss did not improve from -172.99139\n",
      "Epoch 5129/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5730 - val_loss: -173.6862\n",
      "\n",
      "Epoch 05129: loss did not improve from -172.99139\n",
      "Epoch 5130/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6399 - val_loss: -173.5565\n",
      "\n",
      "Epoch 05130: loss did not improve from -172.99139\n",
      "Epoch 5131/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6112 - val_loss: -173.7356\n",
      "\n",
      "Epoch 05131: loss did not improve from -172.99139\n",
      "Epoch 5132/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8985 - val_loss: -173.7110\n",
      "\n",
      "Epoch 05132: loss did not improve from -172.99139\n",
      "Epoch 5133/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7421 - val_loss: -173.4156\n",
      "\n",
      "Epoch 05133: loss did not improve from -172.99139\n",
      "Epoch 5134/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6150 - val_loss: -173.8749\n",
      "\n",
      "Epoch 05134: loss did not improve from -172.99139\n",
      "Epoch 5135/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.4680 - val_loss: -173.3651\n",
      "\n",
      "Epoch 05135: loss did not improve from -172.99139\n",
      "Epoch 5136/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.4951 - val_loss: -173.7157\n",
      "\n",
      "Epoch 05136: loss did not improve from -172.99139\n",
      "Epoch 5137/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6333 - val_loss: -173.6722\n",
      "\n",
      "Epoch 05137: loss did not improve from -172.99139\n",
      "Epoch 5138/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7100 - val_loss: -173.7419\n",
      "\n",
      "Epoch 05138: loss did not improve from -172.99139\n",
      "Epoch 5139/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5676 - val_loss: -173.4102\n",
      "\n",
      "Epoch 05139: loss did not improve from -172.99139\n",
      "Epoch 5140/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5309 - val_loss: -173.7851\n",
      "\n",
      "Epoch 05140: loss did not improve from -172.99139\n",
      "Epoch 5141/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8252 - val_loss: -173.6480\n",
      "\n",
      "Epoch 05141: loss did not improve from -172.99139\n",
      "Epoch 5142/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6497 - val_loss: -173.7868\n",
      "\n",
      "Epoch 05142: loss did not improve from -172.99139\n",
      "Epoch 5143/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7571 - val_loss: -173.6120\n",
      "\n",
      "Epoch 05143: loss did not improve from -172.99139\n",
      "Epoch 5144/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7579 - val_loss: -173.7928\n",
      "\n",
      "Epoch 05144: loss did not improve from -172.99139\n",
      "Epoch 5145/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8090 - val_loss: -173.4614\n",
      "\n",
      "Epoch 05145: loss did not improve from -172.99139\n",
      "Epoch 5146/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8606 - val_loss: -173.5624\n",
      "\n",
      "Epoch 05146: loss did not improve from -172.99139\n",
      "Epoch 5147/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7826 - val_loss: -173.7381\n",
      "\n",
      "Epoch 05147: loss did not improve from -172.99139\n",
      "Epoch 5148/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8576 - val_loss: -173.6308\n",
      "\n",
      "Epoch 05148: loss did not improve from -172.99139\n",
      "Epoch 5149/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7846 - val_loss: -173.7667\n",
      "\n",
      "Epoch 05149: loss did not improve from -172.99139\n",
      "Epoch 5150/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6520 - val_loss: -173.6427\n",
      "\n",
      "Epoch 05150: loss did not improve from -172.99139\n",
      "Epoch 5151/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8349 - val_loss: -173.6156\n",
      "\n",
      "Epoch 05151: loss did not improve from -172.99139\n",
      "Epoch 5152/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.4502 - val_loss: -173.6248\n",
      "\n",
      "Epoch 05152: loss did not improve from -172.99139\n",
      "Epoch 5153/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -172.6000 - val_loss: -173.5820\n",
      "\n",
      "Epoch 05153: loss did not improve from -172.99139\n",
      "Epoch 5154/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6208 - val_loss: -173.5856\n",
      "\n",
      "Epoch 05154: loss did not improve from -172.99139\n",
      "Epoch 5155/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.4550 - val_loss: -173.6430\n",
      "\n",
      "Epoch 05155: loss did not improve from -172.99139\n",
      "Epoch 5156/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6098 - val_loss: -173.5091\n",
      "\n",
      "Epoch 05156: loss did not improve from -172.99139\n",
      "Epoch 5157/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.4726 - val_loss: -173.6273\n",
      "\n",
      "Epoch 05157: loss did not improve from -172.99139\n",
      "Epoch 5158/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.4828 - val_loss: -173.3886\n",
      "\n",
      "Epoch 05158: loss did not improve from -172.99139\n",
      "Epoch 5159/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5651 - val_loss: -173.6119\n",
      "\n",
      "Epoch 05159: loss did not improve from -172.99139\n",
      "Epoch 5160/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5394 - val_loss: -173.2456\n",
      "\n",
      "Epoch 05160: loss did not improve from -172.99139\n",
      "Epoch 5161/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6541 - val_loss: -173.7708\n",
      "\n",
      "Epoch 05161: loss did not improve from -172.99139\n",
      "Epoch 5162/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5099 - val_loss: -173.2931\n",
      "\n",
      "Epoch 05162: loss did not improve from -172.99139\n",
      "Epoch 5163/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5771 - val_loss: -173.7550\n",
      "\n",
      "Epoch 05163: loss did not improve from -172.99139\n",
      "Epoch 5164/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5184 - val_loss: -173.5323\n",
      "\n",
      "Epoch 05164: loss did not improve from -172.99139\n",
      "Epoch 5165/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5684 - val_loss: -173.5602\n",
      "\n",
      "Epoch 05165: loss did not improve from -172.99139\n",
      "Epoch 5166/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6264 - val_loss: -173.8894\n",
      "\n",
      "Epoch 05166: loss did not improve from -172.99139\n",
      "Epoch 5167/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7010 - val_loss: -173.4366\n",
      "\n",
      "Epoch 05167: loss did not improve from -172.99139\n",
      "Epoch 5168/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7420 - val_loss: -173.7843\n",
      "\n",
      "Epoch 05168: loss did not improve from -172.99139\n",
      "Epoch 5169/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -172.8287 - val_loss: -173.6849\n",
      "\n",
      "Epoch 05169: loss did not improve from -172.99139\n",
      "Epoch 5170/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8673 - val_loss: -173.8091\n",
      "\n",
      "Epoch 05170: loss did not improve from -172.99139\n",
      "Epoch 5171/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7738 - val_loss: -173.6969\n",
      "\n",
      "Epoch 05171: loss did not improve from -172.99139\n",
      "Epoch 5172/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8805 - val_loss: -173.7295\n",
      "\n",
      "Epoch 05172: loss did not improve from -172.99139\n",
      "Epoch 5173/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.4818 - val_loss: -173.6183\n",
      "\n",
      "Epoch 05173: loss did not improve from -172.99139\n",
      "Epoch 5174/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.3795 - val_loss: -173.4324\n",
      "\n",
      "Epoch 05174: loss did not improve from -172.99139\n",
      "Epoch 5175/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6991 - val_loss: -173.7469\n",
      "\n",
      "Epoch 05175: loss did not improve from -172.99139\n",
      "Epoch 5176/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7854 - val_loss: -173.5831\n",
      "\n",
      "Epoch 05176: loss did not improve from -172.99139\n",
      "Epoch 5177/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5876 - val_loss: -173.8215\n",
      "\n",
      "Epoch 05177: loss did not improve from -172.99139\n",
      "Epoch 5178/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7968 - val_loss: -173.5259\n",
      "\n",
      "Epoch 05178: loss did not improve from -172.99139\n",
      "Epoch 5179/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8439 - val_loss: -173.7613\n",
      "\n",
      "Epoch 05179: loss did not improve from -172.99139\n",
      "Epoch 5180/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.4855 - val_loss: -173.3286\n",
      "\n",
      "Epoch 05180: loss did not improve from -172.99139\n",
      "Epoch 5181/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7502 - val_loss: -173.8351\n",
      "\n",
      "Epoch 05181: loss did not improve from -172.99139\n",
      "Epoch 5182/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5914 - val_loss: -173.4040\n",
      "\n",
      "Epoch 05182: loss did not improve from -172.99139\n",
      "Epoch 5183/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6939 - val_loss: -173.8047\n",
      "\n",
      "Epoch 05183: loss did not improve from -172.99139\n",
      "Epoch 5184/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6163 - val_loss: -173.6282\n",
      "\n",
      "Epoch 05184: loss did not improve from -172.99139\n",
      "Epoch 5185/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5550 - val_loss: -173.6604\n",
      "\n",
      "Epoch 05185: loss did not improve from -172.99139\n",
      "Epoch 5186/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6070 - val_loss: -173.7394\n",
      "\n",
      "Epoch 05186: loss did not improve from -172.99139\n",
      "Epoch 5187/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6418 - val_loss: -173.5498\n",
      "\n",
      "Epoch 05187: loss did not improve from -172.99139\n",
      "Epoch 5188/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6806 - val_loss: -173.7276\n",
      "\n",
      "Epoch 05188: loss did not improve from -172.99139\n",
      "Epoch 5189/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7935 - val_loss: -173.5484\n",
      "\n",
      "Epoch 05189: loss did not improve from -172.99139\n",
      "Epoch 5190/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6861 - val_loss: -173.5825\n",
      "\n",
      "Epoch 05190: loss did not improve from -172.99139\n",
      "Epoch 5191/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7479 - val_loss: -173.1411\n",
      "\n",
      "Epoch 05191: loss did not improve from -172.99139\n",
      "Epoch 5192/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6457 - val_loss: -173.8539\n",
      "\n",
      "Epoch 05192: loss did not improve from -172.99139\n",
      "Epoch 5193/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6417 - val_loss: -173.1992\n",
      "\n",
      "Epoch 05193: loss did not improve from -172.99139\n",
      "Epoch 5194/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8072 - val_loss: -173.7648\n",
      "\n",
      "Epoch 05194: loss did not improve from -172.99139\n",
      "Epoch 5195/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.9268 - val_loss: -173.4869\n",
      "\n",
      "Epoch 05195: loss did not improve from -172.99139\n",
      "Epoch 5196/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6651 - val_loss: -173.5730\n",
      "\n",
      "Epoch 05196: loss did not improve from -172.99139\n",
      "Epoch 5197/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5946 - val_loss: -173.5314\n",
      "\n",
      "Epoch 05197: loss did not improve from -172.99139\n",
      "Epoch 5198/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6165 - val_loss: -173.3703\n",
      "\n",
      "Epoch 05198: loss did not improve from -172.99139\n",
      "Epoch 5199/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.2873 - val_loss: -173.6427\n",
      "\n",
      "Epoch 05199: loss did not improve from -172.99139\n",
      "Epoch 5200/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7501 - val_loss: -173.5408\n",
      "\n",
      "Epoch 05200: loss did not improve from -172.99139\n",
      "Epoch 5201/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6678 - val_loss: -173.7125\n",
      "\n",
      "Epoch 05201: loss did not improve from -172.99139\n",
      "Epoch 5202/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7542 - val_loss: -173.7835\n",
      "\n",
      "Epoch 05202: loss did not improve from -172.99139\n",
      "Epoch 5203/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.9827 - val_loss: -173.8592\n",
      "\n",
      "Epoch 05203: loss did not improve from -172.99139\n",
      "Epoch 5204/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7223 - val_loss: -173.5094\n",
      "\n",
      "Epoch 05204: loss did not improve from -172.99139\n",
      "Epoch 5205/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7275 - val_loss: -173.7872\n",
      "\n",
      "Epoch 05205: loss did not improve from -172.99139\n",
      "Epoch 5206/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6208 - val_loss: -173.6913\n",
      "\n",
      "Epoch 05206: loss did not improve from -172.99139\n",
      "Epoch 5207/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7002 - val_loss: -173.7754\n",
      "\n",
      "Epoch 05207: loss did not improve from -172.99139\n",
      "Epoch 5208/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.9499 - val_loss: -173.8081\n",
      "\n",
      "Epoch 05208: loss did not improve from -172.99139\n",
      "Epoch 5209/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7197 - val_loss: -173.7086\n",
      "\n",
      "Epoch 05209: loss did not improve from -172.99139\n",
      "Epoch 5210/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.9659 - val_loss: -173.8115\n",
      "\n",
      "Epoch 05210: loss did not improve from -172.99139\n",
      "Epoch 5211/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7816 - val_loss: -173.6033\n",
      "\n",
      "Epoch 05211: loss did not improve from -172.99139\n",
      "Epoch 5212/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7254 - val_loss: -173.8692\n",
      "\n",
      "Epoch 05212: loss did not improve from -172.99139\n",
      "Epoch 5213/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1257 - val_loss: -173.6839\n",
      "\n",
      "Epoch 05213: loss improved from -172.99139 to -173.12568, saving model to gendance.h5\n",
      "Epoch 5214/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.9205 - val_loss: -173.8410\n",
      "\n",
      "Epoch 05214: loss did not improve from -173.12568\n",
      "Epoch 5215/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7592 - val_loss: -173.6978\n",
      "\n",
      "Epoch 05215: loss did not improve from -173.12568\n",
      "Epoch 5216/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6501 - val_loss: -173.7748\n",
      "\n",
      "Epoch 05216: loss did not improve from -173.12568\n",
      "Epoch 5217/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.9372 - val_loss: -173.6833\n",
      "\n",
      "Epoch 05217: loss did not improve from -173.12568\n",
      "Epoch 5218/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7574 - val_loss: -173.7143\n",
      "\n",
      "Epoch 05218: loss did not improve from -173.12568\n",
      "Epoch 5219/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8780 - val_loss: -173.7159\n",
      "\n",
      "Epoch 05219: loss did not improve from -173.12568\n",
      "Epoch 5220/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5700 - val_loss: -173.7452\n",
      "\n",
      "Epoch 05220: loss did not improve from -173.12568\n",
      "Epoch 5221/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8676 - val_loss: -173.6806\n",
      "\n",
      "Epoch 05221: loss did not improve from -173.12568\n",
      "Epoch 5222/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7431 - val_loss: -173.4774\n",
      "\n",
      "Epoch 05222: loss did not improve from -173.12568\n",
      "Epoch 5223/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7642 - val_loss: -173.8198\n",
      "\n",
      "Epoch 05223: loss did not improve from -173.12568\n",
      "Epoch 5224/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6053 - val_loss: -173.7455\n",
      "\n",
      "Epoch 05224: loss did not improve from -173.12568\n",
      "Epoch 5225/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.0119 - val_loss: -173.5986\n",
      "\n",
      "Epoch 05225: loss did not improve from -173.12568\n",
      "Epoch 5226/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8336 - val_loss: -173.6747\n",
      "\n",
      "Epoch 05226: loss did not improve from -173.12568\n",
      "Epoch 5227/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7568 - val_loss: -173.6833\n",
      "\n",
      "Epoch 05227: loss did not improve from -173.12568\n",
      "Epoch 5228/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6688 - val_loss: -173.7108\n",
      "\n",
      "Epoch 05228: loss did not improve from -173.12568\n",
      "Epoch 5229/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7094 - val_loss: -173.5208\n",
      "\n",
      "Epoch 05229: loss did not improve from -173.12568\n",
      "Epoch 5230/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7880 - val_loss: -173.8102\n",
      "\n",
      "Epoch 05230: loss did not improve from -173.12568\n",
      "Epoch 5231/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8266 - val_loss: -173.4982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 05231: loss did not improve from -173.12568\n",
      "Epoch 5232/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5960 - val_loss: -173.6971\n",
      "\n",
      "Epoch 05232: loss did not improve from -173.12568\n",
      "Epoch 5233/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6021 - val_loss: -173.3277\n",
      "\n",
      "Epoch 05233: loss did not improve from -173.12568\n",
      "Epoch 5234/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6674 - val_loss: -173.9394\n",
      "\n",
      "Epoch 05234: loss did not improve from -173.12568\n",
      "Epoch 5235/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7271 - val_loss: -172.9336\n",
      "\n",
      "Epoch 05235: loss did not improve from -173.12568\n",
      "Epoch 5236/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8050 - val_loss: -173.8267\n",
      "\n",
      "Epoch 05236: loss did not improve from -173.12568\n",
      "Epoch 5237/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5463 - val_loss: -173.3344\n",
      "\n",
      "Epoch 05237: loss did not improve from -173.12568\n",
      "Epoch 5238/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7787 - val_loss: -173.7509\n",
      "\n",
      "Epoch 05238: loss did not improve from -173.12568\n",
      "Epoch 5239/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8279 - val_loss: -173.5447\n",
      "\n",
      "Epoch 05239: loss did not improve from -173.12568\n",
      "Epoch 5240/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7493 - val_loss: -173.6786\n",
      "\n",
      "Epoch 05240: loss did not improve from -173.12568\n",
      "Epoch 5241/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7795 - val_loss: -173.5432\n",
      "\n",
      "Epoch 05241: loss did not improve from -173.12568\n",
      "Epoch 5242/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.9715 - val_loss: -173.7418\n",
      "\n",
      "Epoch 05242: loss did not improve from -173.12568\n",
      "Epoch 5243/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.0113 - val_loss: -173.7792\n",
      "\n",
      "Epoch 05243: loss did not improve from -173.12568\n",
      "Epoch 5244/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7242 - val_loss: -173.5518\n",
      "\n",
      "Epoch 05244: loss did not improve from -173.12568\n",
      "Epoch 5245/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.9173 - val_loss: -173.7595\n",
      "\n",
      "Epoch 05245: loss did not improve from -173.12568\n",
      "Epoch 5246/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8682 - val_loss: -173.3846\n",
      "\n",
      "Epoch 05246: loss did not improve from -173.12568\n",
      "Epoch 5247/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5352 - val_loss: -173.5746\n",
      "\n",
      "Epoch 05247: loss did not improve from -173.12568\n",
      "Epoch 5248/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7167 - val_loss: -173.6778\n",
      "\n",
      "Epoch 05248: loss did not improve from -173.12568\n",
      "Epoch 5249/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8748 - val_loss: -173.8364\n",
      "\n",
      "Epoch 05249: loss did not improve from -173.12568\n",
      "Epoch 5250/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8411 - val_loss: -173.6566\n",
      "\n",
      "Epoch 05250: loss did not improve from -173.12568\n",
      "Epoch 5251/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6847 - val_loss: -173.8668\n",
      "\n",
      "Epoch 05251: loss did not improve from -173.12568\n",
      "Epoch 5252/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.0037 - val_loss: -173.5999\n",
      "\n",
      "Epoch 05252: loss did not improve from -173.12568\n",
      "Epoch 5253/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7864 - val_loss: -173.7230\n",
      "\n",
      "Epoch 05253: loss did not improve from -173.12568\n",
      "Epoch 5254/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8660 - val_loss: -173.5263\n",
      "\n",
      "Epoch 05254: loss did not improve from -173.12568\n",
      "Epoch 5255/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8129 - val_loss: -173.7138\n",
      "\n",
      "Epoch 05255: loss did not improve from -173.12568\n",
      "Epoch 5256/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8871 - val_loss: -173.5870\n",
      "\n",
      "Epoch 05256: loss did not improve from -173.12568\n",
      "Epoch 5257/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8567 - val_loss: -173.7671\n",
      "\n",
      "Epoch 05257: loss did not improve from -173.12568\n",
      "Epoch 5258/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7825 - val_loss: -173.7782\n",
      "\n",
      "Epoch 05258: loss did not improve from -173.12568\n",
      "Epoch 5259/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5087 - val_loss: -173.3662\n",
      "\n",
      "Epoch 05259: loss did not improve from -173.12568\n",
      "Epoch 5260/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8532 - val_loss: -173.8879\n",
      "\n",
      "Epoch 05260: loss did not improve from -173.12568\n",
      "Epoch 5261/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7034 - val_loss: -173.3782\n",
      "\n",
      "Epoch 05261: loss did not improve from -173.12568\n",
      "Epoch 5262/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.9527 - val_loss: -173.9647\n",
      "\n",
      "Epoch 05262: loss did not improve from -173.12568\n",
      "Epoch 5263/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6554 - val_loss: -173.4636\n",
      "\n",
      "Epoch 05263: loss did not improve from -173.12568\n",
      "Epoch 5264/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7303 - val_loss: -173.9220\n",
      "\n",
      "Epoch 05264: loss did not improve from -173.12568\n",
      "Epoch 5265/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7803 - val_loss: -173.3463\n",
      "\n",
      "Epoch 05265: loss did not improve from -173.12568\n",
      "Epoch 5266/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8512 - val_loss: -173.9296\n",
      "\n",
      "Epoch 05266: loss did not improve from -173.12568\n",
      "Epoch 5267/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7693 - val_loss: -173.4975\n",
      "\n",
      "Epoch 05267: loss did not improve from -173.12568\n",
      "Epoch 5268/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.0360 - val_loss: -173.9520\n",
      "\n",
      "Epoch 05268: loss did not improve from -173.12568\n",
      "Epoch 5269/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8352 - val_loss: -173.4544\n",
      "\n",
      "Epoch 05269: loss did not improve from -173.12568\n",
      "Epoch 5270/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7144 - val_loss: -173.7568\n",
      "\n",
      "Epoch 05270: loss did not improve from -173.12568\n",
      "Epoch 5271/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.0749 - val_loss: -173.7224\n",
      "\n",
      "Epoch 05271: loss did not improve from -173.12568\n",
      "Epoch 5272/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.9082 - val_loss: -173.7593\n",
      "\n",
      "Epoch 05272: loss did not improve from -173.12568\n",
      "Epoch 5273/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5312 - val_loss: -173.7377\n",
      "\n",
      "Epoch 05273: loss did not improve from -173.12568\n",
      "Epoch 5274/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -172.6556 - val_loss: -173.3746\n",
      "\n",
      "Epoch 05274: loss did not improve from -173.12568\n",
      "Epoch 5275/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6270 - val_loss: -173.8916\n",
      "\n",
      "Epoch 05275: loss did not improve from -173.12568\n",
      "Epoch 5276/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8491 - val_loss: -173.2567\n",
      "\n",
      "Epoch 05276: loss did not improve from -173.12568\n",
      "Epoch 5277/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8126 - val_loss: -173.7340\n",
      "\n",
      "Epoch 05277: loss did not improve from -173.12568\n",
      "Epoch 5278/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.0239 - val_loss: -173.4214\n",
      "\n",
      "Epoch 05278: loss did not improve from -173.12568\n",
      "Epoch 5279/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.0219 - val_loss: -173.7386\n",
      "\n",
      "Epoch 05279: loss did not improve from -173.12568\n",
      "Epoch 5280/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8138 - val_loss: -173.4175\n",
      "\n",
      "Epoch 05280: loss did not improve from -173.12568\n",
      "Epoch 5281/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8470 - val_loss: -173.8762\n",
      "\n",
      "Epoch 05281: loss did not improve from -173.12568\n",
      "Epoch 5282/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8324 - val_loss: -173.8289\n",
      "\n",
      "Epoch 05282: loss did not improve from -173.12568\n",
      "Epoch 5283/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8455 - val_loss: -173.5662\n",
      "\n",
      "Epoch 05283: loss did not improve from -173.12568\n",
      "Epoch 5284/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.9259 - val_loss: -173.8845\n",
      "\n",
      "Epoch 05284: loss did not improve from -173.12568\n",
      "Epoch 5285/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8456 - val_loss: -173.8471\n",
      "\n",
      "Epoch 05285: loss did not improve from -173.12568\n",
      "Epoch 5286/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8694 - val_loss: -173.7245\n",
      "\n",
      "Epoch 05286: loss did not improve from -173.12568\n",
      "Epoch 5287/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.9773 - val_loss: -173.6763\n",
      "\n",
      "Epoch 05287: loss did not improve from -173.12568\n",
      "Epoch 5288/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7572 - val_loss: -173.6284\n",
      "\n",
      "Epoch 05288: loss did not improve from -173.12568\n",
      "Epoch 5289/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1349 - val_loss: -173.8514\n",
      "\n",
      "Epoch 05289: loss improved from -173.12568 to -173.13487, saving model to gendance.h5\n",
      "Epoch 5290/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.0191 - val_loss: -173.7855\n",
      "\n",
      "Epoch 05290: loss did not improve from -173.13487\n",
      "Epoch 5291/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.0477 - val_loss: -173.9383\n",
      "\n",
      "Epoch 05291: loss did not improve from -173.13487\n",
      "Epoch 5292/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1443 - val_loss: -173.7833\n",
      "\n",
      "Epoch 05292: loss improved from -173.13487 to -173.14433, saving model to gendance.h5\n",
      "Epoch 5293/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1789 - val_loss: -173.8093\n",
      "\n",
      "Epoch 05293: loss improved from -173.14433 to -173.17886, saving model to gendance.h5\n",
      "Epoch 5294/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1491 - val_loss: -173.5813\n",
      "\n",
      "Epoch 05294: loss did not improve from -173.17886\n",
      "Epoch 5295/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8990 - val_loss: -173.8182\n",
      "\n",
      "Epoch 05295: loss did not improve from -173.17886\n",
      "Epoch 5296/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8127 - val_loss: -173.6640\n",
      "\n",
      "Epoch 05296: loss did not improve from -173.17886\n",
      "Epoch 5297/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.0755 - val_loss: -174.0014\n",
      "\n",
      "Epoch 05297: loss did not improve from -173.17886\n",
      "Epoch 5298/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.9282 - val_loss: -173.7259\n",
      "\n",
      "Epoch 05298: loss did not improve from -173.17886\n",
      "Epoch 5299/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.9411 - val_loss: -173.9056\n",
      "\n",
      "Epoch 05299: loss did not improve from -173.17886\n",
      "Epoch 5300/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7586 - val_loss: -173.7175\n",
      "\n",
      "Epoch 05300: loss did not improve from -173.17886\n",
      "Epoch 5301/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8810 - val_loss: -173.5966\n",
      "\n",
      "Epoch 05301: loss did not improve from -173.17886\n",
      "Epoch 5302/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.9201 - val_loss: -173.7360\n",
      "\n",
      "Epoch 05302: loss did not improve from -173.17886\n",
      "Epoch 5303/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6080 - val_loss: -173.6367\n",
      "\n",
      "Epoch 05303: loss did not improve from -173.17886\n",
      "Epoch 5304/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7328 - val_loss: -173.7667\n",
      "\n",
      "Epoch 05304: loss did not improve from -173.17886\n",
      "Epoch 5305/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.5387 - val_loss: -173.4003\n",
      "\n",
      "Epoch 05305: loss did not improve from -173.17886\n",
      "Epoch 5306/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7575 - val_loss: -173.8048\n",
      "\n",
      "Epoch 05306: loss did not improve from -173.17886\n",
      "Epoch 5307/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6757 - val_loss: -173.2162\n",
      "\n",
      "Epoch 05307: loss did not improve from -173.17886\n",
      "Epoch 5308/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.9171 - val_loss: -173.9547\n",
      "\n",
      "Epoch 05308: loss did not improve from -173.17886\n",
      "Epoch 5309/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -172.6886 - val_loss: -173.4951\n",
      "\n",
      "Epoch 05309: loss did not improve from -173.17886\n",
      "Epoch 5310/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.9527 - val_loss: -174.0080\n",
      "\n",
      "Epoch 05310: loss did not improve from -173.17886\n",
      "Epoch 5311/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.0301 - val_loss: -173.7018\n",
      "\n",
      "Epoch 05311: loss did not improve from -173.17886\n",
      "Epoch 5312/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.9156 - val_loss: -173.7431\n",
      "\n",
      "Epoch 05312: loss did not improve from -173.17886\n",
      "Epoch 5313/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7278 - val_loss: -173.8058\n",
      "\n",
      "Epoch 05313: loss did not improve from -173.17886\n",
      "Epoch 5314/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.9304 - val_loss: -173.6064\n",
      "\n",
      "Epoch 05314: loss did not improve from -173.17886\n",
      "Epoch 5315/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8342 - val_loss: -173.9058\n",
      "\n",
      "Epoch 05315: loss did not improve from -173.17886\n",
      "Epoch 5316/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -172.8458 - val_loss: -173.4296\n",
      "\n",
      "Epoch 05316: loss did not improve from -173.17886\n",
      "Epoch 5317/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8878 - val_loss: -173.8993\n",
      "\n",
      "Epoch 05317: loss did not improve from -173.17886\n",
      "Epoch 5318/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.9469 - val_loss: -173.4309\n",
      "\n",
      "Epoch 05318: loss did not improve from -173.17886\n",
      "Epoch 5319/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7260 - val_loss: -173.6984\n",
      "\n",
      "Epoch 05319: loss did not improve from -173.17886\n",
      "Epoch 5320/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.0699 - val_loss: -173.7488\n",
      "\n",
      "Epoch 05320: loss did not improve from -173.17886\n",
      "Epoch 5321/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8940 - val_loss: -173.8069\n",
      "\n",
      "Epoch 05321: loss did not improve from -173.17886\n",
      "Epoch 5322/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8877 - val_loss: -173.7591\n",
      "\n",
      "Epoch 05322: loss did not improve from -173.17886\n",
      "Epoch 5323/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.9399 - val_loss: -173.8507\n",
      "\n",
      "Epoch 05323: loss did not improve from -173.17886\n",
      "Epoch 5324/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8369 - val_loss: -173.9210\n",
      "\n",
      "Epoch 05324: loss did not improve from -173.17886\n",
      "Epoch 5325/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7728 - val_loss: -173.7524\n",
      "\n",
      "Epoch 05325: loss did not improve from -173.17886\n",
      "Epoch 5326/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8146 - val_loss: -173.7580\n",
      "\n",
      "Epoch 05326: loss did not improve from -173.17886\n",
      "Epoch 5327/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8072 - val_loss: -173.5412\n",
      "\n",
      "Epoch 05327: loss did not improve from -173.17886\n",
      "Epoch 5328/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8525 - val_loss: -173.9154\n",
      "\n",
      "Epoch 05328: loss did not improve from -173.17886\n",
      "Epoch 5329/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8341 - val_loss: -173.5694\n",
      "\n",
      "Epoch 05329: loss did not improve from -173.17886\n",
      "Epoch 5330/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.9177 - val_loss: -173.8813\n",
      "\n",
      "Epoch 05330: loss did not improve from -173.17886\n",
      "Epoch 5331/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.9738 - val_loss: -173.6605\n",
      "\n",
      "Epoch 05331: loss did not improve from -173.17886\n",
      "Epoch 5332/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8157 - val_loss: -173.8581\n",
      "\n",
      "Epoch 05332: loss did not improve from -173.17886\n",
      "Epoch 5333/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.0738 - val_loss: -173.6987\n",
      "\n",
      "Epoch 05333: loss did not improve from -173.17886\n",
      "Epoch 5334/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.0511 - val_loss: -173.8864\n",
      "\n",
      "Epoch 05334: loss did not improve from -173.17886\n",
      "Epoch 5335/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.9578 - val_loss: -173.6859\n",
      "\n",
      "Epoch 05335: loss did not improve from -173.17886\n",
      "Epoch 5336/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1727 - val_loss: -174.0119\n",
      "\n",
      "Epoch 05336: loss did not improve from -173.17886\n",
      "Epoch 5337/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.0052 - val_loss: -173.7907\n",
      "\n",
      "Epoch 05337: loss did not improve from -173.17886\n",
      "Epoch 5338/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -172.7568 - val_loss: -173.7364\n",
      "\n",
      "Epoch 05338: loss did not improve from -173.17886\n",
      "Epoch 5339/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1134 - val_loss: -173.9275\n",
      "\n",
      "Epoch 05339: loss did not improve from -173.17886\n",
      "Epoch 5340/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.9768 - val_loss: -173.7232\n",
      "\n",
      "Epoch 05340: loss did not improve from -173.17886\n",
      "Epoch 5341/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.0708 - val_loss: -173.9862\n",
      "\n",
      "Epoch 05341: loss did not improve from -173.17886\n",
      "Epoch 5342/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.9108 - val_loss: -173.8478\n",
      "\n",
      "Epoch 05342: loss did not improve from -173.17886\n",
      "Epoch 5343/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -173.0156 - val_loss: -173.8290\n",
      "\n",
      "Epoch 05343: loss did not improve from -173.17886\n",
      "Epoch 5344/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1923 - val_loss: -173.7641\n",
      "\n",
      "Epoch 05344: loss improved from -173.17886 to -173.19234, saving model to gendance.h5\n",
      "Epoch 5345/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1226 - val_loss: -173.9857\n",
      "\n",
      "Epoch 05345: loss did not improve from -173.19234\n",
      "Epoch 5346/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.9898 - val_loss: -173.8014\n",
      "\n",
      "Epoch 05346: loss did not improve from -173.19234\n",
      "Epoch 5347/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.9327 - val_loss: -173.8557\n",
      "\n",
      "Epoch 05347: loss did not improve from -173.19234\n",
      "Epoch 5348/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.0125 - val_loss: -173.7345\n",
      "\n",
      "Epoch 05348: loss did not improve from -173.19234\n",
      "Epoch 5349/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7951 - val_loss: -173.4878\n",
      "\n",
      "Epoch 05349: loss did not improve from -173.19234\n",
      "Epoch 5350/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.9462 - val_loss: -173.9986\n",
      "\n",
      "Epoch 05350: loss did not improve from -173.19234\n",
      "Epoch 5351/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.9108 - val_loss: -173.2107\n",
      "\n",
      "Epoch 05351: loss did not improve from -173.19234\n",
      "Epoch 5352/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6712 - val_loss: -173.7766\n",
      "\n",
      "Epoch 05352: loss did not improve from -173.19234\n",
      "Epoch 5353/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.0023 - val_loss: -173.5780\n",
      "\n",
      "Epoch 05353: loss did not improve from -173.19234\n",
      "Epoch 5354/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.0834 - val_loss: -173.9379\n",
      "\n",
      "Epoch 05354: loss did not improve from -173.19234\n",
      "Epoch 5355/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1272 - val_loss: -173.5910\n",
      "\n",
      "Epoch 05355: loss did not improve from -173.19234\n",
      "Epoch 5356/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.0424 - val_loss: -173.8220\n",
      "\n",
      "Epoch 05356: loss did not improve from -173.19234\n",
      "Epoch 5357/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1368 - val_loss: -173.9288\n",
      "\n",
      "Epoch 05357: loss did not improve from -173.19234\n",
      "Epoch 5358/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8877 - val_loss: -173.9061\n",
      "\n",
      "Epoch 05358: loss did not improve from -173.19234\n",
      "Epoch 5359/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.0250 - val_loss: -173.8972\n",
      "\n",
      "Epoch 05359: loss did not improve from -173.19234\n",
      "Epoch 5360/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.0676 - val_loss: -173.6231\n",
      "\n",
      "Epoch 05360: loss did not improve from -173.19234\n",
      "Epoch 5361/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.0027 - val_loss: -173.9532\n",
      "\n",
      "Epoch 05361: loss did not improve from -173.19234\n",
      "Epoch 5362/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.9995 - val_loss: -173.5042\n",
      "\n",
      "Epoch 05362: loss did not improve from -173.19234\n",
      "Epoch 5363/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2572 - val_loss: -174.1818\n",
      "\n",
      "Epoch 05363: loss improved from -173.19234 to -173.25719, saving model to gendance.h5\n",
      "Epoch 5364/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2045 - val_loss: -173.6938\n",
      "\n",
      "Epoch 05364: loss did not improve from -173.25719\n",
      "Epoch 5365/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.9376 - val_loss: -173.7733\n",
      "\n",
      "Epoch 05365: loss did not improve from -173.25719\n",
      "Epoch 5366/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8304 - val_loss: -173.8599\n",
      "\n",
      "Epoch 05366: loss did not improve from -173.25719\n",
      "Epoch 5367/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.9022 - val_loss: -173.8870\n",
      "\n",
      "Epoch 05367: loss did not improve from -173.25719\n",
      "Epoch 5368/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8408 - val_loss: -173.6708\n",
      "\n",
      "Epoch 05368: loss did not improve from -173.25719\n",
      "Epoch 5369/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8209 - val_loss: -173.7478\n",
      "\n",
      "Epoch 05369: loss did not improve from -173.25719\n",
      "Epoch 5370/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8101 - val_loss: -173.9126\n",
      "\n",
      "Epoch 05370: loss did not improve from -173.25719\n",
      "Epoch 5371/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7408 - val_loss: -173.3218\n",
      "\n",
      "Epoch 05371: loss did not improve from -173.25719\n",
      "Epoch 5372/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8906 - val_loss: -174.0434\n",
      "\n",
      "Epoch 05372: loss did not improve from -173.25719\n",
      "Epoch 5373/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.9429 - val_loss: -173.6795\n",
      "\n",
      "Epoch 05373: loss did not improve from -173.25719\n",
      "Epoch 5374/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.9418 - val_loss: -174.0582\n",
      "\n",
      "Epoch 05374: loss did not improve from -173.25719\n",
      "Epoch 5375/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.9324 - val_loss: -173.7879\n",
      "\n",
      "Epoch 05375: loss did not improve from -173.25719\n",
      "Epoch 5376/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1138 - val_loss: -173.9761\n",
      "\n",
      "Epoch 05376: loss did not improve from -173.25719\n",
      "Epoch 5377/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.9922 - val_loss: -173.9401\n",
      "\n",
      "Epoch 05377: loss did not improve from -173.25719\n",
      "Epoch 5378/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8818 - val_loss: -173.8988\n",
      "\n",
      "Epoch 05378: loss did not improve from -173.25719\n",
      "Epoch 5379/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2127 - val_loss: -174.0586\n",
      "\n",
      "Epoch 05379: loss did not improve from -173.25719\n",
      "Epoch 5380/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1376 - val_loss: -174.0592\n",
      "\n",
      "Epoch 05380: loss did not improve from -173.25719\n",
      "Epoch 5381/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1411 - val_loss: -173.8644\n",
      "\n",
      "Epoch 05381: loss did not improve from -173.25719\n",
      "Epoch 5382/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2571 - val_loss: -173.8753\n",
      "\n",
      "Epoch 05382: loss did not improve from -173.25719\n",
      "Epoch 5383/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1408 - val_loss: -173.8999\n",
      "\n",
      "Epoch 05383: loss did not improve from -173.25719\n",
      "Epoch 5384/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.9224 - val_loss: -174.0429\n",
      "\n",
      "Epoch 05384: loss did not improve from -173.25719\n",
      "Epoch 5385/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.0072 - val_loss: -173.8623\n",
      "\n",
      "Epoch 05385: loss did not improve from -173.25719\n",
      "Epoch 5386/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2016 - val_loss: -174.1409\n",
      "\n",
      "Epoch 05386: loss did not improve from -173.25719\n",
      "Epoch 5387/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1247 - val_loss: -173.8927\n",
      "\n",
      "Epoch 05387: loss did not improve from -173.25719\n",
      "Epoch 5388/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1104 - val_loss: -173.8655\n",
      "\n",
      "Epoch 05388: loss did not improve from -173.25719\n",
      "Epoch 5389/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.9725 - val_loss: -173.7923\n",
      "\n",
      "Epoch 05389: loss did not improve from -173.25719\n",
      "Epoch 5390/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.0628 - val_loss: -173.9667\n",
      "\n",
      "Epoch 05390: loss did not improve from -173.25719\n",
      "Epoch 5391/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2349 - val_loss: -173.9526\n",
      "\n",
      "Epoch 05391: loss did not improve from -173.25719\n",
      "Epoch 5392/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.0185 - val_loss: -173.9401\n",
      "\n",
      "Epoch 05392: loss did not improve from -173.25719\n",
      "Epoch 5393/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2242 - val_loss: -174.0137\n",
      "\n",
      "Epoch 05393: loss did not improve from -173.25719\n",
      "Epoch 5394/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1916 - val_loss: -173.6181\n",
      "\n",
      "Epoch 05394: loss did not improve from -173.25719\n",
      "Epoch 5395/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.9890 - val_loss: -173.9376\n",
      "\n",
      "Epoch 05395: loss did not improve from -173.25719\n",
      "Epoch 5396/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8846 - val_loss: -173.6916\n",
      "\n",
      "Epoch 05396: loss did not improve from -173.25719\n",
      "Epoch 5397/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.0303 - val_loss: -173.9162\n",
      "\n",
      "Epoch 05397: loss did not improve from -173.25719\n",
      "Epoch 5398/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2309 - val_loss: -173.7233\n",
      "\n",
      "Epoch 05398: loss did not improve from -173.25719\n",
      "Epoch 5399/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.0031 - val_loss: -173.9263\n",
      "\n",
      "Epoch 05399: loss did not improve from -173.25719\n",
      "Epoch 5400/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.9115 - val_loss: -173.6847\n",
      "\n",
      "Epoch 05400: loss did not improve from -173.25719\n",
      "Epoch 5401/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1039 - val_loss: -174.0080\n",
      "\n",
      "Epoch 05401: loss did not improve from -173.25719\n",
      "Epoch 5402/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8924 - val_loss: -173.4869\n",
      "\n",
      "Epoch 05402: loss did not improve from -173.25719\n",
      "Epoch 5403/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1964 - val_loss: -174.0511\n",
      "\n",
      "Epoch 05403: loss did not improve from -173.25719\n",
      "Epoch 5404/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.0983 - val_loss: -173.7078\n",
      "\n",
      "Epoch 05404: loss did not improve from -173.25719\n",
      "Epoch 5405/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.9660 - val_loss: -173.9110\n",
      "\n",
      "Epoch 05405: loss did not improve from -173.25719\n",
      "Epoch 5406/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.9838 - val_loss: -173.8801\n",
      "\n",
      "Epoch 05406: loss did not improve from -173.25719\n",
      "Epoch 5407/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.0760 - val_loss: -173.9719\n",
      "\n",
      "Epoch 05407: loss did not improve from -173.25719\n",
      "Epoch 5408/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2241 - val_loss: -173.9989\n",
      "\n",
      "Epoch 05408: loss did not improve from -173.25719\n",
      "Epoch 5409/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8446 - val_loss: -173.7909\n",
      "\n",
      "Epoch 05409: loss did not improve from -173.25719\n",
      "Epoch 5410/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7140 - val_loss: -173.8448\n",
      "\n",
      "Epoch 05410: loss did not improve from -173.25719\n",
      "Epoch 5411/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.9504 - val_loss: -173.5841\n",
      "\n",
      "Epoch 05411: loss did not improve from -173.25719\n",
      "Epoch 5412/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8960 - val_loss: -173.8211\n",
      "\n",
      "Epoch 05412: loss did not improve from -173.25719\n",
      "Epoch 5413/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.9025 - val_loss: -173.6821\n",
      "\n",
      "Epoch 05413: loss did not improve from -173.25719\n",
      "Epoch 5414/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2983 - val_loss: -174.0188\n",
      "\n",
      "Epoch 05414: loss improved from -173.25719 to -173.29827, saving model to gendance.h5\n",
      "Epoch 5415/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2679 - val_loss: -173.9308\n",
      "\n",
      "Epoch 05415: loss did not improve from -173.29827\n",
      "Epoch 5416/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3631 - val_loss: -174.1450\n",
      "\n",
      "Epoch 05416: loss improved from -173.29827 to -173.36308, saving model to gendance.h5\n",
      "Epoch 5417/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.9682 - val_loss: -173.6194\n",
      "\n",
      "Epoch 05417: loss did not improve from -173.36308\n",
      "Epoch 5418/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1419 - val_loss: -174.0552\n",
      "\n",
      "Epoch 05418: loss did not improve from -173.36308\n",
      "Epoch 5419/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -172.9783 - val_loss: -173.8449\n",
      "\n",
      "Epoch 05419: loss did not improve from -173.36308\n",
      "Epoch 5420/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1264 - val_loss: -174.0471\n",
      "\n",
      "Epoch 05420: loss did not improve from -173.36308\n",
      "Epoch 5421/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1873 - val_loss: -174.0426\n",
      "\n",
      "Epoch 05421: loss did not improve from -173.36308\n",
      "Epoch 5422/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2281 - val_loss: -173.8745\n",
      "\n",
      "Epoch 05422: loss did not improve from -173.36308\n",
      "Epoch 5423/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2316 - val_loss: -174.1006\n",
      "\n",
      "Epoch 05423: loss did not improve from -173.36308\n",
      "Epoch 5424/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1013 - val_loss: -173.8107\n",
      "\n",
      "Epoch 05424: loss did not improve from -173.36308\n",
      "Epoch 5425/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3629 - val_loss: -174.1314\n",
      "\n",
      "Epoch 05425: loss did not improve from -173.36308\n",
      "Epoch 5426/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1510 - val_loss: -173.8505\n",
      "\n",
      "Epoch 05426: loss did not improve from -173.36308\n",
      "Epoch 5427/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2470 - val_loss: -174.0768\n",
      "\n",
      "Epoch 05427: loss did not improve from -173.36308\n",
      "Epoch 5428/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1502 - val_loss: -173.7019\n",
      "\n",
      "Epoch 05428: loss did not improve from -173.36308\n",
      "Epoch 5429/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2377 - val_loss: -174.0336\n",
      "\n",
      "Epoch 05429: loss did not improve from -173.36308\n",
      "Epoch 5430/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2806 - val_loss: -174.0390\n",
      "\n",
      "Epoch 05430: loss did not improve from -173.36308\n",
      "Epoch 5431/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.0452 - val_loss: -173.8608\n",
      "\n",
      "Epoch 05431: loss did not improve from -173.36308\n",
      "Epoch 5432/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.0016 - val_loss: -174.1443\n",
      "\n",
      "Epoch 05432: loss did not improve from -173.36308\n",
      "Epoch 5433/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.0612 - val_loss: -173.5640\n",
      "\n",
      "Epoch 05433: loss did not improve from -173.36308\n",
      "Epoch 5434/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.0256 - val_loss: -173.9708\n",
      "\n",
      "Epoch 05434: loss did not improve from -173.36308\n",
      "Epoch 5435/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8553 - val_loss: -173.8029\n",
      "\n",
      "Epoch 05435: loss did not improve from -173.36308\n",
      "Epoch 5436/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.0470 - val_loss: -173.7134\n",
      "\n",
      "Epoch 05436: loss did not improve from -173.36308\n",
      "Epoch 5437/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.0709 - val_loss: -173.8689\n",
      "\n",
      "Epoch 05437: loss did not improve from -173.36308\n",
      "Epoch 5438/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2398 - val_loss: -174.0404\n",
      "\n",
      "Epoch 05438: loss did not improve from -173.36308\n",
      "Epoch 5439/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1513 - val_loss: -173.8418\n",
      "\n",
      "Epoch 05439: loss did not improve from -173.36308\n",
      "Epoch 5440/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1883 - val_loss: -173.9008\n",
      "\n",
      "Epoch 05440: loss did not improve from -173.36308\n",
      "Epoch 5441/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.0153 - val_loss: -173.7446\n",
      "\n",
      "Epoch 05441: loss did not improve from -173.36308\n",
      "Epoch 5442/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2909 - val_loss: -173.9782\n",
      "\n",
      "Epoch 05442: loss did not improve from -173.36308\n",
      "Epoch 5443/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.0128 - val_loss: -173.9068\n",
      "\n",
      "Epoch 05443: loss did not improve from -173.36308\n",
      "Epoch 5444/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7813 - val_loss: -173.4581\n",
      "\n",
      "Epoch 05444: loss did not improve from -173.36308\n",
      "Epoch 5445/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8280 - val_loss: -173.8721\n",
      "\n",
      "Epoch 05445: loss did not improve from -173.36308\n",
      "Epoch 5446/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8684 - val_loss: -173.3966\n",
      "\n",
      "Epoch 05446: loss did not improve from -173.36308\n",
      "Epoch 5447/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8545 - val_loss: -173.9245\n",
      "\n",
      "Epoch 05447: loss did not improve from -173.36308\n",
      "Epoch 5448/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.8491 - val_loss: -173.5352\n",
      "\n",
      "Epoch 05448: loss did not improve from -173.36308\n",
      "Epoch 5449/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.9226 - val_loss: -173.8775\n",
      "\n",
      "Epoch 05449: loss did not improve from -173.36308\n",
      "Epoch 5450/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2171 - val_loss: -173.9814\n",
      "\n",
      "Epoch 05450: loss did not improve from -173.36308\n",
      "Epoch 5451/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3419 - val_loss: -173.9913\n",
      "\n",
      "Epoch 05451: loss did not improve from -173.36308\n",
      "Epoch 5452/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2368 - val_loss: -173.8870\n",
      "\n",
      "Epoch 05452: loss did not improve from -173.36308\n",
      "Epoch 5453/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.0513 - val_loss: -173.8738\n",
      "\n",
      "Epoch 05453: loss did not improve from -173.36308\n",
      "Epoch 5454/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.0019 - val_loss: -173.7131\n",
      "\n",
      "Epoch 05454: loss did not improve from -173.36308\n",
      "Epoch 5455/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1597 - val_loss: -174.0657\n",
      "\n",
      "Epoch 05455: loss did not improve from -173.36308\n",
      "Epoch 5456/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.0607 - val_loss: -173.8889\n",
      "\n",
      "Epoch 05456: loss did not improve from -173.36308\n",
      "Epoch 5457/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3390 - val_loss: -173.9751\n",
      "\n",
      "Epoch 05457: loss did not improve from -173.36308\n",
      "Epoch 5458/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1359 - val_loss: -173.8952\n",
      "\n",
      "Epoch 05458: loss did not improve from -173.36308\n",
      "Epoch 5459/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.0432 - val_loss: -173.9387\n",
      "\n",
      "Epoch 05459: loss did not improve from -173.36308\n",
      "Epoch 5460/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2279 - val_loss: -174.0467\n",
      "\n",
      "Epoch 05460: loss did not improve from -173.36308\n",
      "Epoch 5461/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1912 - val_loss: -174.0619\n",
      "\n",
      "Epoch 05461: loss did not improve from -173.36308\n",
      "Epoch 5462/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -173.1536 - val_loss: -174.0048\n",
      "\n",
      "Epoch 05462: loss did not improve from -173.36308\n",
      "Epoch 5463/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1725 - val_loss: -173.8993\n",
      "\n",
      "Epoch 05463: loss did not improve from -173.36308\n",
      "Epoch 5464/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1276 - val_loss: -173.9305\n",
      "\n",
      "Epoch 05464: loss did not improve from -173.36308\n",
      "Epoch 5465/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2350 - val_loss: -173.6865\n",
      "\n",
      "Epoch 05465: loss did not improve from -173.36308\n",
      "Epoch 5466/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1430 - val_loss: -173.9577\n",
      "\n",
      "Epoch 05466: loss did not improve from -173.36308\n",
      "Epoch 5467/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1310 - val_loss: -173.8848\n",
      "\n",
      "Epoch 05467: loss did not improve from -173.36308\n",
      "Epoch 5468/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1735 - val_loss: -174.0463\n",
      "\n",
      "Epoch 05468: loss did not improve from -173.36308\n",
      "Epoch 5469/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3761 - val_loss: -174.0553\n",
      "\n",
      "Epoch 05469: loss improved from -173.36308 to -173.37608, saving model to gendance.h5\n",
      "Epoch 5470/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2994 - val_loss: -173.9390\n",
      "\n",
      "Epoch 05470: loss did not improve from -173.37608\n",
      "Epoch 5471/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1556 - val_loss: -173.9126\n",
      "\n",
      "Epoch 05471: loss did not improve from -173.37608\n",
      "Epoch 5472/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.0529 - val_loss: -174.0699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 05472: loss did not improve from -173.37608\n",
      "Epoch 5473/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.0493 - val_loss: -173.8719\n",
      "\n",
      "Epoch 05473: loss did not improve from -173.37608\n",
      "Epoch 5474/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3575 - val_loss: -174.0220\n",
      "\n",
      "Epoch 05474: loss did not improve from -173.37608\n",
      "Epoch 5475/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2550 - val_loss: -173.8299\n",
      "\n",
      "Epoch 05475: loss did not improve from -173.37608\n",
      "Epoch 5476/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2622 - val_loss: -174.1630\n",
      "\n",
      "Epoch 05476: loss did not improve from -173.37608\n",
      "Epoch 5477/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1156 - val_loss: -174.0213\n",
      "\n",
      "Epoch 05477: loss did not improve from -173.37608\n",
      "Epoch 5478/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2173 - val_loss: -174.0323\n",
      "\n",
      "Epoch 05478: loss did not improve from -173.37608\n",
      "Epoch 5479/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.0594 - val_loss: -173.9109\n",
      "\n",
      "Epoch 05479: loss did not improve from -173.37608\n",
      "Epoch 5480/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1219 - val_loss: -174.0850\n",
      "\n",
      "Epoch 05480: loss did not improve from -173.37608\n",
      "Epoch 5481/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2040 - val_loss: -173.7428\n",
      "\n",
      "Epoch 05481: loss did not improve from -173.37608\n",
      "Epoch 5482/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2043 - val_loss: -173.9943\n",
      "\n",
      "Epoch 05482: loss did not improve from -173.37608\n",
      "Epoch 5483/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.0679 - val_loss: -173.8273\n",
      "\n",
      "Epoch 05483: loss did not improve from -173.37608\n",
      "Epoch 5484/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.0915 - val_loss: -173.8804\n",
      "\n",
      "Epoch 05484: loss did not improve from -173.37608\n",
      "Epoch 5485/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.9436 - val_loss: -174.0497\n",
      "\n",
      "Epoch 05485: loss did not improve from -173.37608\n",
      "Epoch 5486/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.0781 - val_loss: -173.7451\n",
      "\n",
      "Epoch 05486: loss did not improve from -173.37608\n",
      "Epoch 5487/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1179 - val_loss: -174.1444\n",
      "\n",
      "Epoch 05487: loss did not improve from -173.37608\n",
      "Epoch 5488/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1176 - val_loss: -173.8092\n",
      "\n",
      "Epoch 05488: loss did not improve from -173.37608\n",
      "Epoch 5489/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1813 - val_loss: -174.0445\n",
      "\n",
      "Epoch 05489: loss did not improve from -173.37608\n",
      "Epoch 5490/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1645 - val_loss: -173.8646\n",
      "\n",
      "Epoch 05490: loss did not improve from -173.37608\n",
      "Epoch 5491/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2448 - val_loss: -174.2198\n",
      "\n",
      "Epoch 05491: loss did not improve from -173.37608\n",
      "Epoch 5492/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -173.3488 - val_loss: -173.8363\n",
      "\n",
      "Epoch 05492: loss did not improve from -173.37608\n",
      "Epoch 5493/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2785 - val_loss: -174.1795\n",
      "\n",
      "Epoch 05493: loss did not improve from -173.37608\n",
      "Epoch 5494/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -173.2810 - val_loss: -173.9106\n",
      "\n",
      "Epoch 05494: loss did not improve from -173.37608\n",
      "Epoch 5495/10000\n",
      "16167/16167 [==============================] - 1s 33us/step - loss: -173.2249 - val_loss: -174.0647\n",
      "\n",
      "Epoch 05495: loss did not improve from -173.37608\n",
      "Epoch 5496/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2906 - val_loss: -173.9263\n",
      "\n",
      "Epoch 05496: loss did not improve from -173.37608\n",
      "Epoch 5497/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3754 - val_loss: -173.8940\n",
      "\n",
      "Epoch 05497: loss did not improve from -173.37608\n",
      "Epoch 5498/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2987 - val_loss: -174.1378\n",
      "\n",
      "Epoch 05498: loss did not improve from -173.37608\n",
      "Epoch 5499/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4710 - val_loss: -173.9558\n",
      "\n",
      "Epoch 05499: loss improved from -173.37608 to -173.47099, saving model to gendance.h5\n",
      "Epoch 5500/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -173.3456 - val_loss: -173.9242\n",
      "\n",
      "Epoch 05500: loss did not improve from -173.47099\n",
      "Epoch 5501/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.0654 - val_loss: -173.8970\n",
      "\n",
      "Epoch 05501: loss did not improve from -173.47099\n",
      "Epoch 5502/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1121 - val_loss: -174.0492\n",
      "\n",
      "Epoch 05502: loss did not improve from -173.47099\n",
      "Epoch 5503/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2043 - val_loss: -173.8861\n",
      "\n",
      "Epoch 05503: loss did not improve from -173.47099\n",
      "Epoch 5504/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1593 - val_loss: -174.0346\n",
      "\n",
      "Epoch 05504: loss did not improve from -173.47099\n",
      "Epoch 5505/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2206 - val_loss: -174.1953\n",
      "\n",
      "Epoch 05505: loss did not improve from -173.47099\n",
      "Epoch 5506/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1735 - val_loss: -173.9342\n",
      "\n",
      "Epoch 05506: loss did not improve from -173.47099\n",
      "Epoch 5507/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1368 - val_loss: -174.0539\n",
      "\n",
      "Epoch 05507: loss did not improve from -173.47099\n",
      "Epoch 5508/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1940 - val_loss: -173.9390\n",
      "\n",
      "Epoch 05508: loss did not improve from -173.47099\n",
      "Epoch 5509/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2953 - val_loss: -174.0749\n",
      "\n",
      "Epoch 05509: loss did not improve from -173.47099\n",
      "Epoch 5510/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6098 - val_loss: -174.3507\n",
      "\n",
      "Epoch 05510: loss improved from -173.47099 to -173.60977, saving model to gendance.h5\n",
      "Epoch 5511/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -173.3331 - val_loss: -173.9872\n",
      "\n",
      "Epoch 05511: loss did not improve from -173.60977\n",
      "Epoch 5512/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3928 - val_loss: -174.0321\n",
      "\n",
      "Epoch 05512: loss did not improve from -173.60977\n",
      "Epoch 5513/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -173.1809 - val_loss: -174.0575\n",
      "\n",
      "Epoch 05513: loss did not improve from -173.60977\n",
      "Epoch 5514/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3572 - val_loss: -174.0470\n",
      "\n",
      "Epoch 05514: loss did not improve from -173.60977\n",
      "Epoch 5515/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3975 - val_loss: -173.9679\n",
      "\n",
      "Epoch 05515: loss did not improve from -173.60977\n",
      "Epoch 5516/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2592 - val_loss: -174.0312\n",
      "\n",
      "Epoch 05516: loss did not improve from -173.60977\n",
      "Epoch 5517/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5039 - val_loss: -174.1322\n",
      "\n",
      "Epoch 05517: loss did not improve from -173.60977\n",
      "Epoch 5518/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2969 - val_loss: -174.0199\n",
      "\n",
      "Epoch 05518: loss did not improve from -173.60977\n",
      "Epoch 5519/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3618 - val_loss: -174.2589\n",
      "\n",
      "Epoch 05519: loss did not improve from -173.60977\n",
      "Epoch 5520/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1801 - val_loss: -173.8601\n",
      "\n",
      "Epoch 05520: loss did not improve from -173.60977\n",
      "Epoch 5521/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4373 - val_loss: -174.2882\n",
      "\n",
      "Epoch 05521: loss did not improve from -173.60977\n",
      "Epoch 5522/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5811 - val_loss: -173.9060\n",
      "\n",
      "Epoch 05522: loss did not improve from -173.60977\n",
      "Epoch 5523/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3229 - val_loss: -174.1928\n",
      "\n",
      "Epoch 05523: loss did not improve from -173.60977\n",
      "Epoch 5524/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2031 - val_loss: -173.3800\n",
      "\n",
      "Epoch 05524: loss did not improve from -173.60977\n",
      "Epoch 5525/10000\n",
      "16167/16167 [==============================] - 1s 32us/step - loss: -173.1565 - val_loss: -174.0030\n",
      "\n",
      "Epoch 05525: loss did not improve from -173.60977\n",
      "Epoch 5526/10000\n",
      "16167/16167 [==============================] - 1s 33us/step - loss: -173.3281 - val_loss: -173.8374\n",
      "\n",
      "Epoch 05526: loss did not improve from -173.60977\n",
      "Epoch 5527/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3586 - val_loss: -174.0788\n",
      "\n",
      "Epoch 05527: loss did not improve from -173.60977\n",
      "Epoch 5528/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2464 - val_loss: -173.8657\n",
      "\n",
      "Epoch 05528: loss did not improve from -173.60977\n",
      "Epoch 5529/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1437 - val_loss: -174.0825\n",
      "\n",
      "Epoch 05529: loss did not improve from -173.60977\n",
      "Epoch 5530/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2182 - val_loss: -173.8403\n",
      "\n",
      "Epoch 05530: loss did not improve from -173.60977\n",
      "Epoch 5531/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3130 - val_loss: -174.1388\n",
      "\n",
      "Epoch 05531: loss did not improve from -173.60977\n",
      "Epoch 5532/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3154 - val_loss: -173.8410\n",
      "\n",
      "Epoch 05532: loss did not improve from -173.60977\n",
      "Epoch 5533/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.9573 - val_loss: -173.8548\n",
      "\n",
      "Epoch 05533: loss did not improve from -173.60977\n",
      "Epoch 5534/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.7380 - val_loss: -174.0037\n",
      "\n",
      "Epoch 05534: loss did not improve from -173.60977\n",
      "Epoch 5535/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -172.8487 - val_loss: -173.3472\n",
      "\n",
      "Epoch 05535: loss did not improve from -173.60977\n",
      "Epoch 5536/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.9503 - val_loss: -174.1338\n",
      "\n",
      "Epoch 05536: loss did not improve from -173.60977\n",
      "Epoch 5537/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.6640 - val_loss: -173.1328\n",
      "\n",
      "Epoch 05537: loss did not improve from -173.60977\n",
      "Epoch 5538/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -172.9846 - val_loss: -174.1343\n",
      "\n",
      "Epoch 05538: loss did not improve from -173.60977\n",
      "Epoch 5539/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1249 - val_loss: -173.4668\n",
      "\n",
      "Epoch 05539: loss did not improve from -173.60977\n",
      "Epoch 5540/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1695 - val_loss: -173.9687\n",
      "\n",
      "Epoch 05540: loss did not improve from -173.60977\n",
      "Epoch 5541/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3308 - val_loss: -173.8648\n",
      "\n",
      "Epoch 05541: loss did not improve from -173.60977\n",
      "Epoch 5542/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4449 - val_loss: -174.1786\n",
      "\n",
      "Epoch 05542: loss did not improve from -173.60977\n",
      "Epoch 5543/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2899 - val_loss: -174.0817\n",
      "\n",
      "Epoch 05543: loss did not improve from -173.60977\n",
      "Epoch 5544/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -173.4823 - val_loss: -174.0391\n",
      "\n",
      "Epoch 05544: loss did not improve from -173.60977\n",
      "Epoch 5545/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5166 - val_loss: -174.0512\n",
      "\n",
      "Epoch 05545: loss did not improve from -173.60977\n",
      "Epoch 5546/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3196 - val_loss: -174.1766\n",
      "\n",
      "Epoch 05546: loss did not improve from -173.60977\n",
      "Epoch 5547/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6781 - val_loss: -174.1384\n",
      "\n",
      "Epoch 05547: loss improved from -173.60977 to -173.67807, saving model to gendance.h5\n",
      "Epoch 5548/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3885 - val_loss: -174.1853\n",
      "\n",
      "Epoch 05548: loss did not improve from -173.67807\n",
      "Epoch 5549/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3926 - val_loss: -174.1639\n",
      "\n",
      "Epoch 05549: loss did not improve from -173.67807\n",
      "Epoch 5550/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6833 - val_loss: -174.2673\n",
      "\n",
      "Epoch 05550: loss improved from -173.67807 to -173.68332, saving model to gendance.h5\n",
      "Epoch 5551/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5501 - val_loss: -174.0372\n",
      "\n",
      "Epoch 05551: loss did not improve from -173.68332\n",
      "Epoch 5552/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2123 - val_loss: -174.1231\n",
      "\n",
      "Epoch 05552: loss did not improve from -173.68332\n",
      "Epoch 5553/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3757 - val_loss: -174.0740\n",
      "\n",
      "Epoch 05553: loss did not improve from -173.68332\n",
      "Epoch 5554/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6576 - val_loss: -174.2047\n",
      "\n",
      "Epoch 05554: loss did not improve from -173.68332\n",
      "Epoch 5555/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5474 - val_loss: -174.1218\n",
      "\n",
      "Epoch 05555: loss did not improve from -173.68332\n",
      "Epoch 5556/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3816 - val_loss: -173.8321\n",
      "\n",
      "Epoch 05556: loss did not improve from -173.68332\n",
      "Epoch 5557/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3118 - val_loss: -174.1599\n",
      "\n",
      "Epoch 05557: loss did not improve from -173.68332\n",
      "Epoch 5558/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6198 - val_loss: -174.0610\n",
      "\n",
      "Epoch 05558: loss did not improve from -173.68332\n",
      "Epoch 5559/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4592 - val_loss: -173.9962\n",
      "\n",
      "Epoch 05559: loss did not improve from -173.68332\n",
      "Epoch 5560/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2113 - val_loss: -174.1058\n",
      "\n",
      "Epoch 05560: loss did not improve from -173.68332\n",
      "Epoch 5561/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3828 - val_loss: -173.9789\n",
      "\n",
      "Epoch 05561: loss did not improve from -173.68332\n",
      "Epoch 5562/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.0675 - val_loss: -173.9969\n",
      "\n",
      "Epoch 05562: loss did not improve from -173.68332\n",
      "Epoch 5563/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4232 - val_loss: -174.0121\n",
      "\n",
      "Epoch 05563: loss did not improve from -173.68332\n",
      "Epoch 5564/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1532 - val_loss: -174.1608\n",
      "\n",
      "Epoch 05564: loss did not improve from -173.68332\n",
      "Epoch 5565/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1664 - val_loss: -173.7198\n",
      "\n",
      "Epoch 05565: loss did not improve from -173.68332\n",
      "Epoch 5566/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3575 - val_loss: -174.2716\n",
      "\n",
      "Epoch 05566: loss did not improve from -173.68332\n",
      "Epoch 5567/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4324 - val_loss: -173.8357\n",
      "\n",
      "Epoch 05567: loss did not improve from -173.68332\n",
      "Epoch 5568/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3505 - val_loss: -174.0861\n",
      "\n",
      "Epoch 05568: loss did not improve from -173.68332\n",
      "Epoch 5569/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5122 - val_loss: -174.0459\n",
      "\n",
      "Epoch 05569: loss did not improve from -173.68332\n",
      "Epoch 5570/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2074 - val_loss: -174.0689\n",
      "\n",
      "Epoch 05570: loss did not improve from -173.68332\n",
      "Epoch 5571/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2770 - val_loss: -174.2715\n",
      "\n",
      "Epoch 05571: loss did not improve from -173.68332\n",
      "Epoch 5572/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4296 - val_loss: -173.8921\n",
      "\n",
      "Epoch 05572: loss did not improve from -173.68332\n",
      "Epoch 5573/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2551 - val_loss: -174.1937\n",
      "\n",
      "Epoch 05573: loss did not improve from -173.68332\n",
      "Epoch 5574/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3788 - val_loss: -173.9783\n",
      "\n",
      "Epoch 05574: loss did not improve from -173.68332\n",
      "Epoch 5575/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2826 - val_loss: -174.0727\n",
      "\n",
      "Epoch 05575: loss did not improve from -173.68332\n",
      "Epoch 5576/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4506 - val_loss: -173.9851\n",
      "\n",
      "Epoch 05576: loss did not improve from -173.68332\n",
      "Epoch 5577/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5212 - val_loss: -174.1671\n",
      "\n",
      "Epoch 05577: loss did not improve from -173.68332\n",
      "Epoch 5578/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4098 - val_loss: -174.0476\n",
      "\n",
      "Epoch 05578: loss did not improve from -173.68332\n",
      "Epoch 5579/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3515 - val_loss: -174.2516\n",
      "\n",
      "Epoch 05579: loss did not improve from -173.68332\n",
      "Epoch 5580/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6724 - val_loss: -174.2102\n",
      "\n",
      "Epoch 05580: loss did not improve from -173.68332\n",
      "Epoch 5581/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3104 - val_loss: -174.1492\n",
      "\n",
      "Epoch 05581: loss did not improve from -173.68332\n",
      "Epoch 5582/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3040 - val_loss: -174.2666\n",
      "\n",
      "Epoch 05582: loss did not improve from -173.68332\n",
      "Epoch 5583/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5468 - val_loss: -174.1609\n",
      "\n",
      "Epoch 05583: loss did not improve from -173.68332\n",
      "Epoch 5584/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5219 - val_loss: -174.2542\n",
      "\n",
      "Epoch 05584: loss did not improve from -173.68332\n",
      "Epoch 5585/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3706 - val_loss: -174.2513\n",
      "\n",
      "Epoch 05585: loss did not improve from -173.68332\n",
      "Epoch 5586/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3972 - val_loss: -173.8342\n",
      "\n",
      "Epoch 05586: loss did not improve from -173.68332\n",
      "Epoch 5587/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6587 - val_loss: -174.4619\n",
      "\n",
      "Epoch 05587: loss did not improve from -173.68332\n",
      "Epoch 5588/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6013 - val_loss: -173.8711\n",
      "\n",
      "Epoch 05588: loss did not improve from -173.68332\n",
      "Epoch 5589/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6132 - val_loss: -174.2638\n",
      "\n",
      "Epoch 05589: loss did not improve from -173.68332\n",
      "Epoch 5590/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3836 - val_loss: -174.0848\n",
      "\n",
      "Epoch 05590: loss did not improve from -173.68332\n",
      "Epoch 5591/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4793 - val_loss: -174.3366\n",
      "\n",
      "Epoch 05591: loss did not improve from -173.68332\n",
      "Epoch 5592/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2546 - val_loss: -173.9934\n",
      "\n",
      "Epoch 05592: loss did not improve from -173.68332\n",
      "Epoch 5593/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1896 - val_loss: -173.9725\n",
      "\n",
      "Epoch 05593: loss did not improve from -173.68332\n",
      "Epoch 5594/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2478 - val_loss: -174.1664\n",
      "\n",
      "Epoch 05594: loss did not improve from -173.68332\n",
      "Epoch 5595/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4930 - val_loss: -174.0090\n",
      "\n",
      "Epoch 05595: loss did not improve from -173.68332\n",
      "Epoch 5596/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3846 - val_loss: -174.1462\n",
      "\n",
      "Epoch 05596: loss did not improve from -173.68332\n",
      "Epoch 5597/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.0616 - val_loss: -173.8852\n",
      "\n",
      "Epoch 05597: loss did not improve from -173.68332\n",
      "Epoch 5598/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2649 - val_loss: -173.9738\n",
      "\n",
      "Epoch 05598: loss did not improve from -173.68332\n",
      "Epoch 5599/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3443 - val_loss: -173.8855\n",
      "\n",
      "Epoch 05599: loss did not improve from -173.68332\n",
      "Epoch 5600/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4807 - val_loss: -174.1307\n",
      "\n",
      "Epoch 05600: loss did not improve from -173.68332\n",
      "Epoch 5601/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2553 - val_loss: -173.8957\n",
      "\n",
      "Epoch 05601: loss did not improve from -173.68332\n",
      "Epoch 5602/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4574 - val_loss: -174.1853\n",
      "\n",
      "Epoch 05602: loss did not improve from -173.68332\n",
      "Epoch 5603/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2281 - val_loss: -173.8353\n",
      "\n",
      "Epoch 05603: loss did not improve from -173.68332\n",
      "Epoch 5604/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4941 - val_loss: -174.2191\n",
      "\n",
      "Epoch 05604: loss did not improve from -173.68332\n",
      "Epoch 5605/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3017 - val_loss: -174.0130\n",
      "\n",
      "Epoch 05605: loss did not improve from -173.68332\n",
      "Epoch 5606/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3991 - val_loss: -174.1957\n",
      "\n",
      "Epoch 05606: loss did not improve from -173.68332\n",
      "Epoch 5607/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1405 - val_loss: -173.8952\n",
      "\n",
      "Epoch 05607: loss did not improve from -173.68332\n",
      "Epoch 5608/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3446 - val_loss: -174.2845\n",
      "\n",
      "Epoch 05608: loss did not improve from -173.68332\n",
      "Epoch 5609/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5457 - val_loss: -174.0202\n",
      "\n",
      "Epoch 05609: loss did not improve from -173.68332\n",
      "Epoch 5610/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5454 - val_loss: -174.0477\n",
      "\n",
      "Epoch 05610: loss did not improve from -173.68332\n",
      "Epoch 5611/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3163 - val_loss: -173.9224\n",
      "\n",
      "Epoch 05611: loss did not improve from -173.68332\n",
      "Epoch 5612/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1264 - val_loss: -174.0963\n",
      "\n",
      "Epoch 05612: loss did not improve from -173.68332\n",
      "Epoch 5613/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3994 - val_loss: -174.0846\n",
      "\n",
      "Epoch 05613: loss did not improve from -173.68332\n",
      "Epoch 5614/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3673 - val_loss: -174.2058\n",
      "\n",
      "Epoch 05614: loss did not improve from -173.68332\n",
      "Epoch 5615/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4848 - val_loss: -174.1511\n",
      "\n",
      "Epoch 05615: loss did not improve from -173.68332\n",
      "Epoch 5616/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4754 - val_loss: -173.9721\n",
      "\n",
      "Epoch 05616: loss did not improve from -173.68332\n",
      "Epoch 5617/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6120 - val_loss: -174.2423\n",
      "\n",
      "Epoch 05617: loss did not improve from -173.68332\n",
      "Epoch 5618/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6114 - val_loss: -174.1673\n",
      "\n",
      "Epoch 05618: loss did not improve from -173.68332\n",
      "Epoch 5619/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5705 - val_loss: -174.2836\n",
      "\n",
      "Epoch 05619: loss did not improve from -173.68332\n",
      "Epoch 5620/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4138 - val_loss: -173.7124\n",
      "\n",
      "Epoch 05620: loss did not improve from -173.68332\n",
      "Epoch 5621/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4029 - val_loss: -174.3314\n",
      "\n",
      "Epoch 05621: loss did not improve from -173.68332\n",
      "Epoch 5622/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1292 - val_loss: -173.7981\n",
      "\n",
      "Epoch 05622: loss did not improve from -173.68332\n",
      "Epoch 5623/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3827 - val_loss: -174.2357\n",
      "\n",
      "Epoch 05623: loss did not improve from -173.68332\n",
      "Epoch 5624/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4707 - val_loss: -173.8813\n",
      "\n",
      "Epoch 05624: loss did not improve from -173.68332\n",
      "Epoch 5625/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2662 - val_loss: -174.0988\n",
      "\n",
      "Epoch 05625: loss did not improve from -173.68332\n",
      "Epoch 5626/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1873 - val_loss: -173.8659\n",
      "\n",
      "Epoch 05626: loss did not improve from -173.68332\n",
      "Epoch 5627/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2786 - val_loss: -174.1086\n",
      "\n",
      "Epoch 05627: loss did not improve from -173.68332\n",
      "Epoch 5628/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1484 - val_loss: -174.0741\n",
      "\n",
      "Epoch 05628: loss did not improve from -173.68332\n",
      "Epoch 5629/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2789 - val_loss: -173.8766\n",
      "\n",
      "Epoch 05629: loss did not improve from -173.68332\n",
      "Epoch 5630/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.0944 - val_loss: -174.0637\n",
      "\n",
      "Epoch 05630: loss did not improve from -173.68332\n",
      "Epoch 5631/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2363 - val_loss: -173.8669\n",
      "\n",
      "Epoch 05631: loss did not improve from -173.68332\n",
      "Epoch 5632/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4203 - val_loss: -174.1458\n",
      "\n",
      "Epoch 05632: loss did not improve from -173.68332\n",
      "Epoch 5633/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3735 - val_loss: -173.7933\n",
      "\n",
      "Epoch 05633: loss did not improve from -173.68332\n",
      "Epoch 5634/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2985 - val_loss: -174.2445\n",
      "\n",
      "Epoch 05634: loss did not improve from -173.68332\n",
      "Epoch 5635/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.0579 - val_loss: -173.5154\n",
      "\n",
      "Epoch 05635: loss did not improve from -173.68332\n",
      "Epoch 5636/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.0675 - val_loss: -174.1751\n",
      "\n",
      "Epoch 05636: loss did not improve from -173.68332\n",
      "Epoch 5637/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -173.3152 - val_loss: -173.8965\n",
      "\n",
      "Epoch 05637: loss did not improve from -173.68332\n",
      "Epoch 5638/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3070 - val_loss: -174.0694\n",
      "\n",
      "Epoch 05638: loss did not improve from -173.68332\n",
      "Epoch 5639/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2608 - val_loss: -173.9747\n",
      "\n",
      "Epoch 05639: loss did not improve from -173.68332\n",
      "Epoch 5640/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4321 - val_loss: -174.1787\n",
      "\n",
      "Epoch 05640: loss did not improve from -173.68332\n",
      "Epoch 5641/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3648 - val_loss: -173.8890\n",
      "\n",
      "Epoch 05641: loss did not improve from -173.68332\n",
      "Epoch 5642/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3459 - val_loss: -174.0264\n",
      "\n",
      "Epoch 05642: loss did not improve from -173.68332\n",
      "Epoch 5643/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4185 - val_loss: -174.0337\n",
      "\n",
      "Epoch 05643: loss did not improve from -173.68332\n",
      "Epoch 5644/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4829 - val_loss: -174.1429\n",
      "\n",
      "Epoch 05644: loss did not improve from -173.68332\n",
      "Epoch 5645/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2718 - val_loss: -174.1437\n",
      "\n",
      "Epoch 05645: loss did not improve from -173.68332\n",
      "Epoch 5646/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5891 - val_loss: -174.2495\n",
      "\n",
      "Epoch 05646: loss did not improve from -173.68332\n",
      "Epoch 5647/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4606 - val_loss: -174.2435\n",
      "\n",
      "Epoch 05647: loss did not improve from -173.68332\n",
      "Epoch 5648/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5655 - val_loss: -174.1679\n",
      "\n",
      "Epoch 05648: loss did not improve from -173.68332\n",
      "Epoch 5649/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -173.5619 - val_loss: -174.2537\n",
      "\n",
      "Epoch 05649: loss did not improve from -173.68332\n",
      "Epoch 5650/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.7473 - val_loss: -174.2871\n",
      "\n",
      "Epoch 05650: loss improved from -173.68332 to -173.74727, saving model to gendance.h5\n",
      "Epoch 5651/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4947 - val_loss: -174.1701\n",
      "\n",
      "Epoch 05651: loss did not improve from -173.74727\n",
      "Epoch 5652/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6771 - val_loss: -174.3111\n",
      "\n",
      "Epoch 05652: loss did not improve from -173.74727\n",
      "Epoch 5653/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6004 - val_loss: -174.2152\n",
      "\n",
      "Epoch 05653: loss did not improve from -173.74727\n",
      "Epoch 5654/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4272 - val_loss: -174.2510\n",
      "\n",
      "Epoch 05654: loss did not improve from -173.74727\n",
      "Epoch 5655/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5424 - val_loss: -174.1331\n",
      "\n",
      "Epoch 05655: loss did not improve from -173.74727\n",
      "Epoch 5656/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4780 - val_loss: -174.2546\n",
      "\n",
      "Epoch 05656: loss did not improve from -173.74727\n",
      "Epoch 5657/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4342 - val_loss: -174.0341\n",
      "\n",
      "Epoch 05657: loss did not improve from -173.74727\n",
      "Epoch 5658/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5721 - val_loss: -174.2042\n",
      "\n",
      "Epoch 05658: loss did not improve from -173.74727\n",
      "Epoch 5659/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3662 - val_loss: -174.0526\n",
      "\n",
      "Epoch 05659: loss did not improve from -173.74727\n",
      "Epoch 5660/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5696 - val_loss: -174.1187\n",
      "\n",
      "Epoch 05660: loss did not improve from -173.74727\n",
      "Epoch 5661/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5049 - val_loss: -174.2373\n",
      "\n",
      "Epoch 05661: loss did not improve from -173.74727\n",
      "Epoch 5662/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6349 - val_loss: -174.1408\n",
      "\n",
      "Epoch 05662: loss did not improve from -173.74727\n",
      "Epoch 5663/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4707 - val_loss: -174.2817\n",
      "\n",
      "Epoch 05663: loss did not improve from -173.74727\n",
      "Epoch 5664/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5549 - val_loss: -174.1003\n",
      "\n",
      "Epoch 05664: loss did not improve from -173.74727\n",
      "Epoch 5665/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5470 - val_loss: -174.2561\n",
      "\n",
      "Epoch 05665: loss did not improve from -173.74727\n",
      "Epoch 5666/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4527 - val_loss: -174.2352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 05666: loss did not improve from -173.74727\n",
      "Epoch 5667/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4575 - val_loss: -174.3316\n",
      "\n",
      "Epoch 05667: loss did not improve from -173.74727\n",
      "Epoch 5668/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3726 - val_loss: -173.7858\n",
      "\n",
      "Epoch 05668: loss did not improve from -173.74727\n",
      "Epoch 5669/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3077 - val_loss: -174.3218\n",
      "\n",
      "Epoch 05669: loss did not improve from -173.74727\n",
      "Epoch 5670/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1708 - val_loss: -173.6097\n",
      "\n",
      "Epoch 05670: loss did not improve from -173.74727\n",
      "Epoch 5671/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2076 - val_loss: -174.0611\n",
      "\n",
      "Epoch 05671: loss did not improve from -173.74727\n",
      "Epoch 5672/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3537 - val_loss: -173.8910\n",
      "\n",
      "Epoch 05672: loss did not improve from -173.74727\n",
      "Epoch 5673/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5405 - val_loss: -174.3478\n",
      "\n",
      "Epoch 05673: loss did not improve from -173.74727\n",
      "Epoch 5674/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6108 - val_loss: -174.1781\n",
      "\n",
      "Epoch 05674: loss did not improve from -173.74727\n",
      "Epoch 5675/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4458 - val_loss: -174.1811\n",
      "\n",
      "Epoch 05675: loss did not improve from -173.74727\n",
      "Epoch 5676/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4919 - val_loss: -174.2909\n",
      "\n",
      "Epoch 05676: loss did not improve from -173.74727\n",
      "Epoch 5677/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4233 - val_loss: -173.9871\n",
      "\n",
      "Epoch 05677: loss did not improve from -173.74727\n",
      "Epoch 5678/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4025 - val_loss: -174.2498\n",
      "\n",
      "Epoch 05678: loss did not improve from -173.74727\n",
      "Epoch 5679/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5095 - val_loss: -174.1701\n",
      "\n",
      "Epoch 05679: loss did not improve from -173.74727\n",
      "Epoch 5680/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5253 - val_loss: -173.9106\n",
      "\n",
      "Epoch 05680: loss did not improve from -173.74727\n",
      "Epoch 5681/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4117 - val_loss: -174.2839\n",
      "\n",
      "Epoch 05681: loss did not improve from -173.74727\n",
      "Epoch 5682/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.1750 - val_loss: -173.7535\n",
      "\n",
      "Epoch 05682: loss did not improve from -173.74727\n",
      "Epoch 5683/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4168 - val_loss: -174.3010\n",
      "\n",
      "Epoch 05683: loss did not improve from -173.74727\n",
      "Epoch 5684/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3849 - val_loss: -173.9780\n",
      "\n",
      "Epoch 05684: loss did not improve from -173.74727\n",
      "Epoch 5685/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5460 - val_loss: -174.3612\n",
      "\n",
      "Epoch 05685: loss did not improve from -173.74727\n",
      "Epoch 5686/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5840 - val_loss: -174.1137\n",
      "\n",
      "Epoch 05686: loss did not improve from -173.74727\n",
      "Epoch 5687/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3771 - val_loss: -174.1871\n",
      "\n",
      "Epoch 05687: loss did not improve from -173.74727\n",
      "Epoch 5688/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5387 - val_loss: -173.9664\n",
      "\n",
      "Epoch 05688: loss did not improve from -173.74727\n",
      "Epoch 5689/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4309 - val_loss: -174.3112\n",
      "\n",
      "Epoch 05689: loss did not improve from -173.74727\n",
      "Epoch 5690/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.7877 - val_loss: -174.3201\n",
      "\n",
      "Epoch 05690: loss improved from -173.74727 to -173.78769, saving model to gendance.h5\n",
      "Epoch 5691/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4698 - val_loss: -174.1581\n",
      "\n",
      "Epoch 05691: loss did not improve from -173.78769\n",
      "Epoch 5692/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5100 - val_loss: -174.1384\n",
      "\n",
      "Epoch 05692: loss did not improve from -173.78769\n",
      "Epoch 5693/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4688 - val_loss: -174.1902\n",
      "\n",
      "Epoch 05693: loss did not improve from -173.78769\n",
      "Epoch 5694/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6241 - val_loss: -173.8605\n",
      "\n",
      "Epoch 05694: loss did not improve from -173.78769\n",
      "Epoch 5695/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6052 - val_loss: -174.1679\n",
      "\n",
      "Epoch 05695: loss did not improve from -173.78769\n",
      "Epoch 5696/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4534 - val_loss: -174.0191\n",
      "\n",
      "Epoch 05696: loss did not improve from -173.78769\n",
      "Epoch 5697/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5585 - val_loss: -174.3312\n",
      "\n",
      "Epoch 05697: loss did not improve from -173.78769\n",
      "Epoch 5698/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.7098 - val_loss: -173.9245\n",
      "\n",
      "Epoch 05698: loss did not improve from -173.78769\n",
      "Epoch 5699/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6249 - val_loss: -174.3372\n",
      "\n",
      "Epoch 05699: loss did not improve from -173.78769\n",
      "Epoch 5700/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4819 - val_loss: -173.7011\n",
      "\n",
      "Epoch 05700: loss did not improve from -173.78769\n",
      "Epoch 5701/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3368 - val_loss: -174.1945\n",
      "\n",
      "Epoch 05701: loss did not improve from -173.78769\n",
      "Epoch 5702/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4338 - val_loss: -173.9130\n",
      "\n",
      "Epoch 05702: loss did not improve from -173.78769\n",
      "Epoch 5703/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3639 - val_loss: -174.1008\n",
      "\n",
      "Epoch 05703: loss did not improve from -173.78769\n",
      "Epoch 5704/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3962 - val_loss: -174.0279\n",
      "\n",
      "Epoch 05704: loss did not improve from -173.78769\n",
      "Epoch 5705/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2712 - val_loss: -173.9319\n",
      "\n",
      "Epoch 05705: loss did not improve from -173.78769\n",
      "Epoch 5706/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3304 - val_loss: -174.1767\n",
      "\n",
      "Epoch 05706: loss did not improve from -173.78769\n",
      "Epoch 5707/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3291 - val_loss: -173.8292\n",
      "\n",
      "Epoch 05707: loss did not improve from -173.78769\n",
      "Epoch 5708/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2306 - val_loss: -174.0969\n",
      "\n",
      "Epoch 05708: loss did not improve from -173.78769\n",
      "Epoch 5709/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3705 - val_loss: -173.5553\n",
      "\n",
      "Epoch 05709: loss did not improve from -173.78769\n",
      "Epoch 5710/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5677 - val_loss: -174.2935\n",
      "\n",
      "Epoch 05710: loss did not improve from -173.78769\n",
      "Epoch 5711/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2484 - val_loss: -173.6817\n",
      "\n",
      "Epoch 05711: loss did not improve from -173.78769\n",
      "Epoch 5712/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4226 - val_loss: -174.3103\n",
      "\n",
      "Epoch 05712: loss did not improve from -173.78769\n",
      "Epoch 5713/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4439 - val_loss: -173.9798\n",
      "\n",
      "Epoch 05713: loss did not improve from -173.78769\n",
      "Epoch 5714/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6816 - val_loss: -174.2678\n",
      "\n",
      "Epoch 05714: loss did not improve from -173.78769\n",
      "Epoch 5715/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5203 - val_loss: -174.2730\n",
      "\n",
      "Epoch 05715: loss did not improve from -173.78769\n",
      "Epoch 5716/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4372 - val_loss: -174.1058\n",
      "\n",
      "Epoch 05716: loss did not improve from -173.78769\n",
      "Epoch 5717/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6218 - val_loss: -174.3171\n",
      "\n",
      "Epoch 05717: loss did not improve from -173.78769\n",
      "Epoch 5718/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4379 - val_loss: -174.1827\n",
      "\n",
      "Epoch 05718: loss did not improve from -173.78769\n",
      "Epoch 5719/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6994 - val_loss: -174.0457\n",
      "\n",
      "Epoch 05719: loss did not improve from -173.78769\n",
      "Epoch 5720/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4666 - val_loss: -174.2351\n",
      "\n",
      "Epoch 05720: loss did not improve from -173.78769\n",
      "Epoch 5721/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5811 - val_loss: -174.2016\n",
      "\n",
      "Epoch 05721: loss did not improve from -173.78769\n",
      "Epoch 5722/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.7165 - val_loss: -174.1835\n",
      "\n",
      "Epoch 05722: loss did not improve from -173.78769\n",
      "Epoch 5723/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6483 - val_loss: -174.2607\n",
      "\n",
      "Epoch 05723: loss did not improve from -173.78769\n",
      "Epoch 5724/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5870 - val_loss: -174.2174\n",
      "\n",
      "Epoch 05724: loss did not improve from -173.78769\n",
      "Epoch 5725/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4920 - val_loss: -174.0679\n",
      "\n",
      "Epoch 05725: loss did not improve from -173.78769\n",
      "Epoch 5726/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.7339 - val_loss: -174.3591\n",
      "\n",
      "Epoch 05726: loss did not improve from -173.78769\n",
      "Epoch 5727/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5616 - val_loss: -174.3179\n",
      "\n",
      "Epoch 05727: loss did not improve from -173.78769\n",
      "Epoch 5728/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5095 - val_loss: -174.0751\n",
      "\n",
      "Epoch 05728: loss did not improve from -173.78769\n",
      "Epoch 5729/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6935 - val_loss: -174.2865\n",
      "\n",
      "Epoch 05729: loss did not improve from -173.78769\n",
      "Epoch 5730/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.7444 - val_loss: -174.1963\n",
      "\n",
      "Epoch 05730: loss did not improve from -173.78769\n",
      "Epoch 5731/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6905 - val_loss: -174.1543\n",
      "\n",
      "Epoch 05731: loss did not improve from -173.78769\n",
      "Epoch 5732/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5757 - val_loss: -174.3566\n",
      "\n",
      "Epoch 05732: loss did not improve from -173.78769\n",
      "Epoch 5733/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4681 - val_loss: -173.8001\n",
      "\n",
      "Epoch 05733: loss did not improve from -173.78769\n",
      "Epoch 5734/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5233 - val_loss: -174.3380\n",
      "\n",
      "Epoch 05734: loss did not improve from -173.78769\n",
      "Epoch 5735/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5319 - val_loss: -174.2465\n",
      "\n",
      "Epoch 05735: loss did not improve from -173.78769\n",
      "Epoch 5736/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.7554 - val_loss: -174.3301\n",
      "\n",
      "Epoch 05736: loss did not improve from -173.78769\n",
      "Epoch 5737/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.7550 - val_loss: -174.2536\n",
      "\n",
      "Epoch 05737: loss did not improve from -173.78769\n",
      "Epoch 5738/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6068 - val_loss: -173.9203\n",
      "\n",
      "Epoch 05738: loss did not improve from -173.78769\n",
      "Epoch 5739/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6364 - val_loss: -174.3120\n",
      "\n",
      "Epoch 05739: loss did not improve from -173.78769\n",
      "Epoch 5740/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5421 - val_loss: -173.7642\n",
      "\n",
      "Epoch 05740: loss did not improve from -173.78769\n",
      "Epoch 5741/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4961 - val_loss: -174.0831\n",
      "\n",
      "Epoch 05741: loss did not improve from -173.78769\n",
      "Epoch 5742/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5308 - val_loss: -173.9518\n",
      "\n",
      "Epoch 05742: loss did not improve from -173.78769\n",
      "Epoch 5743/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5780 - val_loss: -174.2023\n",
      "\n",
      "Epoch 05743: loss did not improve from -173.78769\n",
      "Epoch 5744/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.7046 - val_loss: -173.9987\n",
      "\n",
      "Epoch 05744: loss did not improve from -173.78769\n",
      "Epoch 5745/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5605 - val_loss: -174.3419\n",
      "\n",
      "Epoch 05745: loss did not improve from -173.78769\n",
      "Epoch 5746/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.7566 - val_loss: -174.0685\n",
      "\n",
      "Epoch 05746: loss did not improve from -173.78769\n",
      "Epoch 5747/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6667 - val_loss: -174.4202\n",
      "\n",
      "Epoch 05747: loss did not improve from -173.78769\n",
      "Epoch 5748/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6623 - val_loss: -173.9738\n",
      "\n",
      "Epoch 05748: loss did not improve from -173.78769\n",
      "Epoch 5749/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5723 - val_loss: -174.2180\n",
      "\n",
      "Epoch 05749: loss did not improve from -173.78769\n",
      "Epoch 5750/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9046 - val_loss: -174.1644\n",
      "\n",
      "Epoch 05750: loss improved from -173.78769 to -173.90463, saving model to gendance.h5\n",
      "Epoch 5751/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6019 - val_loss: -174.1741\n",
      "\n",
      "Epoch 05751: loss did not improve from -173.90463\n",
      "Epoch 5752/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.7296 - val_loss: -174.3196\n",
      "\n",
      "Epoch 05752: loss did not improve from -173.90463\n",
      "Epoch 5753/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6154 - val_loss: -174.0907\n",
      "\n",
      "Epoch 05753: loss did not improve from -173.90463\n",
      "Epoch 5754/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5332 - val_loss: -174.3555\n",
      "\n",
      "Epoch 05754: loss did not improve from -173.90463\n",
      "Epoch 5755/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -173.8411 - val_loss: -174.0689\n",
      "\n",
      "Epoch 05755: loss did not improve from -173.90463\n",
      "Epoch 5756/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.8158 - val_loss: -174.2188\n",
      "\n",
      "Epoch 05756: loss did not improve from -173.90463\n",
      "Epoch 5757/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6841 - val_loss: -174.3060\n",
      "\n",
      "Epoch 05757: loss did not improve from -173.90463\n",
      "Epoch 5758/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6869 - val_loss: -174.1697\n",
      "\n",
      "Epoch 05758: loss did not improve from -173.90463\n",
      "Epoch 5759/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.7221 - val_loss: -174.2725\n",
      "\n",
      "Epoch 05759: loss did not improve from -173.90463\n",
      "Epoch 5760/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4771 - val_loss: -173.9644\n",
      "\n",
      "Epoch 05760: loss did not improve from -173.90463\n",
      "Epoch 5761/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5827 - val_loss: -174.2912\n",
      "\n",
      "Epoch 05761: loss did not improve from -173.90463\n",
      "Epoch 5762/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.7506 - val_loss: -174.3642\n",
      "\n",
      "Epoch 05762: loss did not improve from -173.90463\n",
      "Epoch 5763/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6190 - val_loss: -174.3408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 05763: loss did not improve from -173.90463\n",
      "Epoch 5764/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2691 - val_loss: -174.0605\n",
      "\n",
      "Epoch 05764: loss did not improve from -173.90463\n",
      "Epoch 5765/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5155 - val_loss: -174.2250\n",
      "\n",
      "Epoch 05765: loss did not improve from -173.90463\n",
      "Epoch 5766/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5163 - val_loss: -174.0257\n",
      "\n",
      "Epoch 05766: loss did not improve from -173.90463\n",
      "Epoch 5767/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5667 - val_loss: -174.1978\n",
      "\n",
      "Epoch 05767: loss did not improve from -173.90463\n",
      "Epoch 5768/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5969 - val_loss: -174.0383\n",
      "\n",
      "Epoch 05768: loss did not improve from -173.90463\n",
      "Epoch 5769/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6367 - val_loss: -174.2792\n",
      "\n",
      "Epoch 05769: loss did not improve from -173.90463\n",
      "Epoch 5770/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6149 - val_loss: -174.0573\n",
      "\n",
      "Epoch 05770: loss did not improve from -173.90463\n",
      "Epoch 5771/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.8062 - val_loss: -174.4182\n",
      "\n",
      "Epoch 05771: loss did not improve from -173.90463\n",
      "Epoch 5772/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6508 - val_loss: -174.0797\n",
      "\n",
      "Epoch 05772: loss did not improve from -173.90463\n",
      "Epoch 5773/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5461 - val_loss: -174.4017\n",
      "\n",
      "Epoch 05773: loss did not improve from -173.90463\n",
      "Epoch 5774/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.7763 - val_loss: -174.1086\n",
      "\n",
      "Epoch 05774: loss did not improve from -173.90463\n",
      "Epoch 5775/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5502 - val_loss: -174.3846\n",
      "\n",
      "Epoch 05775: loss did not improve from -173.90463\n",
      "Epoch 5776/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4593 - val_loss: -173.9781\n",
      "\n",
      "Epoch 05776: loss did not improve from -173.90463\n",
      "Epoch 5777/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5380 - val_loss: -174.2584\n",
      "\n",
      "Epoch 05777: loss did not improve from -173.90463\n",
      "Epoch 5778/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.3568 - val_loss: -173.9019\n",
      "\n",
      "Epoch 05778: loss did not improve from -173.90463\n",
      "Epoch 5779/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4273 - val_loss: -174.2113\n",
      "\n",
      "Epoch 05779: loss did not improve from -173.90463\n",
      "Epoch 5780/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6286 - val_loss: -174.0377\n",
      "\n",
      "Epoch 05780: loss did not improve from -173.90463\n",
      "Epoch 5781/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6313 - val_loss: -174.3684\n",
      "\n",
      "Epoch 05781: loss did not improve from -173.90463\n",
      "Epoch 5782/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.7113 - val_loss: -173.9818\n",
      "\n",
      "Epoch 05782: loss did not improve from -173.90463\n",
      "Epoch 5783/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4743 - val_loss: -174.3744\n",
      "\n",
      "Epoch 05783: loss did not improve from -173.90463\n",
      "Epoch 5784/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4483 - val_loss: -174.1258\n",
      "\n",
      "Epoch 05784: loss did not improve from -173.90463\n",
      "Epoch 5785/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6154 - val_loss: -174.2235\n",
      "\n",
      "Epoch 05785: loss did not improve from -173.90463\n",
      "Epoch 5786/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6147 - val_loss: -174.1366\n",
      "\n",
      "Epoch 05786: loss did not improve from -173.90463\n",
      "Epoch 5787/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -173.5493 - val_loss: -174.1966\n",
      "\n",
      "Epoch 05787: loss did not improve from -173.90463\n",
      "Epoch 5788/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6877 - val_loss: -174.4154\n",
      "\n",
      "Epoch 05788: loss did not improve from -173.90463\n",
      "Epoch 5789/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6112 - val_loss: -174.0911\n",
      "\n",
      "Epoch 05789: loss did not improve from -173.90463\n",
      "Epoch 5790/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.7683 - val_loss: -174.2769\n",
      "\n",
      "Epoch 05790: loss did not improve from -173.90463\n",
      "Epoch 5791/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5862 - val_loss: -174.0874\n",
      "\n",
      "Epoch 05791: loss did not improve from -173.90463\n",
      "Epoch 5792/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5720 - val_loss: -174.3637\n",
      "\n",
      "Epoch 05792: loss did not improve from -173.90463\n",
      "Epoch 5793/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4645 - val_loss: -174.0287\n",
      "\n",
      "Epoch 05793: loss did not improve from -173.90463\n",
      "Epoch 5794/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.8701 - val_loss: -174.4506\n",
      "\n",
      "Epoch 05794: loss did not improve from -173.90463\n",
      "Epoch 5795/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6605 - val_loss: -173.8139\n",
      "\n",
      "Epoch 05795: loss did not improve from -173.90463\n",
      "Epoch 5796/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5781 - val_loss: -174.3769\n",
      "\n",
      "Epoch 05796: loss did not improve from -173.90463\n",
      "Epoch 5797/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6677 - val_loss: -173.9364\n",
      "\n",
      "Epoch 05797: loss did not improve from -173.90463\n",
      "Epoch 5798/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6643 - val_loss: -174.4081\n",
      "\n",
      "Epoch 05798: loss did not improve from -173.90463\n",
      "Epoch 5799/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9004 - val_loss: -174.3612\n",
      "\n",
      "Epoch 05799: loss did not improve from -173.90463\n",
      "Epoch 5800/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5275 - val_loss: -174.2894\n",
      "\n",
      "Epoch 05800: loss did not improve from -173.90463\n",
      "Epoch 5801/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6288 - val_loss: -174.1763\n",
      "\n",
      "Epoch 05801: loss did not improve from -173.90463\n",
      "Epoch 5802/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.7004 - val_loss: -174.4378\n",
      "\n",
      "Epoch 05802: loss did not improve from -173.90463\n",
      "Epoch 5803/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6798 - val_loss: -174.1316\n",
      "\n",
      "Epoch 05803: loss did not improve from -173.90463\n",
      "Epoch 5804/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6736 - val_loss: -174.2643\n",
      "\n",
      "Epoch 05804: loss did not improve from -173.90463\n",
      "Epoch 5805/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6870 - val_loss: -174.2338\n",
      "\n",
      "Epoch 05805: loss did not improve from -173.90463\n",
      "Epoch 5806/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4823 - val_loss: -174.0290\n",
      "\n",
      "Epoch 05806: loss did not improve from -173.90463\n",
      "Epoch 5807/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4097 - val_loss: -174.2474\n",
      "\n",
      "Epoch 05807: loss did not improve from -173.90463\n",
      "Epoch 5808/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5164 - val_loss: -173.8932\n",
      "\n",
      "Epoch 05808: loss did not improve from -173.90463\n",
      "Epoch 5809/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6335 - val_loss: -174.4200\n",
      "\n",
      "Epoch 05809: loss did not improve from -173.90463\n",
      "Epoch 5810/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5938 - val_loss: -174.1537\n",
      "\n",
      "Epoch 05810: loss did not improve from -173.90463\n",
      "Epoch 5811/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6688 - val_loss: -174.4316\n",
      "\n",
      "Epoch 05811: loss did not improve from -173.90463\n",
      "Epoch 5812/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.8195 - val_loss: -174.1518\n",
      "\n",
      "Epoch 05812: loss did not improve from -173.90463\n",
      "Epoch 5813/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.8854 - val_loss: -174.4257\n",
      "\n",
      "Epoch 05813: loss did not improve from -173.90463\n",
      "Epoch 5814/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4585 - val_loss: -174.1508\n",
      "\n",
      "Epoch 05814: loss did not improve from -173.90463\n",
      "Epoch 5815/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4862 - val_loss: -174.3765\n",
      "\n",
      "Epoch 05815: loss did not improve from -173.90463\n",
      "Epoch 5816/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.8312 - val_loss: -174.3171\n",
      "\n",
      "Epoch 05816: loss did not improve from -173.90463\n",
      "Epoch 5817/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.8388 - val_loss: -174.2867\n",
      "\n",
      "Epoch 05817: loss did not improve from -173.90463\n",
      "Epoch 5818/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.8208 - val_loss: -174.2376\n",
      "\n",
      "Epoch 05818: loss did not improve from -173.90463\n",
      "Epoch 5819/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9223 - val_loss: -174.4750\n",
      "\n",
      "Epoch 05819: loss improved from -173.90463 to -173.92225, saving model to gendance.h5\n",
      "Epoch 5820/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.1328 - val_loss: -174.5274\n",
      "\n",
      "Epoch 05820: loss improved from -173.92225 to -174.13277, saving model to gendance.h5\n",
      "Epoch 5821/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -173.8731 - val_loss: -174.3800\n",
      "\n",
      "Epoch 05821: loss did not improve from -174.13277\n",
      "Epoch 5822/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.8199 - val_loss: -174.4371\n",
      "\n",
      "Epoch 05822: loss did not improve from -174.13277\n",
      "Epoch 5823/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.8281 - val_loss: -174.4019\n",
      "\n",
      "Epoch 05823: loss did not improve from -174.13277\n",
      "Epoch 5824/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9307 - val_loss: -174.3804\n",
      "\n",
      "Epoch 05824: loss did not improve from -174.13277\n",
      "Epoch 5825/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.8528 - val_loss: -174.2731\n",
      "\n",
      "Epoch 05825: loss did not improve from -174.13277\n",
      "Epoch 5826/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.8333 - val_loss: -174.1815\n",
      "\n",
      "Epoch 05826: loss did not improve from -174.13277\n",
      "Epoch 5827/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.7651 - val_loss: -174.5033\n",
      "\n",
      "Epoch 05827: loss did not improve from -174.13277\n",
      "Epoch 5828/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.8745 - val_loss: -174.2921\n",
      "\n",
      "Epoch 05828: loss did not improve from -174.13277\n",
      "Epoch 5829/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.7254 - val_loss: -174.4729\n",
      "\n",
      "Epoch 05829: loss did not improve from -174.13277\n",
      "Epoch 5830/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.8380 - val_loss: -174.2992\n",
      "\n",
      "Epoch 05830: loss did not improve from -174.13277\n",
      "Epoch 5831/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0269 - val_loss: -174.5044\n",
      "\n",
      "Epoch 05831: loss did not improve from -174.13277\n",
      "Epoch 5832/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.7700 - val_loss: -174.3150\n",
      "\n",
      "Epoch 05832: loss did not improve from -174.13277\n",
      "Epoch 5833/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9787 - val_loss: -174.4497\n",
      "\n",
      "Epoch 05833: loss did not improve from -174.13277\n",
      "Epoch 5834/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.7871 - val_loss: -174.2906\n",
      "\n",
      "Epoch 05834: loss did not improve from -174.13277\n",
      "Epoch 5835/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6778 - val_loss: -174.2765\n",
      "\n",
      "Epoch 05835: loss did not improve from -174.13277\n",
      "Epoch 5836/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5872 - val_loss: -174.4163\n",
      "\n",
      "Epoch 05836: loss did not improve from -174.13277\n",
      "Epoch 5837/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9648 - val_loss: -174.0124\n",
      "\n",
      "Epoch 05837: loss did not improve from -174.13277\n",
      "Epoch 5838/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4310 - val_loss: -174.3523\n",
      "\n",
      "Epoch 05838: loss did not improve from -174.13277\n",
      "Epoch 5839/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5263 - val_loss: -173.9623\n",
      "\n",
      "Epoch 05839: loss did not improve from -174.13277\n",
      "Epoch 5840/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5215 - val_loss: -174.3969\n",
      "\n",
      "Epoch 05840: loss did not improve from -174.13277\n",
      "Epoch 5841/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.8245 - val_loss: -174.0596\n",
      "\n",
      "Epoch 05841: loss did not improve from -174.13277\n",
      "Epoch 5842/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6180 - val_loss: -174.3731\n",
      "\n",
      "Epoch 05842: loss did not improve from -174.13277\n",
      "Epoch 5843/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9943 - val_loss: -174.3083\n",
      "\n",
      "Epoch 05843: loss did not improve from -174.13277\n",
      "Epoch 5844/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0234 - val_loss: -174.4534\n",
      "\n",
      "Epoch 05844: loss did not improve from -174.13277\n",
      "Epoch 5845/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9437 - val_loss: -174.1858\n",
      "\n",
      "Epoch 05845: loss did not improve from -174.13277\n",
      "Epoch 5846/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9945 - val_loss: -174.5571\n",
      "\n",
      "Epoch 05846: loss did not improve from -174.13277\n",
      "Epoch 5847/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.8642 - val_loss: -174.2520\n",
      "\n",
      "Epoch 05847: loss did not improve from -174.13277\n",
      "Epoch 5848/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9905 - val_loss: -174.4607\n",
      "\n",
      "Epoch 05848: loss did not improve from -174.13277\n",
      "Epoch 5849/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9123 - val_loss: -174.3153\n",
      "\n",
      "Epoch 05849: loss did not improve from -174.13277\n",
      "Epoch 5850/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.7690 - val_loss: -174.3731\n",
      "\n",
      "Epoch 05850: loss did not improve from -174.13277\n",
      "Epoch 5851/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.8012 - val_loss: -174.3732\n",
      "\n",
      "Epoch 05851: loss did not improve from -174.13277\n",
      "Epoch 5852/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6776 - val_loss: -174.0727\n",
      "\n",
      "Epoch 05852: loss did not improve from -174.13277\n",
      "Epoch 5853/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.7902 - val_loss: -174.4589\n",
      "\n",
      "Epoch 05853: loss did not improve from -174.13277\n",
      "Epoch 5854/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.8238 - val_loss: -174.2613\n",
      "\n",
      "Epoch 05854: loss did not improve from -174.13277\n",
      "Epoch 5855/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.7015 - val_loss: -174.1687\n",
      "\n",
      "Epoch 05855: loss did not improve from -174.13277\n",
      "Epoch 5856/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.7088 - val_loss: -174.2110\n",
      "\n",
      "Epoch 05856: loss did not improve from -174.13277\n",
      "Epoch 5857/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6849 - val_loss: -174.3031\n",
      "\n",
      "Epoch 05857: loss did not improve from -174.13277\n",
      "Epoch 5858/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.8924 - val_loss: -174.3122\n",
      "\n",
      "Epoch 05858: loss did not improve from -174.13277\n",
      "Epoch 5859/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.8101 - val_loss: -174.5305\n",
      "\n",
      "Epoch 05859: loss did not improve from -174.13277\n",
      "Epoch 5860/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0167 - val_loss: -174.4248\n",
      "\n",
      "Epoch 05860: loss did not improve from -174.13277\n",
      "Epoch 5861/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0303 - val_loss: -174.4014\n",
      "\n",
      "Epoch 05861: loss did not improve from -174.13277\n",
      "Epoch 5862/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9443 - val_loss: -174.1770\n",
      "\n",
      "Epoch 05862: loss did not improve from -174.13277\n",
      "Epoch 5863/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9865 - val_loss: -174.4347\n",
      "\n",
      "Epoch 05863: loss did not improve from -174.13277\n",
      "Epoch 5864/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.8586 - val_loss: -174.4088\n",
      "\n",
      "Epoch 05864: loss did not improve from -174.13277\n",
      "Epoch 5865/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -173.8030 - val_loss: -174.3300\n",
      "\n",
      "Epoch 05865: loss did not improve from -174.13277\n",
      "Epoch 5866/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9343 - val_loss: -174.3811\n",
      "\n",
      "Epoch 05866: loss did not improve from -174.13277\n",
      "Epoch 5867/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9651 - val_loss: -174.3052\n",
      "\n",
      "Epoch 05867: loss did not improve from -174.13277\n",
      "Epoch 5868/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.7617 - val_loss: -174.2291\n",
      "\n",
      "Epoch 05868: loss did not improve from -174.13277\n",
      "Epoch 5869/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.8889 - val_loss: -174.2815\n",
      "\n",
      "Epoch 05869: loss did not improve from -174.13277\n",
      "Epoch 5870/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.7647 - val_loss: -174.4156\n",
      "\n",
      "Epoch 05870: loss did not improve from -174.13277\n",
      "Epoch 5871/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.4417 - val_loss: -173.6544\n",
      "\n",
      "Epoch 05871: loss did not improve from -174.13277\n",
      "Epoch 5872/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.2690 - val_loss: -174.3115\n",
      "\n",
      "Epoch 05872: loss did not improve from -174.13277\n",
      "Epoch 5873/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5123 - val_loss: -173.9251\n",
      "\n",
      "Epoch 05873: loss did not improve from -174.13277\n",
      "Epoch 5874/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6463 - val_loss: -174.4619\n",
      "\n",
      "Epoch 05874: loss did not improve from -174.13277\n",
      "Epoch 5875/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.8305 - val_loss: -174.2167\n",
      "\n",
      "Epoch 05875: loss did not improve from -174.13277\n",
      "Epoch 5876/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.7477 - val_loss: -174.3757\n",
      "\n",
      "Epoch 05876: loss did not improve from -174.13277\n",
      "Epoch 5877/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9056 - val_loss: -174.2124\n",
      "\n",
      "Epoch 05877: loss did not improve from -174.13277\n",
      "Epoch 5878/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9497 - val_loss: -174.4144\n",
      "\n",
      "Epoch 05878: loss did not improve from -174.13277\n",
      "Epoch 5879/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9567 - val_loss: -174.2447\n",
      "\n",
      "Epoch 05879: loss did not improve from -174.13277\n",
      "Epoch 5880/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.7879 - val_loss: -174.2890\n",
      "\n",
      "Epoch 05880: loss did not improve from -174.13277\n",
      "Epoch 5881/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.8778 - val_loss: -174.2736\n",
      "\n",
      "Epoch 05881: loss did not improve from -174.13277\n",
      "Epoch 5882/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.8696 - val_loss: -174.3847\n",
      "\n",
      "Epoch 05882: loss did not improve from -174.13277\n",
      "Epoch 5883/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0351 - val_loss: -174.1758\n",
      "\n",
      "Epoch 05883: loss did not improve from -174.13277\n",
      "Epoch 5884/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9544 - val_loss: -174.3648\n",
      "\n",
      "Epoch 05884: loss did not improve from -174.13277\n",
      "Epoch 5885/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0265 - val_loss: -174.4159\n",
      "\n",
      "Epoch 05885: loss did not improve from -174.13277\n",
      "Epoch 5886/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0796 - val_loss: -174.2870\n",
      "\n",
      "Epoch 05886: loss did not improve from -174.13277\n",
      "Epoch 5887/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0638 - val_loss: -174.4939\n",
      "\n",
      "Epoch 05887: loss did not improve from -174.13277\n",
      "Epoch 5888/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.7481 - val_loss: -174.2045\n",
      "\n",
      "Epoch 05888: loss did not improve from -174.13277\n",
      "Epoch 5889/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9501 - val_loss: -174.3541\n",
      "\n",
      "Epoch 05889: loss did not improve from -174.13277\n",
      "Epoch 5890/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.8239 - val_loss: -174.3527\n",
      "\n",
      "Epoch 05890: loss did not improve from -174.13277\n",
      "Epoch 5891/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -173.8684 - val_loss: -174.3071\n",
      "\n",
      "Epoch 05891: loss did not improve from -174.13277\n",
      "Epoch 5892/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.8500 - val_loss: -174.4152\n",
      "\n",
      "Epoch 05892: loss did not improve from -174.13277\n",
      "Epoch 5893/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.1738 - val_loss: -174.2912\n",
      "\n",
      "Epoch 05893: loss improved from -174.13277 to -174.17376, saving model to gendance.h5\n",
      "Epoch 5894/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0733 - val_loss: -174.5310\n",
      "\n",
      "Epoch 05894: loss did not improve from -174.17376\n",
      "Epoch 5895/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.1580 - val_loss: -174.5019\n",
      "\n",
      "Epoch 05895: loss did not improve from -174.17376\n",
      "Epoch 5896/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -173.8728 - val_loss: -174.3485\n",
      "\n",
      "Epoch 05896: loss did not improve from -174.17376\n",
      "Epoch 5897/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9624 - val_loss: -174.2953\n",
      "\n",
      "Epoch 05897: loss did not improve from -174.17376\n",
      "Epoch 5898/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.8462 - val_loss: -174.2633\n",
      "\n",
      "Epoch 05898: loss did not improve from -174.17376\n",
      "Epoch 5899/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9408 - val_loss: -174.2514\n",
      "\n",
      "Epoch 05899: loss did not improve from -174.17376\n",
      "Epoch 5900/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9086 - val_loss: -174.3818\n",
      "\n",
      "Epoch 05900: loss did not improve from -174.17376\n",
      "Epoch 5901/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9187 - val_loss: -174.4476\n",
      "\n",
      "Epoch 05901: loss did not improve from -174.17376\n",
      "Epoch 5902/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0257 - val_loss: -174.3239\n",
      "\n",
      "Epoch 05902: loss did not improve from -174.17376\n",
      "Epoch 5903/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.8826 - val_loss: -174.2365\n",
      "\n",
      "Epoch 05903: loss did not improve from -174.17376\n",
      "Epoch 5904/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9752 - val_loss: -174.5574\n",
      "\n",
      "Epoch 05904: loss did not improve from -174.17376\n",
      "Epoch 5905/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9201 - val_loss: -174.1329\n",
      "\n",
      "Epoch 05905: loss did not improve from -174.17376\n",
      "Epoch 5906/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.7627 - val_loss: -174.4962\n",
      "\n",
      "Epoch 05906: loss did not improve from -174.17376\n",
      "Epoch 5907/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.5374 - val_loss: -173.9897\n",
      "\n",
      "Epoch 05907: loss did not improve from -174.17376\n",
      "Epoch 5908/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.7277 - val_loss: -174.3320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 05908: loss did not improve from -174.17376\n",
      "Epoch 5909/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0364 - val_loss: -174.1862\n",
      "\n",
      "Epoch 05909: loss did not improve from -174.17376\n",
      "Epoch 5910/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9007 - val_loss: -174.3742\n",
      "\n",
      "Epoch 05910: loss did not improve from -174.17376\n",
      "Epoch 5911/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.7621 - val_loss: -174.3537\n",
      "\n",
      "Epoch 05911: loss did not improve from -174.17376\n",
      "Epoch 5912/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.8353 - val_loss: -174.2804\n",
      "\n",
      "Epoch 05912: loss did not improve from -174.17376\n",
      "Epoch 5913/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9897 - val_loss: -174.5433\n",
      "\n",
      "Epoch 05913: loss did not improve from -174.17376\n",
      "Epoch 5914/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.8316 - val_loss: -174.0687\n",
      "\n",
      "Epoch 05914: loss did not improve from -174.17376\n",
      "Epoch 5915/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9919 - val_loss: -174.5514\n",
      "\n",
      "Epoch 05915: loss did not improve from -174.17376\n",
      "Epoch 5916/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9458 - val_loss: -174.0642\n",
      "\n",
      "Epoch 05916: loss did not improve from -174.17376\n",
      "Epoch 5917/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6977 - val_loss: -174.4740\n",
      "\n",
      "Epoch 05917: loss did not improve from -174.17376\n",
      "Epoch 5918/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.8865 - val_loss: -174.1964\n",
      "\n",
      "Epoch 05918: loss did not improve from -174.17376\n",
      "Epoch 5919/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.8999 - val_loss: -174.5003\n",
      "\n",
      "Epoch 05919: loss did not improve from -174.17376\n",
      "Epoch 5920/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.8848 - val_loss: -174.0167\n",
      "\n",
      "Epoch 05920: loss did not improve from -174.17376\n",
      "Epoch 5921/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.8329 - val_loss: -174.4821\n",
      "\n",
      "Epoch 05921: loss did not improve from -174.17376\n",
      "Epoch 5922/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.7896 - val_loss: -174.0129\n",
      "\n",
      "Epoch 05922: loss did not improve from -174.17376\n",
      "Epoch 5923/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.7388 - val_loss: -174.4547\n",
      "\n",
      "Epoch 05923: loss did not improve from -174.17376\n",
      "Epoch 5924/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9427 - val_loss: -174.2268\n",
      "\n",
      "Epoch 05924: loss did not improve from -174.17376\n",
      "Epoch 5925/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9427 - val_loss: -174.4550\n",
      "\n",
      "Epoch 05925: loss did not improve from -174.17376\n",
      "Epoch 5926/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.1019 - val_loss: -174.3286\n",
      "\n",
      "Epoch 05926: loss did not improve from -174.17376\n",
      "Epoch 5927/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.1060 - val_loss: -174.4511\n",
      "\n",
      "Epoch 05927: loss did not improve from -174.17376\n",
      "Epoch 5928/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9712 - val_loss: -174.2045\n",
      "\n",
      "Epoch 05928: loss did not improve from -174.17376\n",
      "Epoch 5929/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0360 - val_loss: -174.5587\n",
      "\n",
      "Epoch 05929: loss did not improve from -174.17376\n",
      "Epoch 5930/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9503 - val_loss: -174.3920\n",
      "\n",
      "Epoch 05930: loss did not improve from -174.17376\n",
      "Epoch 5931/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0767 - val_loss: -174.3113\n",
      "\n",
      "Epoch 05931: loss did not improve from -174.17376\n",
      "Epoch 5932/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.1340 - val_loss: -174.4114\n",
      "\n",
      "Epoch 05932: loss did not improve from -174.17376\n",
      "Epoch 5933/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0104 - val_loss: -174.2020\n",
      "\n",
      "Epoch 05933: loss did not improve from -174.17376\n",
      "Epoch 5934/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9704 - val_loss: -174.5407\n",
      "\n",
      "Epoch 05934: loss did not improve from -174.17376\n",
      "Epoch 5935/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.8450 - val_loss: -174.0683\n",
      "\n",
      "Epoch 05935: loss did not improve from -174.17376\n",
      "Epoch 5936/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.7228 - val_loss: -174.4659\n",
      "\n",
      "Epoch 05936: loss did not improve from -174.17376\n",
      "Epoch 5937/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.7995 - val_loss: -174.0597\n",
      "\n",
      "Epoch 05937: loss did not improve from -174.17376\n",
      "Epoch 5938/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.7035 - val_loss: -174.3790\n",
      "\n",
      "Epoch 05938: loss did not improve from -174.17376\n",
      "Epoch 5939/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.8133 - val_loss: -174.1221\n",
      "\n",
      "Epoch 05939: loss did not improve from -174.17376\n",
      "Epoch 5940/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9160 - val_loss: -174.6200\n",
      "\n",
      "Epoch 05940: loss did not improve from -174.17376\n",
      "Epoch 5941/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.8550 - val_loss: -174.0203\n",
      "\n",
      "Epoch 05941: loss did not improve from -174.17376\n",
      "Epoch 5942/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9834 - val_loss: -174.4470\n",
      "\n",
      "Epoch 05942: loss did not improve from -174.17376\n",
      "Epoch 5943/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9838 - val_loss: -174.3358\n",
      "\n",
      "Epoch 05943: loss did not improve from -174.17376\n",
      "Epoch 5944/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.1440 - val_loss: -174.6223\n",
      "\n",
      "Epoch 05944: loss did not improve from -174.17376\n",
      "Epoch 5945/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9207 - val_loss: -174.3576\n",
      "\n",
      "Epoch 05945: loss did not improve from -174.17376\n",
      "Epoch 5946/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0435 - val_loss: -174.4909\n",
      "\n",
      "Epoch 05946: loss did not improve from -174.17376\n",
      "Epoch 5947/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9465 - val_loss: -174.4104\n",
      "\n",
      "Epoch 05947: loss did not improve from -174.17376\n",
      "Epoch 5948/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9708 - val_loss: -174.2551\n",
      "\n",
      "Epoch 05948: loss did not improve from -174.17376\n",
      "Epoch 5949/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0658 - val_loss: -174.5697\n",
      "\n",
      "Epoch 05949: loss did not improve from -174.17376\n",
      "Epoch 5950/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.8893 - val_loss: -174.2807\n",
      "\n",
      "Epoch 05950: loss did not improve from -174.17376\n",
      "Epoch 5951/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0372 - val_loss: -174.5600\n",
      "\n",
      "Epoch 05951: loss did not improve from -174.17376\n",
      "Epoch 5952/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.1048 - val_loss: -174.3600\n",
      "\n",
      "Epoch 05952: loss did not improve from -174.17376\n",
      "Epoch 5953/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2366 - val_loss: -174.5997\n",
      "\n",
      "Epoch 05953: loss improved from -174.17376 to -174.23663, saving model to gendance.h5\n",
      "Epoch 5954/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9812 - val_loss: -174.3670\n",
      "\n",
      "Epoch 05954: loss did not improve from -174.23663\n",
      "Epoch 5955/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.1534 - val_loss: -174.6730\n",
      "\n",
      "Epoch 05955: loss did not improve from -174.23663\n",
      "Epoch 5956/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0870 - val_loss: -174.5338\n",
      "\n",
      "Epoch 05956: loss did not improve from -174.23663\n",
      "Epoch 5957/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9403 - val_loss: -174.3440\n",
      "\n",
      "Epoch 05957: loss did not improve from -174.23663\n",
      "Epoch 5958/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -173.9434 - val_loss: -174.4202\n",
      "\n",
      "Epoch 05958: loss did not improve from -174.23663\n",
      "Epoch 5959/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0453 - val_loss: -174.5089\n",
      "\n",
      "Epoch 05959: loss did not improve from -174.23663\n",
      "Epoch 5960/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.8667 - val_loss: -174.4669\n",
      "\n",
      "Epoch 05960: loss did not improve from -174.23663\n",
      "Epoch 5961/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9555 - val_loss: -174.3670\n",
      "\n",
      "Epoch 05961: loss did not improve from -174.23663\n",
      "Epoch 5962/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9776 - val_loss: -174.5406\n",
      "\n",
      "Epoch 05962: loss did not improve from -174.23663\n",
      "Epoch 5963/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0764 - val_loss: -174.3810\n",
      "\n",
      "Epoch 05963: loss did not improve from -174.23663\n",
      "Epoch 5964/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0450 - val_loss: -174.5709\n",
      "\n",
      "Epoch 05964: loss did not improve from -174.23663\n",
      "Epoch 5965/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2057 - val_loss: -174.6191\n",
      "\n",
      "Epoch 05965: loss did not improve from -174.23663\n",
      "Epoch 5966/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0517 - val_loss: -174.4582\n",
      "\n",
      "Epoch 05966: loss did not improve from -174.23663\n",
      "Epoch 5967/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0662 - val_loss: -174.6140\n",
      "\n",
      "Epoch 05967: loss did not improve from -174.23663\n",
      "Epoch 5968/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0115 - val_loss: -174.2773\n",
      "\n",
      "Epoch 05968: loss did not improve from -174.23663\n",
      "Epoch 5969/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0230 - val_loss: -174.6268\n",
      "\n",
      "Epoch 05969: loss did not improve from -174.23663\n",
      "Epoch 5970/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9111 - val_loss: -174.2680\n",
      "\n",
      "Epoch 05970: loss did not improve from -174.23663\n",
      "Epoch 5971/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0723 - val_loss: -174.6371\n",
      "\n",
      "Epoch 05971: loss did not improve from -174.23663\n",
      "Epoch 5972/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.1227 - val_loss: -174.4888\n",
      "\n",
      "Epoch 05972: loss did not improve from -174.23663\n",
      "Epoch 5973/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0133 - val_loss: -174.4797\n",
      "\n",
      "Epoch 05973: loss did not improve from -174.23663\n",
      "Epoch 5974/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.8419 - val_loss: -174.3388\n",
      "\n",
      "Epoch 05974: loss did not improve from -174.23663\n",
      "Epoch 5975/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9568 - val_loss: -174.5169\n",
      "\n",
      "Epoch 05975: loss did not improve from -174.23663\n",
      "Epoch 5976/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0514 - val_loss: -174.3198\n",
      "\n",
      "Epoch 05976: loss did not improve from -174.23663\n",
      "Epoch 5977/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9406 - val_loss: -174.4903\n",
      "\n",
      "Epoch 05977: loss did not improve from -174.23663\n",
      "Epoch 5978/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.8820 - val_loss: -174.3085\n",
      "\n",
      "Epoch 05978: loss did not improve from -174.23663\n",
      "Epoch 5979/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -174.1440 - val_loss: -174.6004\n",
      "\n",
      "Epoch 05979: loss did not improve from -174.23663\n",
      "Epoch 5980/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.8249 - val_loss: -174.3502\n",
      "\n",
      "Epoch 05980: loss did not improve from -174.23663\n",
      "Epoch 5981/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.8390 - val_loss: -174.4371\n",
      "\n",
      "Epoch 05981: loss did not improve from -174.23663\n",
      "Epoch 5982/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0773 - val_loss: -174.2750\n",
      "\n",
      "Epoch 05982: loss did not improve from -174.23663\n",
      "Epoch 5983/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0510 - val_loss: -174.4293\n",
      "\n",
      "Epoch 05983: loss did not improve from -174.23663\n",
      "Epoch 5984/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0605 - val_loss: -174.1995\n",
      "\n",
      "Epoch 05984: loss did not improve from -174.23663\n",
      "Epoch 5985/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0068 - val_loss: -174.5692\n",
      "\n",
      "Epoch 05985: loss did not improve from -174.23663\n",
      "Epoch 5986/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9897 - val_loss: -174.1212\n",
      "\n",
      "Epoch 05986: loss did not improve from -174.23663\n",
      "Epoch 5987/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0294 - val_loss: -174.5507\n",
      "\n",
      "Epoch 05987: loss did not improve from -174.23663\n",
      "Epoch 5988/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.7696 - val_loss: -174.3026\n",
      "\n",
      "Epoch 05988: loss did not improve from -174.23663\n",
      "Epoch 5989/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0433 - val_loss: -174.4304\n",
      "\n",
      "Epoch 05989: loss did not improve from -174.23663\n",
      "Epoch 5990/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.8375 - val_loss: -174.4990\n",
      "\n",
      "Epoch 05990: loss did not improve from -174.23663\n",
      "Epoch 5991/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6397 - val_loss: -173.9444\n",
      "\n",
      "Epoch 05991: loss did not improve from -174.23663\n",
      "Epoch 5992/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.6833 - val_loss: -174.6063\n",
      "\n",
      "Epoch 05992: loss did not improve from -174.23663\n",
      "Epoch 5993/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.8232 - val_loss: -173.7637\n",
      "\n",
      "Epoch 05993: loss did not improve from -174.23663\n",
      "Epoch 5994/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.8123 - val_loss: -174.5171\n",
      "\n",
      "Epoch 05994: loss did not improve from -174.23663\n",
      "Epoch 5995/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9466 - val_loss: -174.1416\n",
      "\n",
      "Epoch 05995: loss did not improve from -174.23663\n",
      "Epoch 5996/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0790 - val_loss: -174.7337\n",
      "\n",
      "Epoch 05996: loss did not improve from -174.23663\n",
      "Epoch 5997/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -174.0959 - val_loss: -174.4542\n",
      "\n",
      "Epoch 05997: loss did not improve from -174.23663\n",
      "Epoch 5998/10000\n",
      "16167/16167 [==============================] - 1s 32us/step - loss: -174.0590 - val_loss: -174.5233\n",
      "\n",
      "Epoch 05998: loss did not improve from -174.23663\n",
      "Epoch 5999/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0910 - val_loss: -174.4976\n",
      "\n",
      "Epoch 05999: loss did not improve from -174.23663\n",
      "Epoch 6000/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.1124 - val_loss: -174.5696\n",
      "\n",
      "Epoch 06000: loss did not improve from -174.23663\n",
      "Epoch 6001/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2902 - val_loss: -174.5446\n",
      "\n",
      "Epoch 06001: loss improved from -174.23663 to -174.29016, saving model to gendance.h5\n",
      "Epoch 6002/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0672 - val_loss: -174.4597\n",
      "\n",
      "Epoch 06002: loss did not improve from -174.29016\n",
      "Epoch 6003/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3420 - val_loss: -174.4044\n",
      "\n",
      "Epoch 06003: loss improved from -174.29016 to -174.34197, saving model to gendance.h5\n",
      "Epoch 6004/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -173.8774 - val_loss: -174.5000\n",
      "\n",
      "Epoch 06004: loss did not improve from -174.34197\n",
      "Epoch 6005/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3153 - val_loss: -174.5729\n",
      "\n",
      "Epoch 06005: loss did not improve from -174.34197\n",
      "Epoch 6006/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.1550 - val_loss: -174.6418\n",
      "\n",
      "Epoch 06006: loss did not improve from -174.34197\n",
      "Epoch 6007/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0483 - val_loss: -174.4619\n",
      "\n",
      "Epoch 06007: loss did not improve from -174.34197\n",
      "Epoch 6008/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9116 - val_loss: -174.4819\n",
      "\n",
      "Epoch 06008: loss did not improve from -174.34197\n",
      "Epoch 6009/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0636 - val_loss: -174.3587\n",
      "\n",
      "Epoch 06009: loss did not improve from -174.34197\n",
      "Epoch 6010/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.1043 - val_loss: -174.5499\n",
      "\n",
      "Epoch 06010: loss did not improve from -174.34197\n",
      "Epoch 6011/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.1822 - val_loss: -174.5703\n",
      "\n",
      "Epoch 06011: loss did not improve from -174.34197\n",
      "Epoch 6012/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0070 - val_loss: -174.2406\n",
      "\n",
      "Epoch 06012: loss did not improve from -174.34197\n",
      "Epoch 6013/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2629 - val_loss: -174.5639\n",
      "\n",
      "Epoch 06013: loss did not improve from -174.34197\n",
      "Epoch 6014/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.1843 - val_loss: -174.4454\n",
      "\n",
      "Epoch 06014: loss did not improve from -174.34197\n",
      "Epoch 6015/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0628 - val_loss: -174.5902\n",
      "\n",
      "Epoch 06015: loss did not improve from -174.34197\n",
      "Epoch 6016/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2634 - val_loss: -174.4221\n",
      "\n",
      "Epoch 06016: loss did not improve from -174.34197\n",
      "Epoch 6017/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.1026 - val_loss: -174.4913\n",
      "\n",
      "Epoch 06017: loss did not improve from -174.34197\n",
      "Epoch 6018/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.1938 - val_loss: -174.5040\n",
      "\n",
      "Epoch 06018: loss did not improve from -174.34197\n",
      "Epoch 6019/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0557 - val_loss: -174.4490\n",
      "\n",
      "Epoch 06019: loss did not improve from -174.34197\n",
      "Epoch 6020/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2030 - val_loss: -174.5929\n",
      "\n",
      "Epoch 06020: loss did not improve from -174.34197\n",
      "Epoch 6021/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.1643 - val_loss: -174.4288\n",
      "\n",
      "Epoch 06021: loss did not improve from -174.34197\n",
      "Epoch 6022/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9516 - val_loss: -174.5380\n",
      "\n",
      "Epoch 06022: loss did not improve from -174.34197\n",
      "Epoch 6023/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2003 - val_loss: -174.4775\n",
      "\n",
      "Epoch 06023: loss did not improve from -174.34197\n",
      "Epoch 6024/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.1938 - val_loss: -174.6303\n",
      "\n",
      "Epoch 06024: loss did not improve from -174.34197\n",
      "Epoch 6025/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0048 - val_loss: -174.2874\n",
      "\n",
      "Epoch 06025: loss did not improve from -174.34197\n",
      "Epoch 6026/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.8347 - val_loss: -174.4821\n",
      "\n",
      "Epoch 06026: loss did not improve from -174.34197\n",
      "Epoch 6027/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.1197 - val_loss: -174.4298\n",
      "\n",
      "Epoch 06027: loss did not improve from -174.34197\n",
      "Epoch 6028/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.1355 - val_loss: -174.5743\n",
      "\n",
      "Epoch 06028: loss did not improve from -174.34197\n",
      "Epoch 6029/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -174.2471 - val_loss: -174.4685\n",
      "\n",
      "Epoch 06029: loss did not improve from -174.34197\n",
      "Epoch 6030/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2373 - val_loss: -174.7197\n",
      "\n",
      "Epoch 06030: loss did not improve from -174.34197\n",
      "Epoch 6031/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.1340 - val_loss: -174.2624\n",
      "\n",
      "Epoch 06031: loss did not improve from -174.34197\n",
      "Epoch 6032/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2880 - val_loss: -174.6868\n",
      "\n",
      "Epoch 06032: loss did not improve from -174.34197\n",
      "Epoch 6033/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0355 - val_loss: -174.2510\n",
      "\n",
      "Epoch 06033: loss did not improve from -174.34197\n",
      "Epoch 6034/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -174.1243 - val_loss: -174.5869\n",
      "\n",
      "Epoch 06034: loss did not improve from -174.34197\n",
      "Epoch 6035/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0225 - val_loss: -174.1975\n",
      "\n",
      "Epoch 06035: loss did not improve from -174.34197\n",
      "Epoch 6036/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0296 - val_loss: -174.6164\n",
      "\n",
      "Epoch 06036: loss did not improve from -174.34197\n",
      "Epoch 6037/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3033 - val_loss: -174.6020\n",
      "\n",
      "Epoch 06037: loss did not improve from -174.34197\n",
      "Epoch 6038/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.8351 - val_loss: -174.2153\n",
      "\n",
      "Epoch 06038: loss did not improve from -174.34197\n",
      "Epoch 6039/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0672 - val_loss: -174.8778\n",
      "\n",
      "Epoch 06039: loss did not improve from -174.34197\n",
      "Epoch 6040/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9358 - val_loss: -174.1787\n",
      "\n",
      "Epoch 06040: loss did not improve from -174.34197\n",
      "Epoch 6041/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2295 - val_loss: -174.6129\n",
      "\n",
      "Epoch 06041: loss did not improve from -174.34197\n",
      "Epoch 6042/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9328 - val_loss: -174.0898\n",
      "\n",
      "Epoch 06042: loss did not improve from -174.34197\n",
      "Epoch 6043/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.8868 - val_loss: -174.6322\n",
      "\n",
      "Epoch 06043: loss did not improve from -174.34197\n",
      "Epoch 6044/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0128 - val_loss: -174.2934\n",
      "\n",
      "Epoch 06044: loss did not improve from -174.34197\n",
      "Epoch 6045/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0604 - val_loss: -174.6033\n",
      "\n",
      "Epoch 06045: loss did not improve from -174.34197\n",
      "Epoch 6046/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0947 - val_loss: -174.3938\n",
      "\n",
      "Epoch 06046: loss did not improve from -174.34197\n",
      "Epoch 6047/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3291 - val_loss: -174.6125\n",
      "\n",
      "Epoch 06047: loss did not improve from -174.34197\n",
      "Epoch 6048/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2654 - val_loss: -174.5075\n",
      "\n",
      "Epoch 06048: loss did not improve from -174.34197\n",
      "Epoch 6049/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3653 - val_loss: -174.6979\n",
      "\n",
      "Epoch 06049: loss improved from -174.34197 to -174.36533, saving model to gendance.h5\n",
      "Epoch 6050/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2169 - val_loss: -174.4231\n",
      "\n",
      "Epoch 06050: loss did not improve from -174.36533\n",
      "Epoch 6051/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2546 - val_loss: -174.6649\n",
      "\n",
      "Epoch 06051: loss did not improve from -174.36533\n",
      "Epoch 6052/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2364 - val_loss: -174.4666\n",
      "\n",
      "Epoch 06052: loss did not improve from -174.36533\n",
      "Epoch 6053/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.1210 - val_loss: -174.6482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 06053: loss did not improve from -174.36533\n",
      "Epoch 6054/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3903 - val_loss: -174.5981\n",
      "\n",
      "Epoch 06054: loss improved from -174.36533 to -174.39029, saving model to gendance.h5\n",
      "Epoch 6055/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -174.0115 - val_loss: -174.4534\n",
      "\n",
      "Epoch 06055: loss did not improve from -174.39029\n",
      "Epoch 6056/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3613 - val_loss: -174.6488\n",
      "\n",
      "Epoch 06056: loss did not improve from -174.39029\n",
      "Epoch 6057/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2863 - val_loss: -174.4991\n",
      "\n",
      "Epoch 06057: loss did not improve from -174.39029\n",
      "Epoch 6058/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3061 - val_loss: -174.5584\n",
      "\n",
      "Epoch 06058: loss did not improve from -174.39029\n",
      "Epoch 6059/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.1921 - val_loss: -174.5703\n",
      "\n",
      "Epoch 06059: loss did not improve from -174.39029\n",
      "Epoch 6060/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3032 - val_loss: -174.3285\n",
      "\n",
      "Epoch 06060: loss did not improve from -174.39029\n",
      "Epoch 6061/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2070 - val_loss: -174.5972\n",
      "\n",
      "Epoch 06061: loss did not improve from -174.39029\n",
      "Epoch 6062/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2039 - val_loss: -174.2804\n",
      "\n",
      "Epoch 06062: loss did not improve from -174.39029\n",
      "Epoch 6063/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2284 - val_loss: -174.6292\n",
      "\n",
      "Epoch 06063: loss did not improve from -174.39029\n",
      "Epoch 6064/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.1696 - val_loss: -174.1567\n",
      "\n",
      "Epoch 06064: loss did not improve from -174.39029\n",
      "Epoch 6065/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.1808 - val_loss: -174.5697\n",
      "\n",
      "Epoch 06065: loss did not improve from -174.39029\n",
      "Epoch 6066/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.1137 - val_loss: -174.4014\n",
      "\n",
      "Epoch 06066: loss did not improve from -174.39029\n",
      "Epoch 6067/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0629 - val_loss: -174.2510\n",
      "\n",
      "Epoch 06067: loss did not improve from -174.39029\n",
      "Epoch 6068/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.1130 - val_loss: -174.4877\n",
      "\n",
      "Epoch 06068: loss did not improve from -174.39029\n",
      "Epoch 6069/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0318 - val_loss: -174.3074\n",
      "\n",
      "Epoch 06069: loss did not improve from -174.39029\n",
      "Epoch 6070/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.8611 - val_loss: -174.6001\n",
      "\n",
      "Epoch 06070: loss did not improve from -174.39029\n",
      "Epoch 6071/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0135 - val_loss: -174.1163\n",
      "\n",
      "Epoch 06071: loss did not improve from -174.39029\n",
      "Epoch 6072/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0915 - val_loss: -174.5546\n",
      "\n",
      "Epoch 06072: loss did not improve from -174.39029\n",
      "Epoch 6073/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0497 - val_loss: -174.3134\n",
      "\n",
      "Epoch 06073: loss did not improve from -174.39029\n",
      "Epoch 6074/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.1614 - val_loss: -174.5687\n",
      "\n",
      "Epoch 06074: loss did not improve from -174.39029\n",
      "Epoch 6075/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3586 - val_loss: -174.5100\n",
      "\n",
      "Epoch 06075: loss did not improve from -174.39029\n",
      "Epoch 6076/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2872 - val_loss: -174.4552\n",
      "\n",
      "Epoch 06076: loss did not improve from -174.39029\n",
      "Epoch 6077/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.1284 - val_loss: -174.6167\n",
      "\n",
      "Epoch 06077: loss did not improve from -174.39029\n",
      "Epoch 6078/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2519 - val_loss: -174.4973\n",
      "\n",
      "Epoch 06078: loss did not improve from -174.39029\n",
      "Epoch 6079/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2315 - val_loss: -174.5479\n",
      "\n",
      "Epoch 06079: loss did not improve from -174.39029\n",
      "Epoch 6080/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2662 - val_loss: -174.5763\n",
      "\n",
      "Epoch 06080: loss did not improve from -174.39029\n",
      "Epoch 6081/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5008 - val_loss: -174.7561\n",
      "\n",
      "Epoch 06081: loss improved from -174.39029 to -174.50084, saving model to gendance.h5\n",
      "Epoch 6082/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.1937 - val_loss: -174.1821\n",
      "\n",
      "Epoch 06082: loss did not improve from -174.50084\n",
      "Epoch 6083/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2720 - val_loss: -174.5796\n",
      "\n",
      "Epoch 06083: loss did not improve from -174.50084\n",
      "Epoch 6084/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.1302 - val_loss: -174.1905\n",
      "\n",
      "Epoch 06084: loss did not improve from -174.50084\n",
      "Epoch 6085/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3118 - val_loss: -174.5949\n",
      "\n",
      "Epoch 06085: loss did not improve from -174.50084\n",
      "Epoch 6086/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4565 - val_loss: -174.5073\n",
      "\n",
      "Epoch 06086: loss did not improve from -174.50084\n",
      "Epoch 6087/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2118 - val_loss: -174.4690\n",
      "\n",
      "Epoch 06087: loss did not improve from -174.50084\n",
      "Epoch 6088/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4300 - val_loss: -174.6461\n",
      "\n",
      "Epoch 06088: loss did not improve from -174.50084\n",
      "Epoch 6089/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3612 - val_loss: -174.5311\n",
      "\n",
      "Epoch 06089: loss did not improve from -174.50084\n",
      "Epoch 6090/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2282 - val_loss: -174.6937\n",
      "\n",
      "Epoch 06090: loss did not improve from -174.50084\n",
      "Epoch 6091/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4414 - val_loss: -174.4905\n",
      "\n",
      "Epoch 06091: loss did not improve from -174.50084\n",
      "Epoch 6092/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2835 - val_loss: -174.5334\n",
      "\n",
      "Epoch 06092: loss did not improve from -174.50084\n",
      "Epoch 6093/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9817 - val_loss: -174.3549\n",
      "\n",
      "Epoch 06093: loss did not improve from -174.50084\n",
      "Epoch 6094/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3516 - val_loss: -174.5879\n",
      "\n",
      "Epoch 06094: loss did not improve from -174.50084\n",
      "Epoch 6095/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2090 - val_loss: -174.5179\n",
      "\n",
      "Epoch 06095: loss did not improve from -174.50084\n",
      "Epoch 6096/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.1898 - val_loss: -174.3592\n",
      "\n",
      "Epoch 06096: loss did not improve from -174.50084\n",
      "Epoch 6097/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.1592 - val_loss: -174.5884\n",
      "\n",
      "Epoch 06097: loss did not improve from -174.50084\n",
      "Epoch 6098/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3714 - val_loss: -174.6213\n",
      "\n",
      "Epoch 06098: loss did not improve from -174.50084\n",
      "Epoch 6099/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3002 - val_loss: -174.5784\n",
      "\n",
      "Epoch 06099: loss did not improve from -174.50084\n",
      "Epoch 6100/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3526 - val_loss: -174.5949\n",
      "\n",
      "Epoch 06100: loss did not improve from -174.50084\n",
      "Epoch 6101/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.1520 - val_loss: -174.2689\n",
      "\n",
      "Epoch 06101: loss did not improve from -174.50084\n",
      "Epoch 6102/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2857 - val_loss: -174.6945\n",
      "\n",
      "Epoch 06102: loss did not improve from -174.50084\n",
      "Epoch 6103/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.1933 - val_loss: -174.0887\n",
      "\n",
      "Epoch 06103: loss did not improve from -174.50084\n",
      "Epoch 6104/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.1212 - val_loss: -174.4566\n",
      "\n",
      "Epoch 06104: loss did not improve from -174.50084\n",
      "Epoch 6105/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2132 - val_loss: -174.0730\n",
      "\n",
      "Epoch 06105: loss did not improve from -174.50084\n",
      "Epoch 6106/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.1185 - val_loss: -174.5560\n",
      "\n",
      "Epoch 06106: loss did not improve from -174.50084\n",
      "Epoch 6107/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2949 - val_loss: -174.2687\n",
      "\n",
      "Epoch 06107: loss did not improve from -174.50084\n",
      "Epoch 6108/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2927 - val_loss: -174.6310\n",
      "\n",
      "Epoch 06108: loss did not improve from -174.50084\n",
      "Epoch 6109/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.9008 - val_loss: -174.3098\n",
      "\n",
      "Epoch 06109: loss did not improve from -174.50084\n",
      "Epoch 6110/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0737 - val_loss: -174.4344\n",
      "\n",
      "Epoch 06110: loss did not improve from -174.50084\n",
      "Epoch 6111/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3253 - val_loss: -174.5876\n",
      "\n",
      "Epoch 06111: loss did not improve from -174.50084\n",
      "Epoch 6112/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0980 - val_loss: -174.4262\n",
      "\n",
      "Epoch 06112: loss did not improve from -174.50084\n",
      "Epoch 6113/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3293 - val_loss: -174.6407\n",
      "\n",
      "Epoch 06113: loss did not improve from -174.50084\n",
      "Epoch 6114/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.1068 - val_loss: -174.4666\n",
      "\n",
      "Epoch 06114: loss did not improve from -174.50084\n",
      "Epoch 6115/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3728 - val_loss: -174.7556\n",
      "\n",
      "Epoch 06115: loss did not improve from -174.50084\n",
      "Epoch 6116/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3975 - val_loss: -174.3242\n",
      "\n",
      "Epoch 06116: loss did not improve from -174.50084\n",
      "Epoch 6117/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3608 - val_loss: -174.5568\n",
      "\n",
      "Epoch 06117: loss did not improve from -174.50084\n",
      "Epoch 6118/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2208 - val_loss: -174.4459\n",
      "\n",
      "Epoch 06118: loss did not improve from -174.50084\n",
      "Epoch 6119/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.1330 - val_loss: -174.5419\n",
      "\n",
      "Epoch 06119: loss did not improve from -174.50084\n",
      "Epoch 6120/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0877 - val_loss: -174.4072\n",
      "\n",
      "Epoch 06120: loss did not improve from -174.50084\n",
      "Epoch 6121/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2615 - val_loss: -174.4636\n",
      "\n",
      "Epoch 06121: loss did not improve from -174.50084\n",
      "Epoch 6122/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0929 - val_loss: -174.4607\n",
      "\n",
      "Epoch 06122: loss did not improve from -174.50084\n",
      "Epoch 6123/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2551 - val_loss: -174.4483\n",
      "\n",
      "Epoch 06123: loss did not improve from -174.50084\n",
      "Epoch 6124/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2243 - val_loss: -174.4391\n",
      "\n",
      "Epoch 06124: loss did not improve from -174.50084\n",
      "Epoch 6125/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2900 - val_loss: -174.6074\n",
      "\n",
      "Epoch 06125: loss did not improve from -174.50084\n",
      "Epoch 6126/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2720 - val_loss: -174.6040\n",
      "\n",
      "Epoch 06126: loss did not improve from -174.50084\n",
      "Epoch 6127/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0316 - val_loss: -174.4460\n",
      "\n",
      "Epoch 06127: loss did not improve from -174.50084\n",
      "Epoch 6128/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4582 - val_loss: -174.6700\n",
      "\n",
      "Epoch 06128: loss did not improve from -174.50084\n",
      "Epoch 6129/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4635 - val_loss: -174.6849\n",
      "\n",
      "Epoch 06129: loss did not improve from -174.50084\n",
      "Epoch 6130/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2914 - val_loss: -174.6699\n",
      "\n",
      "Epoch 06130: loss did not improve from -174.50084\n",
      "Epoch 6131/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2480 - val_loss: -174.6925\n",
      "\n",
      "Epoch 06131: loss did not improve from -174.50084\n",
      "Epoch 6132/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4465 - val_loss: -174.6333\n",
      "\n",
      "Epoch 06132: loss did not improve from -174.50084\n",
      "Epoch 6133/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4827 - val_loss: -174.6535\n",
      "\n",
      "Epoch 06133: loss did not improve from -174.50084\n",
      "Epoch 6134/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2516 - val_loss: -174.6190\n",
      "\n",
      "Epoch 06134: loss did not improve from -174.50084\n",
      "Epoch 6135/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4979 - val_loss: -174.5833\n",
      "\n",
      "Epoch 06135: loss did not improve from -174.50084\n",
      "Epoch 6136/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3244 - val_loss: -174.5693\n",
      "\n",
      "Epoch 06136: loss did not improve from -174.50084\n",
      "Epoch 6137/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3461 - val_loss: -174.5275\n",
      "\n",
      "Epoch 06137: loss did not improve from -174.50084\n",
      "Epoch 6138/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0919 - val_loss: -174.4365\n",
      "\n",
      "Epoch 06138: loss did not improve from -174.50084\n",
      "Epoch 6139/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.1963 - val_loss: -174.5343\n",
      "\n",
      "Epoch 06139: loss did not improve from -174.50084\n",
      "Epoch 6140/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2144 - val_loss: -174.6593\n",
      "\n",
      "Epoch 06140: loss did not improve from -174.50084\n",
      "Epoch 6141/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2544 - val_loss: -174.5923\n",
      "\n",
      "Epoch 06141: loss did not improve from -174.50084\n",
      "Epoch 6142/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3324 - val_loss: -174.7177\n",
      "\n",
      "Epoch 06142: loss did not improve from -174.50084\n",
      "Epoch 6143/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4459 - val_loss: -174.3250\n",
      "\n",
      "Epoch 06143: loss did not improve from -174.50084\n",
      "Epoch 6144/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3485 - val_loss: -174.6901\n",
      "\n",
      "Epoch 06144: loss did not improve from -174.50084\n",
      "Epoch 6145/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2011 - val_loss: -174.1046\n",
      "\n",
      "Epoch 06145: loss did not improve from -174.50084\n",
      "Epoch 6146/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.1835 - val_loss: -174.5271\n",
      "\n",
      "Epoch 06146: loss did not improve from -174.50084\n",
      "Epoch 6147/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.1936 - val_loss: -174.2486\n",
      "\n",
      "Epoch 06147: loss did not improve from -174.50084\n",
      "Epoch 6148/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2868 - val_loss: -174.7373\n",
      "\n",
      "Epoch 06148: loss did not improve from -174.50084\n",
      "Epoch 6149/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.1165 - val_loss: -174.5282\n",
      "\n",
      "Epoch 06149: loss did not improve from -174.50084\n",
      "Epoch 6150/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3812 - val_loss: -174.7113\n",
      "\n",
      "Epoch 06150: loss did not improve from -174.50084\n",
      "Epoch 6151/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2387 - val_loss: -174.7116\n",
      "\n",
      "Epoch 06151: loss did not improve from -174.50084\n",
      "Epoch 6152/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.1399 - val_loss: -174.3287\n",
      "\n",
      "Epoch 06152: loss did not improve from -174.50084\n",
      "Epoch 6153/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -174.1006 - val_loss: -174.4045\n",
      "\n",
      "Epoch 06153: loss did not improve from -174.50084\n",
      "Epoch 6154/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2363 - val_loss: -174.4498\n",
      "\n",
      "Epoch 06154: loss did not improve from -174.50084\n",
      "Epoch 6155/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -173.8337 - val_loss: -174.4862\n",
      "\n",
      "Epoch 06155: loss did not improve from -174.50084\n",
      "Epoch 6156/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -174.1236 - val_loss: -174.3351\n",
      "\n",
      "Epoch 06156: loss did not improve from -174.50084\n",
      "Epoch 6157/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.1765 - val_loss: -174.5977\n",
      "\n",
      "Epoch 06157: loss did not improve from -174.50084\n",
      "Epoch 6158/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3314 - val_loss: -174.3222\n",
      "\n",
      "Epoch 06158: loss did not improve from -174.50084\n",
      "Epoch 6159/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3871 - val_loss: -174.8734\n",
      "\n",
      "Epoch 06159: loss did not improve from -174.50084\n",
      "Epoch 6160/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0567 - val_loss: -174.4205\n",
      "\n",
      "Epoch 06160: loss did not improve from -174.50084\n",
      "Epoch 6161/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0855 - val_loss: -174.6443\n",
      "\n",
      "Epoch 06161: loss did not improve from -174.50084\n",
      "Epoch 6162/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3981 - val_loss: -174.6153\n",
      "\n",
      "Epoch 06162: loss did not improve from -174.50084\n",
      "Epoch 6163/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3072 - val_loss: -174.5473\n",
      "\n",
      "Epoch 06163: loss did not improve from -174.50084\n",
      "Epoch 6164/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3018 - val_loss: -174.5674\n",
      "\n",
      "Epoch 06164: loss did not improve from -174.50084\n",
      "Epoch 6165/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2553 - val_loss: -174.4473\n",
      "\n",
      "Epoch 06165: loss did not improve from -174.50084\n",
      "Epoch 6166/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3938 - val_loss: -174.6858\n",
      "\n",
      "Epoch 06166: loss did not improve from -174.50084\n",
      "Epoch 6167/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0890 - val_loss: -174.5475\n",
      "\n",
      "Epoch 06167: loss did not improve from -174.50084\n",
      "Epoch 6168/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2590 - val_loss: -174.5578\n",
      "\n",
      "Epoch 06168: loss did not improve from -174.50084\n",
      "Epoch 6169/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5413 - val_loss: -174.7918\n",
      "\n",
      "Epoch 06169: loss improved from -174.50084 to -174.54130, saving model to gendance.h5\n",
      "Epoch 6170/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -174.3706 - val_loss: -174.6044\n",
      "\n",
      "Epoch 06170: loss did not improve from -174.54130\n",
      "Epoch 6171/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5015 - val_loss: -174.6920\n",
      "\n",
      "Epoch 06171: loss did not improve from -174.54130\n",
      "Epoch 6172/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4736 - val_loss: -174.8444\n",
      "\n",
      "Epoch 06172: loss did not improve from -174.54130\n",
      "Epoch 6173/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3124 - val_loss: -174.5178\n",
      "\n",
      "Epoch 06173: loss did not improve from -174.54130\n",
      "Epoch 6174/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5250 - val_loss: -174.7693\n",
      "\n",
      "Epoch 06174: loss did not improve from -174.54130\n",
      "Epoch 6175/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5091 - val_loss: -174.4957\n",
      "\n",
      "Epoch 06175: loss did not improve from -174.54130\n",
      "Epoch 6176/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.1900 - val_loss: -174.6552\n",
      "\n",
      "Epoch 06176: loss did not improve from -174.54130\n",
      "Epoch 6177/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2630 - val_loss: -174.6814\n",
      "\n",
      "Epoch 06177: loss did not improve from -174.54130\n",
      "Epoch 6178/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3486 - val_loss: -174.6748\n",
      "\n",
      "Epoch 06178: loss did not improve from -174.54130\n",
      "Epoch 6179/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2487 - val_loss: -174.7441\n",
      "\n",
      "Epoch 06179: loss did not improve from -174.54130\n",
      "Epoch 6180/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3447 - val_loss: -174.5148\n",
      "\n",
      "Epoch 06180: loss did not improve from -174.54130\n",
      "Epoch 6181/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3537 - val_loss: -174.8359\n",
      "\n",
      "Epoch 06181: loss did not improve from -174.54130\n",
      "Epoch 6182/10000\n",
      "16167/16167 [==============================] - 1s 32us/step - loss: -174.2307 - val_loss: -174.4365\n",
      "\n",
      "Epoch 06182: loss did not improve from -174.54130\n",
      "Epoch 6183/10000\n",
      "16167/16167 [==============================] - 1s 31us/step - loss: -174.1932 - val_loss: -174.6818\n",
      "\n",
      "Epoch 06183: loss did not improve from -174.54130\n",
      "Epoch 6184/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3786 - val_loss: -174.5891\n",
      "\n",
      "Epoch 06184: loss did not improve from -174.54130\n",
      "Epoch 6185/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5774 - val_loss: -174.8066\n",
      "\n",
      "Epoch 06185: loss improved from -174.54130 to -174.57738, saving model to gendance.h5\n",
      "Epoch 6186/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6119 - val_loss: -174.7243\n",
      "\n",
      "Epoch 06186: loss improved from -174.57738 to -174.61193, saving model to gendance.h5\n",
      "Epoch 6187/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3827 - val_loss: -174.7589\n",
      "\n",
      "Epoch 06187: loss did not improve from -174.61193\n",
      "Epoch 6188/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2810 - val_loss: -174.4953\n",
      "\n",
      "Epoch 06188: loss did not improve from -174.61193\n",
      "Epoch 6189/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3362 - val_loss: -174.7467\n",
      "\n",
      "Epoch 06189: loss did not improve from -174.61193\n",
      "Epoch 6190/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3602 - val_loss: -174.6697\n",
      "\n",
      "Epoch 06190: loss did not improve from -174.61193\n",
      "Epoch 6191/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5387 - val_loss: -174.8528\n",
      "\n",
      "Epoch 06191: loss did not improve from -174.61193\n",
      "Epoch 6192/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5283 - val_loss: -174.6920\n",
      "\n",
      "Epoch 06192: loss did not improve from -174.61193\n",
      "Epoch 6193/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4761 - val_loss: -174.8117\n",
      "\n",
      "Epoch 06193: loss did not improve from -174.61193\n",
      "Epoch 6194/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4175 - val_loss: -174.6408\n",
      "\n",
      "Epoch 06194: loss did not improve from -174.61193\n",
      "Epoch 6195/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5345 - val_loss: -174.7194\n",
      "\n",
      "Epoch 06195: loss did not improve from -174.61193\n",
      "Epoch 6196/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3941 - val_loss: -174.5867\n",
      "\n",
      "Epoch 06196: loss did not improve from -174.61193\n",
      "Epoch 6197/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5200 - val_loss: -174.7137\n",
      "\n",
      "Epoch 06197: loss did not improve from -174.61193\n",
      "Epoch 6198/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4224 - val_loss: -174.6980\n",
      "\n",
      "Epoch 06198: loss did not improve from -174.61193\n",
      "Epoch 6199/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4393 - val_loss: -174.6166\n",
      "\n",
      "Epoch 06199: loss did not improve from -174.61193\n",
      "Epoch 6200/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4338 - val_loss: -174.6267\n",
      "\n",
      "Epoch 06200: loss did not improve from -174.61193\n",
      "Epoch 6201/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2948 - val_loss: -174.4000\n",
      "\n",
      "Epoch 06201: loss did not improve from -174.61193\n",
      "Epoch 6202/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2371 - val_loss: -174.8290\n",
      "\n",
      "Epoch 06202: loss did not improve from -174.61193\n",
      "Epoch 6203/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3424 - val_loss: -174.2846\n",
      "\n",
      "Epoch 06203: loss did not improve from -174.61193\n",
      "Epoch 6204/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4184 - val_loss: -174.7168\n",
      "\n",
      "Epoch 06204: loss did not improve from -174.61193\n",
      "Epoch 6205/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3768 - val_loss: -174.1763\n",
      "\n",
      "Epoch 06205: loss did not improve from -174.61193\n",
      "Epoch 6206/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.1793 - val_loss: -174.7368\n",
      "\n",
      "Epoch 06206: loss did not improve from -174.61193\n",
      "Epoch 6207/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3688 - val_loss: -174.5596\n",
      "\n",
      "Epoch 06207: loss did not improve from -174.61193\n",
      "Epoch 6208/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4413 - val_loss: -174.6694\n",
      "\n",
      "Epoch 06208: loss did not improve from -174.61193\n",
      "Epoch 6209/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4475 - val_loss: -174.4871\n",
      "\n",
      "Epoch 06209: loss did not improve from -174.61193\n",
      "Epoch 6210/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4044 - val_loss: -174.7210\n",
      "\n",
      "Epoch 06210: loss did not improve from -174.61193\n",
      "Epoch 6211/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4747 - val_loss: -174.6782\n",
      "\n",
      "Epoch 06211: loss did not improve from -174.61193\n",
      "Epoch 6212/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6655 - val_loss: -174.7921\n",
      "\n",
      "Epoch 06212: loss improved from -174.61193 to -174.66548, saving model to gendance.h5\n",
      "Epoch 6213/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5027 - val_loss: -174.7010\n",
      "\n",
      "Epoch 06213: loss did not improve from -174.66548\n",
      "Epoch 6214/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4284 - val_loss: -174.5487\n",
      "\n",
      "Epoch 06214: loss did not improve from -174.66548\n",
      "Epoch 6215/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4428 - val_loss: -174.7630\n",
      "\n",
      "Epoch 06215: loss did not improve from -174.66548\n",
      "Epoch 6216/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.1309 - val_loss: -174.5744\n",
      "\n",
      "Epoch 06216: loss did not improve from -174.66548\n",
      "Epoch 6217/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4331 - val_loss: -174.8476\n",
      "\n",
      "Epoch 06217: loss did not improve from -174.66548\n",
      "Epoch 6218/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3011 - val_loss: -174.4365\n",
      "\n",
      "Epoch 06218: loss did not improve from -174.66548\n",
      "Epoch 6219/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4915 - val_loss: -174.7727\n",
      "\n",
      "Epoch 06219: loss did not improve from -174.66548\n",
      "Epoch 6220/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3806 - val_loss: -174.4230\n",
      "\n",
      "Epoch 06220: loss did not improve from -174.66548\n",
      "Epoch 6221/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3376 - val_loss: -174.6847\n",
      "\n",
      "Epoch 06221: loss did not improve from -174.66548\n",
      "Epoch 6222/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3563 - val_loss: -174.2381\n",
      "\n",
      "Epoch 06222: loss did not improve from -174.66548\n",
      "Epoch 6223/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4738 - val_loss: -174.7029\n",
      "\n",
      "Epoch 06223: loss did not improve from -174.66548\n",
      "Epoch 6224/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2545 - val_loss: -174.3987\n",
      "\n",
      "Epoch 06224: loss did not improve from -174.66548\n",
      "Epoch 6225/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -174.1560 - val_loss: -174.5552\n",
      "\n",
      "Epoch 06225: loss did not improve from -174.66548\n",
      "Epoch 6226/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.0277 - val_loss: -174.7713\n",
      "\n",
      "Epoch 06226: loss did not improve from -174.66548\n",
      "Epoch 6227/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2206 - val_loss: -174.1902\n",
      "\n",
      "Epoch 06227: loss did not improve from -174.66548\n",
      "Epoch 6228/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.1232 - val_loss: -174.6603\n",
      "\n",
      "Epoch 06228: loss did not improve from -174.66548\n",
      "Epoch 6229/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2731 - val_loss: -174.5187\n",
      "\n",
      "Epoch 06229: loss did not improve from -174.66548\n",
      "Epoch 6230/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5330 - val_loss: -174.7908\n",
      "\n",
      "Epoch 06230: loss did not improve from -174.66548\n",
      "Epoch 6231/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2963 - val_loss: -174.4994\n",
      "\n",
      "Epoch 06231: loss did not improve from -174.66548\n",
      "Epoch 6232/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4864 - val_loss: -174.6202\n",
      "\n",
      "Epoch 06232: loss did not improve from -174.66548\n",
      "Epoch 6233/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5498 - val_loss: -174.6461\n",
      "\n",
      "Epoch 06233: loss did not improve from -174.66548\n",
      "Epoch 6234/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4097 - val_loss: -174.7439\n",
      "\n",
      "Epoch 06234: loss did not improve from -174.66548\n",
      "Epoch 6235/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7196 - val_loss: -174.6895\n",
      "\n",
      "Epoch 06235: loss improved from -174.66548 to -174.71961, saving model to gendance.h5\n",
      "Epoch 6236/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4707 - val_loss: -174.6257\n",
      "\n",
      "Epoch 06236: loss did not improve from -174.71961\n",
      "Epoch 6237/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2995 - val_loss: -174.6272\n",
      "\n",
      "Epoch 06237: loss did not improve from -174.71961\n",
      "Epoch 6238/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -174.3329 - val_loss: -174.6650\n",
      "\n",
      "Epoch 06238: loss did not improve from -174.71961\n",
      "Epoch 6239/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4302 - val_loss: -174.4998\n",
      "\n",
      "Epoch 06239: loss did not improve from -174.71961\n",
      "Epoch 6240/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5502 - val_loss: -174.7319\n",
      "\n",
      "Epoch 06240: loss did not improve from -174.71961\n",
      "Epoch 6241/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5957 - val_loss: -174.5564\n",
      "\n",
      "Epoch 06241: loss did not improve from -174.71961\n",
      "Epoch 6242/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4888 - val_loss: -174.8654\n",
      "\n",
      "Epoch 06242: loss did not improve from -174.71961\n",
      "Epoch 6243/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4899 - val_loss: -174.6622\n",
      "\n",
      "Epoch 06243: loss did not improve from -174.71961\n",
      "Epoch 6244/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4349 - val_loss: -174.9014\n",
      "\n",
      "Epoch 06244: loss did not improve from -174.71961\n",
      "Epoch 6245/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3681 - val_loss: -174.5287\n",
      "\n",
      "Epoch 06245: loss did not improve from -174.71961\n",
      "Epoch 6246/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6909 - val_loss: -174.7264\n",
      "\n",
      "Epoch 06246: loss did not improve from -174.71961\n",
      "Epoch 6247/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5919 - val_loss: -174.7146\n",
      "\n",
      "Epoch 06247: loss did not improve from -174.71961\n",
      "Epoch 6248/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2177 - val_loss: -174.6355\n",
      "\n",
      "Epoch 06248: loss did not improve from -174.71961\n",
      "Epoch 6249/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5390 - val_loss: -174.8244\n",
      "\n",
      "Epoch 06249: loss did not improve from -174.71961\n",
      "Epoch 6250/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5268 - val_loss: -174.8127\n",
      "\n",
      "Epoch 06250: loss did not improve from -174.71961\n",
      "Epoch 6251/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4084 - val_loss: -174.6196\n",
      "\n",
      "Epoch 06251: loss did not improve from -174.71961\n",
      "Epoch 6252/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4640 - val_loss: -174.7312\n",
      "\n",
      "Epoch 06252: loss did not improve from -174.71961\n",
      "Epoch 6253/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4885 - val_loss: -174.5613\n",
      "\n",
      "Epoch 06253: loss did not improve from -174.71961\n",
      "Epoch 6254/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4060 - val_loss: -174.6666\n",
      "\n",
      "Epoch 06254: loss did not improve from -174.71961\n",
      "Epoch 6255/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3930 - val_loss: -174.6482\n",
      "\n",
      "Epoch 06255: loss did not improve from -174.71961\n",
      "Epoch 6256/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6593 - val_loss: -174.8658\n",
      "\n",
      "Epoch 06256: loss did not improve from -174.71961\n",
      "Epoch 6257/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3881 - val_loss: -174.6940\n",
      "\n",
      "Epoch 06257: loss did not improve from -174.71961\n",
      "Epoch 6258/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4474 - val_loss: -174.5390\n",
      "\n",
      "Epoch 06258: loss did not improve from -174.71961\n",
      "Epoch 6259/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4167 - val_loss: -174.7126\n",
      "\n",
      "Epoch 06259: loss did not improve from -174.71961\n",
      "Epoch 6260/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2108 - val_loss: -174.2638\n",
      "\n",
      "Epoch 06260: loss did not improve from -174.71961\n",
      "Epoch 6261/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3915 - val_loss: -174.7289\n",
      "\n",
      "Epoch 06261: loss did not improve from -174.71961\n",
      "Epoch 6262/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3993 - val_loss: -174.4438\n",
      "\n",
      "Epoch 06262: loss did not improve from -174.71961\n",
      "Epoch 6263/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4012 - val_loss: -174.6939\n",
      "\n",
      "Epoch 06263: loss did not improve from -174.71961\n",
      "Epoch 6264/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5258 - val_loss: -174.5547\n",
      "\n",
      "Epoch 06264: loss did not improve from -174.71961\n",
      "Epoch 6265/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5722 - val_loss: -174.8133\n",
      "\n",
      "Epoch 06265: loss did not improve from -174.71961\n",
      "Epoch 6266/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3877 - val_loss: -174.5049\n",
      "\n",
      "Epoch 06266: loss did not improve from -174.71961\n",
      "Epoch 6267/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2095 - val_loss: -174.8204\n",
      "\n",
      "Epoch 06267: loss did not improve from -174.71961\n",
      "Epoch 6268/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2883 - val_loss: -174.4140\n",
      "\n",
      "Epoch 06268: loss did not improve from -174.71961\n",
      "Epoch 6269/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6253 - val_loss: -174.7866\n",
      "\n",
      "Epoch 06269: loss did not improve from -174.71961\n",
      "Epoch 6270/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7114 - val_loss: -174.5417\n",
      "\n",
      "Epoch 06270: loss did not improve from -174.71961\n",
      "Epoch 6271/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5318 - val_loss: -174.5950\n",
      "\n",
      "Epoch 06271: loss did not improve from -174.71961\n",
      "Epoch 6272/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4814 - val_loss: -174.7391\n",
      "\n",
      "Epoch 06272: loss did not improve from -174.71961\n",
      "Epoch 6273/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -174.6322 - val_loss: -174.7545\n",
      "\n",
      "Epoch 06273: loss did not improve from -174.71961\n",
      "Epoch 6274/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6493 - val_loss: -174.7850\n",
      "\n",
      "Epoch 06274: loss did not improve from -174.71961\n",
      "Epoch 6275/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6631 - val_loss: -174.7513\n",
      "\n",
      "Epoch 06275: loss did not improve from -174.71961\n",
      "Epoch 6276/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2824 - val_loss: -174.6551\n",
      "\n",
      "Epoch 06276: loss did not improve from -174.71961\n",
      "Epoch 6277/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -174.1510 - val_loss: -174.6613\n",
      "\n",
      "Epoch 06277: loss did not improve from -174.71961\n",
      "Epoch 6278/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5911 - val_loss: -174.7551\n",
      "\n",
      "Epoch 06278: loss did not improve from -174.71961\n",
      "Epoch 6279/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4057 - val_loss: -174.6293\n",
      "\n",
      "Epoch 06279: loss did not improve from -174.71961\n",
      "Epoch 6280/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4855 - val_loss: -174.7835\n",
      "\n",
      "Epoch 06280: loss did not improve from -174.71961\n",
      "Epoch 6281/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5192 - val_loss: -174.6913\n",
      "\n",
      "Epoch 06281: loss did not improve from -174.71961\n",
      "Epoch 6282/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3702 - val_loss: -174.8094\n",
      "\n",
      "Epoch 06282: loss did not improve from -174.71961\n",
      "Epoch 6283/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -174.4212 - val_loss: -174.3371\n",
      "\n",
      "Epoch 06283: loss did not improve from -174.71961\n",
      "Epoch 6284/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5151 - val_loss: -174.8630\n",
      "\n",
      "Epoch 06284: loss did not improve from -174.71961\n",
      "Epoch 6285/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -174.2116 - val_loss: -174.1176\n",
      "\n",
      "Epoch 06285: loss did not improve from -174.71961\n",
      "Epoch 6286/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4142 - val_loss: -174.8059\n",
      "\n",
      "Epoch 06286: loss did not improve from -174.71961\n",
      "Epoch 6287/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4963 - val_loss: -174.4316\n",
      "\n",
      "Epoch 06287: loss did not improve from -174.71961\n",
      "Epoch 6288/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4122 - val_loss: -174.8043\n",
      "\n",
      "Epoch 06288: loss did not improve from -174.71961\n",
      "Epoch 6289/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5630 - val_loss: -174.6761\n",
      "\n",
      "Epoch 06289: loss did not improve from -174.71961\n",
      "Epoch 6290/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6618 - val_loss: -174.7541\n",
      "\n",
      "Epoch 06290: loss did not improve from -174.71961\n",
      "Epoch 6291/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5479 - val_loss: -174.7855\n",
      "\n",
      "Epoch 06291: loss did not improve from -174.71961\n",
      "Epoch 6292/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6614 - val_loss: -174.7691\n",
      "\n",
      "Epoch 06292: loss did not improve from -174.71961\n",
      "Epoch 6293/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5586 - val_loss: -174.7225\n",
      "\n",
      "Epoch 06293: loss did not improve from -174.71961\n",
      "Epoch 6294/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5548 - val_loss: -174.7593\n",
      "\n",
      "Epoch 06294: loss did not improve from -174.71961\n",
      "Epoch 6295/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6697 - val_loss: -174.9071\n",
      "\n",
      "Epoch 06295: loss did not improve from -174.71961\n",
      "Epoch 6296/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3408 - val_loss: -174.6482\n",
      "\n",
      "Epoch 06296: loss did not improve from -174.71961\n",
      "Epoch 6297/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6093 - val_loss: -174.8791\n",
      "\n",
      "Epoch 06297: loss did not improve from -174.71961\n",
      "Epoch 6298/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4456 - val_loss: -174.5127\n",
      "\n",
      "Epoch 06298: loss did not improve from -174.71961\n",
      "Epoch 6299/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -174.5422 - val_loss: -174.8678\n",
      "\n",
      "Epoch 06299: loss did not improve from -174.71961\n",
      "Epoch 6300/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4405 - val_loss: -174.3607\n",
      "\n",
      "Epoch 06300: loss did not improve from -174.71961\n",
      "Epoch 6301/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3345 - val_loss: -174.6813\n",
      "\n",
      "Epoch 06301: loss did not improve from -174.71961\n",
      "Epoch 6302/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6677 - val_loss: -174.6309\n",
      "\n",
      "Epoch 06302: loss did not improve from -174.71961\n",
      "Epoch 6303/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7097 - val_loss: -174.8306\n",
      "\n",
      "Epoch 06303: loss did not improve from -174.71961\n",
      "Epoch 6304/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.1325 - val_loss: -174.6487\n",
      "\n",
      "Epoch 06304: loss did not improve from -174.71961\n",
      "Epoch 6305/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2916 - val_loss: -174.6057\n",
      "\n",
      "Epoch 06305: loss did not improve from -174.71961\n",
      "Epoch 6306/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2959 - val_loss: -174.8027\n",
      "\n",
      "Epoch 06306: loss did not improve from -174.71961\n",
      "Epoch 6307/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4802 - val_loss: -174.6052\n",
      "\n",
      "Epoch 06307: loss did not improve from -174.71961\n",
      "Epoch 6308/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6557 - val_loss: -174.8770\n",
      "\n",
      "Epoch 06308: loss did not improve from -174.71961\n",
      "Epoch 6309/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4401 - val_loss: -174.5363\n",
      "\n",
      "Epoch 06309: loss did not improve from -174.71961\n",
      "Epoch 6310/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5437 - val_loss: -174.7632\n",
      "\n",
      "Epoch 06310: loss did not improve from -174.71961\n",
      "Epoch 6311/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6149 - val_loss: -174.4993\n",
      "\n",
      "Epoch 06311: loss did not improve from -174.71961\n",
      "Epoch 6312/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5306 - val_loss: -174.7782\n",
      "\n",
      "Epoch 06312: loss did not improve from -174.71961\n",
      "Epoch 6313/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4494 - val_loss: -174.4366\n",
      "\n",
      "Epoch 06313: loss did not improve from -174.71961\n",
      "Epoch 6314/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6316 - val_loss: -174.9306\n",
      "\n",
      "Epoch 06314: loss did not improve from -174.71961\n",
      "Epoch 6315/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4645 - val_loss: -174.6620\n",
      "\n",
      "Epoch 06315: loss did not improve from -174.71961\n",
      "Epoch 6316/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5677 - val_loss: -174.7651\n",
      "\n",
      "Epoch 06316: loss did not improve from -174.71961\n",
      "Epoch 6317/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6227 - val_loss: -174.6773\n",
      "\n",
      "Epoch 06317: loss did not improve from -174.71961\n",
      "Epoch 6318/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2201 - val_loss: -174.7059\n",
      "\n",
      "Epoch 06318: loss did not improve from -174.71961\n",
      "Epoch 6319/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4312 - val_loss: -174.7708\n",
      "\n",
      "Epoch 06319: loss did not improve from -174.71961\n",
      "Epoch 6320/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4475 - val_loss: -174.6077\n",
      "\n",
      "Epoch 06320: loss did not improve from -174.71961\n",
      "Epoch 6321/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4062 - val_loss: -174.7640\n",
      "\n",
      "Epoch 06321: loss did not improve from -174.71961\n",
      "Epoch 6322/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -174.5560 - val_loss: -174.5668\n",
      "\n",
      "Epoch 06322: loss did not improve from -174.71961\n",
      "Epoch 6323/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4451 - val_loss: -174.7741\n",
      "\n",
      "Epoch 06323: loss did not improve from -174.71961\n",
      "Epoch 6324/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5353 - val_loss: -174.5724\n",
      "\n",
      "Epoch 06324: loss did not improve from -174.71961\n",
      "Epoch 6325/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4705 - val_loss: -174.7969\n",
      "\n",
      "Epoch 06325: loss did not improve from -174.71961\n",
      "Epoch 6326/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6277 - val_loss: -174.6591\n",
      "\n",
      "Epoch 06326: loss did not improve from -174.71961\n",
      "Epoch 6327/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5505 - val_loss: -174.6686\n",
      "\n",
      "Epoch 06327: loss did not improve from -174.71961\n",
      "Epoch 6328/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5302 - val_loss: -174.7989\n",
      "\n",
      "Epoch 06328: loss did not improve from -174.71961\n",
      "Epoch 6329/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6998 - val_loss: -174.7602\n",
      "\n",
      "Epoch 06329: loss did not improve from -174.71961\n",
      "Epoch 6330/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8076 - val_loss: -174.7531\n",
      "\n",
      "Epoch 06330: loss improved from -174.71961 to -174.80759, saving model to gendance.h5\n",
      "Epoch 6331/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6196 - val_loss: -174.8827\n",
      "\n",
      "Epoch 06331: loss did not improve from -174.80759\n",
      "Epoch 6332/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5325 - val_loss: -174.8270\n",
      "\n",
      "Epoch 06332: loss did not improve from -174.80759\n",
      "Epoch 6333/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5500 - val_loss: -174.7508\n",
      "\n",
      "Epoch 06333: loss did not improve from -174.80759\n",
      "Epoch 6334/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6299 - val_loss: -174.8611\n",
      "\n",
      "Epoch 06334: loss did not improve from -174.80759\n",
      "Epoch 6335/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8665 - val_loss: -174.7779\n",
      "\n",
      "Epoch 06335: loss improved from -174.80759 to -174.86647, saving model to gendance.h5\n",
      "Epoch 6336/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -174.6978 - val_loss: -174.8566\n",
      "\n",
      "Epoch 06336: loss did not improve from -174.86647\n",
      "Epoch 6337/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6484 - val_loss: -174.7247\n",
      "\n",
      "Epoch 06337: loss did not improve from -174.86647\n",
      "Epoch 6338/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6722 - val_loss: -174.8768\n",
      "\n",
      "Epoch 06338: loss did not improve from -174.86647\n",
      "Epoch 6339/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6068 - val_loss: -174.6837\n",
      "\n",
      "Epoch 06339: loss did not improve from -174.86647\n",
      "Epoch 6340/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5309 - val_loss: -174.8757\n",
      "\n",
      "Epoch 06340: loss did not improve from -174.86647\n",
      "Epoch 6341/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4548 - val_loss: -174.6752\n",
      "\n",
      "Epoch 06341: loss did not improve from -174.86647\n",
      "Epoch 6342/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2740 - val_loss: -174.8223\n",
      "\n",
      "Epoch 06342: loss did not improve from -174.86647\n",
      "Epoch 6343/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4972 - val_loss: -174.3540\n",
      "\n",
      "Epoch 06343: loss did not improve from -174.86647\n",
      "Epoch 6344/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3303 - val_loss: -174.9201\n",
      "\n",
      "Epoch 06344: loss did not improve from -174.86647\n",
      "Epoch 6345/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4833 - val_loss: -174.2212\n",
      "\n",
      "Epoch 06345: loss did not improve from -174.86647\n",
      "Epoch 6346/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5558 - val_loss: -174.9985\n",
      "\n",
      "Epoch 06346: loss did not improve from -174.86647\n",
      "Epoch 6347/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3961 - val_loss: -174.5409\n",
      "\n",
      "Epoch 06347: loss did not improve from -174.86647\n",
      "Epoch 6348/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6203 - val_loss: -174.8859\n",
      "\n",
      "Epoch 06348: loss did not improve from -174.86647\n",
      "Epoch 6349/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4981 - val_loss: -174.5486\n",
      "\n",
      "Epoch 06349: loss did not improve from -174.86647\n",
      "Epoch 6350/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6691 - val_loss: -174.7744\n",
      "\n",
      "Epoch 06350: loss did not improve from -174.86647\n",
      "Epoch 6351/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5605 - val_loss: -174.5705\n",
      "\n",
      "Epoch 06351: loss did not improve from -174.86647\n",
      "Epoch 6352/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4472 - val_loss: -174.6993\n",
      "\n",
      "Epoch 06352: loss did not improve from -174.86647\n",
      "Epoch 6353/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6498 - val_loss: -174.8765\n",
      "\n",
      "Epoch 06353: loss did not improve from -174.86647\n",
      "Epoch 6354/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5590 - val_loss: -174.5972\n",
      "\n",
      "Epoch 06354: loss did not improve from -174.86647\n",
      "Epoch 6355/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5828 - val_loss: -174.8480\n",
      "\n",
      "Epoch 06355: loss did not improve from -174.86647\n",
      "Epoch 6356/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4994 - val_loss: -174.5786\n",
      "\n",
      "Epoch 06356: loss did not improve from -174.86647\n",
      "Epoch 6357/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7133 - val_loss: -174.9461\n",
      "\n",
      "Epoch 06357: loss did not improve from -174.86647\n",
      "Epoch 6358/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7136 - val_loss: -174.8279\n",
      "\n",
      "Epoch 06358: loss did not improve from -174.86647\n",
      "Epoch 6359/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7000 - val_loss: -174.8544\n",
      "\n",
      "Epoch 06359: loss did not improve from -174.86647\n",
      "Epoch 6360/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2940 - val_loss: -174.4953\n",
      "\n",
      "Epoch 06360: loss did not improve from -174.86647\n",
      "Epoch 6361/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5264 - val_loss: -174.8805\n",
      "\n",
      "Epoch 06361: loss did not improve from -174.86647\n",
      "Epoch 6362/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6571 - val_loss: -174.8562\n",
      "\n",
      "Epoch 06362: loss did not improve from -174.86647\n",
      "Epoch 6363/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7297 - val_loss: -174.8259\n",
      "\n",
      "Epoch 06363: loss did not improve from -174.86647\n",
      "Epoch 6364/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6111 - val_loss: -174.8566\n",
      "\n",
      "Epoch 06364: loss did not improve from -174.86647\n",
      "Epoch 6365/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7164 - val_loss: -174.7886\n",
      "\n",
      "Epoch 06365: loss did not improve from -174.86647\n",
      "Epoch 6366/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7479 - val_loss: -174.9299\n",
      "\n",
      "Epoch 06366: loss did not improve from -174.86647\n",
      "Epoch 6367/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -174.5804 - val_loss: -174.8060\n",
      "\n",
      "Epoch 06367: loss did not improve from -174.86647\n",
      "Epoch 6368/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6905 - val_loss: -174.7796\n",
      "\n",
      "Epoch 06368: loss did not improve from -174.86647\n",
      "Epoch 6369/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4334 - val_loss: -174.7752\n",
      "\n",
      "Epoch 06369: loss did not improve from -174.86647\n",
      "Epoch 6370/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7113 - val_loss: -174.8845\n",
      "\n",
      "Epoch 06370: loss did not improve from -174.86647\n",
      "Epoch 6371/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6439 - val_loss: -174.8155\n",
      "\n",
      "Epoch 06371: loss did not improve from -174.86647\n",
      "Epoch 6372/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8378 - val_loss: -174.8369\n",
      "\n",
      "Epoch 06372: loss did not improve from -174.86647\n",
      "Epoch 6373/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7083 - val_loss: -174.8926\n",
      "\n",
      "Epoch 06373: loss did not improve from -174.86647\n",
      "Epoch 6374/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6967 - val_loss: -174.8453\n",
      "\n",
      "Epoch 06374: loss did not improve from -174.86647\n",
      "Epoch 6375/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9729 - val_loss: -174.8516\n",
      "\n",
      "Epoch 06375: loss improved from -174.86647 to -174.97288, saving model to gendance.h5\n",
      "Epoch 6376/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6015 - val_loss: -174.7568\n",
      "\n",
      "Epoch 06376: loss did not improve from -174.97288\n",
      "Epoch 6377/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6398 - val_loss: -174.7655\n",
      "\n",
      "Epoch 06377: loss did not improve from -174.97288\n",
      "Epoch 6378/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7078 - val_loss: -174.7222\n",
      "\n",
      "Epoch 06378: loss did not improve from -174.97288\n",
      "Epoch 6379/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5351 - val_loss: -174.8927\n",
      "\n",
      "Epoch 06379: loss did not improve from -174.97288\n",
      "Epoch 6380/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4041 - val_loss: -174.3457\n",
      "\n",
      "Epoch 06380: loss did not improve from -174.97288\n",
      "Epoch 6381/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4322 - val_loss: -174.9256\n",
      "\n",
      "Epoch 06381: loss did not improve from -174.97288\n",
      "Epoch 6382/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3820 - val_loss: -174.3857\n",
      "\n",
      "Epoch 06382: loss did not improve from -174.97288\n",
      "Epoch 6383/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6258 - val_loss: -174.8210\n",
      "\n",
      "Epoch 06383: loss did not improve from -174.97288\n",
      "Epoch 6384/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7021 - val_loss: -174.5366\n",
      "\n",
      "Epoch 06384: loss did not improve from -174.97288\n",
      "Epoch 6385/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7052 - val_loss: -174.8534\n",
      "\n",
      "Epoch 06385: loss did not improve from -174.97288\n",
      "Epoch 6386/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5075 - val_loss: -174.4799\n",
      "\n",
      "Epoch 06386: loss did not improve from -174.97288\n",
      "Epoch 6387/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4742 - val_loss: -174.7523\n",
      "\n",
      "Epoch 06387: loss did not improve from -174.97288\n",
      "Epoch 6388/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5694 - val_loss: -174.7136\n",
      "\n",
      "Epoch 06388: loss did not improve from -174.97288\n",
      "Epoch 6389/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4197 - val_loss: -174.6879\n",
      "\n",
      "Epoch 06389: loss did not improve from -174.97288\n",
      "Epoch 6390/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3684 - val_loss: -174.8303\n",
      "\n",
      "Epoch 06390: loss did not improve from -174.97288\n",
      "Epoch 6391/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4074 - val_loss: -174.5717\n",
      "\n",
      "Epoch 06391: loss did not improve from -174.97288\n",
      "Epoch 6392/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6030 - val_loss: -174.9308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 06392: loss did not improve from -174.97288\n",
      "Epoch 6393/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6787 - val_loss: -174.8137\n",
      "\n",
      "Epoch 06393: loss did not improve from -174.97288\n",
      "Epoch 6394/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7575 - val_loss: -174.9458\n",
      "\n",
      "Epoch 06394: loss did not improve from -174.97288\n",
      "Epoch 6395/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7486 - val_loss: -174.8352\n",
      "\n",
      "Epoch 06395: loss did not improve from -174.97288\n",
      "Epoch 6396/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8923 - val_loss: -174.8690\n",
      "\n",
      "Epoch 06396: loss did not improve from -174.97288\n",
      "Epoch 6397/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8538 - val_loss: -174.9396\n",
      "\n",
      "Epoch 06397: loss did not improve from -174.97288\n",
      "Epoch 6398/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6330 - val_loss: -175.0408\n",
      "\n",
      "Epoch 06398: loss did not improve from -174.97288\n",
      "Epoch 6399/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -174.8952 - val_loss: -174.6916\n",
      "\n",
      "Epoch 06399: loss did not improve from -174.97288\n",
      "Epoch 6400/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7202 - val_loss: -174.9143\n",
      "\n",
      "Epoch 06400: loss did not improve from -174.97288\n",
      "Epoch 6401/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3880 - val_loss: -174.6451\n",
      "\n",
      "Epoch 06401: loss did not improve from -174.97288\n",
      "Epoch 6402/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5359 - val_loss: -174.8855\n",
      "\n",
      "Epoch 06402: loss did not improve from -174.97288\n",
      "Epoch 6403/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4744 - val_loss: -174.7401\n",
      "\n",
      "Epoch 06403: loss did not improve from -174.97288\n",
      "Epoch 6404/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8333 - val_loss: -174.7960\n",
      "\n",
      "Epoch 06404: loss did not improve from -174.97288\n",
      "Epoch 6405/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6772 - val_loss: -174.9435\n",
      "\n",
      "Epoch 06405: loss did not improve from -174.97288\n",
      "Epoch 6406/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6318 - val_loss: -174.7528\n",
      "\n",
      "Epoch 06406: loss did not improve from -174.97288\n",
      "Epoch 6407/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9645 - val_loss: -174.7545\n",
      "\n",
      "Epoch 06407: loss did not improve from -174.97288\n",
      "Epoch 6408/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7136 - val_loss: -174.9122\n",
      "\n",
      "Epoch 06408: loss did not improve from -174.97288\n",
      "Epoch 6409/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6060 - val_loss: -174.8278\n",
      "\n",
      "Epoch 06409: loss did not improve from -174.97288\n",
      "Epoch 6410/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6379 - val_loss: -174.7806\n",
      "\n",
      "Epoch 06410: loss did not improve from -174.97288\n",
      "Epoch 6411/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7433 - val_loss: -174.8407\n",
      "\n",
      "Epoch 06411: loss did not improve from -174.97288\n",
      "Epoch 6412/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7471 - val_loss: -174.8440\n",
      "\n",
      "Epoch 06412: loss did not improve from -174.97288\n",
      "Epoch 6413/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6049 - val_loss: -174.9573\n",
      "\n",
      "Epoch 06413: loss did not improve from -174.97288\n",
      "Epoch 6414/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6628 - val_loss: -174.5642\n",
      "\n",
      "Epoch 06414: loss did not improve from -174.97288\n",
      "Epoch 6415/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -174.5555 - val_loss: -174.8450\n",
      "\n",
      "Epoch 06415: loss did not improve from -174.97288\n",
      "Epoch 6416/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5139 - val_loss: -174.6967\n",
      "\n",
      "Epoch 06416: loss did not improve from -174.97288\n",
      "Epoch 6417/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7665 - val_loss: -174.8714\n",
      "\n",
      "Epoch 06417: loss did not improve from -174.97288\n",
      "Epoch 6418/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6211 - val_loss: -174.6516\n",
      "\n",
      "Epoch 06418: loss did not improve from -174.97288\n",
      "Epoch 6419/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6722 - val_loss: -174.9454\n",
      "\n",
      "Epoch 06419: loss did not improve from -174.97288\n",
      "Epoch 6420/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8239 - val_loss: -174.7501\n",
      "\n",
      "Epoch 06420: loss did not improve from -174.97288\n",
      "Epoch 6421/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7879 - val_loss: -174.9401\n",
      "\n",
      "Epoch 06421: loss did not improve from -174.97288\n",
      "Epoch 6422/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6387 - val_loss: -174.7801\n",
      "\n",
      "Epoch 06422: loss did not improve from -174.97288\n",
      "Epoch 6423/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6477 - val_loss: -174.9221\n",
      "\n",
      "Epoch 06423: loss did not improve from -174.97288\n",
      "Epoch 6424/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8117 - val_loss: -174.8817\n",
      "\n",
      "Epoch 06424: loss did not improve from -174.97288\n",
      "Epoch 6425/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7004 - val_loss: -174.8605\n",
      "\n",
      "Epoch 06425: loss did not improve from -174.97288\n",
      "Epoch 6426/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5202 - val_loss: -174.9383\n",
      "\n",
      "Epoch 06426: loss did not improve from -174.97288\n",
      "Epoch 6427/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7508 - val_loss: -174.7614\n",
      "\n",
      "Epoch 06427: loss did not improve from -174.97288\n",
      "Epoch 6428/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4405 - val_loss: -174.8500\n",
      "\n",
      "Epoch 06428: loss did not improve from -174.97288\n",
      "Epoch 6429/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -174.6248 - val_loss: -174.2463\n",
      "\n",
      "Epoch 06429: loss did not improve from -174.97288\n",
      "Epoch 6430/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.1341 - val_loss: -174.7473\n",
      "\n",
      "Epoch 06430: loss did not improve from -174.97288\n",
      "Epoch 6431/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4577 - val_loss: -174.3677\n",
      "\n",
      "Epoch 06431: loss did not improve from -174.97288\n",
      "Epoch 6432/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6040 - val_loss: -174.9469\n",
      "\n",
      "Epoch 06432: loss did not improve from -174.97288\n",
      "Epoch 6433/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5666 - val_loss: -174.5085\n",
      "\n",
      "Epoch 06433: loss did not improve from -174.97288\n",
      "Epoch 6434/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7797 - val_loss: -174.8910\n",
      "\n",
      "Epoch 06434: loss did not improve from -174.97288\n",
      "Epoch 6435/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7852 - val_loss: -174.7525\n",
      "\n",
      "Epoch 06435: loss did not improve from -174.97288\n",
      "Epoch 6436/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7043 - val_loss: -174.9624\n",
      "\n",
      "Epoch 06436: loss did not improve from -174.97288\n",
      "Epoch 6437/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5828 - val_loss: -174.6690\n",
      "\n",
      "Epoch 06437: loss did not improve from -174.97288\n",
      "Epoch 6438/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8878 - val_loss: -174.7278\n",
      "\n",
      "Epoch 06438: loss did not improve from -174.97288\n",
      "Epoch 6439/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8100 - val_loss: -174.9392\n",
      "\n",
      "Epoch 06439: loss did not improve from -174.97288\n",
      "Epoch 6440/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7344 - val_loss: -174.7873\n",
      "\n",
      "Epoch 06440: loss did not improve from -174.97288\n",
      "Epoch 6441/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -174.7451 - val_loss: -174.8608\n",
      "\n",
      "Epoch 06441: loss did not improve from -174.97288\n",
      "Epoch 6442/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6016 - val_loss: -174.8020\n",
      "\n",
      "Epoch 06442: loss did not improve from -174.97288\n",
      "Epoch 6443/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5822 - val_loss: -174.8588\n",
      "\n",
      "Epoch 06443: loss did not improve from -174.97288\n",
      "Epoch 6444/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5759 - val_loss: -174.7162\n",
      "\n",
      "Epoch 06444: loss did not improve from -174.97288\n",
      "Epoch 6445/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7581 - val_loss: -174.8956\n",
      "\n",
      "Epoch 06445: loss did not improve from -174.97288\n",
      "Epoch 6446/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8615 - val_loss: -174.7524\n",
      "\n",
      "Epoch 06446: loss did not improve from -174.97288\n",
      "Epoch 6447/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7238 - val_loss: -174.9340\n",
      "\n",
      "Epoch 06447: loss did not improve from -174.97288\n",
      "Epoch 6448/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7920 - val_loss: -174.7733\n",
      "\n",
      "Epoch 06448: loss did not improve from -174.97288\n",
      "Epoch 6449/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8045 - val_loss: -175.1239\n",
      "\n",
      "Epoch 06449: loss did not improve from -174.97288\n",
      "Epoch 6450/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7525 - val_loss: -174.7980\n",
      "\n",
      "Epoch 06450: loss did not improve from -174.97288\n",
      "Epoch 6451/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7532 - val_loss: -175.1169\n",
      "\n",
      "Epoch 06451: loss did not improve from -174.97288\n",
      "Epoch 6452/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8204 - val_loss: -174.9740\n",
      "\n",
      "Epoch 06452: loss did not improve from -174.97288\n",
      "Epoch 6453/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7124 - val_loss: -174.9493\n",
      "\n",
      "Epoch 06453: loss did not improve from -174.97288\n",
      "Epoch 6454/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6942 - val_loss: -174.8563\n",
      "\n",
      "Epoch 06454: loss did not improve from -174.97288\n",
      "Epoch 6455/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6719 - val_loss: -174.9317\n",
      "\n",
      "Epoch 06455: loss did not improve from -174.97288\n",
      "Epoch 6456/10000\n",
      "16167/16167 [==============================] - 1s 31us/step - loss: -174.8708 - val_loss: -174.9555\n",
      "\n",
      "Epoch 06456: loss did not improve from -174.97288\n",
      "Epoch 6457/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6191 - val_loss: -174.8267\n",
      "\n",
      "Epoch 06457: loss did not improve from -174.97288\n",
      "Epoch 6458/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7444 - val_loss: -174.8305\n",
      "\n",
      "Epoch 06458: loss did not improve from -174.97288\n",
      "Epoch 6459/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9857 - val_loss: -175.0725\n",
      "\n",
      "Epoch 06459: loss improved from -174.97288 to -174.98573, saving model to gendance.h5\n",
      "Epoch 6460/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8573 - val_loss: -174.6269\n",
      "\n",
      "Epoch 06460: loss did not improve from -174.98573\n",
      "Epoch 6461/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -174.5431 - val_loss: -175.0573\n",
      "\n",
      "Epoch 06461: loss did not improve from -174.98573\n",
      "Epoch 6462/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -174.8222 - val_loss: -174.6435\n",
      "\n",
      "Epoch 06462: loss did not improve from -174.98573\n",
      "Epoch 6463/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7302 - val_loss: -175.0520\n",
      "\n",
      "Epoch 06463: loss did not improve from -174.98573\n",
      "Epoch 6464/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7938 - val_loss: -174.8879\n",
      "\n",
      "Epoch 06464: loss did not improve from -174.98573\n",
      "Epoch 6465/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6747 - val_loss: -174.7584\n",
      "\n",
      "Epoch 06465: loss did not improve from -174.98573\n",
      "Epoch 6466/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6773 - val_loss: -174.9441\n",
      "\n",
      "Epoch 06466: loss did not improve from -174.98573\n",
      "Epoch 6467/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7140 - val_loss: -174.8343\n",
      "\n",
      "Epoch 06467: loss did not improve from -174.98573\n",
      "Epoch 6468/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9101 - val_loss: -174.8735\n",
      "\n",
      "Epoch 06468: loss did not improve from -174.98573\n",
      "Epoch 6469/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8197 - val_loss: -174.9393\n",
      "\n",
      "Epoch 06469: loss did not improve from -174.98573\n",
      "Epoch 6470/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8736 - val_loss: -175.0269\n",
      "\n",
      "Epoch 06470: loss did not improve from -174.98573\n",
      "Epoch 6471/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5376 - val_loss: -174.7236\n",
      "\n",
      "Epoch 06471: loss did not improve from -174.98573\n",
      "Epoch 6472/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9470 - val_loss: -175.0379\n",
      "\n",
      "Epoch 06472: loss did not improve from -174.98573\n",
      "Epoch 6473/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6061 - val_loss: -174.7738\n",
      "\n",
      "Epoch 06473: loss did not improve from -174.98573\n",
      "Epoch 6474/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7616 - val_loss: -174.8847\n",
      "\n",
      "Epoch 06474: loss did not improve from -174.98573\n",
      "Epoch 6475/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -174.8946 - val_loss: -174.7467\n",
      "\n",
      "Epoch 06475: loss did not improve from -174.98573\n",
      "Epoch 6476/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6470 - val_loss: -174.9680\n",
      "\n",
      "Epoch 06476: loss did not improve from -174.98573\n",
      "Epoch 6477/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6367 - val_loss: -174.6598\n",
      "\n",
      "Epoch 06477: loss did not improve from -174.98573\n",
      "Epoch 6478/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7711 - val_loss: -175.0252\n",
      "\n",
      "Epoch 06478: loss did not improve from -174.98573\n",
      "Epoch 6479/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6936 - val_loss: -174.7123\n",
      "\n",
      "Epoch 06479: loss did not improve from -174.98573\n",
      "Epoch 6480/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8942 - val_loss: -175.0380\n",
      "\n",
      "Epoch 06480: loss did not improve from -174.98573\n",
      "Epoch 6481/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -174.6557 - val_loss: -174.6752\n",
      "\n",
      "Epoch 06481: loss did not improve from -174.98573\n",
      "Epoch 6482/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8474 - val_loss: -174.7476\n",
      "\n",
      "Epoch 06482: loss did not improve from -174.98573\n",
      "Epoch 6483/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5411 - val_loss: -174.8446\n",
      "\n",
      "Epoch 06483: loss did not improve from -174.98573\n",
      "Epoch 6484/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7610 - val_loss: -174.6231\n",
      "\n",
      "Epoch 06484: loss did not improve from -174.98573\n",
      "Epoch 6485/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5240 - val_loss: -174.8644\n",
      "\n",
      "Epoch 06485: loss did not improve from -174.98573\n",
      "Epoch 6486/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8465 - val_loss: -174.6592\n",
      "\n",
      "Epoch 06486: loss did not improve from -174.98573\n",
      "Epoch 6487/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -174.7333 - val_loss: -174.9437\n",
      "\n",
      "Epoch 06487: loss did not improve from -174.98573\n",
      "Epoch 6488/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6674 - val_loss: -174.8266\n",
      "\n",
      "Epoch 06488: loss did not improve from -174.98573\n",
      "Epoch 6489/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6098 - val_loss: -174.8884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 06489: loss did not improve from -174.98573\n",
      "Epoch 6490/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8750 - val_loss: -174.8142\n",
      "\n",
      "Epoch 06490: loss did not improve from -174.98573\n",
      "Epoch 6491/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6424 - val_loss: -174.8971\n",
      "\n",
      "Epoch 06491: loss did not improve from -174.98573\n",
      "Epoch 6492/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -174.6868 - val_loss: -174.7602\n",
      "\n",
      "Epoch 06492: loss did not improve from -174.98573\n",
      "Epoch 6493/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7850 - val_loss: -175.0276\n",
      "\n",
      "Epoch 06493: loss did not improve from -174.98573\n",
      "Epoch 6494/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7954 - val_loss: -174.7463\n",
      "\n",
      "Epoch 06494: loss did not improve from -174.98573\n",
      "Epoch 6495/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9405 - val_loss: -175.0599\n",
      "\n",
      "Epoch 06495: loss did not improve from -174.98573\n",
      "Epoch 6496/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7893 - val_loss: -174.8239\n",
      "\n",
      "Epoch 06496: loss did not improve from -174.98573\n",
      "Epoch 6497/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8330 - val_loss: -174.8253\n",
      "\n",
      "Epoch 06497: loss did not improve from -174.98573\n",
      "Epoch 6498/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6765 - val_loss: -174.8450\n",
      "\n",
      "Epoch 06498: loss did not improve from -174.98573\n",
      "Epoch 6499/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8385 - val_loss: -174.8675\n",
      "\n",
      "Epoch 06499: loss did not improve from -174.98573\n",
      "Epoch 6500/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8993 - val_loss: -175.0337\n",
      "\n",
      "Epoch 06500: loss did not improve from -174.98573\n",
      "Epoch 6501/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7027 - val_loss: -174.6154\n",
      "\n",
      "Epoch 06501: loss did not improve from -174.98573\n",
      "Epoch 6502/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0148 - val_loss: -175.0048\n",
      "\n",
      "Epoch 06502: loss improved from -174.98573 to -175.01479, saving model to gendance.h5\n",
      "Epoch 6503/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7268 - val_loss: -174.6013\n",
      "\n",
      "Epoch 06503: loss did not improve from -175.01479\n",
      "Epoch 6504/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5511 - val_loss: -175.0700\n",
      "\n",
      "Epoch 06504: loss did not improve from -175.01479\n",
      "Epoch 6505/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0511 - val_loss: -174.8244\n",
      "\n",
      "Epoch 06505: loss improved from -175.01479 to -175.05112, saving model to gendance.h5\n",
      "Epoch 6506/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8575 - val_loss: -174.9003\n",
      "\n",
      "Epoch 06506: loss did not improve from -175.05112\n",
      "Epoch 6507/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -174.7720 - val_loss: -174.8111\n",
      "\n",
      "Epoch 06507: loss did not improve from -175.05112\n",
      "Epoch 6508/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8888 - val_loss: -174.9895\n",
      "\n",
      "Epoch 06508: loss did not improve from -175.05112\n",
      "Epoch 6509/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8017 - val_loss: -174.8420\n",
      "\n",
      "Epoch 06509: loss did not improve from -175.05112\n",
      "Epoch 6510/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9025 - val_loss: -175.0496\n",
      "\n",
      "Epoch 06510: loss did not improve from -175.05112\n",
      "Epoch 6511/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9406 - val_loss: -174.9924\n",
      "\n",
      "Epoch 06511: loss did not improve from -175.05112\n",
      "Epoch 6512/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0482 - val_loss: -174.9067\n",
      "\n",
      "Epoch 06512: loss did not improve from -175.05112\n",
      "Epoch 6513/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8912 - val_loss: -175.1047\n",
      "\n",
      "Epoch 06513: loss did not improve from -175.05112\n",
      "Epoch 6514/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9784 - val_loss: -174.6333\n",
      "\n",
      "Epoch 06514: loss did not improve from -175.05112\n",
      "Epoch 6515/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -174.8292 - val_loss: -175.0177\n",
      "\n",
      "Epoch 06515: loss did not improve from -175.05112\n",
      "Epoch 6516/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7725 - val_loss: -174.7695\n",
      "\n",
      "Epoch 06516: loss did not improve from -175.05112\n",
      "Epoch 6517/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8826 - val_loss: -174.9315\n",
      "\n",
      "Epoch 06517: loss did not improve from -175.05112\n",
      "Epoch 6518/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7760 - val_loss: -174.7761\n",
      "\n",
      "Epoch 06518: loss did not improve from -175.05112\n",
      "Epoch 6519/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7902 - val_loss: -174.8649\n",
      "\n",
      "Epoch 06519: loss did not improve from -175.05112\n",
      "Epoch 6520/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8423 - val_loss: -174.7126\n",
      "\n",
      "Epoch 06520: loss did not improve from -175.05112\n",
      "Epoch 6521/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8623 - val_loss: -174.9553\n",
      "\n",
      "Epoch 06521: loss did not improve from -175.05112\n",
      "Epoch 6522/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9599 - val_loss: -175.0475\n",
      "\n",
      "Epoch 06522: loss did not improve from -175.05112\n",
      "Epoch 6523/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8191 - val_loss: -174.9231\n",
      "\n",
      "Epoch 06523: loss did not improve from -175.05112\n",
      "Epoch 6524/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9586 - val_loss: -175.1032\n",
      "\n",
      "Epoch 06524: loss did not improve from -175.05112\n",
      "Epoch 6525/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9251 - val_loss: -174.7191\n",
      "\n",
      "Epoch 06525: loss did not improve from -175.05112\n",
      "Epoch 6526/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7877 - val_loss: -174.9106\n",
      "\n",
      "Epoch 06526: loss did not improve from -175.05112\n",
      "Epoch 6527/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7102 - val_loss: -174.7457\n",
      "\n",
      "Epoch 06527: loss did not improve from -175.05112\n",
      "Epoch 6528/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7704 - val_loss: -175.0331\n",
      "\n",
      "Epoch 06528: loss did not improve from -175.05112\n",
      "Epoch 6529/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8345 - val_loss: -174.5894\n",
      "\n",
      "Epoch 06529: loss did not improve from -175.05112\n",
      "Epoch 6530/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8481 - val_loss: -175.0672\n",
      "\n",
      "Epoch 06530: loss did not improve from -175.05112\n",
      "Epoch 6531/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8417 - val_loss: -174.7770\n",
      "\n",
      "Epoch 06531: loss did not improve from -175.05112\n",
      "Epoch 6532/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0124 - val_loss: -175.1065\n",
      "\n",
      "Epoch 06532: loss did not improve from -175.05112\n",
      "Epoch 6533/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8313 - val_loss: -174.8412\n",
      "\n",
      "Epoch 06533: loss did not improve from -175.05112\n",
      "Epoch 6534/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8255 - val_loss: -174.9651\n",
      "\n",
      "Epoch 06534: loss did not improve from -175.05112\n",
      "Epoch 6535/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1301 - val_loss: -174.6916\n",
      "\n",
      "Epoch 06535: loss improved from -175.05112 to -175.13012, saving model to gendance.h5\n",
      "Epoch 6536/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9916 - val_loss: -175.0371\n",
      "\n",
      "Epoch 06536: loss did not improve from -175.13012\n",
      "Epoch 6537/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8744 - val_loss: -174.8507\n",
      "\n",
      "Epoch 06537: loss did not improve from -175.13012\n",
      "Epoch 6538/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8179 - val_loss: -175.0691\n",
      "\n",
      "Epoch 06538: loss did not improve from -175.13012\n",
      "Epoch 6539/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2133 - val_loss: -174.8696\n",
      "\n",
      "Epoch 06539: loss improved from -175.13012 to -175.21327, saving model to gendance.h5\n",
      "Epoch 6540/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8517 - val_loss: -175.1285\n",
      "\n",
      "Epoch 06540: loss did not improve from -175.21327\n",
      "Epoch 6541/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9236 - val_loss: -174.9863\n",
      "\n",
      "Epoch 06541: loss did not improve from -175.21327\n",
      "Epoch 6542/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9288 - val_loss: -174.9053\n",
      "\n",
      "Epoch 06542: loss did not improve from -175.21327\n",
      "Epoch 6543/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9423 - val_loss: -174.8662\n",
      "\n",
      "Epoch 06543: loss did not improve from -175.21327\n",
      "Epoch 6544/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9448 - val_loss: -175.0038\n",
      "\n",
      "Epoch 06544: loss did not improve from -175.21327\n",
      "Epoch 6545/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9972 - val_loss: -175.0225\n",
      "\n",
      "Epoch 06545: loss did not improve from -175.21327\n",
      "Epoch 6546/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -175.1108 - val_loss: -175.0116\n",
      "\n",
      "Epoch 06546: loss did not improve from -175.21327\n",
      "Epoch 6547/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9469 - val_loss: -174.8951\n",
      "\n",
      "Epoch 06547: loss did not improve from -175.21327\n",
      "Epoch 6548/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9250 - val_loss: -174.7489\n",
      "\n",
      "Epoch 06548: loss did not improve from -175.21327\n",
      "Epoch 6549/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8189 - val_loss: -175.0758\n",
      "\n",
      "Epoch 06549: loss did not improve from -175.21327\n",
      "Epoch 6550/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7334 - val_loss: -174.7054\n",
      "\n",
      "Epoch 06550: loss did not improve from -175.21327\n",
      "Epoch 6551/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8667 - val_loss: -175.0797\n",
      "\n",
      "Epoch 06551: loss did not improve from -175.21327\n",
      "Epoch 6552/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8881 - val_loss: -175.0614\n",
      "\n",
      "Epoch 06552: loss did not improve from -175.21327\n",
      "Epoch 6553/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8291 - val_loss: -175.0414\n",
      "\n",
      "Epoch 06553: loss did not improve from -175.21327\n",
      "Epoch 6554/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8914 - val_loss: -174.8720\n",
      "\n",
      "Epoch 06554: loss did not improve from -175.21327\n",
      "Epoch 6555/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9410 - val_loss: -175.1472\n",
      "\n",
      "Epoch 06555: loss did not improve from -175.21327\n",
      "Epoch 6556/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8863 - val_loss: -174.7043\n",
      "\n",
      "Epoch 06556: loss did not improve from -175.21327\n",
      "Epoch 6557/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8541 - val_loss: -174.9385\n",
      "\n",
      "Epoch 06557: loss did not improve from -175.21327\n",
      "Epoch 6558/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8514 - val_loss: -174.9574\n",
      "\n",
      "Epoch 06558: loss did not improve from -175.21327\n",
      "Epoch 6559/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9940 - val_loss: -174.9403\n",
      "\n",
      "Epoch 06559: loss did not improve from -175.21327\n",
      "Epoch 6560/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0380 - val_loss: -175.0703\n",
      "\n",
      "Epoch 06560: loss did not improve from -175.21327\n",
      "Epoch 6561/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8619 - val_loss: -174.9538\n",
      "\n",
      "Epoch 06561: loss did not improve from -175.21327\n",
      "Epoch 6562/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9903 - val_loss: -174.9502\n",
      "\n",
      "Epoch 06562: loss did not improve from -175.21327\n",
      "Epoch 6563/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9344 - val_loss: -174.8191\n",
      "\n",
      "Epoch 06563: loss did not improve from -175.21327\n",
      "Epoch 6564/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9579 - val_loss: -174.9287\n",
      "\n",
      "Epoch 06564: loss did not improve from -175.21327\n",
      "Epoch 6565/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -174.9328 - val_loss: -174.8915\n",
      "\n",
      "Epoch 06565: loss did not improve from -175.21327\n",
      "Epoch 6566/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8411 - val_loss: -174.8099\n",
      "\n",
      "Epoch 06566: loss did not improve from -175.21327\n",
      "Epoch 6567/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7373 - val_loss: -175.0509\n",
      "\n",
      "Epoch 06567: loss did not improve from -175.21327\n",
      "Epoch 6568/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7761 - val_loss: -174.7740\n",
      "\n",
      "Epoch 06568: loss did not improve from -175.21327\n",
      "Epoch 6569/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9691 - val_loss: -174.9592\n",
      "\n",
      "Epoch 06569: loss did not improve from -175.21327\n",
      "Epoch 6570/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7897 - val_loss: -174.7215\n",
      "\n",
      "Epoch 06570: loss did not improve from -175.21327\n",
      "Epoch 6571/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8429 - val_loss: -175.0855\n",
      "\n",
      "Epoch 06571: loss did not improve from -175.21327\n",
      "Epoch 6572/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8733 - val_loss: -174.7548\n",
      "\n",
      "Epoch 06572: loss did not improve from -175.21327\n",
      "Epoch 6573/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8407 - val_loss: -174.9092\n",
      "\n",
      "Epoch 06573: loss did not improve from -175.21327\n",
      "Epoch 6574/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8138 - val_loss: -174.8562\n",
      "\n",
      "Epoch 06574: loss did not improve from -175.21327\n",
      "Epoch 6575/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9666 - val_loss: -174.9466\n",
      "\n",
      "Epoch 06575: loss did not improve from -175.21327\n",
      "Epoch 6576/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7718 - val_loss: -174.7496\n",
      "\n",
      "Epoch 06576: loss did not improve from -175.21327\n",
      "Epoch 6577/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8835 - val_loss: -174.9909\n",
      "\n",
      "Epoch 06577: loss did not improve from -175.21327\n",
      "Epoch 6578/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0195 - val_loss: -174.7979\n",
      "\n",
      "Epoch 06578: loss did not improve from -175.21327\n",
      "Epoch 6579/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9057 - val_loss: -175.0118\n",
      "\n",
      "Epoch 06579: loss did not improve from -175.21327\n",
      "Epoch 6580/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6748 - val_loss: -174.7263\n",
      "\n",
      "Epoch 06580: loss did not improve from -175.21327\n",
      "Epoch 6581/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7335 - val_loss: -174.9535\n",
      "\n",
      "Epoch 06581: loss did not improve from -175.21327\n",
      "Epoch 6582/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9197 - val_loss: -174.5467\n",
      "\n",
      "Epoch 06582: loss did not improve from -175.21327\n",
      "Epoch 6583/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3282 - val_loss: -174.7059\n",
      "\n",
      "Epoch 06583: loss did not improve from -175.21327\n",
      "Epoch 6584/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.4868 - val_loss: -174.9990\n",
      "\n",
      "Epoch 06584: loss did not improve from -175.21327\n",
      "Epoch 6585/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.3819 - val_loss: -174.1764\n",
      "\n",
      "Epoch 06585: loss did not improve from -175.21327\n",
      "Epoch 6586/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.2847 - val_loss: -174.9026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 06586: loss did not improve from -175.21327\n",
      "Epoch 6587/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6489 - val_loss: -174.5371\n",
      "\n",
      "Epoch 06587: loss did not improve from -175.21327\n",
      "Epoch 6588/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9567 - val_loss: -175.1159\n",
      "\n",
      "Epoch 06588: loss did not improve from -175.21327\n",
      "Epoch 6589/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8971 - val_loss: -174.8613\n",
      "\n",
      "Epoch 06589: loss did not improve from -175.21327\n",
      "Epoch 6590/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1246 - val_loss: -175.1788\n",
      "\n",
      "Epoch 06590: loss did not improve from -175.21327\n",
      "Epoch 6591/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -175.1313 - val_loss: -174.9949\n",
      "\n",
      "Epoch 06591: loss did not improve from -175.21327\n",
      "Epoch 6592/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9692 - val_loss: -175.1004\n",
      "\n",
      "Epoch 06592: loss did not improve from -175.21327\n",
      "Epoch 6593/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9002 - val_loss: -175.0767\n",
      "\n",
      "Epoch 06593: loss did not improve from -175.21327\n",
      "Epoch 6594/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7180 - val_loss: -174.9652\n",
      "\n",
      "Epoch 06594: loss did not improve from -175.21327\n",
      "Epoch 6595/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0088 - val_loss: -175.0953\n",
      "\n",
      "Epoch 06595: loss did not improve from -175.21327\n",
      "Epoch 6596/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7824 - val_loss: -175.0350\n",
      "\n",
      "Epoch 06596: loss did not improve from -175.21327\n",
      "Epoch 6597/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0633 - val_loss: -174.9360\n",
      "\n",
      "Epoch 06597: loss did not improve from -175.21327\n",
      "Epoch 6598/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9226 - val_loss: -175.0853\n",
      "\n",
      "Epoch 06598: loss did not improve from -175.21327\n",
      "Epoch 6599/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8014 - val_loss: -174.9429\n",
      "\n",
      "Epoch 06599: loss did not improve from -175.21327\n",
      "Epoch 6600/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9442 - val_loss: -175.0407\n",
      "\n",
      "Epoch 06600: loss did not improve from -175.21327\n",
      "Epoch 6601/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9652 - val_loss: -175.0560\n",
      "\n",
      "Epoch 06601: loss did not improve from -175.21327\n",
      "Epoch 6602/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0622 - val_loss: -174.9858\n",
      "\n",
      "Epoch 06602: loss did not improve from -175.21327\n",
      "Epoch 6603/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0677 - val_loss: -175.0928\n",
      "\n",
      "Epoch 06603: loss did not improve from -175.21327\n",
      "Epoch 6604/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0704 - val_loss: -175.1806\n",
      "\n",
      "Epoch 06604: loss did not improve from -175.21327\n",
      "Epoch 6605/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8614 - val_loss: -174.9999\n",
      "\n",
      "Epoch 06605: loss did not improve from -175.21327\n",
      "Epoch 6606/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9814 - val_loss: -175.1433\n",
      "\n",
      "Epoch 06606: loss did not improve from -175.21327\n",
      "Epoch 6607/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0008 - val_loss: -175.0940\n",
      "\n",
      "Epoch 06607: loss did not improve from -175.21327\n",
      "Epoch 6608/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7715 - val_loss: -175.0703\n",
      "\n",
      "Epoch 06608: loss did not improve from -175.21327\n",
      "Epoch 6609/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9496 - val_loss: -174.8563\n",
      "\n",
      "Epoch 06609: loss did not improve from -175.21327\n",
      "Epoch 6610/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1166 - val_loss: -175.2302\n",
      "\n",
      "Epoch 06610: loss did not improve from -175.21327\n",
      "Epoch 6611/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0044 - val_loss: -175.0755\n",
      "\n",
      "Epoch 06611: loss did not improve from -175.21327\n",
      "Epoch 6612/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0908 - val_loss: -175.0779\n",
      "\n",
      "Epoch 06612: loss did not improve from -175.21327\n",
      "Epoch 6613/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7454 - val_loss: -174.9006\n",
      "\n",
      "Epoch 06613: loss did not improve from -175.21327\n",
      "Epoch 6614/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -174.9707 - val_loss: -175.0887\n",
      "\n",
      "Epoch 06614: loss did not improve from -175.21327\n",
      "Epoch 6615/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1181 - val_loss: -175.2094\n",
      "\n",
      "Epoch 06615: loss did not improve from -175.21327\n",
      "Epoch 6616/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0574 - val_loss: -175.0029\n",
      "\n",
      "Epoch 06616: loss did not improve from -175.21327\n",
      "Epoch 6617/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0480 - val_loss: -175.1719\n",
      "\n",
      "Epoch 06617: loss did not improve from -175.21327\n",
      "Epoch 6618/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9194 - val_loss: -174.8690\n",
      "\n",
      "Epoch 06618: loss did not improve from -175.21327\n",
      "Epoch 6619/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9906 - val_loss: -175.0803\n",
      "\n",
      "Epoch 06619: loss did not improve from -175.21327\n",
      "Epoch 6620/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8357 - val_loss: -175.0023\n",
      "\n",
      "Epoch 06620: loss did not improve from -175.21327\n",
      "Epoch 6621/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9967 - val_loss: -175.1271\n",
      "\n",
      "Epoch 06621: loss did not improve from -175.21327\n",
      "Epoch 6622/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8732 - val_loss: -175.0031\n",
      "\n",
      "Epoch 06622: loss did not improve from -175.21327\n",
      "Epoch 6623/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0073 - val_loss: -175.0467\n",
      "\n",
      "Epoch 06623: loss did not improve from -175.21327\n",
      "Epoch 6624/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8468 - val_loss: -174.9106\n",
      "\n",
      "Epoch 06624: loss did not improve from -175.21327\n",
      "Epoch 6625/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9328 - val_loss: -174.9209\n",
      "\n",
      "Epoch 06625: loss did not improve from -175.21327\n",
      "Epoch 6626/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -174.8165 - val_loss: -174.9481\n",
      "\n",
      "Epoch 06626: loss did not improve from -175.21327\n",
      "Epoch 6627/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8906 - val_loss: -175.2449\n",
      "\n",
      "Epoch 06627: loss did not improve from -175.21327\n",
      "Epoch 6628/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9218 - val_loss: -174.8801\n",
      "\n",
      "Epoch 06628: loss did not improve from -175.21327\n",
      "Epoch 6629/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8708 - val_loss: -175.0771\n",
      "\n",
      "Epoch 06629: loss did not improve from -175.21327\n",
      "Epoch 6630/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0392 - val_loss: -175.0186\n",
      "\n",
      "Epoch 06630: loss did not improve from -175.21327\n",
      "Epoch 6631/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9762 - val_loss: -174.9376\n",
      "\n",
      "Epoch 06631: loss did not improve from -175.21327\n",
      "Epoch 6632/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9542 - val_loss: -175.0626\n",
      "\n",
      "Epoch 06632: loss did not improve from -175.21327\n",
      "Epoch 6633/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7247 - val_loss: -174.9410\n",
      "\n",
      "Epoch 06633: loss did not improve from -175.21327\n",
      "Epoch 6634/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9852 - val_loss: -175.0592\n",
      "\n",
      "Epoch 06634: loss did not improve from -175.21327\n",
      "Epoch 6635/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8018 - val_loss: -175.1264\n",
      "\n",
      "Epoch 06635: loss did not improve from -175.21327\n",
      "Epoch 6636/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.6316 - val_loss: -174.4648\n",
      "\n",
      "Epoch 06636: loss did not improve from -175.21327\n",
      "Epoch 6637/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8497 - val_loss: -175.1565\n",
      "\n",
      "Epoch 06637: loss did not improve from -175.21327\n",
      "Epoch 6638/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8453 - val_loss: -174.5714\n",
      "\n",
      "Epoch 06638: loss did not improve from -175.21327\n",
      "Epoch 6639/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.7003 - val_loss: -175.0465\n",
      "\n",
      "Epoch 06639: loss did not improve from -175.21327\n",
      "Epoch 6640/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0924 - val_loss: -175.0936\n",
      "\n",
      "Epoch 06640: loss did not improve from -175.21327\n",
      "Epoch 6641/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0016 - val_loss: -175.1032\n",
      "\n",
      "Epoch 06641: loss did not improve from -175.21327\n",
      "Epoch 6642/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9776 - val_loss: -175.1045\n",
      "\n",
      "Epoch 06642: loss did not improve from -175.21327\n",
      "Epoch 6643/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9822 - val_loss: -175.1239\n",
      "\n",
      "Epoch 06643: loss did not improve from -175.21327\n",
      "Epoch 6644/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0523 - val_loss: -174.9637\n",
      "\n",
      "Epoch 06644: loss did not improve from -175.21327\n",
      "Epoch 6645/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1414 - val_loss: -175.2035\n",
      "\n",
      "Epoch 06645: loss did not improve from -175.21327\n",
      "Epoch 6646/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0339 - val_loss: -175.0284\n",
      "\n",
      "Epoch 06646: loss did not improve from -175.21327\n",
      "Epoch 6647/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1805 - val_loss: -175.1275\n",
      "\n",
      "Epoch 06647: loss did not improve from -175.21327\n",
      "Epoch 6648/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9014 - val_loss: -174.8783\n",
      "\n",
      "Epoch 06648: loss did not improve from -175.21327\n",
      "Epoch 6649/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2077 - val_loss: -175.1687\n",
      "\n",
      "Epoch 06649: loss did not improve from -175.21327\n",
      "Epoch 6650/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9100 - val_loss: -175.1050\n",
      "\n",
      "Epoch 06650: loss did not improve from -175.21327\n",
      "Epoch 6651/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9775 - val_loss: -175.0619\n",
      "\n",
      "Epoch 06651: loss did not improve from -175.21327\n",
      "Epoch 6652/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9979 - val_loss: -175.0069\n",
      "\n",
      "Epoch 06652: loss did not improve from -175.21327\n",
      "Epoch 6653/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0397 - val_loss: -174.9676\n",
      "\n",
      "Epoch 06653: loss did not improve from -175.21327\n",
      "Epoch 6654/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -174.9081 - val_loss: -175.2148\n",
      "\n",
      "Epoch 06654: loss did not improve from -175.21327\n",
      "Epoch 6655/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8729 - val_loss: -174.7750\n",
      "\n",
      "Epoch 06655: loss did not improve from -175.21327\n",
      "Epoch 6656/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8902 - val_loss: -175.0837\n",
      "\n",
      "Epoch 06656: loss did not improve from -175.21327\n",
      "Epoch 6657/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -174.7896 - val_loss: -174.7288\n",
      "\n",
      "Epoch 06657: loss did not improve from -175.21327\n",
      "Epoch 6658/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8100 - val_loss: -175.1626\n",
      "\n",
      "Epoch 06658: loss did not improve from -175.21327\n",
      "Epoch 6659/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8805 - val_loss: -174.8615\n",
      "\n",
      "Epoch 06659: loss did not improve from -175.21327\n",
      "Epoch 6660/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1388 - val_loss: -175.1331\n",
      "\n",
      "Epoch 06660: loss did not improve from -175.21327\n",
      "Epoch 6661/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9930 - val_loss: -174.9136\n",
      "\n",
      "Epoch 06661: loss did not improve from -175.21327\n",
      "Epoch 6662/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9711 - val_loss: -175.1927\n",
      "\n",
      "Epoch 06662: loss did not improve from -175.21327\n",
      "Epoch 6663/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0505 - val_loss: -175.0125\n",
      "\n",
      "Epoch 06663: loss did not improve from -175.21327\n",
      "Epoch 6664/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9612 - val_loss: -174.8977\n",
      "\n",
      "Epoch 06664: loss did not improve from -175.21327\n",
      "Epoch 6665/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1047 - val_loss: -175.1818\n",
      "\n",
      "Epoch 06665: loss did not improve from -175.21327\n",
      "Epoch 6666/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8053 - val_loss: -175.0465\n",
      "\n",
      "Epoch 06666: loss did not improve from -175.21327\n",
      "Epoch 6667/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1583 - val_loss: -175.2705\n",
      "\n",
      "Epoch 06667: loss did not improve from -175.21327\n",
      "Epoch 6668/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0650 - val_loss: -175.1201\n",
      "\n",
      "Epoch 06668: loss did not improve from -175.21327\n",
      "Epoch 6669/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2364 - val_loss: -175.1458\n",
      "\n",
      "Epoch 06669: loss improved from -175.21327 to -175.23643, saving model to gendance.h5\n",
      "Epoch 6670/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2699 - val_loss: -175.0516\n",
      "\n",
      "Epoch 06670: loss improved from -175.23643 to -175.26988, saving model to gendance.h5\n",
      "Epoch 6671/10000\n",
      "16167/16167 [==============================] - 1s 32us/step - loss: -175.0434 - val_loss: -175.2063\n",
      "\n",
      "Epoch 06671: loss did not improve from -175.26988\n",
      "Epoch 6672/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1121 - val_loss: -174.8121\n",
      "\n",
      "Epoch 06672: loss did not improve from -175.26988\n",
      "Epoch 6673/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2149 - val_loss: -175.3268\n",
      "\n",
      "Epoch 06673: loss did not improve from -175.26988\n",
      "Epoch 6674/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0055 - val_loss: -174.9389\n",
      "\n",
      "Epoch 06674: loss did not improve from -175.26988\n",
      "Epoch 6675/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9024 - val_loss: -175.1323\n",
      "\n",
      "Epoch 06675: loss did not improve from -175.26988\n",
      "Epoch 6676/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2253 - val_loss: -175.2017\n",
      "\n",
      "Epoch 06676: loss did not improve from -175.26988\n",
      "Epoch 6677/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0444 - val_loss: -175.0317\n",
      "\n",
      "Epoch 06677: loss did not improve from -175.26988\n",
      "Epoch 6678/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1039 - val_loss: -175.1311\n",
      "\n",
      "Epoch 06678: loss did not improve from -175.26988\n",
      "Epoch 6679/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2974 - val_loss: -175.1099\n",
      "\n",
      "Epoch 06679: loss improved from -175.26988 to -175.29739, saving model to gendance.h5\n",
      "Epoch 6680/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2138 - val_loss: -175.1198\n",
      "\n",
      "Epoch 06680: loss did not improve from -175.29739\n",
      "Epoch 6681/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1366 - val_loss: -175.0294\n",
      "\n",
      "Epoch 06681: loss did not improve from -175.29739\n",
      "Epoch 6682/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0873 - val_loss: -175.1484\n",
      "\n",
      "Epoch 06682: loss did not improve from -175.29739\n",
      "Epoch 6683/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 31us/step - loss: -175.0632 - val_loss: -174.9277\n",
      "\n",
      "Epoch 06683: loss did not improve from -175.29739\n",
      "Epoch 6684/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.5848 - val_loss: -175.0476\n",
      "\n",
      "Epoch 06684: loss did not improve from -175.29739\n",
      "Epoch 6685/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0614 - val_loss: -175.0355\n",
      "\n",
      "Epoch 06685: loss did not improve from -175.29739\n",
      "Epoch 6686/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0282 - val_loss: -175.2716\n",
      "\n",
      "Epoch 06686: loss did not improve from -175.29739\n",
      "Epoch 6687/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0091 - val_loss: -174.8014\n",
      "\n",
      "Epoch 06687: loss did not improve from -175.29739\n",
      "Epoch 6688/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0167 - val_loss: -175.2378\n",
      "\n",
      "Epoch 06688: loss did not improve from -175.29739\n",
      "Epoch 6689/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9857 - val_loss: -174.6571\n",
      "\n",
      "Epoch 06689: loss did not improve from -175.29739\n",
      "Epoch 6690/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9914 - val_loss: -175.1890\n",
      "\n",
      "Epoch 06690: loss did not improve from -175.29739\n",
      "Epoch 6691/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9589 - val_loss: -174.7766\n",
      "\n",
      "Epoch 06691: loss did not improve from -175.29739\n",
      "Epoch 6692/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1126 - val_loss: -175.2266\n",
      "\n",
      "Epoch 06692: loss did not improve from -175.29739\n",
      "Epoch 6693/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9775 - val_loss: -174.9209\n",
      "\n",
      "Epoch 06693: loss did not improve from -175.29739\n",
      "Epoch 6694/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1065 - val_loss: -175.1559\n",
      "\n",
      "Epoch 06694: loss did not improve from -175.29739\n",
      "Epoch 6695/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0853 - val_loss: -175.0396\n",
      "\n",
      "Epoch 06695: loss did not improve from -175.29739\n",
      "Epoch 6696/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2823 - val_loss: -175.1843\n",
      "\n",
      "Epoch 06696: loss did not improve from -175.29739\n",
      "Epoch 6697/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1157 - val_loss: -175.2289\n",
      "\n",
      "Epoch 06697: loss did not improve from -175.29739\n",
      "Epoch 6698/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0961 - val_loss: -174.9443\n",
      "\n",
      "Epoch 06698: loss did not improve from -175.29739\n",
      "Epoch 6699/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1608 - val_loss: -175.0839\n",
      "\n",
      "Epoch 06699: loss did not improve from -175.29739\n",
      "Epoch 6700/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1735 - val_loss: -174.9539\n",
      "\n",
      "Epoch 06700: loss did not improve from -175.29739\n",
      "Epoch 6701/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9441 - val_loss: -175.0041\n",
      "\n",
      "Epoch 06701: loss did not improve from -175.29739\n",
      "Epoch 6702/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8978 - val_loss: -174.8022\n",
      "\n",
      "Epoch 06702: loss did not improve from -175.29739\n",
      "Epoch 6703/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1624 - val_loss: -175.1938\n",
      "\n",
      "Epoch 06703: loss did not improve from -175.29739\n",
      "Epoch 6704/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1541 - val_loss: -175.1686\n",
      "\n",
      "Epoch 06704: loss did not improve from -175.29739\n",
      "Epoch 6705/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0209 - val_loss: -175.2267\n",
      "\n",
      "Epoch 06705: loss did not improve from -175.29739\n",
      "Epoch 6706/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0094 - val_loss: -174.9239\n",
      "\n",
      "Epoch 06706: loss did not improve from -175.29739\n",
      "Epoch 6707/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1120 - val_loss: -175.0832\n",
      "\n",
      "Epoch 06707: loss did not improve from -175.29739\n",
      "Epoch 6708/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9641 - val_loss: -174.9436\n",
      "\n",
      "Epoch 06708: loss did not improve from -175.29739\n",
      "Epoch 6709/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9624 - val_loss: -175.1233\n",
      "\n",
      "Epoch 06709: loss did not improve from -175.29739\n",
      "Epoch 6710/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0354 - val_loss: -174.7624\n",
      "\n",
      "Epoch 06710: loss did not improve from -175.29739\n",
      "Epoch 6711/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2263 - val_loss: -175.2502\n",
      "\n",
      "Epoch 06711: loss did not improve from -175.29739\n",
      "Epoch 6712/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1809 - val_loss: -174.9835\n",
      "\n",
      "Epoch 06712: loss did not improve from -175.29739\n",
      "Epoch 6713/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1704 - val_loss: -175.1631\n",
      "\n",
      "Epoch 06713: loss did not improve from -175.29739\n",
      "Epoch 6714/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1099 - val_loss: -175.1034\n",
      "\n",
      "Epoch 06714: loss did not improve from -175.29739\n",
      "Epoch 6715/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0310 - val_loss: -174.9655\n",
      "\n",
      "Epoch 06715: loss did not improve from -175.29739\n",
      "Epoch 6716/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1542 - val_loss: -175.0749\n",
      "\n",
      "Epoch 06716: loss did not improve from -175.29739\n",
      "Epoch 6717/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0905 - val_loss: -174.8893\n",
      "\n",
      "Epoch 06717: loss did not improve from -175.29739\n",
      "Epoch 6718/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0173 - val_loss: -175.0671\n",
      "\n",
      "Epoch 06718: loss did not improve from -175.29739\n",
      "Epoch 6719/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1594 - val_loss: -174.8930\n",
      "\n",
      "Epoch 06719: loss did not improve from -175.29739\n",
      "Epoch 6720/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9864 - val_loss: -175.1225\n",
      "\n",
      "Epoch 06720: loss did not improve from -175.29739\n",
      "Epoch 6721/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1178 - val_loss: -175.1581\n",
      "\n",
      "Epoch 06721: loss did not improve from -175.29739\n",
      "Epoch 6722/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -174.9259 - val_loss: -175.0284\n",
      "\n",
      "Epoch 06722: loss did not improve from -175.29739\n",
      "Epoch 6723/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -174.9228 - val_loss: -175.1140\n",
      "\n",
      "Epoch 06723: loss did not improve from -175.29739\n",
      "Epoch 6724/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0809 - val_loss: -174.9748\n",
      "\n",
      "Epoch 06724: loss did not improve from -175.29739\n",
      "Epoch 6725/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3738 - val_loss: -175.2599\n",
      "\n",
      "Epoch 06725: loss improved from -175.29739 to -175.37382, saving model to gendance.h5\n",
      "Epoch 6726/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0933 - val_loss: -174.8477\n",
      "\n",
      "Epoch 06726: loss did not improve from -175.37382\n",
      "Epoch 6727/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3341 - val_loss: -175.2116\n",
      "\n",
      "Epoch 06727: loss did not improve from -175.37382\n",
      "Epoch 6728/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9549 - val_loss: -174.8743\n",
      "\n",
      "Epoch 06728: loss did not improve from -175.37382\n",
      "Epoch 6729/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9026 - val_loss: -175.1122\n",
      "\n",
      "Epoch 06729: loss did not improve from -175.37382\n",
      "Epoch 6730/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -174.9720 - val_loss: -174.9388\n",
      "\n",
      "Epoch 06730: loss did not improve from -175.37382\n",
      "Epoch 6731/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2527 - val_loss: -175.0927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 06731: loss did not improve from -175.37382\n",
      "Epoch 6732/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3391 - val_loss: -174.9803\n",
      "\n",
      "Epoch 06732: loss did not improve from -175.37382\n",
      "Epoch 6733/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1519 - val_loss: -175.0630\n",
      "\n",
      "Epoch 06733: loss did not improve from -175.37382\n",
      "Epoch 6734/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -175.1990 - val_loss: -174.9831\n",
      "\n",
      "Epoch 06734: loss did not improve from -175.37382\n",
      "Epoch 6735/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0815 - val_loss: -174.9853\n",
      "\n",
      "Epoch 06735: loss did not improve from -175.37382\n",
      "Epoch 6736/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0745 - val_loss: -175.0520\n",
      "\n",
      "Epoch 06736: loss did not improve from -175.37382\n",
      "Epoch 6737/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1870 - val_loss: -174.7897\n",
      "\n",
      "Epoch 06737: loss did not improve from -175.37382\n",
      "Epoch 6738/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0532 - val_loss: -175.1538\n",
      "\n",
      "Epoch 06738: loss did not improve from -175.37382\n",
      "Epoch 6739/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3455 - val_loss: -174.9173\n",
      "\n",
      "Epoch 06739: loss did not improve from -175.37382\n",
      "Epoch 6740/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1166 - val_loss: -175.0827\n",
      "\n",
      "Epoch 06740: loss did not improve from -175.37382\n",
      "Epoch 6741/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0667 - val_loss: -174.8344\n",
      "\n",
      "Epoch 06741: loss did not improve from -175.37382\n",
      "Epoch 6742/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1791 - val_loss: -175.1303\n",
      "\n",
      "Epoch 06742: loss did not improve from -175.37382\n",
      "Epoch 6743/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9412 - val_loss: -174.8022\n",
      "\n",
      "Epoch 06743: loss did not improve from -175.37382\n",
      "Epoch 6744/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0641 - val_loss: -175.1766\n",
      "\n",
      "Epoch 06744: loss did not improve from -175.37382\n",
      "Epoch 6745/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0611 - val_loss: -174.8012\n",
      "\n",
      "Epoch 06745: loss did not improve from -175.37382\n",
      "Epoch 6746/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3927 - val_loss: -175.1519\n",
      "\n",
      "Epoch 06746: loss improved from -175.37382 to -175.39273, saving model to gendance.h5\n",
      "Epoch 6747/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0799 - val_loss: -174.6823\n",
      "\n",
      "Epoch 06747: loss did not improve from -175.39273\n",
      "Epoch 6748/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0699 - val_loss: -175.1156\n",
      "\n",
      "Epoch 06748: loss did not improve from -175.39273\n",
      "Epoch 6749/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0181 - val_loss: -174.5798\n",
      "\n",
      "Epoch 06749: loss did not improve from -175.39273\n",
      "Epoch 6750/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1286 - val_loss: -175.2199\n",
      "\n",
      "Epoch 06750: loss did not improve from -175.39273\n",
      "Epoch 6751/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8571 - val_loss: -174.8297\n",
      "\n",
      "Epoch 06751: loss did not improve from -175.39273\n",
      "Epoch 6752/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0295 - val_loss: -175.1524\n",
      "\n",
      "Epoch 06752: loss did not improve from -175.39273\n",
      "Epoch 6753/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0560 - val_loss: -175.1670\n",
      "\n",
      "Epoch 06753: loss did not improve from -175.39273\n",
      "Epoch 6754/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.8982 - val_loss: -174.8969\n",
      "\n",
      "Epoch 06754: loss did not improve from -175.39273\n",
      "Epoch 6755/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1938 - val_loss: -175.1127\n",
      "\n",
      "Epoch 06755: loss did not improve from -175.39273\n",
      "Epoch 6756/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4724 - val_loss: -175.1814\n",
      "\n",
      "Epoch 06756: loss improved from -175.39273 to -175.47242, saving model to gendance.h5\n",
      "Epoch 6757/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0149 - val_loss: -175.0319\n",
      "\n",
      "Epoch 06757: loss did not improve from -175.47242\n",
      "Epoch 6758/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0945 - val_loss: -175.2109\n",
      "\n",
      "Epoch 06758: loss did not improve from -175.47242\n",
      "Epoch 6759/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0844 - val_loss: -175.2398\n",
      "\n",
      "Epoch 06759: loss did not improve from -175.47242\n",
      "Epoch 6760/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1833 - val_loss: -175.1221\n",
      "\n",
      "Epoch 06760: loss did not improve from -175.47242\n",
      "Epoch 6761/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1802 - val_loss: -175.1643\n",
      "\n",
      "Epoch 06761: loss did not improve from -175.47242\n",
      "Epoch 6762/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2390 - val_loss: -175.1145\n",
      "\n",
      "Epoch 06762: loss did not improve from -175.47242\n",
      "Epoch 6763/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3242 - val_loss: -175.1752\n",
      "\n",
      "Epoch 06763: loss did not improve from -175.47242\n",
      "Epoch 6764/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0337 - val_loss: -174.8268\n",
      "\n",
      "Epoch 06764: loss did not improve from -175.47242\n",
      "Epoch 6765/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0339 - val_loss: -175.1894\n",
      "\n",
      "Epoch 06765: loss did not improve from -175.47242\n",
      "Epoch 6766/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9971 - val_loss: -174.7503\n",
      "\n",
      "Epoch 06766: loss did not improve from -175.47242\n",
      "Epoch 6767/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1211 - val_loss: -175.2119\n",
      "\n",
      "Epoch 06767: loss did not improve from -175.47242\n",
      "Epoch 6768/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1070 - val_loss: -174.8803\n",
      "\n",
      "Epoch 06768: loss did not improve from -175.47242\n",
      "Epoch 6769/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3357 - val_loss: -175.0946\n",
      "\n",
      "Epoch 06769: loss did not improve from -175.47242\n",
      "Epoch 6770/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0019 - val_loss: -174.9121\n",
      "\n",
      "Epoch 06770: loss did not improve from -175.47242\n",
      "Epoch 6771/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3192 - val_loss: -175.0776\n",
      "\n",
      "Epoch 06771: loss did not improve from -175.47242\n",
      "Epoch 6772/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4223 - val_loss: -175.0338\n",
      "\n",
      "Epoch 06772: loss did not improve from -175.47242\n",
      "Epoch 6773/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0956 - val_loss: -175.0661\n",
      "\n",
      "Epoch 06773: loss did not improve from -175.47242\n",
      "Epoch 6774/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0169 - val_loss: -175.0901\n",
      "\n",
      "Epoch 06774: loss did not improve from -175.47242\n",
      "Epoch 6775/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1527 - val_loss: -175.1025\n",
      "\n",
      "Epoch 06775: loss did not improve from -175.47242\n",
      "Epoch 6776/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1913 - val_loss: -175.1477\n",
      "\n",
      "Epoch 06776: loss did not improve from -175.47242\n",
      "Epoch 6777/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1700 - val_loss: -175.0985\n",
      "\n",
      "Epoch 06777: loss did not improve from -175.47242\n",
      "Epoch 6778/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1537 - val_loss: -175.1240\n",
      "\n",
      "Epoch 06778: loss did not improve from -175.47242\n",
      "Epoch 6779/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2965 - val_loss: -175.0176\n",
      "\n",
      "Epoch 06779: loss did not improve from -175.47242\n",
      "Epoch 6780/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0862 - val_loss: -175.1058\n",
      "\n",
      "Epoch 06780: loss did not improve from -175.47242\n",
      "Epoch 6781/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9153 - val_loss: -175.0692\n",
      "\n",
      "Epoch 06781: loss did not improve from -175.47242\n",
      "Epoch 6782/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1522 - val_loss: -175.0807\n",
      "\n",
      "Epoch 06782: loss did not improve from -175.47242\n",
      "Epoch 6783/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1956 - val_loss: -174.9885\n",
      "\n",
      "Epoch 06783: loss did not improve from -175.47242\n",
      "Epoch 6784/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3175 - val_loss: -175.0888\n",
      "\n",
      "Epoch 06784: loss did not improve from -175.47242\n",
      "Epoch 6785/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2204 - val_loss: -175.0753\n",
      "\n",
      "Epoch 06785: loss did not improve from -175.47242\n",
      "Epoch 6786/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2496 - val_loss: -175.1544\n",
      "\n",
      "Epoch 06786: loss did not improve from -175.47242\n",
      "Epoch 6787/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3658 - val_loss: -175.2768\n",
      "\n",
      "Epoch 06787: loss did not improve from -175.47242\n",
      "Epoch 6788/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1683 - val_loss: -175.0460\n",
      "\n",
      "Epoch 06788: loss did not improve from -175.47242\n",
      "Epoch 6789/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3395 - val_loss: -175.2289\n",
      "\n",
      "Epoch 06789: loss did not improve from -175.47242\n",
      "Epoch 6790/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3315 - val_loss: -175.1891\n",
      "\n",
      "Epoch 06790: loss did not improve from -175.47242\n",
      "Epoch 6791/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2790 - val_loss: -175.0655\n",
      "\n",
      "Epoch 06791: loss did not improve from -175.47242\n",
      "Epoch 6792/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3572 - val_loss: -175.1706\n",
      "\n",
      "Epoch 06792: loss did not improve from -175.47242\n",
      "Epoch 6793/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1146 - val_loss: -174.8893\n",
      "\n",
      "Epoch 06793: loss did not improve from -175.47242\n",
      "Epoch 6794/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0726 - val_loss: -175.0026\n",
      "\n",
      "Epoch 06794: loss did not improve from -175.47242\n",
      "Epoch 6795/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2189 - val_loss: -174.8169\n",
      "\n",
      "Epoch 06795: loss did not improve from -175.47242\n",
      "Epoch 6796/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1579 - val_loss: -175.1297\n",
      "\n",
      "Epoch 06796: loss did not improve from -175.47242\n",
      "Epoch 6797/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3762 - val_loss: -174.7827\n",
      "\n",
      "Epoch 06797: loss did not improve from -175.47242\n",
      "Epoch 6798/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1818 - val_loss: -175.0871\n",
      "\n",
      "Epoch 06798: loss did not improve from -175.47242\n",
      "Epoch 6799/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1876 - val_loss: -174.9240\n",
      "\n",
      "Epoch 06799: loss did not improve from -175.47242\n",
      "Epoch 6800/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1873 - val_loss: -175.1598\n",
      "\n",
      "Epoch 06800: loss did not improve from -175.47242\n",
      "Epoch 6801/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2078 - val_loss: -175.1391\n",
      "\n",
      "Epoch 06801: loss did not improve from -175.47242\n",
      "Epoch 6802/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3782 - val_loss: -175.1236\n",
      "\n",
      "Epoch 06802: loss did not improve from -175.47242\n",
      "Epoch 6803/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0618 - val_loss: -174.8994\n",
      "\n",
      "Epoch 06803: loss did not improve from -175.47242\n",
      "Epoch 6804/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9369 - val_loss: -175.1276\n",
      "\n",
      "Epoch 06804: loss did not improve from -175.47242\n",
      "Epoch 6805/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9388 - val_loss: -175.1463\n",
      "\n",
      "Epoch 06805: loss did not improve from -175.47242\n",
      "Epoch 6806/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1286 - val_loss: -174.9010\n",
      "\n",
      "Epoch 06806: loss did not improve from -175.47242\n",
      "Epoch 6807/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9532 - val_loss: -175.1607\n",
      "\n",
      "Epoch 06807: loss did not improve from -175.47242\n",
      "Epoch 6808/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9053 - val_loss: -174.8447\n",
      "\n",
      "Epoch 06808: loss did not improve from -175.47242\n",
      "Epoch 6809/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2302 - val_loss: -175.1625\n",
      "\n",
      "Epoch 06809: loss did not improve from -175.47242\n",
      "Epoch 6810/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3276 - val_loss: -174.9235\n",
      "\n",
      "Epoch 06810: loss did not improve from -175.47242\n",
      "Epoch 6811/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1377 - val_loss: -175.2530\n",
      "\n",
      "Epoch 06811: loss did not improve from -175.47242\n",
      "Epoch 6812/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2984 - val_loss: -175.0722\n",
      "\n",
      "Epoch 06812: loss did not improve from -175.47242\n",
      "Epoch 6813/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1221 - val_loss: -175.1006\n",
      "\n",
      "Epoch 06813: loss did not improve from -175.47242\n",
      "Epoch 6814/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3822 - val_loss: -174.8597\n",
      "\n",
      "Epoch 06814: loss did not improve from -175.47242\n",
      "Epoch 6815/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1459 - val_loss: -175.0822\n",
      "\n",
      "Epoch 06815: loss did not improve from -175.47242\n",
      "Epoch 6816/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4000 - val_loss: -175.0201\n",
      "\n",
      "Epoch 06816: loss did not improve from -175.47242\n",
      "Epoch 6817/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3460 - val_loss: -175.1167\n",
      "\n",
      "Epoch 06817: loss did not improve from -175.47242\n",
      "Epoch 6818/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2301 - val_loss: -175.1488\n",
      "\n",
      "Epoch 06818: loss did not improve from -175.47242\n",
      "Epoch 6819/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2066 - val_loss: -175.0577\n",
      "\n",
      "Epoch 06819: loss did not improve from -175.47242\n",
      "Epoch 6820/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5206 - val_loss: -175.3185\n",
      "\n",
      "Epoch 06820: loss improved from -175.47242 to -175.52056, saving model to gendance.h5\n",
      "Epoch 6821/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1990 - val_loss: -175.0664\n",
      "\n",
      "Epoch 06821: loss did not improve from -175.52056\n",
      "Epoch 6822/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2457 - val_loss: -175.0759\n",
      "\n",
      "Epoch 06822: loss did not improve from -175.52056\n",
      "Epoch 6823/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3475 - val_loss: -175.1136\n",
      "\n",
      "Epoch 06823: loss did not improve from -175.52056\n",
      "Epoch 6824/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3610 - val_loss: -175.2175\n",
      "\n",
      "Epoch 06824: loss did not improve from -175.52056\n",
      "Epoch 6825/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2668 - val_loss: -174.9917\n",
      "\n",
      "Epoch 06825: loss did not improve from -175.52056\n",
      "Epoch 6826/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0547 - val_loss: -175.2690\n",
      "\n",
      "Epoch 06826: loss did not improve from -175.52056\n",
      "Epoch 6827/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4821 - val_loss: -174.9799\n",
      "\n",
      "Epoch 06827: loss did not improve from -175.52056\n",
      "Epoch 6828/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -175.2393 - val_loss: -175.2866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 06828: loss did not improve from -175.52056\n",
      "Epoch 6829/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2958 - val_loss: -174.9535\n",
      "\n",
      "Epoch 06829: loss did not improve from -175.52056\n",
      "Epoch 6830/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0275 - val_loss: -175.1157\n",
      "\n",
      "Epoch 06830: loss did not improve from -175.52056\n",
      "Epoch 6831/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0954 - val_loss: -174.7937\n",
      "\n",
      "Epoch 06831: loss did not improve from -175.52056\n",
      "Epoch 6832/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4174 - val_loss: -175.2714\n",
      "\n",
      "Epoch 06832: loss did not improve from -175.52056\n",
      "Epoch 6833/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6327 - val_loss: -175.2147\n",
      "\n",
      "Epoch 06833: loss improved from -175.52056 to -175.63269, saving model to gendance.h5\n",
      "Epoch 6834/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4323 - val_loss: -175.2482\n",
      "\n",
      "Epoch 06834: loss did not improve from -175.63269\n",
      "Epoch 6835/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0915 - val_loss: -175.1278\n",
      "\n",
      "Epoch 06835: loss did not improve from -175.63269\n",
      "Epoch 6836/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1586 - val_loss: -174.8764\n",
      "\n",
      "Epoch 06836: loss did not improve from -175.63269\n",
      "Epoch 6837/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0131 - val_loss: -175.0595\n",
      "\n",
      "Epoch 06837: loss did not improve from -175.63269\n",
      "Epoch 6838/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0799 - val_loss: -174.8022\n",
      "\n",
      "Epoch 06838: loss did not improve from -175.63269\n",
      "Epoch 6839/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5153 - val_loss: -175.0851\n",
      "\n",
      "Epoch 06839: loss did not improve from -175.63269\n",
      "Epoch 6840/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1774 - val_loss: -174.7727\n",
      "\n",
      "Epoch 06840: loss did not improve from -175.63269\n",
      "Epoch 6841/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -174.9285 - val_loss: -175.0857\n",
      "\n",
      "Epoch 06841: loss did not improve from -175.63269\n",
      "Epoch 6842/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1798 - val_loss: -174.8802\n",
      "\n",
      "Epoch 06842: loss did not improve from -175.63269\n",
      "Epoch 6843/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1815 - val_loss: -175.1575\n",
      "\n",
      "Epoch 06843: loss did not improve from -175.63269\n",
      "Epoch 6844/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3727 - val_loss: -174.9227\n",
      "\n",
      "Epoch 06844: loss did not improve from -175.63269\n",
      "Epoch 6845/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2735 - val_loss: -175.2020\n",
      "\n",
      "Epoch 06845: loss did not improve from -175.63269\n",
      "Epoch 6846/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1196 - val_loss: -174.8256\n",
      "\n",
      "Epoch 06846: loss did not improve from -175.63269\n",
      "Epoch 6847/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3514 - val_loss: -175.3201\n",
      "\n",
      "Epoch 06847: loss did not improve from -175.63269\n",
      "Epoch 6848/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3827 - val_loss: -175.1355\n",
      "\n",
      "Epoch 06848: loss did not improve from -175.63269\n",
      "Epoch 6849/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4427 - val_loss: -175.1161\n",
      "\n",
      "Epoch 06849: loss did not improve from -175.63269\n",
      "Epoch 6850/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3076 - val_loss: -175.0720\n",
      "\n",
      "Epoch 06850: loss did not improve from -175.63269\n",
      "Epoch 6851/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2862 - val_loss: -175.1566\n",
      "\n",
      "Epoch 06851: loss did not improve from -175.63269\n",
      "Epoch 6852/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2860 - val_loss: -175.0594\n",
      "\n",
      "Epoch 06852: loss did not improve from -175.63269\n",
      "Epoch 6853/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2091 - val_loss: -175.1995\n",
      "\n",
      "Epoch 06853: loss did not improve from -175.63269\n",
      "Epoch 6854/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4512 - val_loss: -175.1042\n",
      "\n",
      "Epoch 06854: loss did not improve from -175.63269\n",
      "Epoch 6855/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2590 - val_loss: -175.1948\n",
      "\n",
      "Epoch 06855: loss did not improve from -175.63269\n",
      "Epoch 6856/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3796 - val_loss: -175.2551\n",
      "\n",
      "Epoch 06856: loss did not improve from -175.63269\n",
      "Epoch 6857/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2699 - val_loss: -175.3419\n",
      "\n",
      "Epoch 06857: loss did not improve from -175.63269\n",
      "Epoch 6858/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3061 - val_loss: -175.1293\n",
      "\n",
      "Epoch 06858: loss did not improve from -175.63269\n",
      "Epoch 6859/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3649 - val_loss: -175.1865\n",
      "\n",
      "Epoch 06859: loss did not improve from -175.63269\n",
      "Epoch 6860/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2565 - val_loss: -174.9906\n",
      "\n",
      "Epoch 06860: loss did not improve from -175.63269\n",
      "Epoch 6861/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3092 - val_loss: -175.2400\n",
      "\n",
      "Epoch 06861: loss did not improve from -175.63269\n",
      "Epoch 6862/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0994 - val_loss: -175.1205\n",
      "\n",
      "Epoch 06862: loss did not improve from -175.63269\n",
      "Epoch 6863/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3354 - val_loss: -175.1312\n",
      "\n",
      "Epoch 06863: loss did not improve from -175.63269\n",
      "Epoch 6864/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2481 - val_loss: -175.2183\n",
      "\n",
      "Epoch 06864: loss did not improve from -175.63269\n",
      "Epoch 6865/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1478 - val_loss: -174.8139\n",
      "\n",
      "Epoch 06865: loss did not improve from -175.63269\n",
      "Epoch 6866/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3955 - val_loss: -175.2959\n",
      "\n",
      "Epoch 06866: loss did not improve from -175.63269\n",
      "Epoch 6867/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0676 - val_loss: -174.7727\n",
      "\n",
      "Epoch 06867: loss did not improve from -175.63269\n",
      "Epoch 6868/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0925 - val_loss: -175.2849\n",
      "\n",
      "Epoch 06868: loss did not improve from -175.63269\n",
      "Epoch 6869/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3781 - val_loss: -174.9871\n",
      "\n",
      "Epoch 06869: loss did not improve from -175.63269\n",
      "Epoch 6870/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5259 - val_loss: -175.3690\n",
      "\n",
      "Epoch 06870: loss did not improve from -175.63269\n",
      "Epoch 6871/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5617 - val_loss: -175.0829\n",
      "\n",
      "Epoch 06871: loss did not improve from -175.63269\n",
      "Epoch 6872/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2386 - val_loss: -175.2156\n",
      "\n",
      "Epoch 06872: loss did not improve from -175.63269\n",
      "Epoch 6873/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4020 - val_loss: -175.1074\n",
      "\n",
      "Epoch 06873: loss did not improve from -175.63269\n",
      "Epoch 6874/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -175.4439 - val_loss: -175.2840\n",
      "\n",
      "Epoch 06874: loss did not improve from -175.63269\n",
      "Epoch 6875/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2110 - val_loss: -174.8623\n",
      "\n",
      "Epoch 06875: loss did not improve from -175.63269\n",
      "Epoch 6876/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1036 - val_loss: -175.2093\n",
      "\n",
      "Epoch 06876: loss did not improve from -175.63269\n",
      "Epoch 6877/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0583 - val_loss: -174.9323\n",
      "\n",
      "Epoch 06877: loss did not improve from -175.63269\n",
      "Epoch 6878/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1218 - val_loss: -175.1047\n",
      "\n",
      "Epoch 06878: loss did not improve from -175.63269\n",
      "Epoch 6879/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0130 - val_loss: -175.1765\n",
      "\n",
      "Epoch 06879: loss did not improve from -175.63269\n",
      "Epoch 6880/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1956 - val_loss: -175.0463\n",
      "\n",
      "Epoch 06880: loss did not improve from -175.63269\n",
      "Epoch 6881/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2181 - val_loss: -175.2466\n",
      "\n",
      "Epoch 06881: loss did not improve from -175.63269\n",
      "Epoch 6882/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1791 - val_loss: -174.8402\n",
      "\n",
      "Epoch 06882: loss did not improve from -175.63269\n",
      "Epoch 6883/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0838 - val_loss: -175.2718\n",
      "\n",
      "Epoch 06883: loss did not improve from -175.63269\n",
      "Epoch 6884/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2075 - val_loss: -174.7541\n",
      "\n",
      "Epoch 06884: loss did not improve from -175.63269\n",
      "Epoch 6885/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3918 - val_loss: -175.3463\n",
      "\n",
      "Epoch 06885: loss did not improve from -175.63269\n",
      "Epoch 6886/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4582 - val_loss: -175.0236\n",
      "\n",
      "Epoch 06886: loss did not improve from -175.63269\n",
      "Epoch 6887/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4448 - val_loss: -175.2105\n",
      "\n",
      "Epoch 06887: loss did not improve from -175.63269\n",
      "Epoch 6888/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4771 - val_loss: -175.1965\n",
      "\n",
      "Epoch 06888: loss did not improve from -175.63269\n",
      "Epoch 6889/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1772 - val_loss: -175.1835\n",
      "\n",
      "Epoch 06889: loss did not improve from -175.63269\n",
      "Epoch 6890/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3898 - val_loss: -175.2670\n",
      "\n",
      "Epoch 06890: loss did not improve from -175.63269\n",
      "Epoch 6891/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3024 - val_loss: -175.1423\n",
      "\n",
      "Epoch 06891: loss did not improve from -175.63269\n",
      "Epoch 6892/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2991 - val_loss: -175.2046\n",
      "\n",
      "Epoch 06892: loss did not improve from -175.63269\n",
      "Epoch 6893/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3099 - val_loss: -175.2392\n",
      "\n",
      "Epoch 06893: loss did not improve from -175.63269\n",
      "Epoch 6894/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3123 - val_loss: -175.2287\n",
      "\n",
      "Epoch 06894: loss did not improve from -175.63269\n",
      "Epoch 6895/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4207 - val_loss: -175.1984\n",
      "\n",
      "Epoch 06895: loss did not improve from -175.63269\n",
      "Epoch 6896/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3832 - val_loss: -175.3031\n",
      "\n",
      "Epoch 06896: loss did not improve from -175.63269\n",
      "Epoch 6897/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2950 - val_loss: -175.0660\n",
      "\n",
      "Epoch 06897: loss did not improve from -175.63269\n",
      "Epoch 6898/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4709 - val_loss: -175.3072\n",
      "\n",
      "Epoch 06898: loss did not improve from -175.63269\n",
      "Epoch 6899/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5946 - val_loss: -175.2191\n",
      "\n",
      "Epoch 06899: loss did not improve from -175.63269\n",
      "Epoch 6900/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5436 - val_loss: -175.3678\n",
      "\n",
      "Epoch 06900: loss did not improve from -175.63269\n",
      "Epoch 6901/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3286 - val_loss: -175.0959\n",
      "\n",
      "Epoch 06901: loss did not improve from -175.63269\n",
      "Epoch 6902/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4208 - val_loss: -175.2587\n",
      "\n",
      "Epoch 06902: loss did not improve from -175.63269\n",
      "Epoch 6903/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2208 - val_loss: -175.0875\n",
      "\n",
      "Epoch 06903: loss did not improve from -175.63269\n",
      "Epoch 6904/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2471 - val_loss: -175.2770\n",
      "\n",
      "Epoch 06904: loss did not improve from -175.63269\n",
      "Epoch 6905/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3433 - val_loss: -175.1545\n",
      "\n",
      "Epoch 06905: loss did not improve from -175.63269\n",
      "Epoch 6906/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2139 - val_loss: -175.1198\n",
      "\n",
      "Epoch 06906: loss did not improve from -175.63269\n",
      "Epoch 6907/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1805 - val_loss: -175.1287\n",
      "\n",
      "Epoch 06907: loss did not improve from -175.63269\n",
      "Epoch 6908/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3406 - val_loss: -175.1505\n",
      "\n",
      "Epoch 06908: loss did not improve from -175.63269\n",
      "Epoch 6909/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1548 - val_loss: -175.1726\n",
      "\n",
      "Epoch 06909: loss did not improve from -175.63269\n",
      "Epoch 6910/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2552 - val_loss: -175.2133\n",
      "\n",
      "Epoch 06910: loss did not improve from -175.63269\n",
      "Epoch 6911/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2650 - val_loss: -174.9866\n",
      "\n",
      "Epoch 06911: loss did not improve from -175.63269\n",
      "Epoch 6912/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -175.1692 - val_loss: -174.8462\n",
      "\n",
      "Epoch 06912: loss did not improve from -175.63269\n",
      "Epoch 6913/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0995 - val_loss: -175.2412\n",
      "\n",
      "Epoch 06913: loss did not improve from -175.63269\n",
      "Epoch 6914/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3779 - val_loss: -174.7868\n",
      "\n",
      "Epoch 06914: loss did not improve from -175.63269\n",
      "Epoch 6915/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.0718 - val_loss: -175.0855\n",
      "\n",
      "Epoch 06915: loss did not improve from -175.63269\n",
      "Epoch 6916/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4274 - val_loss: -174.8966\n",
      "\n",
      "Epoch 06916: loss did not improve from -175.63269\n",
      "Epoch 6917/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4742 - val_loss: -175.3045\n",
      "\n",
      "Epoch 06917: loss did not improve from -175.63269\n",
      "Epoch 6918/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4366 - val_loss: -174.9029\n",
      "\n",
      "Epoch 06918: loss did not improve from -175.63269\n",
      "Epoch 6919/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2023 - val_loss: -175.1905\n",
      "\n",
      "Epoch 06919: loss did not improve from -175.63269\n",
      "Epoch 6920/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2250 - val_loss: -175.1778\n",
      "\n",
      "Epoch 06920: loss did not improve from -175.63269\n",
      "Epoch 6921/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3696 - val_loss: -175.1283\n",
      "\n",
      "Epoch 06921: loss did not improve from -175.63269\n",
      "Epoch 6922/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4427 - val_loss: -175.2708\n",
      "\n",
      "Epoch 06922: loss did not improve from -175.63269\n",
      "Epoch 6923/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4368 - val_loss: -175.0425\n",
      "\n",
      "Epoch 06923: loss did not improve from -175.63269\n",
      "Epoch 6924/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5487 - val_loss: -175.2833\n",
      "\n",
      "Epoch 06924: loss did not improve from -175.63269\n",
      "Epoch 6925/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2215 - val_loss: -175.0852\n",
      "\n",
      "Epoch 06925: loss did not improve from -175.63269\n",
      "Epoch 6926/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4086 - val_loss: -175.0706\n",
      "\n",
      "Epoch 06926: loss did not improve from -175.63269\n",
      "Epoch 6927/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3093 - val_loss: -175.0845\n",
      "\n",
      "Epoch 06927: loss did not improve from -175.63269\n",
      "Epoch 6928/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4478 - val_loss: -174.9871\n",
      "\n",
      "Epoch 06928: loss did not improve from -175.63269\n",
      "Epoch 6929/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1261 - val_loss: -175.2421\n",
      "\n",
      "Epoch 06929: loss did not improve from -175.63269\n",
      "Epoch 6930/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3730 - val_loss: -174.8358\n",
      "\n",
      "Epoch 06930: loss did not improve from -175.63269\n",
      "Epoch 6931/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -175.2816 - val_loss: -175.3482\n",
      "\n",
      "Epoch 06931: loss did not improve from -175.63269\n",
      "Epoch 6932/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3148 - val_loss: -174.8308\n",
      "\n",
      "Epoch 06932: loss did not improve from -175.63269\n",
      "Epoch 6933/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2526 - val_loss: -175.2641\n",
      "\n",
      "Epoch 06933: loss did not improve from -175.63269\n",
      "Epoch 6934/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3467 - val_loss: -175.1436\n",
      "\n",
      "Epoch 06934: loss did not improve from -175.63269\n",
      "Epoch 6935/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5011 - val_loss: -175.2575\n",
      "\n",
      "Epoch 06935: loss did not improve from -175.63269\n",
      "Epoch 6936/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3158 - val_loss: -175.1455\n",
      "\n",
      "Epoch 06936: loss did not improve from -175.63269\n",
      "Epoch 6937/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3515 - val_loss: -175.1650\n",
      "\n",
      "Epoch 06937: loss did not improve from -175.63269\n",
      "Epoch 6938/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3777 - val_loss: -175.2626\n",
      "\n",
      "Epoch 06938: loss did not improve from -175.63269\n",
      "Epoch 6939/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -175.1091 - val_loss: -174.8087\n",
      "\n",
      "Epoch 06939: loss did not improve from -175.63269\n",
      "Epoch 6940/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4498 - val_loss: -175.3368\n",
      "\n",
      "Epoch 06940: loss did not improve from -175.63269\n",
      "Epoch 6941/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4329 - val_loss: -174.8470\n",
      "\n",
      "Epoch 06941: loss did not improve from -175.63269\n",
      "Epoch 6942/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3184 - val_loss: -175.3327\n",
      "\n",
      "Epoch 06942: loss did not improve from -175.63269\n",
      "Epoch 6943/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4395 - val_loss: -174.9438\n",
      "\n",
      "Epoch 06943: loss did not improve from -175.63269\n",
      "Epoch 6944/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3764 - val_loss: -175.0936\n",
      "\n",
      "Epoch 06944: loss did not improve from -175.63269\n",
      "Epoch 6945/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2800 - val_loss: -175.1558\n",
      "\n",
      "Epoch 06945: loss did not improve from -175.63269\n",
      "Epoch 6946/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6703 - val_loss: -175.2324\n",
      "\n",
      "Epoch 06946: loss improved from -175.63269 to -175.67031, saving model to gendance.h5\n",
      "Epoch 6947/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3353 - val_loss: -174.9065\n",
      "\n",
      "Epoch 06947: loss did not improve from -175.67031\n",
      "Epoch 6948/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -175.4901 - val_loss: -175.1454\n",
      "\n",
      "Epoch 06948: loss did not improve from -175.67031\n",
      "Epoch 6949/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4340 - val_loss: -175.0877\n",
      "\n",
      "Epoch 06949: loss did not improve from -175.67031\n",
      "Epoch 6950/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4655 - val_loss: -174.9352\n",
      "\n",
      "Epoch 06950: loss did not improve from -175.67031\n",
      "Epoch 6951/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3329 - val_loss: -175.1909\n",
      "\n",
      "Epoch 06951: loss did not improve from -175.67031\n",
      "Epoch 6952/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3673 - val_loss: -174.9457\n",
      "\n",
      "Epoch 06952: loss did not improve from -175.67031\n",
      "Epoch 6953/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2173 - val_loss: -175.2444\n",
      "\n",
      "Epoch 06953: loss did not improve from -175.67031\n",
      "Epoch 6954/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4464 - val_loss: -175.1090\n",
      "\n",
      "Epoch 06954: loss did not improve from -175.67031\n",
      "Epoch 6955/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3725 - val_loss: -175.2350\n",
      "\n",
      "Epoch 06955: loss did not improve from -175.67031\n",
      "Epoch 6956/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3656 - val_loss: -175.1111\n",
      "\n",
      "Epoch 06956: loss did not improve from -175.67031\n",
      "Epoch 6957/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -175.5211 - val_loss: -175.3165\n",
      "\n",
      "Epoch 06957: loss did not improve from -175.67031\n",
      "Epoch 6958/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3871 - val_loss: -175.0915\n",
      "\n",
      "Epoch 06958: loss did not improve from -175.67031\n",
      "Epoch 6959/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5539 - val_loss: -175.3063\n",
      "\n",
      "Epoch 06959: loss did not improve from -175.67031\n",
      "Epoch 6960/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4161 - val_loss: -174.9572\n",
      "\n",
      "Epoch 06960: loss did not improve from -175.67031\n",
      "Epoch 6961/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3489 - val_loss: -175.1864\n",
      "\n",
      "Epoch 06961: loss did not improve from -175.67031\n",
      "Epoch 6962/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4521 - val_loss: -175.3656\n",
      "\n",
      "Epoch 06962: loss did not improve from -175.67031\n",
      "Epoch 6963/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5531 - val_loss: -175.1554\n",
      "\n",
      "Epoch 06963: loss did not improve from -175.67031\n",
      "Epoch 6964/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -175.4930 - val_loss: -175.2848\n",
      "\n",
      "Epoch 06964: loss did not improve from -175.67031\n",
      "Epoch 6965/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3522 - val_loss: -175.0524\n",
      "\n",
      "Epoch 06965: loss did not improve from -175.67031\n",
      "Epoch 6966/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -175.4187 - val_loss: -175.2652\n",
      "\n",
      "Epoch 06966: loss did not improve from -175.67031\n",
      "Epoch 6967/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4648 - val_loss: -175.1409\n",
      "\n",
      "Epoch 06967: loss did not improve from -175.67031\n",
      "Epoch 6968/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6138 - val_loss: -175.1774\n",
      "\n",
      "Epoch 06968: loss did not improve from -175.67031\n",
      "Epoch 6969/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4485 - val_loss: -175.1775\n",
      "\n",
      "Epoch 06969: loss did not improve from -175.67031\n",
      "Epoch 6970/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5170 - val_loss: -175.4188\n",
      "\n",
      "Epoch 06970: loss did not improve from -175.67031\n",
      "Epoch 6971/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4963 - val_loss: -175.1683\n",
      "\n",
      "Epoch 06971: loss did not improve from -175.67031\n",
      "Epoch 6972/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6072 - val_loss: -175.3339\n",
      "\n",
      "Epoch 06972: loss did not improve from -175.67031\n",
      "Epoch 6973/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3540 - val_loss: -175.1066\n",
      "\n",
      "Epoch 06973: loss did not improve from -175.67031\n",
      "Epoch 6974/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6078 - val_loss: -175.3106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 06974: loss did not improve from -175.67031\n",
      "Epoch 6975/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5119 - val_loss: -174.9998\n",
      "\n",
      "Epoch 06975: loss did not improve from -175.67031\n",
      "Epoch 6976/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5144 - val_loss: -175.3388\n",
      "\n",
      "Epoch 06976: loss did not improve from -175.67031\n",
      "Epoch 6977/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5267 - val_loss: -175.0801\n",
      "\n",
      "Epoch 06977: loss did not improve from -175.67031\n",
      "Epoch 6978/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5429 - val_loss: -175.2325\n",
      "\n",
      "Epoch 06978: loss did not improve from -175.67031\n",
      "Epoch 6979/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6424 - val_loss: -175.3334\n",
      "\n",
      "Epoch 06979: loss did not improve from -175.67031\n",
      "Epoch 6980/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4102 - val_loss: -175.0965\n",
      "\n",
      "Epoch 06980: loss did not improve from -175.67031\n",
      "Epoch 6981/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3587 - val_loss: -175.2312\n",
      "\n",
      "Epoch 06981: loss did not improve from -175.67031\n",
      "Epoch 6982/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4633 - val_loss: -175.1095\n",
      "\n",
      "Epoch 06982: loss did not improve from -175.67031\n",
      "Epoch 6983/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5704 - val_loss: -175.2594\n",
      "\n",
      "Epoch 06983: loss did not improve from -175.67031\n",
      "Epoch 6984/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -175.2852 - val_loss: -175.0586\n",
      "\n",
      "Epoch 06984: loss did not improve from -175.67031\n",
      "Epoch 6985/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3443 - val_loss: -175.3283\n",
      "\n",
      "Epoch 06985: loss did not improve from -175.67031\n",
      "Epoch 6986/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3358 - val_loss: -174.8969\n",
      "\n",
      "Epoch 06986: loss did not improve from -175.67031\n",
      "Epoch 6987/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6645 - val_loss: -175.3396\n",
      "\n",
      "Epoch 06987: loss did not improve from -175.67031\n",
      "Epoch 6988/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3059 - val_loss: -175.1125\n",
      "\n",
      "Epoch 06988: loss did not improve from -175.67031\n",
      "Epoch 6989/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2964 - val_loss: -175.3820\n",
      "\n",
      "Epoch 06989: loss did not improve from -175.67031\n",
      "Epoch 6990/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4073 - val_loss: -174.8890\n",
      "\n",
      "Epoch 06990: loss did not improve from -175.67031\n",
      "Epoch 6991/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4093 - val_loss: -175.3965\n",
      "\n",
      "Epoch 06991: loss did not improve from -175.67031\n",
      "Epoch 6992/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5576 - val_loss: -175.1029\n",
      "\n",
      "Epoch 06992: loss did not improve from -175.67031\n",
      "Epoch 6993/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4873 - val_loss: -175.2544\n",
      "\n",
      "Epoch 06993: loss did not improve from -175.67031\n",
      "Epoch 6994/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4929 - val_loss: -175.3121\n",
      "\n",
      "Epoch 06994: loss did not improve from -175.67031\n",
      "Epoch 6995/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2788 - val_loss: -175.1178\n",
      "\n",
      "Epoch 06995: loss did not improve from -175.67031\n",
      "Epoch 6996/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5098 - val_loss: -175.2495\n",
      "\n",
      "Epoch 06996: loss did not improve from -175.67031\n",
      "Epoch 6997/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6935 - val_loss: -175.1577\n",
      "\n",
      "Epoch 06997: loss improved from -175.67031 to -175.69347, saving model to gendance.h5\n",
      "Epoch 6998/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2706 - val_loss: -175.1896\n",
      "\n",
      "Epoch 06998: loss did not improve from -175.69347\n",
      "Epoch 6999/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5058 - val_loss: -174.9801\n",
      "\n",
      "Epoch 06999: loss did not improve from -175.69347\n",
      "Epoch 7000/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3902 - val_loss: -175.3037\n",
      "\n",
      "Epoch 07000: loss did not improve from -175.69347\n",
      "Epoch 7001/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -175.3315 - val_loss: -174.9732\n",
      "\n",
      "Epoch 07001: loss did not improve from -175.69347\n",
      "Epoch 7002/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3887 - val_loss: -175.3429\n",
      "\n",
      "Epoch 07002: loss did not improve from -175.69347\n",
      "Epoch 7003/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3462 - val_loss: -174.8583\n",
      "\n",
      "Epoch 07003: loss did not improve from -175.69347\n",
      "Epoch 7004/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6934 - val_loss: -175.3394\n",
      "\n",
      "Epoch 07004: loss did not improve from -175.69347\n",
      "Epoch 7005/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4693 - val_loss: -175.1863\n",
      "\n",
      "Epoch 07005: loss did not improve from -175.69347\n",
      "Epoch 7006/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4832 - val_loss: -175.1071\n",
      "\n",
      "Epoch 07006: loss did not improve from -175.69347\n",
      "Epoch 7007/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4420 - val_loss: -175.2181\n",
      "\n",
      "Epoch 07007: loss did not improve from -175.69347\n",
      "Epoch 7008/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5283 - val_loss: -175.2159\n",
      "\n",
      "Epoch 07008: loss did not improve from -175.69347\n",
      "Epoch 7009/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4871 - val_loss: -175.2874\n",
      "\n",
      "Epoch 07009: loss did not improve from -175.69347\n",
      "Epoch 7010/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5902 - val_loss: -175.2704\n",
      "\n",
      "Epoch 07010: loss did not improve from -175.69347\n",
      "Epoch 7011/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5069 - val_loss: -175.2689\n",
      "\n",
      "Epoch 07011: loss did not improve from -175.69347\n",
      "Epoch 7012/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4213 - val_loss: -174.9950\n",
      "\n",
      "Epoch 07012: loss did not improve from -175.69347\n",
      "Epoch 7013/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6377 - val_loss: -175.3956\n",
      "\n",
      "Epoch 07013: loss did not improve from -175.69347\n",
      "Epoch 7014/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3992 - val_loss: -175.1520\n",
      "\n",
      "Epoch 07014: loss did not improve from -175.69347\n",
      "Epoch 7015/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3666 - val_loss: -175.3337\n",
      "\n",
      "Epoch 07015: loss did not improve from -175.69347\n",
      "Epoch 7016/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3278 - val_loss: -174.9700\n",
      "\n",
      "Epoch 07016: loss did not improve from -175.69347\n",
      "Epoch 7017/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3956 - val_loss: -175.2666\n",
      "\n",
      "Epoch 07017: loss did not improve from -175.69347\n",
      "Epoch 7018/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5144 - val_loss: -175.1595\n",
      "\n",
      "Epoch 07018: loss did not improve from -175.69347\n",
      "Epoch 7019/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6737 - val_loss: -175.3538\n",
      "\n",
      "Epoch 07019: loss did not improve from -175.69347\n",
      "Epoch 7020/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4434 - val_loss: -175.1103\n",
      "\n",
      "Epoch 07020: loss did not improve from -175.69347\n",
      "Epoch 7021/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4756 - val_loss: -175.1878\n",
      "\n",
      "Epoch 07021: loss did not improve from -175.69347\n",
      "Epoch 7022/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6377 - val_loss: -175.2267\n",
      "\n",
      "Epoch 07022: loss did not improve from -175.69347\n",
      "Epoch 7023/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7214 - val_loss: -175.3010\n",
      "\n",
      "Epoch 07023: loss improved from -175.69347 to -175.72140, saving model to gendance.h5\n",
      "Epoch 7024/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3324 - val_loss: -175.0766\n",
      "\n",
      "Epoch 07024: loss did not improve from -175.72140\n",
      "Epoch 7025/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4768 - val_loss: -175.1597\n",
      "\n",
      "Epoch 07025: loss did not improve from -175.72140\n",
      "Epoch 7026/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4981 - val_loss: -175.2433\n",
      "\n",
      "Epoch 07026: loss did not improve from -175.72140\n",
      "Epoch 7027/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4089 - val_loss: -175.3111\n",
      "\n",
      "Epoch 07027: loss did not improve from -175.72140\n",
      "Epoch 7028/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5233 - val_loss: -175.2091\n",
      "\n",
      "Epoch 07028: loss did not improve from -175.72140\n",
      "Epoch 7029/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3448 - val_loss: -175.2268\n",
      "\n",
      "Epoch 07029: loss did not improve from -175.72140\n",
      "Epoch 7030/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5102 - val_loss: -175.2545\n",
      "\n",
      "Epoch 07030: loss did not improve from -175.72140\n",
      "Epoch 7031/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3893 - val_loss: -175.0846\n",
      "\n",
      "Epoch 07031: loss did not improve from -175.72140\n",
      "Epoch 7032/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5421 - val_loss: -175.3810\n",
      "\n",
      "Epoch 07032: loss did not improve from -175.72140\n",
      "Epoch 7033/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4850 - val_loss: -175.0568\n",
      "\n",
      "Epoch 07033: loss did not improve from -175.72140\n",
      "Epoch 7034/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3000 - val_loss: -175.2834\n",
      "\n",
      "Epoch 07034: loss did not improve from -175.72140\n",
      "Epoch 7035/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4199 - val_loss: -175.0298\n",
      "\n",
      "Epoch 07035: loss did not improve from -175.72140\n",
      "Epoch 7036/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3785 - val_loss: -175.3349\n",
      "\n",
      "Epoch 07036: loss did not improve from -175.72140\n",
      "Epoch 7037/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3749 - val_loss: -174.9730\n",
      "\n",
      "Epoch 07037: loss did not improve from -175.72140\n",
      "Epoch 7038/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2862 - val_loss: -175.4096\n",
      "\n",
      "Epoch 07038: loss did not improve from -175.72140\n",
      "Epoch 7039/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5199 - val_loss: -175.1220\n",
      "\n",
      "Epoch 07039: loss did not improve from -175.72140\n",
      "Epoch 7040/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4494 - val_loss: -175.3157\n",
      "\n",
      "Epoch 07040: loss did not improve from -175.72140\n",
      "Epoch 7041/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4758 - val_loss: -175.0933\n",
      "\n",
      "Epoch 07041: loss did not improve from -175.72140\n",
      "Epoch 7042/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3438 - val_loss: -175.2014\n",
      "\n",
      "Epoch 07042: loss did not improve from -175.72140\n",
      "Epoch 7043/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4390 - val_loss: -175.1801\n",
      "\n",
      "Epoch 07043: loss did not improve from -175.72140\n",
      "Epoch 7044/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7000 - val_loss: -175.1849\n",
      "\n",
      "Epoch 07044: loss did not improve from -175.72140\n",
      "Epoch 7045/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4555 - val_loss: -175.2196\n",
      "\n",
      "Epoch 07045: loss did not improve from -175.72140\n",
      "Epoch 7046/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4687 - val_loss: -175.1908\n",
      "\n",
      "Epoch 07046: loss did not improve from -175.72140\n",
      "Epoch 7047/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4385 - val_loss: -175.2481\n",
      "\n",
      "Epoch 07047: loss did not improve from -175.72140\n",
      "Epoch 7048/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4767 - val_loss: -175.2393\n",
      "\n",
      "Epoch 07048: loss did not improve from -175.72140\n",
      "Epoch 7049/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7684 - val_loss: -175.3576\n",
      "\n",
      "Epoch 07049: loss improved from -175.72140 to -175.76837, saving model to gendance.h5\n",
      "Epoch 7050/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5907 - val_loss: -175.2785\n",
      "\n",
      "Epoch 07050: loss did not improve from -175.76837\n",
      "Epoch 7051/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4657 - val_loss: -175.2215\n",
      "\n",
      "Epoch 07051: loss did not improve from -175.76837\n",
      "Epoch 7052/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4370 - val_loss: -175.2247\n",
      "\n",
      "Epoch 07052: loss did not improve from -175.76837\n",
      "Epoch 7053/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1681 - val_loss: -175.1753\n",
      "\n",
      "Epoch 07053: loss did not improve from -175.76837\n",
      "Epoch 7054/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6110 - val_loss: -175.2130\n",
      "\n",
      "Epoch 07054: loss did not improve from -175.76837\n",
      "Epoch 7055/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5607 - val_loss: -175.2285\n",
      "\n",
      "Epoch 07055: loss did not improve from -175.76837\n",
      "Epoch 7056/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5487 - val_loss: -175.3040\n",
      "\n",
      "Epoch 07056: loss did not improve from -175.76837\n",
      "Epoch 7057/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5880 - val_loss: -175.2389\n",
      "\n",
      "Epoch 07057: loss did not improve from -175.76837\n",
      "Epoch 7058/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5708 - val_loss: -175.2898\n",
      "\n",
      "Epoch 07058: loss did not improve from -175.76837\n",
      "Epoch 7059/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6168 - val_loss: -175.2356\n",
      "\n",
      "Epoch 07059: loss did not improve from -175.76837\n",
      "Epoch 7060/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8199 - val_loss: -175.3453\n",
      "\n",
      "Epoch 07060: loss improved from -175.76837 to -175.81993, saving model to gendance.h5\n",
      "Epoch 7061/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6206 - val_loss: -175.2061\n",
      "\n",
      "Epoch 07061: loss did not improve from -175.81993\n",
      "Epoch 7062/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6070 - val_loss: -175.3216\n",
      "\n",
      "Epoch 07062: loss did not improve from -175.81993\n",
      "Epoch 7063/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6256 - val_loss: -174.9511\n",
      "\n",
      "Epoch 07063: loss did not improve from -175.81993\n",
      "Epoch 7064/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -175.4715 - val_loss: -175.2885\n",
      "\n",
      "Epoch 07064: loss did not improve from -175.81993\n",
      "Epoch 7065/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4267 - val_loss: -175.2768\n",
      "\n",
      "Epoch 07065: loss did not improve from -175.81993\n",
      "Epoch 7066/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6345 - val_loss: -175.2684\n",
      "\n",
      "Epoch 07066: loss did not improve from -175.81993\n",
      "Epoch 7067/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4712 - val_loss: -175.3555\n",
      "\n",
      "Epoch 07067: loss did not improve from -175.81993\n",
      "Epoch 7068/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3170 - val_loss: -174.7486\n",
      "\n",
      "Epoch 07068: loss did not improve from -175.81993\n",
      "Epoch 7069/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1538 - val_loss: -175.2668\n",
      "\n",
      "Epoch 07069: loss did not improve from -175.81993\n",
      "Epoch 7070/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5268 - val_loss: -174.8809\n",
      "\n",
      "Epoch 07070: loss did not improve from -175.81993\n",
      "Epoch 7071/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4972 - val_loss: -175.3991\n",
      "\n",
      "Epoch 07071: loss did not improve from -175.81993\n",
      "Epoch 7072/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5995 - val_loss: -174.9746\n",
      "\n",
      "Epoch 07072: loss did not improve from -175.81993\n",
      "Epoch 7073/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6789 - val_loss: -175.4363\n",
      "\n",
      "Epoch 07073: loss did not improve from -175.81993\n",
      "Epoch 7074/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5426 - val_loss: -174.9296\n",
      "\n",
      "Epoch 07074: loss did not improve from -175.81993\n",
      "Epoch 7075/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5868 - val_loss: -175.2484\n",
      "\n",
      "Epoch 07075: loss did not improve from -175.81993\n",
      "Epoch 7076/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6919 - val_loss: -175.1987\n",
      "\n",
      "Epoch 07076: loss did not improve from -175.81993\n",
      "Epoch 7077/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8320 - val_loss: -175.2146\n",
      "\n",
      "Epoch 07077: loss improved from -175.81993 to -175.83200, saving model to gendance.h5\n",
      "Epoch 7078/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4484 - val_loss: -175.2276\n",
      "\n",
      "Epoch 07078: loss did not improve from -175.83200\n",
      "Epoch 7079/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6727 - val_loss: -175.3122\n",
      "\n",
      "Epoch 07079: loss did not improve from -175.83200\n",
      "Epoch 7080/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6012 - val_loss: -175.4155\n",
      "\n",
      "Epoch 07080: loss did not improve from -175.83200\n",
      "Epoch 7081/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4838 - val_loss: -175.1234\n",
      "\n",
      "Epoch 07081: loss did not improve from -175.83200\n",
      "Epoch 7082/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5584 - val_loss: -175.1505\n",
      "\n",
      "Epoch 07082: loss did not improve from -175.83200\n",
      "Epoch 7083/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4362 - val_loss: -175.1353\n",
      "\n",
      "Epoch 07083: loss did not improve from -175.83200\n",
      "Epoch 7084/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6068 - val_loss: -175.2121\n",
      "\n",
      "Epoch 07084: loss did not improve from -175.83200\n",
      "Epoch 7085/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -175.6226 - val_loss: -175.1189\n",
      "\n",
      "Epoch 07085: loss did not improve from -175.83200\n",
      "Epoch 7086/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6344 - val_loss: -175.2499\n",
      "\n",
      "Epoch 07086: loss did not improve from -175.83200\n",
      "Epoch 7087/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6155 - val_loss: -175.1761\n",
      "\n",
      "Epoch 07087: loss did not improve from -175.83200\n",
      "Epoch 7088/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1767 - val_loss: -175.2237\n",
      "\n",
      "Epoch 07088: loss did not improve from -175.83200\n",
      "Epoch 7089/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6399 - val_loss: -175.0636\n",
      "\n",
      "Epoch 07089: loss did not improve from -175.83200\n",
      "Epoch 7090/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5846 - val_loss: -175.2678\n",
      "\n",
      "Epoch 07090: loss did not improve from -175.83200\n",
      "Epoch 7091/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3941 - val_loss: -174.9858\n",
      "\n",
      "Epoch 07091: loss did not improve from -175.83200\n",
      "Epoch 7092/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4349 - val_loss: -175.1816\n",
      "\n",
      "Epoch 07092: loss did not improve from -175.83200\n",
      "Epoch 7093/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5024 - val_loss: -175.0690\n",
      "\n",
      "Epoch 07093: loss did not improve from -175.83200\n",
      "Epoch 7094/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2573 - val_loss: -175.1411\n",
      "\n",
      "Epoch 07094: loss did not improve from -175.83200\n",
      "Epoch 7095/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3441 - val_loss: -175.3116\n",
      "\n",
      "Epoch 07095: loss did not improve from -175.83200\n",
      "Epoch 7096/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3159 - val_loss: -174.8356\n",
      "\n",
      "Epoch 07096: loss did not improve from -175.83200\n",
      "Epoch 7097/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3924 - val_loss: -175.2866\n",
      "\n",
      "Epoch 07097: loss did not improve from -175.83200\n",
      "Epoch 7098/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4979 - val_loss: -174.9623\n",
      "\n",
      "Epoch 07098: loss did not improve from -175.83200\n",
      "Epoch 7099/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4773 - val_loss: -175.2729\n",
      "\n",
      "Epoch 07099: loss did not improve from -175.83200\n",
      "Epoch 7100/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6606 - val_loss: -175.1990\n",
      "\n",
      "Epoch 07100: loss did not improve from -175.83200\n",
      "Epoch 7101/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7149 - val_loss: -175.3121\n",
      "\n",
      "Epoch 07101: loss did not improve from -175.83200\n",
      "Epoch 7102/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5116 - val_loss: -175.2483\n",
      "\n",
      "Epoch 07102: loss did not improve from -175.83200\n",
      "Epoch 7103/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4380 - val_loss: -175.2109\n",
      "\n",
      "Epoch 07103: loss did not improve from -175.83200\n",
      "Epoch 7104/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5650 - val_loss: -175.2252\n",
      "\n",
      "Epoch 07104: loss did not improve from -175.83200\n",
      "Epoch 7105/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7333 - val_loss: -175.3555\n",
      "\n",
      "Epoch 07105: loss did not improve from -175.83200\n",
      "Epoch 7106/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5790 - val_loss: -175.0888\n",
      "\n",
      "Epoch 07106: loss did not improve from -175.83200\n",
      "Epoch 7107/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5930 - val_loss: -175.1665\n",
      "\n",
      "Epoch 07107: loss did not improve from -175.83200\n",
      "Epoch 7108/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6518 - val_loss: -175.2523\n",
      "\n",
      "Epoch 07108: loss did not improve from -175.83200\n",
      "Epoch 7109/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7664 - val_loss: -175.3719\n",
      "\n",
      "Epoch 07109: loss did not improve from -175.83200\n",
      "Epoch 7110/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5961 - val_loss: -175.1690\n",
      "\n",
      "Epoch 07110: loss did not improve from -175.83200\n",
      "Epoch 7111/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5147 - val_loss: -175.2763\n",
      "\n",
      "Epoch 07111: loss did not improve from -175.83200\n",
      "Epoch 7112/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5942 - val_loss: -175.2707\n",
      "\n",
      "Epoch 07112: loss did not improve from -175.83200\n",
      "Epoch 7113/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6500 - val_loss: -175.3670\n",
      "\n",
      "Epoch 07113: loss did not improve from -175.83200\n",
      "Epoch 7114/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5914 - val_loss: -175.2147\n",
      "\n",
      "Epoch 07114: loss did not improve from -175.83200\n",
      "Epoch 7115/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4702 - val_loss: -175.2152\n",
      "\n",
      "Epoch 07115: loss did not improve from -175.83200\n",
      "Epoch 7116/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5691 - val_loss: -175.0950\n",
      "\n",
      "Epoch 07116: loss did not improve from -175.83200\n",
      "Epoch 7117/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9216 - val_loss: -175.2315\n",
      "\n",
      "Epoch 07117: loss improved from -175.83200 to -175.92161, saving model to gendance.h5\n",
      "Epoch 7118/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7320 - val_loss: -175.3465\n",
      "\n",
      "Epoch 07118: loss did not improve from -175.92161\n",
      "Epoch 7119/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5159 - val_loss: -175.2627\n",
      "\n",
      "Epoch 07119: loss did not improve from -175.92161\n",
      "Epoch 7120/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5489 - val_loss: -175.1763\n",
      "\n",
      "Epoch 07120: loss did not improve from -175.92161\n",
      "Epoch 7121/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8791 - val_loss: -175.1819\n",
      "\n",
      "Epoch 07121: loss did not improve from -175.92161\n",
      "Epoch 7122/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5123 - val_loss: -175.2063\n",
      "\n",
      "Epoch 07122: loss did not improve from -175.92161\n",
      "Epoch 7123/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6441 - val_loss: -175.1688\n",
      "\n",
      "Epoch 07123: loss did not improve from -175.92161\n",
      "Epoch 7124/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4852 - val_loss: -175.2547\n",
      "\n",
      "Epoch 07124: loss did not improve from -175.92161\n",
      "Epoch 7125/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4935 - val_loss: -175.1028\n",
      "\n",
      "Epoch 07125: loss did not improve from -175.92161\n",
      "Epoch 7126/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7729 - val_loss: -175.2930\n",
      "\n",
      "Epoch 07126: loss did not improve from -175.92161\n",
      "Epoch 7127/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8524 - val_loss: -175.2046\n",
      "\n",
      "Epoch 07127: loss did not improve from -175.92161\n",
      "Epoch 7128/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4564 - val_loss: -175.3307\n",
      "\n",
      "Epoch 07128: loss did not improve from -175.92161\n",
      "Epoch 7129/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3726 - val_loss: -175.0898\n",
      "\n",
      "Epoch 07129: loss did not improve from -175.92161\n",
      "Epoch 7130/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5753 - val_loss: -175.2139\n",
      "\n",
      "Epoch 07130: loss did not improve from -175.92161\n",
      "Epoch 7131/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4633 - val_loss: -175.1271\n",
      "\n",
      "Epoch 07131: loss did not improve from -175.92161\n",
      "Epoch 7132/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6669 - val_loss: -175.3407\n",
      "\n",
      "Epoch 07132: loss did not improve from -175.92161\n",
      "Epoch 7133/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4108 - val_loss: -175.2509\n",
      "\n",
      "Epoch 07133: loss did not improve from -175.92161\n",
      "Epoch 7134/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6444 - val_loss: -175.2159\n",
      "\n",
      "Epoch 07134: loss did not improve from -175.92161\n",
      "Epoch 7135/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8993 - val_loss: -175.2580\n",
      "\n",
      "Epoch 07135: loss did not improve from -175.92161\n",
      "Epoch 7136/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6371 - val_loss: -175.4463\n",
      "\n",
      "Epoch 07136: loss did not improve from -175.92161\n",
      "Epoch 7137/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7025 - val_loss: -175.2595\n",
      "\n",
      "Epoch 07137: loss did not improve from -175.92161\n",
      "Epoch 7138/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3961 - val_loss: -175.1261\n",
      "\n",
      "Epoch 07138: loss did not improve from -175.92161\n",
      "Epoch 7139/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7049 - val_loss: -175.2886\n",
      "\n",
      "Epoch 07139: loss did not improve from -175.92161\n",
      "Epoch 7140/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5351 - val_loss: -175.1701\n",
      "\n",
      "Epoch 07140: loss did not improve from -175.92161\n",
      "Epoch 7141/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5130 - val_loss: -175.1751\n",
      "\n",
      "Epoch 07141: loss did not improve from -175.92161\n",
      "Epoch 7142/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.1838 - val_loss: -174.9909\n",
      "\n",
      "Epoch 07142: loss did not improve from -175.92161\n",
      "Epoch 7143/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2792 - val_loss: -175.2898\n",
      "\n",
      "Epoch 07143: loss did not improve from -175.92161\n",
      "Epoch 7144/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3520 - val_loss: -174.6305\n",
      "\n",
      "Epoch 07144: loss did not improve from -175.92161\n",
      "Epoch 7145/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4723 - val_loss: -175.4356\n",
      "\n",
      "Epoch 07145: loss did not improve from -175.92161\n",
      "Epoch 7146/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6305 - val_loss: -175.0480\n",
      "\n",
      "Epoch 07146: loss did not improve from -175.92161\n",
      "Epoch 7147/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7403 - val_loss: -175.4294\n",
      "\n",
      "Epoch 07147: loss did not improve from -175.92161\n",
      "Epoch 7148/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6407 - val_loss: -175.1733\n",
      "\n",
      "Epoch 07148: loss did not improve from -175.92161\n",
      "Epoch 7149/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5615 - val_loss: -175.3363\n",
      "\n",
      "Epoch 07149: loss did not improve from -175.92161\n",
      "Epoch 7150/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8070 - val_loss: -175.3697\n",
      "\n",
      "Epoch 07150: loss did not improve from -175.92161\n",
      "Epoch 7151/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -175.5982 - val_loss: -175.2550\n",
      "\n",
      "Epoch 07151: loss did not improve from -175.92161\n",
      "Epoch 7152/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5654 - val_loss: -175.3001\n",
      "\n",
      "Epoch 07152: loss did not improve from -175.92161\n",
      "Epoch 7153/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6169 - val_loss: -175.2701\n",
      "\n",
      "Epoch 07153: loss did not improve from -175.92161\n",
      "Epoch 7154/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7391 - val_loss: -175.1653\n",
      "\n",
      "Epoch 07154: loss did not improve from -175.92161\n",
      "Epoch 7155/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6950 - val_loss: -175.2357\n",
      "\n",
      "Epoch 07155: loss did not improve from -175.92161\n",
      "Epoch 7156/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6605 - val_loss: -175.2798\n",
      "\n",
      "Epoch 07156: loss did not improve from -175.92161\n",
      "Epoch 7157/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6750 - val_loss: -175.3942\n",
      "\n",
      "Epoch 07157: loss did not improve from -175.92161\n",
      "Epoch 7158/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7648 - val_loss: -175.2335\n",
      "\n",
      "Epoch 07158: loss did not improve from -175.92161\n",
      "Epoch 7159/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5972 - val_loss: -175.1988\n",
      "\n",
      "Epoch 07159: loss did not improve from -175.92161\n",
      "Epoch 7160/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6074 - val_loss: -175.2021\n",
      "\n",
      "Epoch 07160: loss did not improve from -175.92161\n",
      "Epoch 7161/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7590 - val_loss: -175.2531\n",
      "\n",
      "Epoch 07161: loss did not improve from -175.92161\n",
      "Epoch 7162/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6606 - val_loss: -175.2811\n",
      "\n",
      "Epoch 07162: loss did not improve from -175.92161\n",
      "Epoch 7163/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4478 - val_loss: -175.0883\n",
      "\n",
      "Epoch 07163: loss did not improve from -175.92161\n",
      "Epoch 7164/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7410 - val_loss: -175.4901\n",
      "\n",
      "Epoch 07164: loss did not improve from -175.92161\n",
      "Epoch 7165/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7621 - val_loss: -175.3190\n",
      "\n",
      "Epoch 07165: loss did not improve from -175.92161\n",
      "Epoch 7166/10000\n",
      "16167/16167 [==============================] - 1s 33us/step - loss: -175.7040 - val_loss: -175.3505\n",
      "\n",
      "Epoch 07166: loss did not improve from -175.92161\n",
      "Epoch 7167/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7378 - val_loss: -175.2474\n",
      "\n",
      "Epoch 07167: loss did not improve from -175.92161\n",
      "Epoch 7168/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9449 - val_loss: -175.3945\n",
      "\n",
      "Epoch 07168: loss improved from -175.92161 to -175.94493, saving model to gendance.h5\n",
      "Epoch 7169/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9305 - val_loss: -175.2830\n",
      "\n",
      "Epoch 07169: loss did not improve from -175.94493\n",
      "Epoch 7170/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5431 - val_loss: -175.2435\n",
      "\n",
      "Epoch 07170: loss did not improve from -175.94493\n",
      "Epoch 7171/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6173 - val_loss: -175.3136\n",
      "\n",
      "Epoch 07171: loss did not improve from -175.94493\n",
      "Epoch 7172/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6438 - val_loss: -175.2119\n",
      "\n",
      "Epoch 07172: loss did not improve from -175.94493\n",
      "Epoch 7173/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4682 - val_loss: -175.3022\n",
      "\n",
      "Epoch 07173: loss did not improve from -175.94493\n",
      "Epoch 7174/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3819 - val_loss: -175.2078\n",
      "\n",
      "Epoch 07174: loss did not improve from -175.94493\n",
      "Epoch 7175/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5903 - val_loss: -175.4140\n",
      "\n",
      "Epoch 07175: loss did not improve from -175.94493\n",
      "Epoch 7176/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7372 - val_loss: -175.1744\n",
      "\n",
      "Epoch 07176: loss did not improve from -175.94493\n",
      "Epoch 7177/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7338 - val_loss: -175.4264\n",
      "\n",
      "Epoch 07177: loss did not improve from -175.94493\n",
      "Epoch 7178/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7756 - val_loss: -175.2199\n",
      "\n",
      "Epoch 07178: loss did not improve from -175.94493\n",
      "Epoch 7179/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5443 - val_loss: -175.3858\n",
      "\n",
      "Epoch 07179: loss did not improve from -175.94493\n",
      "Epoch 7180/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5818 - val_loss: -175.0794\n",
      "\n",
      "Epoch 07180: loss did not improve from -175.94493\n",
      "Epoch 7181/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8356 - val_loss: -175.5449\n",
      "\n",
      "Epoch 07181: loss did not improve from -175.94493\n",
      "Epoch 7182/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6422 - val_loss: -175.0784\n",
      "\n",
      "Epoch 07182: loss did not improve from -175.94493\n",
      "Epoch 7183/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6433 - val_loss: -175.3633\n",
      "\n",
      "Epoch 07183: loss did not improve from -175.94493\n",
      "Epoch 7184/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5952 - val_loss: -175.0620\n",
      "\n",
      "Epoch 07184: loss did not improve from -175.94493\n",
      "Epoch 7185/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7880 - val_loss: -175.4606\n",
      "\n",
      "Epoch 07185: loss did not improve from -175.94493\n",
      "Epoch 7186/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9349 - val_loss: -175.2144\n",
      "\n",
      "Epoch 07186: loss did not improve from -175.94493\n",
      "Epoch 7187/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6118 - val_loss: -175.3121\n",
      "\n",
      "Epoch 07187: loss did not improve from -175.94493\n",
      "Epoch 7188/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6855 - val_loss: -175.4441\n",
      "\n",
      "Epoch 07188: loss did not improve from -175.94493\n",
      "Epoch 7189/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.3732 - val_loss: -175.2405\n",
      "\n",
      "Epoch 07189: loss did not improve from -175.94493\n",
      "Epoch 7190/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6392 - val_loss: -175.5131\n",
      "\n",
      "Epoch 07190: loss did not improve from -175.94493\n",
      "Epoch 7191/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5897 - val_loss: -175.2375\n",
      "\n",
      "Epoch 07191: loss did not improve from -175.94493\n",
      "Epoch 7192/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8002 - val_loss: -175.3681\n",
      "\n",
      "Epoch 07192: loss did not improve from -175.94493\n",
      "Epoch 7193/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6864 - val_loss: -175.3343\n",
      "\n",
      "Epoch 07193: loss did not improve from -175.94493\n",
      "Epoch 7194/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6846 - val_loss: -175.1477\n",
      "\n",
      "Epoch 07194: loss did not improve from -175.94493\n",
      "Epoch 7195/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6554 - val_loss: -175.3919\n",
      "\n",
      "Epoch 07195: loss did not improve from -175.94493\n",
      "Epoch 7196/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6713 - val_loss: -175.2237\n",
      "\n",
      "Epoch 07196: loss did not improve from -175.94493\n",
      "Epoch 7197/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7536 - val_loss: -175.5333\n",
      "\n",
      "Epoch 07197: loss did not improve from -175.94493\n",
      "Epoch 7198/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6746 - val_loss: -175.0483\n",
      "\n",
      "Epoch 07198: loss did not improve from -175.94493\n",
      "Epoch 7199/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7445 - val_loss: -175.4242\n",
      "\n",
      "Epoch 07199: loss did not improve from -175.94493\n",
      "Epoch 7200/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6336 - val_loss: -175.0256\n",
      "\n",
      "Epoch 07200: loss did not improve from -175.94493\n",
      "Epoch 7201/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7545 - val_loss: -175.2887\n",
      "\n",
      "Epoch 07201: loss did not improve from -175.94493\n",
      "Epoch 7202/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6541 - val_loss: -175.0367\n",
      "\n",
      "Epoch 07202: loss did not improve from -175.94493\n",
      "Epoch 7203/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5237 - val_loss: -175.3070\n",
      "\n",
      "Epoch 07203: loss did not improve from -175.94493\n",
      "Epoch 7204/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7515 - val_loss: -174.9914\n",
      "\n",
      "Epoch 07204: loss did not improve from -175.94493\n",
      "Epoch 7205/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7812 - val_loss: -175.3981\n",
      "\n",
      "Epoch 07205: loss did not improve from -175.94493\n",
      "Epoch 7206/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4789 - val_loss: -175.0293\n",
      "\n",
      "Epoch 07206: loss did not improve from -175.94493\n",
      "Epoch 7207/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5508 - val_loss: -175.2637\n",
      "\n",
      "Epoch 07207: loss did not improve from -175.94493\n",
      "Epoch 7208/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7329 - val_loss: -175.3142\n",
      "\n",
      "Epoch 07208: loss did not improve from -175.94493\n",
      "Epoch 7209/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -175.6822 - val_loss: -175.2418\n",
      "\n",
      "Epoch 07209: loss did not improve from -175.94493\n",
      "Epoch 7210/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6661 - val_loss: -175.2120\n",
      "\n",
      "Epoch 07210: loss did not improve from -175.94493\n",
      "Epoch 7211/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7733 - val_loss: -175.1027\n",
      "\n",
      "Epoch 07211: loss did not improve from -175.94493\n",
      "Epoch 7212/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6195 - val_loss: -175.3781\n",
      "\n",
      "Epoch 07212: loss did not improve from -175.94493\n",
      "Epoch 7213/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7289 - val_loss: -175.1323\n",
      "\n",
      "Epoch 07213: loss did not improve from -175.94493\n",
      "Epoch 7214/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.2844 - val_loss: -175.3324\n",
      "\n",
      "Epoch 07214: loss did not improve from -175.94493\n",
      "Epoch 7215/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5295 - val_loss: -174.9543\n",
      "\n",
      "Epoch 07215: loss did not improve from -175.94493\n",
      "Epoch 7216/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6104 - val_loss: -175.4334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 07216: loss did not improve from -175.94493\n",
      "Epoch 7217/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7366 - val_loss: -175.1669\n",
      "\n",
      "Epoch 07217: loss did not improve from -175.94493\n",
      "Epoch 7218/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8693 - val_loss: -175.3906\n",
      "\n",
      "Epoch 07218: loss did not improve from -175.94493\n",
      "Epoch 7219/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8122 - val_loss: -175.3301\n",
      "\n",
      "Epoch 07219: loss did not improve from -175.94493\n",
      "Epoch 7220/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8826 - val_loss: -175.3616\n",
      "\n",
      "Epoch 07220: loss did not improve from -175.94493\n",
      "Epoch 7221/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7674 - val_loss: -175.3650\n",
      "\n",
      "Epoch 07221: loss did not improve from -175.94493\n",
      "Epoch 7222/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6058 - val_loss: -175.3097\n",
      "\n",
      "Epoch 07222: loss did not improve from -175.94493\n",
      "Epoch 7223/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9043 - val_loss: -175.3609\n",
      "\n",
      "Epoch 07223: loss did not improve from -175.94493\n",
      "Epoch 7224/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9390 - val_loss: -175.4876\n",
      "\n",
      "Epoch 07224: loss did not improve from -175.94493\n",
      "Epoch 7225/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6965 - val_loss: -175.1957\n",
      "\n",
      "Epoch 07225: loss did not improve from -175.94493\n",
      "Epoch 7226/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7407 - val_loss: -175.3545\n",
      "\n",
      "Epoch 07226: loss did not improve from -175.94493\n",
      "Epoch 7227/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8266 - val_loss: -175.2598\n",
      "\n",
      "Epoch 07227: loss did not improve from -175.94493\n",
      "Epoch 7228/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7540 - val_loss: -175.2867\n",
      "\n",
      "Epoch 07228: loss did not improve from -175.94493\n",
      "Epoch 7229/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6743 - val_loss: -175.3597\n",
      "\n",
      "Epoch 07229: loss did not improve from -175.94493\n",
      "Epoch 7230/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8593 - val_loss: -175.3666\n",
      "\n",
      "Epoch 07230: loss did not improve from -175.94493\n",
      "Epoch 7231/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8694 - val_loss: -175.2803\n",
      "\n",
      "Epoch 07231: loss did not improve from -175.94493\n",
      "Epoch 7232/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7962 - val_loss: -175.3638\n",
      "\n",
      "Epoch 07232: loss did not improve from -175.94493\n",
      "Epoch 7233/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5957 - val_loss: -175.2515\n",
      "\n",
      "Epoch 07233: loss did not improve from -175.94493\n",
      "Epoch 7234/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7979 - val_loss: -175.2656\n",
      "\n",
      "Epoch 07234: loss did not improve from -175.94493\n",
      "Epoch 7235/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6504 - val_loss: -175.2373\n",
      "\n",
      "Epoch 07235: loss did not improve from -175.94493\n",
      "Epoch 7236/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5978 - val_loss: -175.2712\n",
      "\n",
      "Epoch 07236: loss did not improve from -175.94493\n",
      "Epoch 7237/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8077 - val_loss: -175.3643\n",
      "\n",
      "Epoch 07237: loss did not improve from -175.94493\n",
      "Epoch 7238/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8655 - val_loss: -175.4582\n",
      "\n",
      "Epoch 07238: loss did not improve from -175.94493\n",
      "Epoch 7239/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6429 - val_loss: -175.3959\n",
      "\n",
      "Epoch 07239: loss did not improve from -175.94493\n",
      "Epoch 7240/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8230 - val_loss: -175.3544\n",
      "\n",
      "Epoch 07240: loss did not improve from -175.94493\n",
      "Epoch 7241/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6157 - val_loss: -175.4040\n",
      "\n",
      "Epoch 07241: loss did not improve from -175.94493\n",
      "Epoch 7242/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8278 - val_loss: -175.4956\n",
      "\n",
      "Epoch 07242: loss did not improve from -175.94493\n",
      "Epoch 7243/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6611 - val_loss: -175.3082\n",
      "\n",
      "Epoch 07243: loss did not improve from -175.94493\n",
      "Epoch 7244/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -175.6778 - val_loss: -175.3891\n",
      "\n",
      "Epoch 07244: loss did not improve from -175.94493\n",
      "Epoch 7245/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8146 - val_loss: -175.1823\n",
      "\n",
      "Epoch 07245: loss did not improve from -175.94493\n",
      "Epoch 7246/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7997 - val_loss: -175.4928\n",
      "\n",
      "Epoch 07246: loss did not improve from -175.94493\n",
      "Epoch 7247/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8625 - val_loss: -175.2617\n",
      "\n",
      "Epoch 07247: loss did not improve from -175.94493\n",
      "Epoch 7248/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8077 - val_loss: -175.4094\n",
      "\n",
      "Epoch 07248: loss did not improve from -175.94493\n",
      "Epoch 7249/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6962 - val_loss: -175.2791\n",
      "\n",
      "Epoch 07249: loss did not improve from -175.94493\n",
      "Epoch 7250/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7694 - val_loss: -175.5362\n",
      "\n",
      "Epoch 07250: loss did not improve from -175.94493\n",
      "Epoch 7251/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -175.7500 - val_loss: -174.9526\n",
      "\n",
      "Epoch 07251: loss did not improve from -175.94493\n",
      "Epoch 7252/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9214 - val_loss: -175.4647\n",
      "\n",
      "Epoch 07252: loss did not improve from -175.94493\n",
      "Epoch 7253/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7482 - val_loss: -175.2230\n",
      "\n",
      "Epoch 07253: loss did not improve from -175.94493\n",
      "Epoch 7254/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4854 - val_loss: -175.1380\n",
      "\n",
      "Epoch 07254: loss did not improve from -175.94493\n",
      "Epoch 7255/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -175.4233 - val_loss: -175.3578\n",
      "\n",
      "Epoch 07255: loss did not improve from -175.94493\n",
      "Epoch 7256/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5939 - val_loss: -175.1504\n",
      "\n",
      "Epoch 07256: loss did not improve from -175.94493\n",
      "Epoch 7257/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5569 - val_loss: -175.4539\n",
      "\n",
      "Epoch 07257: loss did not improve from -175.94493\n",
      "Epoch 7258/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6715 - val_loss: -175.1799\n",
      "\n",
      "Epoch 07258: loss did not improve from -175.94493\n",
      "Epoch 7259/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7366 - val_loss: -175.3861\n",
      "\n",
      "Epoch 07259: loss did not improve from -175.94493\n",
      "Epoch 7260/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5078 - val_loss: -175.1749\n",
      "\n",
      "Epoch 07260: loss did not improve from -175.94493\n",
      "Epoch 7261/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6822 - val_loss: -175.4841\n",
      "\n",
      "Epoch 07261: loss did not improve from -175.94493\n",
      "Epoch 7262/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7189 - val_loss: -175.2734\n",
      "\n",
      "Epoch 07262: loss did not improve from -175.94493\n",
      "Epoch 7263/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6578 - val_loss: -175.4114\n",
      "\n",
      "Epoch 07263: loss did not improve from -175.94493\n",
      "Epoch 7264/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7988 - val_loss: -175.4754\n",
      "\n",
      "Epoch 07264: loss did not improve from -175.94493\n",
      "Epoch 7265/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8520 - val_loss: -175.4073\n",
      "\n",
      "Epoch 07265: loss did not improve from -175.94493\n",
      "Epoch 7266/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9393 - val_loss: -175.4335\n",
      "\n",
      "Epoch 07266: loss did not improve from -175.94493\n",
      "Epoch 7267/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6504 - val_loss: -175.2700\n",
      "\n",
      "Epoch 07267: loss did not improve from -175.94493\n",
      "Epoch 7268/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9208 - val_loss: -175.4544\n",
      "\n",
      "Epoch 07268: loss did not improve from -175.94493\n",
      "Epoch 7269/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7223 - val_loss: -175.3219\n",
      "\n",
      "Epoch 07269: loss did not improve from -175.94493\n",
      "Epoch 7270/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8718 - val_loss: -175.3939\n",
      "\n",
      "Epoch 07270: loss did not improve from -175.94493\n",
      "Epoch 7271/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8478 - val_loss: -175.3650\n",
      "\n",
      "Epoch 07271: loss did not improve from -175.94493\n",
      "Epoch 7272/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8056 - val_loss: -175.4096\n",
      "\n",
      "Epoch 07272: loss did not improve from -175.94493\n",
      "Epoch 7273/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7571 - val_loss: -175.3393\n",
      "\n",
      "Epoch 07273: loss did not improve from -175.94493\n",
      "Epoch 7274/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8752 - val_loss: -175.3961\n",
      "\n",
      "Epoch 07274: loss did not improve from -175.94493\n",
      "Epoch 7275/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8742 - val_loss: -175.4292\n",
      "\n",
      "Epoch 07275: loss did not improve from -175.94493\n",
      "Epoch 7276/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1134 - val_loss: -175.4566\n",
      "\n",
      "Epoch 07276: loss improved from -175.94493 to -176.11343, saving model to gendance.h5\n",
      "Epoch 7277/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0233 - val_loss: -175.3206\n",
      "\n",
      "Epoch 07277: loss did not improve from -176.11343\n",
      "Epoch 7278/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9362 - val_loss: -175.4330\n",
      "\n",
      "Epoch 07278: loss did not improve from -176.11343\n",
      "Epoch 7279/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9029 - val_loss: -175.3780\n",
      "\n",
      "Epoch 07279: loss did not improve from -176.11343\n",
      "Epoch 7280/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7260 - val_loss: -175.4388\n",
      "\n",
      "Epoch 07280: loss did not improve from -176.11343\n",
      "Epoch 7281/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5464 - val_loss: -175.3217\n",
      "\n",
      "Epoch 07281: loss did not improve from -176.11343\n",
      "Epoch 7282/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7714 - val_loss: -175.4055\n",
      "\n",
      "Epoch 07282: loss did not improve from -176.11343\n",
      "Epoch 7283/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8423 - val_loss: -175.4036\n",
      "\n",
      "Epoch 07283: loss did not improve from -176.11343\n",
      "Epoch 7284/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5620 - val_loss: -175.3897\n",
      "\n",
      "Epoch 07284: loss did not improve from -176.11343\n",
      "Epoch 7285/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8660 - val_loss: -175.4475\n",
      "\n",
      "Epoch 07285: loss did not improve from -176.11343\n",
      "Epoch 7286/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7331 - val_loss: -175.3147\n",
      "\n",
      "Epoch 07286: loss did not improve from -176.11343\n",
      "Epoch 7287/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8848 - val_loss: -175.3717\n",
      "\n",
      "Epoch 07287: loss did not improve from -176.11343\n",
      "Epoch 7288/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6987 - val_loss: -175.3650\n",
      "\n",
      "Epoch 07288: loss did not improve from -176.11343\n",
      "Epoch 7289/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8163 - val_loss: -175.1777\n",
      "\n",
      "Epoch 07289: loss did not improve from -176.11343\n",
      "Epoch 7290/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6190 - val_loss: -175.3207\n",
      "\n",
      "Epoch 07290: loss did not improve from -176.11343\n",
      "Epoch 7291/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4800 - val_loss: -174.9425\n",
      "\n",
      "Epoch 07291: loss did not improve from -176.11343\n",
      "Epoch 7292/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6891 - val_loss: -175.3247\n",
      "\n",
      "Epoch 07292: loss did not improve from -176.11343\n",
      "Epoch 7293/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5500 - val_loss: -175.1053\n",
      "\n",
      "Epoch 07293: loss did not improve from -176.11343\n",
      "Epoch 7294/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7223 - val_loss: -175.5092\n",
      "\n",
      "Epoch 07294: loss did not improve from -176.11343\n",
      "Epoch 7295/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8422 - val_loss: -175.1406\n",
      "\n",
      "Epoch 07295: loss did not improve from -176.11343\n",
      "Epoch 7296/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8360 - val_loss: -175.4842\n",
      "\n",
      "Epoch 07296: loss did not improve from -176.11343\n",
      "Epoch 7297/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6682 - val_loss: -174.9909\n",
      "\n",
      "Epoch 07297: loss did not improve from -176.11343\n",
      "Epoch 7298/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1364 - val_loss: -175.6664\n",
      "\n",
      "Epoch 07298: loss improved from -176.11343 to -176.13636, saving model to gendance.h5\n",
      "Epoch 7299/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8542 - val_loss: -175.1941\n",
      "\n",
      "Epoch 07299: loss did not improve from -176.13636\n",
      "Epoch 7300/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8614 - val_loss: -175.4478\n",
      "\n",
      "Epoch 07300: loss did not improve from -176.13636\n",
      "Epoch 7301/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1446 - val_loss: -175.4896\n",
      "\n",
      "Epoch 07301: loss improved from -176.13636 to -176.14464, saving model to gendance.h5\n",
      "Epoch 7302/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8371 - val_loss: -175.3465\n",
      "\n",
      "Epoch 07302: loss did not improve from -176.14464\n",
      "Epoch 7303/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7541 - val_loss: -175.4241\n",
      "\n",
      "Epoch 07303: loss did not improve from -176.14464\n",
      "Epoch 7304/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8549 - val_loss: -175.4106\n",
      "\n",
      "Epoch 07304: loss did not improve from -176.14464\n",
      "Epoch 7305/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7377 - val_loss: -175.4408\n",
      "\n",
      "Epoch 07305: loss did not improve from -176.14464\n",
      "Epoch 7306/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9913 - val_loss: -175.3426\n",
      "\n",
      "Epoch 07306: loss did not improve from -176.14464\n",
      "Epoch 7307/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8401 - val_loss: -175.3502\n",
      "\n",
      "Epoch 07307: loss did not improve from -176.14464\n",
      "Epoch 7308/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9528 - val_loss: -175.3987\n",
      "\n",
      "Epoch 07308: loss did not improve from -176.14464\n",
      "Epoch 7309/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5876 - val_loss: -175.4670\n",
      "\n",
      "Epoch 07309: loss did not improve from -176.14464\n",
      "Epoch 7310/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -175.7476 - val_loss: -175.1095\n",
      "\n",
      "Epoch 07310: loss did not improve from -176.14464\n",
      "Epoch 7311/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -175.7806 - val_loss: -175.5137\n",
      "\n",
      "Epoch 07311: loss did not improve from -176.14464\n",
      "Epoch 7312/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8310 - val_loss: -175.2743\n",
      "\n",
      "Epoch 07312: loss did not improve from -176.14464\n",
      "Epoch 7313/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7427 - val_loss: -175.4000\n",
      "\n",
      "Epoch 07313: loss did not improve from -176.14464\n",
      "Epoch 7314/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8029 - val_loss: -174.9902\n",
      "\n",
      "Epoch 07314: loss did not improve from -176.14464\n",
      "Epoch 7315/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9186 - val_loss: -175.3545\n",
      "\n",
      "Epoch 07315: loss did not improve from -176.14464\n",
      "Epoch 7316/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9254 - val_loss: -175.3432\n",
      "\n",
      "Epoch 07316: loss did not improve from -176.14464\n",
      "Epoch 7317/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6977 - val_loss: -175.3425\n",
      "\n",
      "Epoch 07317: loss did not improve from -176.14464\n",
      "Epoch 7318/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8790 - val_loss: -175.4442\n",
      "\n",
      "Epoch 07318: loss did not improve from -176.14464\n",
      "Epoch 7319/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8498 - val_loss: -175.2423\n",
      "\n",
      "Epoch 07319: loss did not improve from -176.14464\n",
      "Epoch 7320/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7967 - val_loss: -175.4394\n",
      "\n",
      "Epoch 07320: loss did not improve from -176.14464\n",
      "Epoch 7321/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7164 - val_loss: -175.1918\n",
      "\n",
      "Epoch 07321: loss did not improve from -176.14464\n",
      "Epoch 7322/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6412 - val_loss: -175.5083\n",
      "\n",
      "Epoch 07322: loss did not improve from -176.14464\n",
      "Epoch 7323/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7491 - val_loss: -175.2155\n",
      "\n",
      "Epoch 07323: loss did not improve from -176.14464\n",
      "Epoch 7324/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -176.0840 - val_loss: -175.5341\n",
      "\n",
      "Epoch 07324: loss did not improve from -176.14464\n",
      "Epoch 7325/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1090 - val_loss: -175.3212\n",
      "\n",
      "Epoch 07325: loss did not improve from -176.14464\n",
      "Epoch 7326/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8992 - val_loss: -175.5339\n",
      "\n",
      "Epoch 07326: loss did not improve from -176.14464\n",
      "Epoch 7327/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7631 - val_loss: -175.4820\n",
      "\n",
      "Epoch 07327: loss did not improve from -176.14464\n",
      "Epoch 7328/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8792 - val_loss: -175.4856\n",
      "\n",
      "Epoch 07328: loss did not improve from -176.14464\n",
      "Epoch 7329/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9844 - val_loss: -175.3570\n",
      "\n",
      "Epoch 07329: loss did not improve from -176.14464\n",
      "Epoch 7330/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7533 - val_loss: -175.2032\n",
      "\n",
      "Epoch 07330: loss did not improve from -176.14464\n",
      "Epoch 7331/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8758 - val_loss: -175.5588\n",
      "\n",
      "Epoch 07331: loss did not improve from -176.14464\n",
      "Epoch 7332/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9706 - val_loss: -175.2750\n",
      "\n",
      "Epoch 07332: loss did not improve from -176.14464\n",
      "Epoch 7333/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0921 - val_loss: -175.5532\n",
      "\n",
      "Epoch 07333: loss did not improve from -176.14464\n",
      "Epoch 7334/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9477 - val_loss: -175.2606\n",
      "\n",
      "Epoch 07334: loss did not improve from -176.14464\n",
      "Epoch 7335/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8552 - val_loss: -175.3303\n",
      "\n",
      "Epoch 07335: loss did not improve from -176.14464\n",
      "Epoch 7336/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8098 - val_loss: -175.4980\n",
      "\n",
      "Epoch 07336: loss did not improve from -176.14464\n",
      "Epoch 7337/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9406 - val_loss: -175.3470\n",
      "\n",
      "Epoch 07337: loss did not improve from -176.14464\n",
      "Epoch 7338/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4710 - val_loss: -175.3928\n",
      "\n",
      "Epoch 07338: loss did not improve from -176.14464\n",
      "Epoch 7339/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8906 - val_loss: -175.2602\n",
      "\n",
      "Epoch 07339: loss did not improve from -176.14464\n",
      "Epoch 7340/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5654 - val_loss: -175.5262\n",
      "\n",
      "Epoch 07340: loss did not improve from -176.14464\n",
      "Epoch 7341/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6994 - val_loss: -174.9683\n",
      "\n",
      "Epoch 07341: loss did not improve from -176.14464\n",
      "Epoch 7342/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8980 - val_loss: -175.6871\n",
      "\n",
      "Epoch 07342: loss did not improve from -176.14464\n",
      "Epoch 7343/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9072 - val_loss: -175.3030\n",
      "\n",
      "Epoch 07343: loss did not improve from -176.14464\n",
      "Epoch 7344/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8978 - val_loss: -175.6195\n",
      "\n",
      "Epoch 07344: loss did not improve from -176.14464\n",
      "Epoch 7345/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8860 - val_loss: -175.3595\n",
      "\n",
      "Epoch 07345: loss did not improve from -176.14464\n",
      "Epoch 7346/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9187 - val_loss: -175.5375\n",
      "\n",
      "Epoch 07346: loss did not improve from -176.14464\n",
      "Epoch 7347/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6653 - val_loss: -175.3445\n",
      "\n",
      "Epoch 07347: loss did not improve from -176.14464\n",
      "Epoch 7348/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8762 - val_loss: -175.5185\n",
      "\n",
      "Epoch 07348: loss did not improve from -176.14464\n",
      "Epoch 7349/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7142 - val_loss: -175.3948\n",
      "\n",
      "Epoch 07349: loss did not improve from -176.14464\n",
      "Epoch 7350/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9063 - val_loss: -175.4350\n",
      "\n",
      "Epoch 07350: loss did not improve from -176.14464\n",
      "Epoch 7351/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8676 - val_loss: -175.3812\n",
      "\n",
      "Epoch 07351: loss did not improve from -176.14464\n",
      "Epoch 7352/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9701 - val_loss: -175.3930\n",
      "\n",
      "Epoch 07352: loss did not improve from -176.14464\n",
      "Epoch 7353/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0244 - val_loss: -175.5734\n",
      "\n",
      "Epoch 07353: loss did not improve from -176.14464\n",
      "Epoch 7354/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0095 - val_loss: -175.3576\n",
      "\n",
      "Epoch 07354: loss did not improve from -176.14464\n",
      "Epoch 7355/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8860 - val_loss: -175.4337\n",
      "\n",
      "Epoch 07355: loss did not improve from -176.14464\n",
      "Epoch 7356/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6335 - val_loss: -175.2364\n",
      "\n",
      "Epoch 07356: loss did not improve from -176.14464\n",
      "Epoch 7357/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9094 - val_loss: -175.3134\n",
      "\n",
      "Epoch 07357: loss did not improve from -176.14464\n",
      "Epoch 7358/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7895 - val_loss: -175.3980\n",
      "\n",
      "Epoch 07358: loss did not improve from -176.14464\n",
      "Epoch 7359/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9240 - val_loss: -175.3439\n",
      "\n",
      "Epoch 07359: loss did not improve from -176.14464\n",
      "Epoch 7360/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9026 - val_loss: -175.5921\n",
      "\n",
      "Epoch 07360: loss did not improve from -176.14464\n",
      "Epoch 7361/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9160 - val_loss: -175.2272\n",
      "\n",
      "Epoch 07361: loss did not improve from -176.14464\n",
      "Epoch 7362/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9846 - val_loss: -175.4976\n",
      "\n",
      "Epoch 07362: loss did not improve from -176.14464\n",
      "Epoch 7363/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8414 - val_loss: -175.2729\n",
      "\n",
      "Epoch 07363: loss did not improve from -176.14464\n",
      "Epoch 7364/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8729 - val_loss: -175.5091\n",
      "\n",
      "Epoch 07364: loss did not improve from -176.14464\n",
      "Epoch 7365/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6054 - val_loss: -175.3601\n",
      "\n",
      "Epoch 07365: loss did not improve from -176.14464\n",
      "Epoch 7366/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7223 - val_loss: -175.3292\n",
      "\n",
      "Epoch 07366: loss did not improve from -176.14464\n",
      "Epoch 7367/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9619 - val_loss: -175.3972\n",
      "\n",
      "Epoch 07367: loss did not improve from -176.14464\n",
      "Epoch 7368/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9600 - val_loss: -175.4510\n",
      "\n",
      "Epoch 07368: loss did not improve from -176.14464\n",
      "Epoch 7369/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0078 - val_loss: -175.4954\n",
      "\n",
      "Epoch 07369: loss did not improve from -176.14464\n",
      "Epoch 7370/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8739 - val_loss: -175.3430\n",
      "\n",
      "Epoch 07370: loss did not improve from -176.14464\n",
      "Epoch 7371/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6992 - val_loss: -175.4315\n",
      "\n",
      "Epoch 07371: loss did not improve from -176.14464\n",
      "Epoch 7372/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6571 - val_loss: -175.1698\n",
      "\n",
      "Epoch 07372: loss did not improve from -176.14464\n",
      "Epoch 7373/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9338 - val_loss: -175.5052\n",
      "\n",
      "Epoch 07373: loss did not improve from -176.14464\n",
      "Epoch 7374/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9179 - val_loss: -175.4954\n",
      "\n",
      "Epoch 07374: loss did not improve from -176.14464\n",
      "Epoch 7375/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0652 - val_loss: -175.5421\n",
      "\n",
      "Epoch 07375: loss did not improve from -176.14464\n",
      "Epoch 7376/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9891 - val_loss: -175.4160\n",
      "\n",
      "Epoch 07376: loss did not improve from -176.14464\n",
      "Epoch 7377/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8936 - val_loss: -175.4463\n",
      "\n",
      "Epoch 07377: loss did not improve from -176.14464\n",
      "Epoch 7378/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0152 - val_loss: -175.4559\n",
      "\n",
      "Epoch 07378: loss did not improve from -176.14464\n",
      "Epoch 7379/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0122 - val_loss: -175.5103\n",
      "\n",
      "Epoch 07379: loss did not improve from -176.14464\n",
      "Epoch 7380/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9893 - val_loss: -175.3373\n",
      "\n",
      "Epoch 07380: loss did not improve from -176.14464\n",
      "Epoch 7381/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8870 - val_loss: -175.4717\n",
      "\n",
      "Epoch 07381: loss did not improve from -176.14464\n",
      "Epoch 7382/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8099 - val_loss: -175.2042\n",
      "\n",
      "Epoch 07382: loss did not improve from -176.14464\n",
      "Epoch 7383/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8820 - val_loss: -175.4732\n",
      "\n",
      "Epoch 07383: loss did not improve from -176.14464\n",
      "Epoch 7384/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1330 - val_loss: -175.2989\n",
      "\n",
      "Epoch 07384: loss did not improve from -176.14464\n",
      "Epoch 7385/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0757 - val_loss: -175.5912\n",
      "\n",
      "Epoch 07385: loss did not improve from -176.14464\n",
      "Epoch 7386/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1981 - val_loss: -175.3839\n",
      "\n",
      "Epoch 07386: loss improved from -176.14464 to -176.19805, saving model to gendance.h5\n",
      "Epoch 7387/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -176.0352 - val_loss: -175.4931\n",
      "\n",
      "Epoch 07387: loss did not improve from -176.19805\n",
      "Epoch 7388/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9343 - val_loss: -175.2458\n",
      "\n",
      "Epoch 07388: loss did not improve from -176.19805\n",
      "Epoch 7389/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1205 - val_loss: -175.5376\n",
      "\n",
      "Epoch 07389: loss did not improve from -176.19805\n",
      "Epoch 7390/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8463 - val_loss: -175.1515\n",
      "\n",
      "Epoch 07390: loss did not improve from -176.19805\n",
      "Epoch 7391/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9728 - val_loss: -175.5789\n",
      "\n",
      "Epoch 07391: loss did not improve from -176.19805\n",
      "Epoch 7392/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6502 - val_loss: -175.3189\n",
      "\n",
      "Epoch 07392: loss did not improve from -176.19805\n",
      "Epoch 7393/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9512 - val_loss: -175.3948\n",
      "\n",
      "Epoch 07393: loss did not improve from -176.19805\n",
      "Epoch 7394/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6124 - val_loss: -175.3835\n",
      "\n",
      "Epoch 07394: loss did not improve from -176.19805\n",
      "Epoch 7395/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5742 - val_loss: -174.8904\n",
      "\n",
      "Epoch 07395: loss did not improve from -176.19805\n",
      "Epoch 7396/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6117 - val_loss: -175.4784\n",
      "\n",
      "Epoch 07396: loss did not improve from -176.19805\n",
      "Epoch 7397/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.4056 - val_loss: -174.8088\n",
      "\n",
      "Epoch 07397: loss did not improve from -176.19805\n",
      "Epoch 7398/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.5660 - val_loss: -175.5106\n",
      "\n",
      "Epoch 07398: loss did not improve from -176.19805\n",
      "Epoch 7399/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.6392 - val_loss: -175.0298\n",
      "\n",
      "Epoch 07399: loss did not improve from -176.19805\n",
      "Epoch 7400/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8654 - val_loss: -175.4308\n",
      "\n",
      "Epoch 07400: loss did not improve from -176.19805\n",
      "Epoch 7401/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -176.1022 - val_loss: -175.4674\n",
      "\n",
      "Epoch 07401: loss did not improve from -176.19805\n",
      "Epoch 7402/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8993 - val_loss: -175.5036\n",
      "\n",
      "Epoch 07402: loss did not improve from -176.19805\n",
      "Epoch 7403/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9700 - val_loss: -175.4962\n",
      "\n",
      "Epoch 07403: loss did not improve from -176.19805\n",
      "Epoch 7404/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0512 - val_loss: -175.4239\n",
      "\n",
      "Epoch 07404: loss did not improve from -176.19805\n",
      "Epoch 7405/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9200 - val_loss: -175.4983\n",
      "\n",
      "Epoch 07405: loss did not improve from -176.19805\n",
      "Epoch 7406/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0091 - val_loss: -175.4431\n",
      "\n",
      "Epoch 07406: loss did not improve from -176.19805\n",
      "Epoch 7407/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0505 - val_loss: -175.5580\n",
      "\n",
      "Epoch 07407: loss did not improve from -176.19805\n",
      "Epoch 7408/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9559 - val_loss: -175.4606\n",
      "\n",
      "Epoch 07408: loss did not improve from -176.19805\n",
      "Epoch 7409/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2170 - val_loss: -175.5686\n",
      "\n",
      "Epoch 07409: loss improved from -176.19805 to -176.21701, saving model to gendance.h5\n",
      "Epoch 7410/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0348 - val_loss: -175.5433\n",
      "\n",
      "Epoch 07410: loss did not improve from -176.21701\n",
      "Epoch 7411/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1599 - val_loss: -175.4385\n",
      "\n",
      "Epoch 07411: loss did not improve from -176.21701\n",
      "Epoch 7412/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0640 - val_loss: -175.6003\n",
      "\n",
      "Epoch 07412: loss did not improve from -176.21701\n",
      "Epoch 7413/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8584 - val_loss: -175.3008\n",
      "\n",
      "Epoch 07413: loss did not improve from -176.21701\n",
      "Epoch 7414/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7553 - val_loss: -175.3864\n",
      "\n",
      "Epoch 07414: loss did not improve from -176.21701\n",
      "Epoch 7415/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9761 - val_loss: -175.5474\n",
      "\n",
      "Epoch 07415: loss did not improve from -176.21701\n",
      "Epoch 7416/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9787 - val_loss: -175.3639\n",
      "\n",
      "Epoch 07416: loss did not improve from -176.21701\n",
      "Epoch 7417/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1169 - val_loss: -175.5265\n",
      "\n",
      "Epoch 07417: loss did not improve from -176.21701\n",
      "Epoch 7418/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9671 - val_loss: -175.2636\n",
      "\n",
      "Epoch 07418: loss did not improve from -176.21701\n",
      "Epoch 7419/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8769 - val_loss: -175.3853\n",
      "\n",
      "Epoch 07419: loss did not improve from -176.21701\n",
      "Epoch 7420/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0865 - val_loss: -175.5174\n",
      "\n",
      "Epoch 07420: loss did not improve from -176.21701\n",
      "Epoch 7421/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0763 - val_loss: -175.4359\n",
      "\n",
      "Epoch 07421: loss did not improve from -176.21701\n",
      "Epoch 7422/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8906 - val_loss: -175.4615\n",
      "\n",
      "Epoch 07422: loss did not improve from -176.21701\n",
      "Epoch 7423/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9951 - val_loss: -175.3679\n",
      "\n",
      "Epoch 07423: loss did not improve from -176.21701\n",
      "Epoch 7424/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8174 - val_loss: -175.3576\n",
      "\n",
      "Epoch 07424: loss did not improve from -176.21701\n",
      "Epoch 7425/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9566 - val_loss: -175.5775\n",
      "\n",
      "Epoch 07425: loss did not improve from -176.21701\n",
      "Epoch 7426/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0313 - val_loss: -175.4835\n",
      "\n",
      "Epoch 07426: loss did not improve from -176.21701\n",
      "Epoch 7427/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9437 - val_loss: -175.4884\n",
      "\n",
      "Epoch 07427: loss did not improve from -176.21701\n",
      "Epoch 7428/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9395 - val_loss: -175.4780\n",
      "\n",
      "Epoch 07428: loss did not improve from -176.21701\n",
      "Epoch 7429/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9459 - val_loss: -175.4866\n",
      "\n",
      "Epoch 07429: loss did not improve from -176.21701\n",
      "Epoch 7430/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9187 - val_loss: -175.3753\n",
      "\n",
      "Epoch 07430: loss did not improve from -176.21701\n",
      "Epoch 7431/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9919 - val_loss: -175.4940\n",
      "\n",
      "Epoch 07431: loss did not improve from -176.21701\n",
      "Epoch 7432/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9385 - val_loss: -175.3021\n",
      "\n",
      "Epoch 07432: loss did not improve from -176.21701\n",
      "Epoch 7433/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0418 - val_loss: -175.4554\n",
      "\n",
      "Epoch 07433: loss did not improve from -176.21701\n",
      "Epoch 7434/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8948 - val_loss: -175.3857\n",
      "\n",
      "Epoch 07434: loss did not improve from -176.21701\n",
      "Epoch 7435/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9386 - val_loss: -175.4806\n",
      "\n",
      "Epoch 07435: loss did not improve from -176.21701\n",
      "Epoch 7436/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8786 - val_loss: -175.4923\n",
      "\n",
      "Epoch 07436: loss did not improve from -176.21701\n",
      "Epoch 7437/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8427 - val_loss: -175.3821\n",
      "\n",
      "Epoch 07437: loss did not improve from -176.21701\n",
      "Epoch 7438/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -175.9210 - val_loss: -175.5158\n",
      "\n",
      "Epoch 07438: loss did not improve from -176.21701\n",
      "Epoch 7439/10000\n",
      "16167/16167 [==============================] - 1s 33us/step - loss: -175.8769 - val_loss: -175.2637\n",
      "\n",
      "Epoch 07439: loss did not improve from -176.21701\n",
      "Epoch 7440/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7709 - val_loss: -175.5649\n",
      "\n",
      "Epoch 07440: loss did not improve from -176.21701\n",
      "Epoch 7441/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8207 - val_loss: -175.1299\n",
      "\n",
      "Epoch 07441: loss did not improve from -176.21701\n",
      "Epoch 7442/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9266 - val_loss: -175.6425\n",
      "\n",
      "Epoch 07442: loss did not improve from -176.21701\n",
      "Epoch 7443/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0001 - val_loss: -175.1211\n",
      "\n",
      "Epoch 07443: loss did not improve from -176.21701\n",
      "Epoch 7444/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -175.8483 - val_loss: -175.6223\n",
      "\n",
      "Epoch 07444: loss did not improve from -176.21701\n",
      "Epoch 7445/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0100 - val_loss: -175.2427\n",
      "\n",
      "Epoch 07445: loss did not improve from -176.21701\n",
      "Epoch 7446/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9364 - val_loss: -175.4899\n",
      "\n",
      "Epoch 07446: loss did not improve from -176.21701\n",
      "Epoch 7447/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7771 - val_loss: -175.2747\n",
      "\n",
      "Epoch 07447: loss did not improve from -176.21701\n",
      "Epoch 7448/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9055 - val_loss: -175.4958\n",
      "\n",
      "Epoch 07448: loss did not improve from -176.21701\n",
      "Epoch 7449/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8677 - val_loss: -175.5092\n",
      "\n",
      "Epoch 07449: loss did not improve from -176.21701\n",
      "Epoch 7450/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2229 - val_loss: -175.4588\n",
      "\n",
      "Epoch 07450: loss improved from -176.21701 to -176.22295, saving model to gendance.h5\n",
      "Epoch 7451/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -176.0232 - val_loss: -175.6480\n",
      "\n",
      "Epoch 07451: loss did not improve from -176.22295\n",
      "Epoch 7452/10000\n",
      "16167/16167 [==============================] - 1s 31us/step - loss: -175.7388 - val_loss: -175.2556\n",
      "\n",
      "Epoch 07452: loss did not improve from -176.22295\n",
      "Epoch 7453/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -175.9363 - val_loss: -175.5799\n",
      "\n",
      "Epoch 07453: loss did not improve from -176.22295\n",
      "Epoch 7454/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1530 - val_loss: -175.4229\n",
      "\n",
      "Epoch 07454: loss did not improve from -176.22295\n",
      "Epoch 7455/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2022 - val_loss: -175.6425\n",
      "\n",
      "Epoch 07455: loss did not improve from -176.22295\n",
      "Epoch 7456/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9713 - val_loss: -175.2490\n",
      "\n",
      "Epoch 07456: loss did not improve from -176.22295\n",
      "Epoch 7457/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9207 - val_loss: -175.4930\n",
      "\n",
      "Epoch 07457: loss did not improve from -176.22295\n",
      "Epoch 7458/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8951 - val_loss: -175.2469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 07458: loss did not improve from -176.22295\n",
      "Epoch 7459/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1468 - val_loss: -175.7002\n",
      "\n",
      "Epoch 07459: loss did not improve from -176.22295\n",
      "Epoch 7460/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2463 - val_loss: -175.4480\n",
      "\n",
      "Epoch 07460: loss improved from -176.22295 to -176.24634, saving model to gendance.h5\n",
      "Epoch 7461/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1404 - val_loss: -175.5367\n",
      "\n",
      "Epoch 07461: loss did not improve from -176.24634\n",
      "Epoch 7462/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8428 - val_loss: -175.4776\n",
      "\n",
      "Epoch 07462: loss did not improve from -176.24634\n",
      "Epoch 7463/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2257 - val_loss: -175.4875\n",
      "\n",
      "Epoch 07463: loss did not improve from -176.24634\n",
      "Epoch 7464/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0208 - val_loss: -175.4796\n",
      "\n",
      "Epoch 07464: loss did not improve from -176.24634\n",
      "Epoch 7465/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9816 - val_loss: -175.3157\n",
      "\n",
      "Epoch 07465: loss did not improve from -176.24634\n",
      "Epoch 7466/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9157 - val_loss: -175.6614\n",
      "\n",
      "Epoch 07466: loss did not improve from -176.24634\n",
      "Epoch 7467/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0877 - val_loss: -175.4290\n",
      "\n",
      "Epoch 07467: loss did not improve from -176.24634\n",
      "Epoch 7468/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0669 - val_loss: -175.5025\n",
      "\n",
      "Epoch 07468: loss did not improve from -176.24634\n",
      "Epoch 7469/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9566 - val_loss: -175.4807\n",
      "\n",
      "Epoch 07469: loss did not improve from -176.24634\n",
      "Epoch 7470/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0421 - val_loss: -175.4639\n",
      "\n",
      "Epoch 07470: loss did not improve from -176.24634\n",
      "Epoch 7471/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9953 - val_loss: -175.4706\n",
      "\n",
      "Epoch 07471: loss did not improve from -176.24634\n",
      "Epoch 7472/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1844 - val_loss: -175.6159\n",
      "\n",
      "Epoch 07472: loss did not improve from -176.24634\n",
      "Epoch 7473/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7884 - val_loss: -175.3346\n",
      "\n",
      "Epoch 07473: loss did not improve from -176.24634\n",
      "Epoch 7474/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -176.1353 - val_loss: -175.4577\n",
      "\n",
      "Epoch 07474: loss did not improve from -176.24634\n",
      "Epoch 7475/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8299 - val_loss: -175.4493\n",
      "\n",
      "Epoch 07475: loss did not improve from -176.24634\n",
      "Epoch 7476/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8788 - val_loss: -175.3508\n",
      "\n",
      "Epoch 07476: loss did not improve from -176.24634\n",
      "Epoch 7477/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8687 - val_loss: -175.5324\n",
      "\n",
      "Epoch 07477: loss did not improve from -176.24634\n",
      "Epoch 7478/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7219 - val_loss: -175.0852\n",
      "\n",
      "Epoch 07478: loss did not improve from -176.24634\n",
      "Epoch 7479/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8957 - val_loss: -175.5753\n",
      "\n",
      "Epoch 07479: loss did not improve from -176.24634\n",
      "Epoch 7480/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8172 - val_loss: -175.1389\n",
      "\n",
      "Epoch 07480: loss did not improve from -176.24634\n",
      "Epoch 7481/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9028 - val_loss: -175.5532\n",
      "\n",
      "Epoch 07481: loss did not improve from -176.24634\n",
      "Epoch 7482/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -175.9530 - val_loss: -175.2730\n",
      "\n",
      "Epoch 07482: loss did not improve from -176.24634\n",
      "Epoch 7483/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2026 - val_loss: -175.5903\n",
      "\n",
      "Epoch 07483: loss did not improve from -176.24634\n",
      "Epoch 7484/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1597 - val_loss: -175.4656\n",
      "\n",
      "Epoch 07484: loss did not improve from -176.24634\n",
      "Epoch 7485/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9111 - val_loss: -175.4728\n",
      "\n",
      "Epoch 07485: loss did not improve from -176.24634\n",
      "Epoch 7486/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1364 - val_loss: -175.4683\n",
      "\n",
      "Epoch 07486: loss did not improve from -176.24634\n",
      "Epoch 7487/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2427 - val_loss: -175.6274\n",
      "\n",
      "Epoch 07487: loss did not improve from -176.24634\n",
      "Epoch 7488/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1549 - val_loss: -175.5289\n",
      "\n",
      "Epoch 07488: loss did not improve from -176.24634\n",
      "Epoch 7489/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1461 - val_loss: -175.5177\n",
      "\n",
      "Epoch 07489: loss did not improve from -176.24634\n",
      "Epoch 7490/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8603 - val_loss: -175.5485\n",
      "\n",
      "Epoch 07490: loss did not improve from -176.24634\n",
      "Epoch 7491/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0495 - val_loss: -175.2970\n",
      "\n",
      "Epoch 07491: loss did not improve from -176.24634\n",
      "Epoch 7492/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9257 - val_loss: -175.5287\n",
      "\n",
      "Epoch 07492: loss did not improve from -176.24634\n",
      "Epoch 7493/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1384 - val_loss: -175.5018\n",
      "\n",
      "Epoch 07493: loss did not improve from -176.24634\n",
      "Epoch 7494/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9825 - val_loss: -175.5822\n",
      "\n",
      "Epoch 07494: loss did not improve from -176.24634\n",
      "Epoch 7495/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2254 - val_loss: -175.4759\n",
      "\n",
      "Epoch 07495: loss did not improve from -176.24634\n",
      "Epoch 7496/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1348 - val_loss: -175.4782\n",
      "\n",
      "Epoch 07496: loss did not improve from -176.24634\n",
      "Epoch 7497/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0599 - val_loss: -175.4670\n",
      "\n",
      "Epoch 07497: loss did not improve from -176.24634\n",
      "Epoch 7498/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8821 - val_loss: -175.5084\n",
      "\n",
      "Epoch 07498: loss did not improve from -176.24634\n",
      "Epoch 7499/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0305 - val_loss: -175.5313\n",
      "\n",
      "Epoch 07499: loss did not improve from -176.24634\n",
      "Epoch 7500/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2568 - val_loss: -175.5585\n",
      "\n",
      "Epoch 07500: loss improved from -176.24634 to -176.25675, saving model to gendance.h5\n",
      "Epoch 7501/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0699 - val_loss: -175.5520\n",
      "\n",
      "Epoch 07501: loss did not improve from -176.25675\n",
      "Epoch 7502/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9201 - val_loss: -175.4561\n",
      "\n",
      "Epoch 07502: loss did not improve from -176.25675\n",
      "Epoch 7503/10000\n",
      "16167/16167 [==============================] - 1s 31us/step - loss: -175.8941 - val_loss: -175.5510\n",
      "\n",
      "Epoch 07503: loss did not improve from -176.25675\n",
      "Epoch 7504/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0568 - val_loss: -175.3606\n",
      "\n",
      "Epoch 07504: loss did not improve from -176.25675\n",
      "Epoch 7505/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1643 - val_loss: -175.4988\n",
      "\n",
      "Epoch 07505: loss did not improve from -176.25675\n",
      "Epoch 7506/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1495 - val_loss: -175.4583\n",
      "\n",
      "Epoch 07506: loss did not improve from -176.25675\n",
      "Epoch 7507/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9973 - val_loss: -175.5634\n",
      "\n",
      "Epoch 07507: loss did not improve from -176.25675\n",
      "Epoch 7508/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2106 - val_loss: -175.5056\n",
      "\n",
      "Epoch 07508: loss did not improve from -176.25675\n",
      "Epoch 7509/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0615 - val_loss: -175.4944\n",
      "\n",
      "Epoch 07509: loss did not improve from -176.25675\n",
      "Epoch 7510/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0707 - val_loss: -175.4104\n",
      "\n",
      "Epoch 07510: loss did not improve from -176.25675\n",
      "Epoch 7511/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8542 - val_loss: -175.5534\n",
      "\n",
      "Epoch 07511: loss did not improve from -176.25675\n",
      "Epoch 7512/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1721 - val_loss: -175.4894\n",
      "\n",
      "Epoch 07512: loss did not improve from -176.25675\n",
      "Epoch 7513/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9512 - val_loss: -175.5193\n",
      "\n",
      "Epoch 07513: loss did not improve from -176.25675\n",
      "Epoch 7514/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8357 - val_loss: -175.2264\n",
      "\n",
      "Epoch 07514: loss did not improve from -176.25675\n",
      "Epoch 7515/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9555 - val_loss: -175.6435\n",
      "\n",
      "Epoch 07515: loss did not improve from -176.25675\n",
      "Epoch 7516/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0431 - val_loss: -175.5593\n",
      "\n",
      "Epoch 07516: loss did not improve from -176.25675\n",
      "Epoch 7517/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0499 - val_loss: -175.6034\n",
      "\n",
      "Epoch 07517: loss did not improve from -176.25675\n",
      "Epoch 7518/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0528 - val_loss: -175.4078\n",
      "\n",
      "Epoch 07518: loss did not improve from -176.25675\n",
      "Epoch 7519/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0019 - val_loss: -175.6846\n",
      "\n",
      "Epoch 07519: loss did not improve from -176.25675\n",
      "Epoch 7520/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2402 - val_loss: -175.4397\n",
      "\n",
      "Epoch 07520: loss did not improve from -176.25675\n",
      "Epoch 7521/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8961 - val_loss: -175.5991\n",
      "\n",
      "Epoch 07521: loss did not improve from -176.25675\n",
      "Epoch 7522/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8884 - val_loss: -175.1370\n",
      "\n",
      "Epoch 07522: loss did not improve from -176.25675\n",
      "Epoch 7523/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9621 - val_loss: -175.6644\n",
      "\n",
      "Epoch 07523: loss did not improve from -176.25675\n",
      "Epoch 7524/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1083 - val_loss: -175.2695\n",
      "\n",
      "Epoch 07524: loss did not improve from -176.25675\n",
      "Epoch 7525/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -176.0737 - val_loss: -175.6189\n",
      "\n",
      "Epoch 07525: loss did not improve from -176.25675\n",
      "Epoch 7526/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8540 - val_loss: -175.4402\n",
      "\n",
      "Epoch 07526: loss did not improve from -176.25675\n",
      "Epoch 7527/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1255 - val_loss: -175.5243\n",
      "\n",
      "Epoch 07527: loss did not improve from -176.25675\n",
      "Epoch 7528/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1186 - val_loss: -175.4756\n",
      "\n",
      "Epoch 07528: loss did not improve from -176.25675\n",
      "Epoch 7529/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9519 - val_loss: -175.5585\n",
      "\n",
      "Epoch 07529: loss did not improve from -176.25675\n",
      "Epoch 7530/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0240 - val_loss: -175.4603\n",
      "\n",
      "Epoch 07530: loss did not improve from -176.25675\n",
      "Epoch 7531/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7723 - val_loss: -175.6044\n",
      "\n",
      "Epoch 07531: loss did not improve from -176.25675\n",
      "Epoch 7532/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0075 - val_loss: -175.3208\n",
      "\n",
      "Epoch 07532: loss did not improve from -176.25675\n",
      "Epoch 7533/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9180 - val_loss: -175.5056\n",
      "\n",
      "Epoch 07533: loss did not improve from -176.25675\n",
      "Epoch 7534/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1629 - val_loss: -175.2224\n",
      "\n",
      "Epoch 07534: loss did not improve from -176.25675\n",
      "Epoch 7535/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1735 - val_loss: -175.6808\n",
      "\n",
      "Epoch 07535: loss did not improve from -176.25675\n",
      "Epoch 7536/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0677 - val_loss: -175.4669\n",
      "\n",
      "Epoch 07536: loss did not improve from -176.25675\n",
      "Epoch 7537/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0914 - val_loss: -175.6113\n",
      "\n",
      "Epoch 07537: loss did not improve from -176.25675\n",
      "Epoch 7538/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1568 - val_loss: -175.4896\n",
      "\n",
      "Epoch 07538: loss did not improve from -176.25675\n",
      "Epoch 7539/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9741 - val_loss: -175.5945\n",
      "\n",
      "Epoch 07539: loss did not improve from -176.25675\n",
      "Epoch 7540/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9762 - val_loss: -175.4632\n",
      "\n",
      "Epoch 07540: loss did not improve from -176.25675\n",
      "Epoch 7541/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0010 - val_loss: -175.5512\n",
      "\n",
      "Epoch 07541: loss did not improve from -176.25675\n",
      "Epoch 7542/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8400 - val_loss: -175.3091\n",
      "\n",
      "Epoch 07542: loss did not improve from -176.25675\n",
      "Epoch 7543/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1035 - val_loss: -175.6028\n",
      "\n",
      "Epoch 07543: loss did not improve from -176.25675\n",
      "Epoch 7544/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1174 - val_loss: -175.4770\n",
      "\n",
      "Epoch 07544: loss did not improve from -176.25675\n",
      "Epoch 7545/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9339 - val_loss: -175.6088\n",
      "\n",
      "Epoch 07545: loss did not improve from -176.25675\n",
      "Epoch 7546/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3004 - val_loss: -175.6257\n",
      "\n",
      "Epoch 07546: loss improved from -176.25675 to -176.30041, saving model to gendance.h5\n",
      "Epoch 7547/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1999 - val_loss: -175.6219\n",
      "\n",
      "Epoch 07547: loss did not improve from -176.30041\n",
      "Epoch 7548/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -176.2294 - val_loss: -175.7764\n",
      "\n",
      "Epoch 07548: loss did not improve from -176.30041\n",
      "Epoch 7549/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0583 - val_loss: -175.5143\n",
      "\n",
      "Epoch 07549: loss did not improve from -176.30041\n",
      "Epoch 7550/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0392 - val_loss: -175.6263\n",
      "\n",
      "Epoch 07550: loss did not improve from -176.30041\n",
      "Epoch 7551/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1424 - val_loss: -175.4311\n",
      "\n",
      "Epoch 07551: loss did not improve from -176.30041\n",
      "Epoch 7552/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0132 - val_loss: -175.7627\n",
      "\n",
      "Epoch 07552: loss did not improve from -176.30041\n",
      "Epoch 7553/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1842 - val_loss: -175.4756\n",
      "\n",
      "Epoch 07553: loss did not improve from -176.30041\n",
      "Epoch 7554/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0716 - val_loss: -175.6561\n",
      "\n",
      "Epoch 07554: loss did not improve from -176.30041\n",
      "Epoch 7555/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1824 - val_loss: -175.5973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 07555: loss did not improve from -176.30041\n",
      "Epoch 7556/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2055 - val_loss: -175.6565\n",
      "\n",
      "Epoch 07556: loss did not improve from -176.30041\n",
      "Epoch 7557/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0786 - val_loss: -175.5636\n",
      "\n",
      "Epoch 07557: loss did not improve from -176.30041\n",
      "Epoch 7558/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0777 - val_loss: -175.5787\n",
      "\n",
      "Epoch 07558: loss did not improve from -176.30041\n",
      "Epoch 7559/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9316 - val_loss: -175.5664\n",
      "\n",
      "Epoch 07559: loss did not improve from -176.30041\n",
      "Epoch 7560/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9910 - val_loss: -175.4245\n",
      "\n",
      "Epoch 07560: loss did not improve from -176.30041\n",
      "Epoch 7561/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1382 - val_loss: -175.7023\n",
      "\n",
      "Epoch 07561: loss did not improve from -176.30041\n",
      "Epoch 7562/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -176.0387 - val_loss: -175.4854\n",
      "\n",
      "Epoch 07562: loss did not improve from -176.30041\n",
      "Epoch 7563/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9267 - val_loss: -175.5560\n",
      "\n",
      "Epoch 07563: loss did not improve from -176.30041\n",
      "Epoch 7564/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7564 - val_loss: -175.4452\n",
      "\n",
      "Epoch 07564: loss did not improve from -176.30041\n",
      "Epoch 7565/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0142 - val_loss: -175.5492\n",
      "\n",
      "Epoch 07565: loss did not improve from -176.30041\n",
      "Epoch 7566/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9016 - val_loss: -175.2817\n",
      "\n",
      "Epoch 07566: loss did not improve from -176.30041\n",
      "Epoch 7567/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0493 - val_loss: -175.6639\n",
      "\n",
      "Epoch 07567: loss did not improve from -176.30041\n",
      "Epoch 7568/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9534 - val_loss: -175.6776\n",
      "\n",
      "Epoch 07568: loss did not improve from -176.30041\n",
      "Epoch 7569/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9616 - val_loss: -175.3261\n",
      "\n",
      "Epoch 07569: loss did not improve from -176.30041\n",
      "Epoch 7570/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9144 - val_loss: -175.7149\n",
      "\n",
      "Epoch 07570: loss did not improve from -176.30041\n",
      "Epoch 7571/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8241 - val_loss: -175.1644\n",
      "\n",
      "Epoch 07571: loss did not improve from -176.30041\n",
      "Epoch 7572/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9306 - val_loss: -175.6087\n",
      "\n",
      "Epoch 07572: loss did not improve from -176.30041\n",
      "Epoch 7573/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.7476 - val_loss: -175.1594\n",
      "\n",
      "Epoch 07573: loss did not improve from -176.30041\n",
      "Epoch 7574/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0717 - val_loss: -175.6362\n",
      "\n",
      "Epoch 07574: loss did not improve from -176.30041\n",
      "Epoch 7575/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1625 - val_loss: -175.3283\n",
      "\n",
      "Epoch 07575: loss did not improve from -176.30041\n",
      "Epoch 7576/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1391 - val_loss: -175.6077\n",
      "\n",
      "Epoch 07576: loss did not improve from -176.30041\n",
      "Epoch 7577/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0976 - val_loss: -175.4313\n",
      "\n",
      "Epoch 07577: loss did not improve from -176.30041\n",
      "Epoch 7578/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0735 - val_loss: -175.6217\n",
      "\n",
      "Epoch 07578: loss did not improve from -176.30041\n",
      "Epoch 7579/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1800 - val_loss: -175.5574\n",
      "\n",
      "Epoch 07579: loss did not improve from -176.30041\n",
      "Epoch 7580/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1576 - val_loss: -175.5564\n",
      "\n",
      "Epoch 07580: loss did not improve from -176.30041\n",
      "Epoch 7581/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1307 - val_loss: -175.5677\n",
      "\n",
      "Epoch 07581: loss did not improve from -176.30041\n",
      "Epoch 7582/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2496 - val_loss: -175.6212\n",
      "\n",
      "Epoch 07582: loss did not improve from -176.30041\n",
      "Epoch 7583/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0308 - val_loss: -175.5036\n",
      "\n",
      "Epoch 07583: loss did not improve from -176.30041\n",
      "Epoch 7584/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1310 - val_loss: -175.5978\n",
      "\n",
      "Epoch 07584: loss did not improve from -176.30041\n",
      "Epoch 7585/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1192 - val_loss: -175.5427\n",
      "\n",
      "Epoch 07585: loss did not improve from -176.30041\n",
      "Epoch 7586/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4340 - val_loss: -175.6856\n",
      "\n",
      "Epoch 07586: loss improved from -176.30041 to -176.43403, saving model to gendance.h5\n",
      "Epoch 7587/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2344 - val_loss: -175.4626\n",
      "\n",
      "Epoch 07587: loss did not improve from -176.43403\n",
      "Epoch 7588/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9811 - val_loss: -175.5718\n",
      "\n",
      "Epoch 07588: loss did not improve from -176.43403\n",
      "Epoch 7589/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9286 - val_loss: -175.4991\n",
      "\n",
      "Epoch 07589: loss did not improve from -176.43403\n",
      "Epoch 7590/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1112 - val_loss: -175.5310\n",
      "\n",
      "Epoch 07590: loss did not improve from -176.43403\n",
      "Epoch 7591/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9822 - val_loss: -175.6230\n",
      "\n",
      "Epoch 07591: loss did not improve from -176.43403\n",
      "Epoch 7592/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2028 - val_loss: -175.3806\n",
      "\n",
      "Epoch 07592: loss did not improve from -176.43403\n",
      "Epoch 7593/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0483 - val_loss: -175.5947\n",
      "\n",
      "Epoch 07593: loss did not improve from -176.43403\n",
      "Epoch 7594/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1745 - val_loss: -175.3723\n",
      "\n",
      "Epoch 07594: loss did not improve from -176.43403\n",
      "Epoch 7595/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0094 - val_loss: -175.3914\n",
      "\n",
      "Epoch 07595: loss did not improve from -176.43403\n",
      "Epoch 7596/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0570 - val_loss: -175.4646\n",
      "\n",
      "Epoch 07596: loss did not improve from -176.43403\n",
      "Epoch 7597/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0232 - val_loss: -175.5514\n",
      "\n",
      "Epoch 07597: loss did not improve from -176.43403\n",
      "Epoch 7598/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1670 - val_loss: -175.6569\n",
      "\n",
      "Epoch 07598: loss did not improve from -176.43403\n",
      "Epoch 7599/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1746 - val_loss: -175.4875\n",
      "\n",
      "Epoch 07599: loss did not improve from -176.43403\n",
      "Epoch 7600/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1608 - val_loss: -175.5975\n",
      "\n",
      "Epoch 07600: loss did not improve from -176.43403\n",
      "Epoch 7601/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1455 - val_loss: -175.4725\n",
      "\n",
      "Epoch 07601: loss did not improve from -176.43403\n",
      "Epoch 7602/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4118 - val_loss: -175.6834\n",
      "\n",
      "Epoch 07602: loss did not improve from -176.43403\n",
      "Epoch 7603/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3213 - val_loss: -175.6333\n",
      "\n",
      "Epoch 07603: loss did not improve from -176.43403\n",
      "Epoch 7604/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0001 - val_loss: -175.4399\n",
      "\n",
      "Epoch 07604: loss did not improve from -176.43403\n",
      "Epoch 7605/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4657 - val_loss: -175.7669\n",
      "\n",
      "Epoch 07605: loss improved from -176.43403 to -176.46565, saving model to gendance.h5\n",
      "Epoch 7606/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0974 - val_loss: -175.7797\n",
      "\n",
      "Epoch 07606: loss did not improve from -176.46565\n",
      "Epoch 7607/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3814 - val_loss: -175.5304\n",
      "\n",
      "Epoch 07607: loss did not improve from -176.46565\n",
      "Epoch 7608/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -176.2549 - val_loss: -175.6794\n",
      "\n",
      "Epoch 07608: loss did not improve from -176.46565\n",
      "Epoch 7609/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1168 - val_loss: -175.6057\n",
      "\n",
      "Epoch 07609: loss did not improve from -176.46565\n",
      "Epoch 7610/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2207 - val_loss: -175.6068\n",
      "\n",
      "Epoch 07610: loss did not improve from -176.46565\n",
      "Epoch 7611/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0136 - val_loss: -175.4646\n",
      "\n",
      "Epoch 07611: loss did not improve from -176.46565\n",
      "Epoch 7612/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1659 - val_loss: -175.7516\n",
      "\n",
      "Epoch 07612: loss did not improve from -176.46565\n",
      "Epoch 7613/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1875 - val_loss: -175.5656\n",
      "\n",
      "Epoch 07613: loss did not improve from -176.46565\n",
      "Epoch 7614/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1255 - val_loss: -175.7902\n",
      "\n",
      "Epoch 07614: loss did not improve from -176.46565\n",
      "Epoch 7615/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2870 - val_loss: -175.5036\n",
      "\n",
      "Epoch 07615: loss did not improve from -176.46565\n",
      "Epoch 7616/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1474 - val_loss: -175.5615\n",
      "\n",
      "Epoch 07616: loss did not improve from -176.46565\n",
      "Epoch 7617/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1936 - val_loss: -175.2662\n",
      "\n",
      "Epoch 07617: loss did not improve from -176.46565\n",
      "Epoch 7618/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1155 - val_loss: -175.5229\n",
      "\n",
      "Epoch 07618: loss did not improve from -176.46565\n",
      "Epoch 7619/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3020 - val_loss: -175.4811\n",
      "\n",
      "Epoch 07619: loss did not improve from -176.46565\n",
      "Epoch 7620/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1614 - val_loss: -175.6988\n",
      "\n",
      "Epoch 07620: loss did not improve from -176.46565\n",
      "Epoch 7621/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0194 - val_loss: -175.3216\n",
      "\n",
      "Epoch 07621: loss did not improve from -176.46565\n",
      "Epoch 7622/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9702 - val_loss: -175.7201\n",
      "\n",
      "Epoch 07622: loss did not improve from -176.46565\n",
      "Epoch 7623/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0066 - val_loss: -175.3232\n",
      "\n",
      "Epoch 07623: loss did not improve from -176.46565\n",
      "Epoch 7624/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0798 - val_loss: -175.5585\n",
      "\n",
      "Epoch 07624: loss did not improve from -176.46565\n",
      "Epoch 7625/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2767 - val_loss: -175.2128\n",
      "\n",
      "Epoch 07625: loss did not improve from -176.46565\n",
      "Epoch 7626/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1587 - val_loss: -175.6768\n",
      "\n",
      "Epoch 07626: loss did not improve from -176.46565\n",
      "Epoch 7627/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2063 - val_loss: -175.4240\n",
      "\n",
      "Epoch 07627: loss did not improve from -176.46565\n",
      "Epoch 7628/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0383 - val_loss: -175.5178\n",
      "\n",
      "Epoch 07628: loss did not improve from -176.46565\n",
      "Epoch 7629/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1126 - val_loss: -175.4495\n",
      "\n",
      "Epoch 07629: loss did not improve from -176.46565\n",
      "Epoch 7630/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9485 - val_loss: -175.4786\n",
      "\n",
      "Epoch 07630: loss did not improve from -176.46565\n",
      "Epoch 7631/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4184 - val_loss: -175.6410\n",
      "\n",
      "Epoch 07631: loss did not improve from -176.46565\n",
      "Epoch 7632/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0648 - val_loss: -175.5138\n",
      "\n",
      "Epoch 07632: loss did not improve from -176.46565\n",
      "Epoch 7633/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2866 - val_loss: -175.6678\n",
      "\n",
      "Epoch 07633: loss did not improve from -176.46565\n",
      "Epoch 7634/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1816 - val_loss: -175.5907\n",
      "\n",
      "Epoch 07634: loss did not improve from -176.46565\n",
      "Epoch 7635/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1579 - val_loss: -175.5665\n",
      "\n",
      "Epoch 07635: loss did not improve from -176.46565\n",
      "Epoch 7636/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1518 - val_loss: -175.5613\n",
      "\n",
      "Epoch 07636: loss did not improve from -176.46565\n",
      "Epoch 7637/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0899 - val_loss: -175.5942\n",
      "\n",
      "Epoch 07637: loss did not improve from -176.46565\n",
      "Epoch 7638/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2241 - val_loss: -175.6317\n",
      "\n",
      "Epoch 07638: loss did not improve from -176.46565\n",
      "Epoch 7639/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1969 - val_loss: -175.6175\n",
      "\n",
      "Epoch 07639: loss did not improve from -176.46565\n",
      "Epoch 7640/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1096 - val_loss: -175.3885\n",
      "\n",
      "Epoch 07640: loss did not improve from -176.46565\n",
      "Epoch 7641/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2501 - val_loss: -175.5679\n",
      "\n",
      "Epoch 07641: loss did not improve from -176.46565\n",
      "Epoch 7642/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0845 - val_loss: -175.4701\n",
      "\n",
      "Epoch 07642: loss did not improve from -176.46565\n",
      "Epoch 7643/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1781 - val_loss: -175.5489\n",
      "\n",
      "Epoch 07643: loss did not improve from -176.46565\n",
      "Epoch 7644/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2734 - val_loss: -175.5480\n",
      "\n",
      "Epoch 07644: loss did not improve from -176.46565\n",
      "Epoch 7645/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0509 - val_loss: -175.5143\n",
      "\n",
      "Epoch 07645: loss did not improve from -176.46565\n",
      "Epoch 7646/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1100 - val_loss: -175.5258\n",
      "\n",
      "Epoch 07646: loss did not improve from -176.46565\n",
      "Epoch 7647/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1374 - val_loss: -175.5480\n",
      "\n",
      "Epoch 07647: loss did not improve from -176.46565\n",
      "Epoch 7648/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1580 - val_loss: -175.5251\n",
      "\n",
      "Epoch 07648: loss did not improve from -176.46565\n",
      "Epoch 7649/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0671 - val_loss: -175.6194\n",
      "\n",
      "Epoch 07649: loss did not improve from -176.46565\n",
      "Epoch 7650/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1601 - val_loss: -175.4285\n",
      "\n",
      "Epoch 07650: loss did not improve from -176.46565\n",
      "Epoch 7651/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2160 - val_loss: -175.6968\n",
      "\n",
      "Epoch 07651: loss did not improve from -176.46565\n",
      "Epoch 7652/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3742 - val_loss: -175.4494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 07652: loss did not improve from -176.46565\n",
      "Epoch 7653/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3359 - val_loss: -175.7148\n",
      "\n",
      "Epoch 07653: loss did not improve from -176.46565\n",
      "Epoch 7654/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1486 - val_loss: -175.1987\n",
      "\n",
      "Epoch 07654: loss did not improve from -176.46565\n",
      "Epoch 7655/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0925 - val_loss: -175.5326\n",
      "\n",
      "Epoch 07655: loss did not improve from -176.46565\n",
      "Epoch 7656/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1341 - val_loss: -175.1426\n",
      "\n",
      "Epoch 07656: loss did not improve from -176.46565\n",
      "Epoch 7657/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0879 - val_loss: -175.6297\n",
      "\n",
      "Epoch 07657: loss did not improve from -176.46565\n",
      "Epoch 7658/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0196 - val_loss: -175.2930\n",
      "\n",
      "Epoch 07658: loss did not improve from -176.46565\n",
      "Epoch 7659/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1061 - val_loss: -175.6640\n",
      "\n",
      "Epoch 07659: loss did not improve from -176.46565\n",
      "Epoch 7660/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2262 - val_loss: -175.4386\n",
      "\n",
      "Epoch 07660: loss did not improve from -176.46565\n",
      "Epoch 7661/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9515 - val_loss: -175.4099\n",
      "\n",
      "Epoch 07661: loss did not improve from -176.46565\n",
      "Epoch 7662/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0184 - val_loss: -175.5952\n",
      "\n",
      "Epoch 07662: loss did not improve from -176.46565\n",
      "Epoch 7663/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0094 - val_loss: -175.5515\n",
      "\n",
      "Epoch 07663: loss did not improve from -176.46565\n",
      "Epoch 7664/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0659 - val_loss: -175.8823\n",
      "\n",
      "Epoch 07664: loss did not improve from -176.46565\n",
      "Epoch 7665/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1716 - val_loss: -175.5040\n",
      "\n",
      "Epoch 07665: loss did not improve from -176.46565\n",
      "Epoch 7666/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4067 - val_loss: -175.7137\n",
      "\n",
      "Epoch 07666: loss did not improve from -176.46565\n",
      "Epoch 7667/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4009 - val_loss: -175.3458\n",
      "\n",
      "Epoch 07667: loss did not improve from -176.46565\n",
      "Epoch 7668/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1365 - val_loss: -175.6933\n",
      "\n",
      "Epoch 07668: loss did not improve from -176.46565\n",
      "Epoch 7669/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2592 - val_loss: -175.3816\n",
      "\n",
      "Epoch 07669: loss did not improve from -176.46565\n",
      "Epoch 7670/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4288 - val_loss: -175.7454\n",
      "\n",
      "Epoch 07670: loss did not improve from -176.46565\n",
      "Epoch 7671/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2354 - val_loss: -175.5712\n",
      "\n",
      "Epoch 07671: loss did not improve from -176.46565\n",
      "Epoch 7672/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4512 - val_loss: -175.6842\n",
      "\n",
      "Epoch 07672: loss did not improve from -176.46565\n",
      "Epoch 7673/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3265 - val_loss: -175.5359\n",
      "\n",
      "Epoch 07673: loss did not improve from -176.46565\n",
      "Epoch 7674/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2431 - val_loss: -175.6372\n",
      "\n",
      "Epoch 07674: loss did not improve from -176.46565\n",
      "Epoch 7675/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2913 - val_loss: -175.6404\n",
      "\n",
      "Epoch 07675: loss did not improve from -176.46565\n",
      "Epoch 7676/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1742 - val_loss: -175.4972\n",
      "\n",
      "Epoch 07676: loss did not improve from -176.46565\n",
      "Epoch 7677/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4114 - val_loss: -175.5995\n",
      "\n",
      "Epoch 07677: loss did not improve from -176.46565\n",
      "Epoch 7678/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4715 - val_loss: -175.6242\n",
      "\n",
      "Epoch 07678: loss improved from -176.46565 to -176.47146, saving model to gendance.h5\n",
      "Epoch 7679/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -176.3708 - val_loss: -175.7651\n",
      "\n",
      "Epoch 07679: loss did not improve from -176.47146\n",
      "Epoch 7680/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2389 - val_loss: -175.5477\n",
      "\n",
      "Epoch 07680: loss did not improve from -176.47146\n",
      "Epoch 7681/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3417 - val_loss: -175.6782\n",
      "\n",
      "Epoch 07681: loss did not improve from -176.47146\n",
      "Epoch 7682/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2349 - val_loss: -175.7609\n",
      "\n",
      "Epoch 07682: loss did not improve from -176.47146\n",
      "Epoch 7683/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1719 - val_loss: -175.5987\n",
      "\n",
      "Epoch 07683: loss did not improve from -176.47146\n",
      "Epoch 7684/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3665 - val_loss: -175.6635\n",
      "\n",
      "Epoch 07684: loss did not improve from -176.47146\n",
      "Epoch 7685/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2666 - val_loss: -175.4645\n",
      "\n",
      "Epoch 07685: loss did not improve from -176.47146\n",
      "Epoch 7686/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2025 - val_loss: -175.6470\n",
      "\n",
      "Epoch 07686: loss did not improve from -176.47146\n",
      "Epoch 7687/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4538 - val_loss: -175.6713\n",
      "\n",
      "Epoch 07687: loss did not improve from -176.47146\n",
      "Epoch 7688/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3352 - val_loss: -175.6233\n",
      "\n",
      "Epoch 07688: loss did not improve from -176.47146\n",
      "Epoch 7689/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5741 - val_loss: -175.7416\n",
      "\n",
      "Epoch 07689: loss improved from -176.47146 to -176.57410, saving model to gendance.h5\n",
      "Epoch 7690/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3832 - val_loss: -175.6768\n",
      "\n",
      "Epoch 07690: loss did not improve from -176.57410\n",
      "Epoch 7691/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1659 - val_loss: -175.4835\n",
      "\n",
      "Epoch 07691: loss did not improve from -176.57410\n",
      "Epoch 7692/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2090 - val_loss: -175.5678\n",
      "\n",
      "Epoch 07692: loss did not improve from -176.57410\n",
      "Epoch 7693/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1860 - val_loss: -175.4898\n",
      "\n",
      "Epoch 07693: loss did not improve from -176.57410\n",
      "Epoch 7694/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3164 - val_loss: -175.7018\n",
      "\n",
      "Epoch 07694: loss did not improve from -176.57410\n",
      "Epoch 7695/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2928 - val_loss: -175.5576\n",
      "\n",
      "Epoch 07695: loss did not improve from -176.57410\n",
      "Epoch 7696/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1548 - val_loss: -175.6266\n",
      "\n",
      "Epoch 07696: loss did not improve from -176.57410\n",
      "Epoch 7697/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2079 - val_loss: -175.6419\n",
      "\n",
      "Epoch 07697: loss did not improve from -176.57410\n",
      "Epoch 7698/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1344 - val_loss: -175.6231\n",
      "\n",
      "Epoch 07698: loss did not improve from -176.57410\n",
      "Epoch 7699/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2962 - val_loss: -175.7014\n",
      "\n",
      "Epoch 07699: loss did not improve from -176.57410\n",
      "Epoch 7700/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2145 - val_loss: -175.4011\n",
      "\n",
      "Epoch 07700: loss did not improve from -176.57410\n",
      "Epoch 7701/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2627 - val_loss: -175.7794\n",
      "\n",
      "Epoch 07701: loss did not improve from -176.57410\n",
      "Epoch 7702/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1927 - val_loss: -175.4367\n",
      "\n",
      "Epoch 07702: loss did not improve from -176.57410\n",
      "Epoch 7703/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2072 - val_loss: -175.7229\n",
      "\n",
      "Epoch 07703: loss did not improve from -176.57410\n",
      "Epoch 7704/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2940 - val_loss: -175.4695\n",
      "\n",
      "Epoch 07704: loss did not improve from -176.57410\n",
      "Epoch 7705/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1647 - val_loss: -175.7954\n",
      "\n",
      "Epoch 07705: loss did not improve from -176.57410\n",
      "Epoch 7706/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0941 - val_loss: -175.3576\n",
      "\n",
      "Epoch 07706: loss did not improve from -176.57410\n",
      "Epoch 7707/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1783 - val_loss: -175.7107\n",
      "\n",
      "Epoch 07707: loss did not improve from -176.57410\n",
      "Epoch 7708/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1102 - val_loss: -175.3976\n",
      "\n",
      "Epoch 07708: loss did not improve from -176.57410\n",
      "Epoch 7709/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1400 - val_loss: -175.7091\n",
      "\n",
      "Epoch 07709: loss did not improve from -176.57410\n",
      "Epoch 7710/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -176.1488 - val_loss: -175.5437\n",
      "\n",
      "Epoch 07710: loss did not improve from -176.57410\n",
      "Epoch 7711/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3026 - val_loss: -175.5106\n",
      "\n",
      "Epoch 07711: loss did not improve from -176.57410\n",
      "Epoch 7712/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2643 - val_loss: -175.6903\n",
      "\n",
      "Epoch 07712: loss did not improve from -176.57410\n",
      "Epoch 7713/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4318 - val_loss: -175.6205\n",
      "\n",
      "Epoch 07713: loss did not improve from -176.57410\n",
      "Epoch 7714/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2594 - val_loss: -175.6978\n",
      "\n",
      "Epoch 07714: loss did not improve from -176.57410\n",
      "Epoch 7715/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2035 - val_loss: -175.4663\n",
      "\n",
      "Epoch 07715: loss did not improve from -176.57410\n",
      "Epoch 7716/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4804 - val_loss: -175.7322\n",
      "\n",
      "Epoch 07716: loss did not improve from -176.57410\n",
      "Epoch 7717/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2790 - val_loss: -175.5907\n",
      "\n",
      "Epoch 07717: loss did not improve from -176.57410\n",
      "Epoch 7718/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2581 - val_loss: -175.6336\n",
      "\n",
      "Epoch 07718: loss did not improve from -176.57410\n",
      "Epoch 7719/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2420 - val_loss: -175.5695\n",
      "\n",
      "Epoch 07719: loss did not improve from -176.57410\n",
      "Epoch 7720/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4506 - val_loss: -175.7702\n",
      "\n",
      "Epoch 07720: loss did not improve from -176.57410\n",
      "Epoch 7721/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2793 - val_loss: -175.6731\n",
      "\n",
      "Epoch 07721: loss did not improve from -176.57410\n",
      "Epoch 7722/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2440 - val_loss: -175.6922\n",
      "\n",
      "Epoch 07722: loss did not improve from -176.57410\n",
      "Epoch 7723/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3100 - val_loss: -175.7296\n",
      "\n",
      "Epoch 07723: loss did not improve from -176.57410\n",
      "Epoch 7724/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4535 - val_loss: -175.8020\n",
      "\n",
      "Epoch 07724: loss did not improve from -176.57410\n",
      "Epoch 7725/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2762 - val_loss: -175.5958\n",
      "\n",
      "Epoch 07725: loss did not improve from -176.57410\n",
      "Epoch 7726/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1893 - val_loss: -175.6952\n",
      "\n",
      "Epoch 07726: loss did not improve from -176.57410\n",
      "Epoch 7727/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3491 - val_loss: -175.5252\n",
      "\n",
      "Epoch 07727: loss did not improve from -176.57410\n",
      "Epoch 7728/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2648 - val_loss: -175.7302\n",
      "\n",
      "Epoch 07728: loss did not improve from -176.57410\n",
      "Epoch 7729/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0922 - val_loss: -175.6621\n",
      "\n",
      "Epoch 07729: loss did not improve from -176.57410\n",
      "Epoch 7730/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2577 - val_loss: -175.5328\n",
      "\n",
      "Epoch 07730: loss did not improve from -176.57410\n",
      "Epoch 7731/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0922 - val_loss: -175.6916\n",
      "\n",
      "Epoch 07731: loss did not improve from -176.57410\n",
      "Epoch 7732/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0298 - val_loss: -175.4930\n",
      "\n",
      "Epoch 07732: loss did not improve from -176.57410\n",
      "Epoch 7733/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2977 - val_loss: -175.7388\n",
      "\n",
      "Epoch 07733: loss did not improve from -176.57410\n",
      "Epoch 7734/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1979 - val_loss: -175.4612\n",
      "\n",
      "Epoch 07734: loss did not improve from -176.57410\n",
      "Epoch 7735/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1486 - val_loss: -175.6509\n",
      "\n",
      "Epoch 07735: loss did not improve from -176.57410\n",
      "Epoch 7736/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2650 - val_loss: -175.5725\n",
      "\n",
      "Epoch 07736: loss did not improve from -176.57410\n",
      "Epoch 7737/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2399 - val_loss: -175.6801\n",
      "\n",
      "Epoch 07737: loss did not improve from -176.57410\n",
      "Epoch 7738/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2529 - val_loss: -175.5935\n",
      "\n",
      "Epoch 07738: loss did not improve from -176.57410\n",
      "Epoch 7739/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1203 - val_loss: -175.6044\n",
      "\n",
      "Epoch 07739: loss did not improve from -176.57410\n",
      "Epoch 7740/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4267 - val_loss: -175.5592\n",
      "\n",
      "Epoch 07740: loss did not improve from -176.57410\n",
      "Epoch 7741/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1024 - val_loss: -175.6540\n",
      "\n",
      "Epoch 07741: loss did not improve from -176.57410\n",
      "Epoch 7742/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2758 - val_loss: -175.5137\n",
      "\n",
      "Epoch 07742: loss did not improve from -176.57410\n",
      "Epoch 7743/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2277 - val_loss: -175.6248\n",
      "\n",
      "Epoch 07743: loss did not improve from -176.57410\n",
      "Epoch 7744/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2953 - val_loss: -175.4455\n",
      "\n",
      "Epoch 07744: loss did not improve from -176.57410\n",
      "Epoch 7745/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3886 - val_loss: -175.7813\n",
      "\n",
      "Epoch 07745: loss did not improve from -176.57410\n",
      "Epoch 7746/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3947 - val_loss: -175.4294\n",
      "\n",
      "Epoch 07746: loss did not improve from -176.57410\n",
      "Epoch 7747/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2364 - val_loss: -175.8146\n",
      "\n",
      "Epoch 07747: loss did not improve from -176.57410\n",
      "Epoch 7748/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5254 - val_loss: -175.4906\n",
      "\n",
      "Epoch 07748: loss did not improve from -176.57410\n",
      "Epoch 7749/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4210 - val_loss: -175.7616\n",
      "\n",
      "Epoch 07749: loss did not improve from -176.57410\n",
      "Epoch 7750/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2135 - val_loss: -175.6954\n",
      "\n",
      "Epoch 07750: loss did not improve from -176.57410\n",
      "Epoch 7751/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2255 - val_loss: -175.7224\n",
      "\n",
      "Epoch 07751: loss did not improve from -176.57410\n",
      "Epoch 7752/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1791 - val_loss: -175.6917\n",
      "\n",
      "Epoch 07752: loss did not improve from -176.57410\n",
      "Epoch 7753/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0954 - val_loss: -175.6266\n",
      "\n",
      "Epoch 07753: loss did not improve from -176.57410\n",
      "Epoch 7754/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5070 - val_loss: -175.7846\n",
      "\n",
      "Epoch 07754: loss did not improve from -176.57410\n",
      "Epoch 7755/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2942 - val_loss: -175.4795\n",
      "\n",
      "Epoch 07755: loss did not improve from -176.57410\n",
      "Epoch 7756/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2145 - val_loss: -175.7917\n",
      "\n",
      "Epoch 07756: loss did not improve from -176.57410\n",
      "Epoch 7757/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.8988 - val_loss: -175.3694\n",
      "\n",
      "Epoch 07757: loss did not improve from -176.57410\n",
      "Epoch 7758/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3391 - val_loss: -175.8527\n",
      "\n",
      "Epoch 07758: loss did not improve from -176.57410\n",
      "Epoch 7759/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -176.3367 - val_loss: -175.4525\n",
      "\n",
      "Epoch 07759: loss did not improve from -176.57410\n",
      "Epoch 7760/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4778 - val_loss: -175.8093\n",
      "\n",
      "Epoch 07760: loss did not improve from -176.57410\n",
      "Epoch 7761/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2185 - val_loss: -175.5523\n",
      "\n",
      "Epoch 07761: loss did not improve from -176.57410\n",
      "Epoch 7762/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -176.4063 - val_loss: -175.8290\n",
      "\n",
      "Epoch 07762: loss did not improve from -176.57410\n",
      "Epoch 7763/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2910 - val_loss: -175.6656\n",
      "\n",
      "Epoch 07763: loss did not improve from -176.57410\n",
      "Epoch 7764/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4782 - val_loss: -175.6417\n",
      "\n",
      "Epoch 07764: loss did not improve from -176.57410\n",
      "Epoch 7765/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2909 - val_loss: -175.6578\n",
      "\n",
      "Epoch 07765: loss did not improve from -176.57410\n",
      "Epoch 7766/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1095 - val_loss: -175.5718\n",
      "\n",
      "Epoch 07766: loss did not improve from -176.57410\n",
      "Epoch 7767/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4064 - val_loss: -175.7593\n",
      "\n",
      "Epoch 07767: loss did not improve from -176.57410\n",
      "Epoch 7768/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2325 - val_loss: -175.4227\n",
      "\n",
      "Epoch 07768: loss did not improve from -176.57410\n",
      "Epoch 7769/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2484 - val_loss: -175.6940\n",
      "\n",
      "Epoch 07769: loss did not improve from -176.57410\n",
      "Epoch 7770/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1266 - val_loss: -175.5314\n",
      "\n",
      "Epoch 07770: loss did not improve from -176.57410\n",
      "Epoch 7771/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4097 - val_loss: -175.6867\n",
      "\n",
      "Epoch 07771: loss did not improve from -176.57410\n",
      "Epoch 7772/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4069 - val_loss: -175.5448\n",
      "\n",
      "Epoch 07772: loss did not improve from -176.57410\n",
      "Epoch 7773/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -176.2664 - val_loss: -175.7588\n",
      "\n",
      "Epoch 07773: loss did not improve from -176.57410\n",
      "Epoch 7774/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2567 - val_loss: -175.6337\n",
      "\n",
      "Epoch 07774: loss did not improve from -176.57410\n",
      "Epoch 7775/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2837 - val_loss: -175.7123\n",
      "\n",
      "Epoch 07775: loss did not improve from -176.57410\n",
      "Epoch 7776/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3220 - val_loss: -175.5284\n",
      "\n",
      "Epoch 07776: loss did not improve from -176.57410\n",
      "Epoch 7777/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2494 - val_loss: -175.6499\n",
      "\n",
      "Epoch 07777: loss did not improve from -176.57410\n",
      "Epoch 7778/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2056 - val_loss: -175.6226\n",
      "\n",
      "Epoch 07778: loss did not improve from -176.57410\n",
      "Epoch 7779/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1966 - val_loss: -175.5192\n",
      "\n",
      "Epoch 07779: loss did not improve from -176.57410\n",
      "Epoch 7780/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3131 - val_loss: -175.8370\n",
      "\n",
      "Epoch 07780: loss did not improve from -176.57410\n",
      "Epoch 7781/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5473 - val_loss: -175.5939\n",
      "\n",
      "Epoch 07781: loss did not improve from -176.57410\n",
      "Epoch 7782/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3489 - val_loss: -175.7459\n",
      "\n",
      "Epoch 07782: loss did not improve from -176.57410\n",
      "Epoch 7783/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2756 - val_loss: -175.6369\n",
      "\n",
      "Epoch 07783: loss did not improve from -176.57410\n",
      "Epoch 7784/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3753 - val_loss: -175.7172\n",
      "\n",
      "Epoch 07784: loss did not improve from -176.57410\n",
      "Epoch 7785/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2008 - val_loss: -175.7101\n",
      "\n",
      "Epoch 07785: loss did not improve from -176.57410\n",
      "Epoch 7786/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4498 - val_loss: -175.6869\n",
      "\n",
      "Epoch 07786: loss did not improve from -176.57410\n",
      "Epoch 7787/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4212 - val_loss: -175.6913\n",
      "\n",
      "Epoch 07787: loss did not improve from -176.57410\n",
      "Epoch 7788/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4621 - val_loss: -175.4348\n",
      "\n",
      "Epoch 07788: loss did not improve from -176.57410\n",
      "Epoch 7789/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2312 - val_loss: -175.6272\n",
      "\n",
      "Epoch 07789: loss did not improve from -176.57410\n",
      "Epoch 7790/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2679 - val_loss: -175.6964\n",
      "\n",
      "Epoch 07790: loss did not improve from -176.57410\n",
      "Epoch 7791/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -176.3918 - val_loss: -175.7419\n",
      "\n",
      "Epoch 07791: loss did not improve from -176.57410\n",
      "Epoch 7792/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2267 - val_loss: -175.5443\n",
      "\n",
      "Epoch 07792: loss did not improve from -176.57410\n",
      "Epoch 7793/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1601 - val_loss: -175.5794\n",
      "\n",
      "Epoch 07793: loss did not improve from -176.57410\n",
      "Epoch 7794/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1291 - val_loss: -175.2541\n",
      "\n",
      "Epoch 07794: loss did not improve from -176.57410\n",
      "Epoch 7795/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4186 - val_loss: -175.6078\n",
      "\n",
      "Epoch 07795: loss did not improve from -176.57410\n",
      "Epoch 7796/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1705 - val_loss: -175.6014\n",
      "\n",
      "Epoch 07796: loss did not improve from -176.57410\n",
      "Epoch 7797/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1658 - val_loss: -175.4777\n",
      "\n",
      "Epoch 07797: loss did not improve from -176.57410\n",
      "Epoch 7798/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -175.9584 - val_loss: -175.7039\n",
      "\n",
      "Epoch 07798: loss did not improve from -176.57410\n",
      "Epoch 7799/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2407 - val_loss: -175.3191\n",
      "\n",
      "Epoch 07799: loss did not improve from -176.57410\n",
      "Epoch 7800/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5045 - val_loss: -175.9477\n",
      "\n",
      "Epoch 07800: loss did not improve from -176.57410\n",
      "Epoch 7801/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1973 - val_loss: -175.4804\n",
      "\n",
      "Epoch 07801: loss did not improve from -176.57410\n",
      "Epoch 7802/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1899 - val_loss: -175.6936\n",
      "\n",
      "Epoch 07802: loss did not improve from -176.57410\n",
      "Epoch 7803/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4202 - val_loss: -175.4459\n",
      "\n",
      "Epoch 07803: loss did not improve from -176.57410\n",
      "Epoch 7804/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3483 - val_loss: -175.8285\n",
      "\n",
      "Epoch 07804: loss did not improve from -176.57410\n",
      "Epoch 7805/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2989 - val_loss: -175.4834\n",
      "\n",
      "Epoch 07805: loss did not improve from -176.57410\n",
      "Epoch 7806/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3941 - val_loss: -175.8365\n",
      "\n",
      "Epoch 07806: loss did not improve from -176.57410\n",
      "Epoch 7807/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5418 - val_loss: -175.6701\n",
      "\n",
      "Epoch 07807: loss did not improve from -176.57410\n",
      "Epoch 7808/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4600 - val_loss: -175.8365\n",
      "\n",
      "Epoch 07808: loss did not improve from -176.57410\n",
      "Epoch 7809/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4052 - val_loss: -175.7348\n",
      "\n",
      "Epoch 07809: loss did not improve from -176.57410\n",
      "Epoch 7810/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4493 - val_loss: -175.6620\n",
      "\n",
      "Epoch 07810: loss did not improve from -176.57410\n",
      "Epoch 7811/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2081 - val_loss: -175.5142\n",
      "\n",
      "Epoch 07811: loss did not improve from -176.57410\n",
      "Epoch 7812/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4311 - val_loss: -175.6616\n",
      "\n",
      "Epoch 07812: loss did not improve from -176.57410\n",
      "Epoch 7813/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4032 - val_loss: -175.6530\n",
      "\n",
      "Epoch 07813: loss did not improve from -176.57410\n",
      "Epoch 7814/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4875 - val_loss: -175.6782\n",
      "\n",
      "Epoch 07814: loss did not improve from -176.57410\n",
      "Epoch 7815/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4826 - val_loss: -175.7017\n",
      "\n",
      "Epoch 07815: loss did not improve from -176.57410\n",
      "Epoch 7816/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5584 - val_loss: -175.6040\n",
      "\n",
      "Epoch 07816: loss did not improve from -176.57410\n",
      "Epoch 7817/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7291 - val_loss: -175.8546\n",
      "\n",
      "Epoch 07817: loss improved from -176.57410 to -176.72907, saving model to gendance.h5\n",
      "Epoch 7818/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4742 - val_loss: -175.6744\n",
      "\n",
      "Epoch 07818: loss did not improve from -176.72907\n",
      "Epoch 7819/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1943 - val_loss: -175.6925\n",
      "\n",
      "Epoch 07819: loss did not improve from -176.72907\n",
      "Epoch 7820/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3803 - val_loss: -175.7476\n",
      "\n",
      "Epoch 07820: loss did not improve from -176.72907\n",
      "Epoch 7821/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4823 - val_loss: -175.7711\n",
      "\n",
      "Epoch 07821: loss did not improve from -176.72907\n",
      "Epoch 7822/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2235 - val_loss: -175.5921\n",
      "\n",
      "Epoch 07822: loss did not improve from -176.72907\n",
      "Epoch 7823/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3575 - val_loss: -175.8583\n",
      "\n",
      "Epoch 07823: loss did not improve from -176.72907\n",
      "Epoch 7824/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3272 - val_loss: -175.4776\n",
      "\n",
      "Epoch 07824: loss did not improve from -176.72907\n",
      "Epoch 7825/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2824 - val_loss: -175.6765\n",
      "\n",
      "Epoch 07825: loss did not improve from -176.72907\n",
      "Epoch 7826/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3298 - val_loss: -175.5482\n",
      "\n",
      "Epoch 07826: loss did not improve from -176.72907\n",
      "Epoch 7827/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2104 - val_loss: -175.6715\n",
      "\n",
      "Epoch 07827: loss did not improve from -176.72907\n",
      "Epoch 7828/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2006 - val_loss: -175.6031\n",
      "\n",
      "Epoch 07828: loss did not improve from -176.72907\n",
      "Epoch 7829/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2351 - val_loss: -175.6259\n",
      "\n",
      "Epoch 07829: loss did not improve from -176.72907\n",
      "Epoch 7830/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2563 - val_loss: -175.6817\n",
      "\n",
      "Epoch 07830: loss did not improve from -176.72907\n",
      "Epoch 7831/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3089 - val_loss: -175.6103\n",
      "\n",
      "Epoch 07831: loss did not improve from -176.72907\n",
      "Epoch 7832/10000\n",
      "16167/16167 [==============================] - 1s 32us/step - loss: -176.3181 - val_loss: -175.6781\n",
      "\n",
      "Epoch 07832: loss did not improve from -176.72907\n",
      "Epoch 7833/10000\n",
      "16167/16167 [==============================] - 1s 33us/step - loss: -176.3753 - val_loss: -175.6393\n",
      "\n",
      "Epoch 07833: loss did not improve from -176.72907\n",
      "Epoch 7834/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3545 - val_loss: -175.6840\n",
      "\n",
      "Epoch 07834: loss did not improve from -176.72907\n",
      "Epoch 7835/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3178 - val_loss: -175.7588\n",
      "\n",
      "Epoch 07835: loss did not improve from -176.72907\n",
      "Epoch 7836/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -176.3449 - val_loss: -175.6837\n",
      "\n",
      "Epoch 07836: loss did not improve from -176.72907\n",
      "Epoch 7837/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3624 - val_loss: -175.5974\n",
      "\n",
      "Epoch 07837: loss did not improve from -176.72907\n",
      "Epoch 7838/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3043 - val_loss: -175.7386\n",
      "\n",
      "Epoch 07838: loss did not improve from -176.72907\n",
      "Epoch 7839/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5345 - val_loss: -175.6810\n",
      "\n",
      "Epoch 07839: loss did not improve from -176.72907\n",
      "Epoch 7840/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4084 - val_loss: -175.6866\n",
      "\n",
      "Epoch 07840: loss did not improve from -176.72907\n",
      "Epoch 7841/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3091 - val_loss: -175.3971\n",
      "\n",
      "Epoch 07841: loss did not improve from -176.72907\n",
      "Epoch 7842/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3355 - val_loss: -175.7130\n",
      "\n",
      "Epoch 07842: loss did not improve from -176.72907\n",
      "Epoch 7843/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3541 - val_loss: -175.6989\n",
      "\n",
      "Epoch 07843: loss did not improve from -176.72907\n",
      "Epoch 7844/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -176.1922 - val_loss: -175.6093\n",
      "\n",
      "Epoch 07844: loss did not improve from -176.72907\n",
      "Epoch 7845/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4263 - val_loss: -175.7590\n",
      "\n",
      "Epoch 07845: loss did not improve from -176.72907\n",
      "Epoch 7846/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3798 - val_loss: -175.6879\n",
      "\n",
      "Epoch 07846: loss did not improve from -176.72907\n",
      "Epoch 7847/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3941 - val_loss: -175.6868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 07847: loss did not improve from -176.72907\n",
      "Epoch 7848/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3794 - val_loss: -175.6250\n",
      "\n",
      "Epoch 07848: loss did not improve from -176.72907\n",
      "Epoch 7849/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3407 - val_loss: -175.6008\n",
      "\n",
      "Epoch 07849: loss did not improve from -176.72907\n",
      "Epoch 7850/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3003 - val_loss: -175.7282\n",
      "\n",
      "Epoch 07850: loss did not improve from -176.72907\n",
      "Epoch 7851/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3762 - val_loss: -175.4196\n",
      "\n",
      "Epoch 07851: loss did not improve from -176.72907\n",
      "Epoch 7852/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2754 - val_loss: -175.7957\n",
      "\n",
      "Epoch 07852: loss did not improve from -176.72907\n",
      "Epoch 7853/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4545 - val_loss: -175.3628\n",
      "\n",
      "Epoch 07853: loss did not improve from -176.72907\n",
      "Epoch 7854/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3137 - val_loss: -175.7817\n",
      "\n",
      "Epoch 07854: loss did not improve from -176.72907\n",
      "Epoch 7855/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1896 - val_loss: -175.2809\n",
      "\n",
      "Epoch 07855: loss did not improve from -176.72907\n",
      "Epoch 7856/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4327 - val_loss: -175.8985\n",
      "\n",
      "Epoch 07856: loss did not improve from -176.72907\n",
      "Epoch 7857/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2184 - val_loss: -175.2845\n",
      "\n",
      "Epoch 07857: loss did not improve from -176.72907\n",
      "Epoch 7858/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2889 - val_loss: -175.6122\n",
      "\n",
      "Epoch 07858: loss did not improve from -176.72907\n",
      "Epoch 7859/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4096 - val_loss: -175.2442\n",
      "\n",
      "Epoch 07859: loss did not improve from -176.72907\n",
      "Epoch 7860/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3569 - val_loss: -175.7176\n",
      "\n",
      "Epoch 07860: loss did not improve from -176.72907\n",
      "Epoch 7861/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5188 - val_loss: -175.6246\n",
      "\n",
      "Epoch 07861: loss did not improve from -176.72907\n",
      "Epoch 7862/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2928 - val_loss: -175.6317\n",
      "\n",
      "Epoch 07862: loss did not improve from -176.72907\n",
      "Epoch 7863/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3279 - val_loss: -175.7966\n",
      "\n",
      "Epoch 07863: loss did not improve from -176.72907\n",
      "Epoch 7864/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3420 - val_loss: -175.8253\n",
      "\n",
      "Epoch 07864: loss did not improve from -176.72907\n",
      "Epoch 7865/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5994 - val_loss: -175.8906\n",
      "\n",
      "Epoch 07865: loss did not improve from -176.72907\n",
      "Epoch 7866/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4367 - val_loss: -175.6051\n",
      "\n",
      "Epoch 07866: loss did not improve from -176.72907\n",
      "Epoch 7867/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2223 - val_loss: -175.6137\n",
      "\n",
      "Epoch 07867: loss did not improve from -176.72907\n",
      "Epoch 7868/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1457 - val_loss: -175.6411\n",
      "\n",
      "Epoch 07868: loss did not improve from -176.72907\n",
      "Epoch 7869/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3628 - val_loss: -175.7443\n",
      "\n",
      "Epoch 07869: loss did not improve from -176.72907\n",
      "Epoch 7870/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1528 - val_loss: -175.6356\n",
      "\n",
      "Epoch 07870: loss did not improve from -176.72907\n",
      "Epoch 7871/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4457 - val_loss: -175.5764\n",
      "\n",
      "Epoch 07871: loss did not improve from -176.72907\n",
      "Epoch 7872/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6212 - val_loss: -175.7514\n",
      "\n",
      "Epoch 07872: loss did not improve from -176.72907\n",
      "Epoch 7873/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4640 - val_loss: -175.6860\n",
      "\n",
      "Epoch 07873: loss did not improve from -176.72907\n",
      "Epoch 7874/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4940 - val_loss: -175.6361\n",
      "\n",
      "Epoch 07874: loss did not improve from -176.72907\n",
      "Epoch 7875/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3811 - val_loss: -175.7545\n",
      "\n",
      "Epoch 07875: loss did not improve from -176.72907\n",
      "Epoch 7876/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4885 - val_loss: -175.6820\n",
      "\n",
      "Epoch 07876: loss did not improve from -176.72907\n",
      "Epoch 7877/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2138 - val_loss: -175.5989\n",
      "\n",
      "Epoch 07877: loss did not improve from -176.72907\n",
      "Epoch 7878/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3953 - val_loss: -175.7066\n",
      "\n",
      "Epoch 07878: loss did not improve from -176.72907\n",
      "Epoch 7879/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5374 - val_loss: -175.7614\n",
      "\n",
      "Epoch 07879: loss did not improve from -176.72907\n",
      "Epoch 7880/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6139 - val_loss: -175.6958\n",
      "\n",
      "Epoch 07880: loss did not improve from -176.72907\n",
      "Epoch 7881/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3993 - val_loss: -175.4520\n",
      "\n",
      "Epoch 07881: loss did not improve from -176.72907\n",
      "Epoch 7882/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4627 - val_loss: -175.6164\n",
      "\n",
      "Epoch 07882: loss did not improve from -176.72907\n",
      "Epoch 7883/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4762 - val_loss: -175.5223\n",
      "\n",
      "Epoch 07883: loss did not improve from -176.72907\n",
      "Epoch 7884/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4056 - val_loss: -175.6015\n",
      "\n",
      "Epoch 07884: loss did not improve from -176.72907\n",
      "Epoch 7885/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2094 - val_loss: -175.5996\n",
      "\n",
      "Epoch 07885: loss did not improve from -176.72907\n",
      "Epoch 7886/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2692 - val_loss: -175.5604\n",
      "\n",
      "Epoch 07886: loss did not improve from -176.72907\n",
      "Epoch 7887/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3400 - val_loss: -175.6563\n",
      "\n",
      "Epoch 07887: loss did not improve from -176.72907\n",
      "Epoch 7888/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2240 - val_loss: -175.4741\n",
      "\n",
      "Epoch 07888: loss did not improve from -176.72907\n",
      "Epoch 7889/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0864 - val_loss: -175.6404\n",
      "\n",
      "Epoch 07889: loss did not improve from -176.72907\n",
      "Epoch 7890/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.0322 - val_loss: -175.1461\n",
      "\n",
      "Epoch 07890: loss did not improve from -176.72907\n",
      "Epoch 7891/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1322 - val_loss: -175.7424\n",
      "\n",
      "Epoch 07891: loss did not improve from -176.72907\n",
      "Epoch 7892/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2121 - val_loss: -175.4546\n",
      "\n",
      "Epoch 07892: loss did not improve from -176.72907\n",
      "Epoch 7893/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2686 - val_loss: -175.5704\n",
      "\n",
      "Epoch 07893: loss did not improve from -176.72907\n",
      "Epoch 7894/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5085 - val_loss: -175.6941\n",
      "\n",
      "Epoch 07894: loss did not improve from -176.72907\n",
      "Epoch 7895/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7845 - val_loss: -175.7887\n",
      "\n",
      "Epoch 07895: loss improved from -176.72907 to -176.78448, saving model to gendance.h5\n",
      "Epoch 7896/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2628 - val_loss: -175.6923\n",
      "\n",
      "Epoch 07896: loss did not improve from -176.78448\n",
      "Epoch 7897/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3470 - val_loss: -175.7117\n",
      "\n",
      "Epoch 07897: loss did not improve from -176.78448\n",
      "Epoch 7898/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5227 - val_loss: -175.5907\n",
      "\n",
      "Epoch 07898: loss did not improve from -176.78448\n",
      "Epoch 7899/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5531 - val_loss: -175.8075\n",
      "\n",
      "Epoch 07899: loss did not improve from -176.78448\n",
      "Epoch 7900/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5662 - val_loss: -175.7441\n",
      "\n",
      "Epoch 07900: loss did not improve from -176.78448\n",
      "Epoch 7901/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5651 - val_loss: -175.7094\n",
      "\n",
      "Epoch 07901: loss did not improve from -176.78448\n",
      "Epoch 7902/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4892 - val_loss: -175.6247\n",
      "\n",
      "Epoch 07902: loss did not improve from -176.78448\n",
      "Epoch 7903/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5806 - val_loss: -175.7073\n",
      "\n",
      "Epoch 07903: loss did not improve from -176.78448\n",
      "Epoch 7904/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3841 - val_loss: -175.6723\n",
      "\n",
      "Epoch 07904: loss did not improve from -176.78448\n",
      "Epoch 7905/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4009 - val_loss: -175.6100\n",
      "\n",
      "Epoch 07905: loss did not improve from -176.78448\n",
      "Epoch 7906/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4785 - val_loss: -175.7725\n",
      "\n",
      "Epoch 07906: loss did not improve from -176.78448\n",
      "Epoch 7907/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2640 - val_loss: -175.3957\n",
      "\n",
      "Epoch 07907: loss did not improve from -176.78448\n",
      "Epoch 7908/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5030 - val_loss: -175.8749\n",
      "\n",
      "Epoch 07908: loss did not improve from -176.78448\n",
      "Epoch 7909/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4797 - val_loss: -175.6007\n",
      "\n",
      "Epoch 07909: loss did not improve from -176.78448\n",
      "Epoch 7910/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3470 - val_loss: -175.8917\n",
      "\n",
      "Epoch 07910: loss did not improve from -176.78448\n",
      "Epoch 7911/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7576 - val_loss: -175.6353\n",
      "\n",
      "Epoch 07911: loss did not improve from -176.78448\n",
      "Epoch 7912/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3830 - val_loss: -175.6727\n",
      "\n",
      "Epoch 07912: loss did not improve from -176.78448\n",
      "Epoch 7913/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5139 - val_loss: -175.7501\n",
      "\n",
      "Epoch 07913: loss did not improve from -176.78448\n",
      "Epoch 7914/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4294 - val_loss: -175.6842\n",
      "\n",
      "Epoch 07914: loss did not improve from -176.78448\n",
      "Epoch 7915/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5079 - val_loss: -175.7602\n",
      "\n",
      "Epoch 07915: loss did not improve from -176.78448\n",
      "Epoch 7916/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -176.4281 - val_loss: -175.7478\n",
      "\n",
      "Epoch 07916: loss did not improve from -176.78448\n",
      "Epoch 7917/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5987 - val_loss: -175.7285\n",
      "\n",
      "Epoch 07917: loss did not improve from -176.78448\n",
      "Epoch 7918/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4668 - val_loss: -175.7040\n",
      "\n",
      "Epoch 07918: loss did not improve from -176.78448\n",
      "Epoch 7919/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4890 - val_loss: -175.6225\n",
      "\n",
      "Epoch 07919: loss did not improve from -176.78448\n",
      "Epoch 7920/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4427 - val_loss: -175.6063\n",
      "\n",
      "Epoch 07920: loss did not improve from -176.78448\n",
      "Epoch 7921/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5662 - val_loss: -175.7006\n",
      "\n",
      "Epoch 07921: loss did not improve from -176.78448\n",
      "Epoch 7922/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6055 - val_loss: -175.7200\n",
      "\n",
      "Epoch 07922: loss did not improve from -176.78448\n",
      "Epoch 7923/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4835 - val_loss: -175.7907\n",
      "\n",
      "Epoch 07923: loss did not improve from -176.78448\n",
      "Epoch 7924/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4887 - val_loss: -175.6913\n",
      "\n",
      "Epoch 07924: loss did not improve from -176.78448\n",
      "Epoch 7925/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5639 - val_loss: -175.7913\n",
      "\n",
      "Epoch 07925: loss did not improve from -176.78448\n",
      "Epoch 7926/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4441 - val_loss: -175.7435\n",
      "\n",
      "Epoch 07926: loss did not improve from -176.78448\n",
      "Epoch 7927/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5537 - val_loss: -175.7719\n",
      "\n",
      "Epoch 07927: loss did not improve from -176.78448\n",
      "Epoch 7928/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5453 - val_loss: -175.7586\n",
      "\n",
      "Epoch 07928: loss did not improve from -176.78448\n",
      "Epoch 7929/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5298 - val_loss: -175.7778\n",
      "\n",
      "Epoch 07929: loss did not improve from -176.78448\n",
      "Epoch 7930/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5401 - val_loss: -175.8328\n",
      "\n",
      "Epoch 07930: loss did not improve from -176.78448\n",
      "Epoch 7931/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5688 - val_loss: -175.6868\n",
      "\n",
      "Epoch 07931: loss did not improve from -176.78448\n",
      "Epoch 7932/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5458 - val_loss: -175.5675\n",
      "\n",
      "Epoch 07932: loss did not improve from -176.78448\n",
      "Epoch 7933/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4071 - val_loss: -175.8359\n",
      "\n",
      "Epoch 07933: loss did not improve from -176.78448\n",
      "Epoch 7934/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2021 - val_loss: -175.4145\n",
      "\n",
      "Epoch 07934: loss did not improve from -176.78448\n",
      "Epoch 7935/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3371 - val_loss: -175.7132\n",
      "\n",
      "Epoch 07935: loss did not improve from -176.78448\n",
      "Epoch 7936/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3237 - val_loss: -175.4071\n",
      "\n",
      "Epoch 07936: loss did not improve from -176.78448\n",
      "Epoch 7937/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6051 - val_loss: -175.7915\n",
      "\n",
      "Epoch 07937: loss did not improve from -176.78448\n",
      "Epoch 7938/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4958 - val_loss: -175.6636\n",
      "\n",
      "Epoch 07938: loss did not improve from -176.78448\n",
      "Epoch 7939/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -176.5399 - val_loss: -175.7507\n",
      "\n",
      "Epoch 07939: loss did not improve from -176.78448\n",
      "Epoch 7940/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -176.2954 - val_loss: -175.6246\n",
      "\n",
      "Epoch 07940: loss did not improve from -176.78448\n",
      "Epoch 7941/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1612 - val_loss: -175.5339\n",
      "\n",
      "Epoch 07941: loss did not improve from -176.78448\n",
      "Epoch 7942/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3964 - val_loss: -175.8487\n",
      "\n",
      "Epoch 07942: loss did not improve from -176.78448\n",
      "Epoch 7943/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1835 - val_loss: -175.4904\n",
      "\n",
      "Epoch 07943: loss did not improve from -176.78448\n",
      "Epoch 7944/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2628 - val_loss: -175.9280\n",
      "\n",
      "Epoch 07944: loss did not improve from -176.78448\n",
      "Epoch 7945/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.1452 - val_loss: -175.4700\n",
      "\n",
      "Epoch 07945: loss did not improve from -176.78448\n",
      "Epoch 7946/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3861 - val_loss: -175.8428\n",
      "\n",
      "Epoch 07946: loss did not improve from -176.78448\n",
      "Epoch 7947/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2481 - val_loss: -175.4422\n",
      "\n",
      "Epoch 07947: loss did not improve from -176.78448\n",
      "Epoch 7948/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5483 - val_loss: -175.7619\n",
      "\n",
      "Epoch 07948: loss did not improve from -176.78448\n",
      "Epoch 7949/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4570 - val_loss: -175.6820\n",
      "\n",
      "Epoch 07949: loss did not improve from -176.78448\n",
      "Epoch 7950/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4567 - val_loss: -175.8211\n",
      "\n",
      "Epoch 07950: loss did not improve from -176.78448\n",
      "Epoch 7951/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7086 - val_loss: -175.6841\n",
      "\n",
      "Epoch 07951: loss did not improve from -176.78448\n",
      "Epoch 7952/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4663 - val_loss: -175.6927\n",
      "\n",
      "Epoch 07952: loss did not improve from -176.78448\n",
      "Epoch 7953/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5873 - val_loss: -175.8189\n",
      "\n",
      "Epoch 07953: loss did not improve from -176.78448\n",
      "Epoch 7954/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3152 - val_loss: -175.7126\n",
      "\n",
      "Epoch 07954: loss did not improve from -176.78448\n",
      "Epoch 7955/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5344 - val_loss: -175.7138\n",
      "\n",
      "Epoch 07955: loss did not improve from -176.78448\n",
      "Epoch 7956/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3917 - val_loss: -175.6748\n",
      "\n",
      "Epoch 07956: loss did not improve from -176.78448\n",
      "Epoch 7957/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6610 - val_loss: -175.7036\n",
      "\n",
      "Epoch 07957: loss did not improve from -176.78448\n",
      "Epoch 7958/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3181 - val_loss: -175.6914\n",
      "\n",
      "Epoch 07958: loss did not improve from -176.78448\n",
      "Epoch 7959/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5867 - val_loss: -175.6068\n",
      "\n",
      "Epoch 07959: loss did not improve from -176.78448\n",
      "Epoch 7960/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2750 - val_loss: -175.7451\n",
      "\n",
      "Epoch 07960: loss did not improve from -176.78448\n",
      "Epoch 7961/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6887 - val_loss: -175.6814\n",
      "\n",
      "Epoch 07961: loss did not improve from -176.78448\n",
      "Epoch 7962/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5427 - val_loss: -175.7694\n",
      "\n",
      "Epoch 07962: loss did not improve from -176.78448\n",
      "Epoch 7963/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4795 - val_loss: -175.6617\n",
      "\n",
      "Epoch 07963: loss did not improve from -176.78448\n",
      "Epoch 7964/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6865 - val_loss: -175.7844\n",
      "\n",
      "Epoch 07964: loss did not improve from -176.78448\n",
      "Epoch 7965/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4678 - val_loss: -175.5932\n",
      "\n",
      "Epoch 07965: loss did not improve from -176.78448\n",
      "Epoch 7966/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4915 - val_loss: -175.7258\n",
      "\n",
      "Epoch 07966: loss did not improve from -176.78448\n",
      "Epoch 7967/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5133 - val_loss: -175.8902\n",
      "\n",
      "Epoch 07967: loss did not improve from -176.78448\n",
      "Epoch 7968/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6544 - val_loss: -175.7438\n",
      "\n",
      "Epoch 07968: loss did not improve from -176.78448\n",
      "Epoch 7969/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4806 - val_loss: -175.8373\n",
      "\n",
      "Epoch 07969: loss did not improve from -176.78448\n",
      "Epoch 7970/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4478 - val_loss: -175.5558\n",
      "\n",
      "Epoch 07970: loss did not improve from -176.78448\n",
      "Epoch 7971/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2900 - val_loss: -175.5842\n",
      "\n",
      "Epoch 07971: loss did not improve from -176.78448\n",
      "Epoch 7972/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5446 - val_loss: -175.7081\n",
      "\n",
      "Epoch 07972: loss did not improve from -176.78448\n",
      "Epoch 7973/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2672 - val_loss: -175.7542\n",
      "\n",
      "Epoch 07973: loss did not improve from -176.78448\n",
      "Epoch 7974/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4607 - val_loss: -175.6463\n",
      "\n",
      "Epoch 07974: loss did not improve from -176.78448\n",
      "Epoch 7975/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6343 - val_loss: -175.7370\n",
      "\n",
      "Epoch 07975: loss did not improve from -176.78448\n",
      "Epoch 7976/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3547 - val_loss: -175.5627\n",
      "\n",
      "Epoch 07976: loss did not improve from -176.78448\n",
      "Epoch 7977/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6362 - val_loss: -175.7261\n",
      "\n",
      "Epoch 07977: loss did not improve from -176.78448\n",
      "Epoch 7978/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5486 - val_loss: -175.7211\n",
      "\n",
      "Epoch 07978: loss did not improve from -176.78448\n",
      "Epoch 7979/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3082 - val_loss: -175.4970\n",
      "\n",
      "Epoch 07979: loss did not improve from -176.78448\n",
      "Epoch 7980/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3035 - val_loss: -175.7685\n",
      "\n",
      "Epoch 07980: loss did not improve from -176.78448\n",
      "Epoch 7981/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3858 - val_loss: -175.5884\n",
      "\n",
      "Epoch 07981: loss did not improve from -176.78448\n",
      "Epoch 7982/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5996 - val_loss: -175.8287\n",
      "\n",
      "Epoch 07982: loss did not improve from -176.78448\n",
      "Epoch 7983/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5996 - val_loss: -175.5458\n",
      "\n",
      "Epoch 07983: loss did not improve from -176.78448\n",
      "Epoch 7984/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6373 - val_loss: -175.8653\n",
      "\n",
      "Epoch 07984: loss did not improve from -176.78448\n",
      "Epoch 7985/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -176.4620 - val_loss: -175.4747\n",
      "\n",
      "Epoch 07985: loss did not improve from -176.78448\n",
      "Epoch 7986/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4131 - val_loss: -175.8218\n",
      "\n",
      "Epoch 07986: loss did not improve from -176.78448\n",
      "Epoch 7987/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5106 - val_loss: -175.5356\n",
      "\n",
      "Epoch 07987: loss did not improve from -176.78448\n",
      "Epoch 7988/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5955 - val_loss: -175.6276\n",
      "\n",
      "Epoch 07988: loss did not improve from -176.78448\n",
      "Epoch 7989/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4295 - val_loss: -175.6590\n",
      "\n",
      "Epoch 07989: loss did not improve from -176.78448\n",
      "Epoch 7990/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6938 - val_loss: -175.7709\n",
      "\n",
      "Epoch 07990: loss did not improve from -176.78448\n",
      "Epoch 7991/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5608 - val_loss: -175.7814\n",
      "\n",
      "Epoch 07991: loss did not improve from -176.78448\n",
      "Epoch 7992/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5749 - val_loss: -175.8141\n",
      "\n",
      "Epoch 07992: loss did not improve from -176.78448\n",
      "Epoch 7993/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5177 - val_loss: -175.7192\n",
      "\n",
      "Epoch 07993: loss did not improve from -176.78448\n",
      "Epoch 7994/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4401 - val_loss: -175.5937\n",
      "\n",
      "Epoch 07994: loss did not improve from -176.78448\n",
      "Epoch 7995/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -176.4371 - val_loss: -175.8438\n",
      "\n",
      "Epoch 07995: loss did not improve from -176.78448\n",
      "Epoch 7996/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3476 - val_loss: -175.3540\n",
      "\n",
      "Epoch 07996: loss did not improve from -176.78448\n",
      "Epoch 7997/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4976 - val_loss: -175.8118\n",
      "\n",
      "Epoch 07997: loss did not improve from -176.78448\n",
      "Epoch 7998/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4311 - val_loss: -175.4469\n",
      "\n",
      "Epoch 07998: loss did not improve from -176.78448\n",
      "Epoch 7999/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5332 - val_loss: -175.9010\n",
      "\n",
      "Epoch 07999: loss did not improve from -176.78448\n",
      "Epoch 8000/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6415 - val_loss: -175.7104\n",
      "\n",
      "Epoch 08000: loss did not improve from -176.78448\n",
      "Epoch 8001/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6102 - val_loss: -175.8728\n",
      "\n",
      "Epoch 08001: loss did not improve from -176.78448\n",
      "Epoch 8002/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6544 - val_loss: -175.8049\n",
      "\n",
      "Epoch 08002: loss did not improve from -176.78448\n",
      "Epoch 8003/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4492 - val_loss: -175.6652\n",
      "\n",
      "Epoch 08003: loss did not improve from -176.78448\n",
      "Epoch 8004/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4116 - val_loss: -175.7077\n",
      "\n",
      "Epoch 08004: loss did not improve from -176.78448\n",
      "Epoch 8005/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5544 - val_loss: -175.6007\n",
      "\n",
      "Epoch 08005: loss did not improve from -176.78448\n",
      "Epoch 8006/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -176.6444 - val_loss: -175.7796\n",
      "\n",
      "Epoch 08006: loss did not improve from -176.78448\n",
      "Epoch 8007/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4521 - val_loss: -175.7802\n",
      "\n",
      "Epoch 08007: loss did not improve from -176.78448\n",
      "Epoch 8008/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8063 - val_loss: -175.7736\n",
      "\n",
      "Epoch 08008: loss improved from -176.78448 to -176.80629, saving model to gendance.h5\n",
      "Epoch 8009/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5722 - val_loss: -175.7202\n",
      "\n",
      "Epoch 08009: loss did not improve from -176.80629\n",
      "Epoch 8010/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4161 - val_loss: -175.7258\n",
      "\n",
      "Epoch 08010: loss did not improve from -176.80629\n",
      "Epoch 8011/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2780 - val_loss: -175.7819\n",
      "\n",
      "Epoch 08011: loss did not improve from -176.80629\n",
      "Epoch 8012/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5638 - val_loss: -175.6487\n",
      "\n",
      "Epoch 08012: loss did not improve from -176.80629\n",
      "Epoch 8013/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5450 - val_loss: -175.6673\n",
      "\n",
      "Epoch 08013: loss did not improve from -176.80629\n",
      "Epoch 8014/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6755 - val_loss: -175.8186\n",
      "\n",
      "Epoch 08014: loss did not improve from -176.80629\n",
      "Epoch 8015/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5811 - val_loss: -175.7674\n",
      "\n",
      "Epoch 08015: loss did not improve from -176.80629\n",
      "Epoch 8016/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5989 - val_loss: -175.6993\n",
      "\n",
      "Epoch 08016: loss did not improve from -176.80629\n",
      "Epoch 8017/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4745 - val_loss: -175.6611\n",
      "\n",
      "Epoch 08017: loss did not improve from -176.80629\n",
      "Epoch 8018/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5774 - val_loss: -175.7521\n",
      "\n",
      "Epoch 08018: loss did not improve from -176.80629\n",
      "Epoch 8019/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5261 - val_loss: -175.6313\n",
      "\n",
      "Epoch 08019: loss did not improve from -176.80629\n",
      "Epoch 8020/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5280 - val_loss: -175.7701\n",
      "\n",
      "Epoch 08020: loss did not improve from -176.80629\n",
      "Epoch 8021/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4354 - val_loss: -175.4770\n",
      "\n",
      "Epoch 08021: loss did not improve from -176.80629\n",
      "Epoch 8022/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4622 - val_loss: -175.8589\n",
      "\n",
      "Epoch 08022: loss did not improve from -176.80629\n",
      "Epoch 8023/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3495 - val_loss: -175.3452\n",
      "\n",
      "Epoch 08023: loss did not improve from -176.80629\n",
      "Epoch 8024/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3406 - val_loss: -175.7369\n",
      "\n",
      "Epoch 08024: loss did not improve from -176.80629\n",
      "Epoch 8025/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -176.5087 - val_loss: -175.4474\n",
      "\n",
      "Epoch 08025: loss did not improve from -176.80629\n",
      "Epoch 8026/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5236 - val_loss: -175.8604\n",
      "\n",
      "Epoch 08026: loss did not improve from -176.80629\n",
      "Epoch 8027/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4502 - val_loss: -175.8113\n",
      "\n",
      "Epoch 08027: loss did not improve from -176.80629\n",
      "Epoch 8028/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5158 - val_loss: -175.6673\n",
      "\n",
      "Epoch 08028: loss did not improve from -176.80629\n",
      "Epoch 8029/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6277 - val_loss: -175.8317\n",
      "\n",
      "Epoch 08029: loss did not improve from -176.80629\n",
      "Epoch 8030/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6295 - val_loss: -175.7743\n",
      "\n",
      "Epoch 08030: loss did not improve from -176.80629\n",
      "Epoch 8031/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6365 - val_loss: -175.8688\n",
      "\n",
      "Epoch 08031: loss did not improve from -176.80629\n",
      "Epoch 8032/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6485 - val_loss: -175.8477\n",
      "\n",
      "Epoch 08032: loss did not improve from -176.80629\n",
      "Epoch 8033/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5670 - val_loss: -175.8963\n",
      "\n",
      "Epoch 08033: loss did not improve from -176.80629\n",
      "Epoch 8034/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5764 - val_loss: -175.6553\n",
      "\n",
      "Epoch 08034: loss did not improve from -176.80629\n",
      "Epoch 8035/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2829 - val_loss: -175.7425\n",
      "\n",
      "Epoch 08035: loss did not improve from -176.80629\n",
      "Epoch 8036/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5366 - val_loss: -175.7199\n",
      "\n",
      "Epoch 08036: loss did not improve from -176.80629\n",
      "Epoch 8037/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7033 - val_loss: -175.9109\n",
      "\n",
      "Epoch 08037: loss did not improve from -176.80629\n",
      "Epoch 8038/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6903 - val_loss: -175.7734\n",
      "\n",
      "Epoch 08038: loss did not improve from -176.80629\n",
      "Epoch 8039/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6996 - val_loss: -175.8231\n",
      "\n",
      "Epoch 08039: loss did not improve from -176.80629\n",
      "Epoch 8040/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5804 - val_loss: -175.8084\n",
      "\n",
      "Epoch 08040: loss did not improve from -176.80629\n",
      "Epoch 8041/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6120 - val_loss: -175.7979\n",
      "\n",
      "Epoch 08041: loss did not improve from -176.80629\n",
      "Epoch 8042/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4598 - val_loss: -175.6868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 08042: loss did not improve from -176.80629\n",
      "Epoch 8043/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4650 - val_loss: -175.7520\n",
      "\n",
      "Epoch 08043: loss did not improve from -176.80629\n",
      "Epoch 8044/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6464 - val_loss: -175.8385\n",
      "\n",
      "Epoch 08044: loss did not improve from -176.80629\n",
      "Epoch 8045/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4609 - val_loss: -175.6718\n",
      "\n",
      "Epoch 08045: loss did not improve from -176.80629\n",
      "Epoch 8046/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3680 - val_loss: -175.7728\n",
      "\n",
      "Epoch 08046: loss did not improve from -176.80629\n",
      "Epoch 8047/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4106 - val_loss: -175.6872\n",
      "\n",
      "Epoch 08047: loss did not improve from -176.80629\n",
      "Epoch 8048/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5539 - val_loss: -175.7678\n",
      "\n",
      "Epoch 08048: loss did not improve from -176.80629\n",
      "Epoch 8049/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5613 - val_loss: -175.6572\n",
      "\n",
      "Epoch 08049: loss did not improve from -176.80629\n",
      "Epoch 8050/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6483 - val_loss: -175.8240\n",
      "\n",
      "Epoch 08050: loss did not improve from -176.80629\n",
      "Epoch 8051/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5918 - val_loss: -175.6566\n",
      "\n",
      "Epoch 08051: loss did not improve from -176.80629\n",
      "Epoch 8052/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5852 - val_loss: -175.7584\n",
      "\n",
      "Epoch 08052: loss did not improve from -176.80629\n",
      "Epoch 8053/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5081 - val_loss: -175.6624\n",
      "\n",
      "Epoch 08053: loss did not improve from -176.80629\n",
      "Epoch 8054/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8406 - val_loss: -175.8353\n",
      "\n",
      "Epoch 08054: loss improved from -176.80629 to -176.84059, saving model to gendance.h5\n",
      "Epoch 8055/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -176.7049 - val_loss: -175.8016\n",
      "\n",
      "Epoch 08055: loss did not improve from -176.84059\n",
      "Epoch 8056/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7347 - val_loss: -175.8646\n",
      "\n",
      "Epoch 08056: loss did not improve from -176.84059\n",
      "Epoch 8057/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9425 - val_loss: -175.7023\n",
      "\n",
      "Epoch 08057: loss improved from -176.84059 to -176.94251, saving model to gendance.h5\n",
      "Epoch 8058/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4222 - val_loss: -175.7719\n",
      "\n",
      "Epoch 08058: loss did not improve from -176.94251\n",
      "Epoch 8059/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6331 - val_loss: -175.7701\n",
      "\n",
      "Epoch 08059: loss did not improve from -176.94251\n",
      "Epoch 8060/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5875 - val_loss: -175.7891\n",
      "\n",
      "Epoch 08060: loss did not improve from -176.94251\n",
      "Epoch 8061/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8247 - val_loss: -175.8031\n",
      "\n",
      "Epoch 08061: loss did not improve from -176.94251\n",
      "Epoch 8062/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7790 - val_loss: -175.7941\n",
      "\n",
      "Epoch 08062: loss did not improve from -176.94251\n",
      "Epoch 8063/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5795 - val_loss: -175.7149\n",
      "\n",
      "Epoch 08063: loss did not improve from -176.94251\n",
      "Epoch 8064/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5955 - val_loss: -175.6486\n",
      "\n",
      "Epoch 08064: loss did not improve from -176.94251\n",
      "Epoch 8065/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6028 - val_loss: -175.8138\n",
      "\n",
      "Epoch 08065: loss did not improve from -176.94251\n",
      "Epoch 8066/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -176.4080 - val_loss: -175.6318\n",
      "\n",
      "Epoch 08066: loss did not improve from -176.94251\n",
      "Epoch 8067/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8198 - val_loss: -175.8810\n",
      "\n",
      "Epoch 08067: loss did not improve from -176.94251\n",
      "Epoch 8068/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2178 - val_loss: -175.4765\n",
      "\n",
      "Epoch 08068: loss did not improve from -176.94251\n",
      "Epoch 8069/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.2635 - val_loss: -175.8706\n",
      "\n",
      "Epoch 08069: loss did not improve from -176.94251\n",
      "Epoch 8070/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3565 - val_loss: -175.3616\n",
      "\n",
      "Epoch 08070: loss did not improve from -176.94251\n",
      "Epoch 8071/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5821 - val_loss: -175.8643\n",
      "\n",
      "Epoch 08071: loss did not improve from -176.94251\n",
      "Epoch 8072/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6053 - val_loss: -175.4762\n",
      "\n",
      "Epoch 08072: loss did not improve from -176.94251\n",
      "Epoch 8073/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7329 - val_loss: -175.9321\n",
      "\n",
      "Epoch 08073: loss did not improve from -176.94251\n",
      "Epoch 8074/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6944 - val_loss: -175.5064\n",
      "\n",
      "Epoch 08074: loss did not improve from -176.94251\n",
      "Epoch 8075/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6275 - val_loss: -175.7159\n",
      "\n",
      "Epoch 08075: loss did not improve from -176.94251\n",
      "Epoch 8076/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6166 - val_loss: -175.6788\n",
      "\n",
      "Epoch 08076: loss did not improve from -176.94251\n",
      "Epoch 8077/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6351 - val_loss: -175.7871\n",
      "\n",
      "Epoch 08077: loss did not improve from -176.94251\n",
      "Epoch 8078/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4887 - val_loss: -175.7516\n",
      "\n",
      "Epoch 08078: loss did not improve from -176.94251\n",
      "Epoch 8079/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6081 - val_loss: -175.8004\n",
      "\n",
      "Epoch 08079: loss did not improve from -176.94251\n",
      "Epoch 8080/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5007 - val_loss: -175.7647\n",
      "\n",
      "Epoch 08080: loss did not improve from -176.94251\n",
      "Epoch 8081/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4832 - val_loss: -175.6716\n",
      "\n",
      "Epoch 08081: loss did not improve from -176.94251\n",
      "Epoch 8082/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7059 - val_loss: -175.9654\n",
      "\n",
      "Epoch 08082: loss did not improve from -176.94251\n",
      "Epoch 8083/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6221 - val_loss: -175.6946\n",
      "\n",
      "Epoch 08083: loss did not improve from -176.94251\n",
      "Epoch 8084/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6261 - val_loss: -175.8759\n",
      "\n",
      "Epoch 08084: loss did not improve from -176.94251\n",
      "Epoch 8085/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7606 - val_loss: -175.7654\n",
      "\n",
      "Epoch 08085: loss did not improve from -176.94251\n",
      "Epoch 8086/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7667 - val_loss: -175.9125\n",
      "\n",
      "Epoch 08086: loss did not improve from -176.94251\n",
      "Epoch 8087/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7206 - val_loss: -175.6603\n",
      "\n",
      "Epoch 08087: loss did not improve from -176.94251\n",
      "Epoch 8088/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6825 - val_loss: -175.9088\n",
      "\n",
      "Epoch 08088: loss did not improve from -176.94251\n",
      "Epoch 8089/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6162 - val_loss: -175.8333\n",
      "\n",
      "Epoch 08089: loss did not improve from -176.94251\n",
      "Epoch 8090/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5383 - val_loss: -175.7072\n",
      "\n",
      "Epoch 08090: loss did not improve from -176.94251\n",
      "Epoch 8091/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6782 - val_loss: -175.7916\n",
      "\n",
      "Epoch 08091: loss did not improve from -176.94251\n",
      "Epoch 8092/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7198 - val_loss: -175.7585\n",
      "\n",
      "Epoch 08092: loss did not improve from -176.94251\n",
      "Epoch 8093/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5638 - val_loss: -175.8355\n",
      "\n",
      "Epoch 08093: loss did not improve from -176.94251\n",
      "Epoch 8094/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5927 - val_loss: -175.8080\n",
      "\n",
      "Epoch 08094: loss did not improve from -176.94251\n",
      "Epoch 8095/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5447 - val_loss: -175.7322\n",
      "\n",
      "Epoch 08095: loss did not improve from -176.94251\n",
      "Epoch 8096/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6349 - val_loss: -175.9138\n",
      "\n",
      "Epoch 08096: loss did not improve from -176.94251\n",
      "Epoch 8097/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6648 - val_loss: -175.9746\n",
      "\n",
      "Epoch 08097: loss did not improve from -176.94251\n",
      "Epoch 8098/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7232 - val_loss: -175.7992\n",
      "\n",
      "Epoch 08098: loss did not improve from -176.94251\n",
      "Epoch 8099/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9128 - val_loss: -175.8592\n",
      "\n",
      "Epoch 08099: loss did not improve from -176.94251\n",
      "Epoch 8100/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5918 - val_loss: -175.8439\n",
      "\n",
      "Epoch 08100: loss did not improve from -176.94251\n",
      "Epoch 8101/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3739 - val_loss: -175.9251\n",
      "\n",
      "Epoch 08101: loss did not improve from -176.94251\n",
      "Epoch 8102/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7051 - val_loss: -175.6553\n",
      "\n",
      "Epoch 08102: loss did not improve from -176.94251\n",
      "Epoch 8103/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7200 - val_loss: -175.9688\n",
      "\n",
      "Epoch 08103: loss did not improve from -176.94251\n",
      "Epoch 8104/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5578 - val_loss: -175.4855\n",
      "\n",
      "Epoch 08104: loss did not improve from -176.94251\n",
      "Epoch 8105/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4455 - val_loss: -175.8358\n",
      "\n",
      "Epoch 08105: loss did not improve from -176.94251\n",
      "Epoch 8106/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7651 - val_loss: -175.6967\n",
      "\n",
      "Epoch 08106: loss did not improve from -176.94251\n",
      "Epoch 8107/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6719 - val_loss: -175.9283\n",
      "\n",
      "Epoch 08107: loss did not improve from -176.94251\n",
      "Epoch 8108/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6748 - val_loss: -175.7166\n",
      "\n",
      "Epoch 08108: loss did not improve from -176.94251\n",
      "Epoch 8109/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5449 - val_loss: -175.8591\n",
      "\n",
      "Epoch 08109: loss did not improve from -176.94251\n",
      "Epoch 8110/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6484 - val_loss: -175.7974\n",
      "\n",
      "Epoch 08110: loss did not improve from -176.94251\n",
      "Epoch 8111/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6209 - val_loss: -175.8911\n",
      "\n",
      "Epoch 08111: loss did not improve from -176.94251\n",
      "Epoch 8112/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3687 - val_loss: -175.6926\n",
      "\n",
      "Epoch 08112: loss did not improve from -176.94251\n",
      "Epoch 8113/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7544 - val_loss: -175.7977\n",
      "\n",
      "Epoch 08113: loss did not improve from -176.94251\n",
      "Epoch 8114/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6281 - val_loss: -175.8426\n",
      "\n",
      "Epoch 08114: loss did not improve from -176.94251\n",
      "Epoch 8115/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5275 - val_loss: -175.7089\n",
      "\n",
      "Epoch 08115: loss did not improve from -176.94251\n",
      "Epoch 8116/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7682 - val_loss: -175.9382\n",
      "\n",
      "Epoch 08116: loss did not improve from -176.94251\n",
      "Epoch 8117/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6246 - val_loss: -175.6913\n",
      "\n",
      "Epoch 08117: loss did not improve from -176.94251\n",
      "Epoch 8118/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6078 - val_loss: -175.8615\n",
      "\n",
      "Epoch 08118: loss did not improve from -176.94251\n",
      "Epoch 8119/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8412 - val_loss: -175.6493\n",
      "\n",
      "Epoch 08119: loss did not improve from -176.94251\n",
      "Epoch 8120/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4001 - val_loss: -175.6905\n",
      "\n",
      "Epoch 08120: loss did not improve from -176.94251\n",
      "Epoch 8121/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7219 - val_loss: -175.5819\n",
      "\n",
      "Epoch 08121: loss did not improve from -176.94251\n",
      "Epoch 8122/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8873 - val_loss: -175.9313\n",
      "\n",
      "Epoch 08122: loss did not improve from -176.94251\n",
      "Epoch 8123/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8111 - val_loss: -175.6528\n",
      "\n",
      "Epoch 08123: loss did not improve from -176.94251\n",
      "Epoch 8124/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5164 - val_loss: -175.9166\n",
      "\n",
      "Epoch 08124: loss did not improve from -176.94251\n",
      "Epoch 8125/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4110 - val_loss: -175.6840\n",
      "\n",
      "Epoch 08125: loss did not improve from -176.94251\n",
      "Epoch 8126/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8132 - val_loss: -175.8759\n",
      "\n",
      "Epoch 08126: loss did not improve from -176.94251\n",
      "Epoch 8127/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6643 - val_loss: -175.8006\n",
      "\n",
      "Epoch 08127: loss did not improve from -176.94251\n",
      "Epoch 8128/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6508 - val_loss: -175.8344\n",
      "\n",
      "Epoch 08128: loss did not improve from -176.94251\n",
      "Epoch 8129/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7748 - val_loss: -175.8565\n",
      "\n",
      "Epoch 08129: loss did not improve from -176.94251\n",
      "Epoch 8130/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8531 - val_loss: -175.7557\n",
      "\n",
      "Epoch 08130: loss did not improve from -176.94251\n",
      "Epoch 8131/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8583 - val_loss: -175.8456\n",
      "\n",
      "Epoch 08131: loss did not improve from -176.94251\n",
      "Epoch 8132/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4054 - val_loss: -175.7790\n",
      "\n",
      "Epoch 08132: loss did not improve from -176.94251\n",
      "Epoch 8133/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6569 - val_loss: -175.7682\n",
      "\n",
      "Epoch 08133: loss did not improve from -176.94251\n",
      "Epoch 8134/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7786 - val_loss: -175.9180\n",
      "\n",
      "Epoch 08134: loss did not improve from -176.94251\n",
      "Epoch 8135/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5518 - val_loss: -175.7397\n",
      "\n",
      "Epoch 08135: loss did not improve from -176.94251\n",
      "Epoch 8136/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7082 - val_loss: -175.8724\n",
      "\n",
      "Epoch 08136: loss did not improve from -176.94251\n",
      "Epoch 8137/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9618 - val_loss: -175.7221\n",
      "\n",
      "Epoch 08137: loss improved from -176.94251 to -176.96182, saving model to gendance.h5\n",
      "Epoch 8138/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7084 - val_loss: -175.9274\n",
      "\n",
      "Epoch 08138: loss did not improve from -176.96182\n",
      "Epoch 8139/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7047 - val_loss: -175.6431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 08139: loss did not improve from -176.96182\n",
      "Epoch 8140/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8016 - val_loss: -175.8527\n",
      "\n",
      "Epoch 08140: loss did not improve from -176.96182\n",
      "Epoch 8141/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6516 - val_loss: -175.8363\n",
      "\n",
      "Epoch 08141: loss did not improve from -176.96182\n",
      "Epoch 8142/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5353 - val_loss: -175.8913\n",
      "\n",
      "Epoch 08142: loss did not improve from -176.96182\n",
      "Epoch 8143/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6225 - val_loss: -175.8828\n",
      "\n",
      "Epoch 08143: loss did not improve from -176.96182\n",
      "Epoch 8144/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6012 - val_loss: -175.5306\n",
      "\n",
      "Epoch 08144: loss did not improve from -176.96182\n",
      "Epoch 8145/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8246 - val_loss: -175.7467\n",
      "\n",
      "Epoch 08145: loss did not improve from -176.96182\n",
      "Epoch 8146/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6414 - val_loss: -175.4547\n",
      "\n",
      "Epoch 08146: loss did not improve from -176.96182\n",
      "Epoch 8147/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5222 - val_loss: -175.8558\n",
      "\n",
      "Epoch 08147: loss did not improve from -176.96182\n",
      "Epoch 8148/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6786 - val_loss: -175.4512\n",
      "\n",
      "Epoch 08148: loss did not improve from -176.96182\n",
      "Epoch 8149/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7711 - val_loss: -175.8344\n",
      "\n",
      "Epoch 08149: loss did not improve from -176.96182\n",
      "Epoch 8150/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4710 - val_loss: -175.5170\n",
      "\n",
      "Epoch 08150: loss did not improve from -176.96182\n",
      "Epoch 8151/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5362 - val_loss: -175.8123\n",
      "\n",
      "Epoch 08151: loss did not improve from -176.96182\n",
      "Epoch 8152/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7992 - val_loss: -175.6255\n",
      "\n",
      "Epoch 08152: loss did not improve from -176.96182\n",
      "Epoch 8153/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -176.7693 - val_loss: -175.9380\n",
      "\n",
      "Epoch 08153: loss did not improve from -176.96182\n",
      "Epoch 8154/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8238 - val_loss: -175.8782\n",
      "\n",
      "Epoch 08154: loss did not improve from -176.96182\n",
      "Epoch 8155/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5841 - val_loss: -175.8062\n",
      "\n",
      "Epoch 08155: loss did not improve from -176.96182\n",
      "Epoch 8156/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7729 - val_loss: -175.9182\n",
      "\n",
      "Epoch 08156: loss did not improve from -176.96182\n",
      "Epoch 8157/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5305 - val_loss: -175.7464\n",
      "\n",
      "Epoch 08157: loss did not improve from -176.96182\n",
      "Epoch 8158/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7330 - val_loss: -175.9410\n",
      "\n",
      "Epoch 08158: loss did not improve from -176.96182\n",
      "Epoch 8159/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7494 - val_loss: -175.7874\n",
      "\n",
      "Epoch 08159: loss did not improve from -176.96182\n",
      "Epoch 8160/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9969 - val_loss: -175.9335\n",
      "\n",
      "Epoch 08160: loss improved from -176.96182 to -176.99685, saving model to gendance.h5\n",
      "Epoch 8161/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7673 - val_loss: -175.7246\n",
      "\n",
      "Epoch 08161: loss did not improve from -176.99685\n",
      "Epoch 8162/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7147 - val_loss: -175.9334\n",
      "\n",
      "Epoch 08162: loss did not improve from -176.99685\n",
      "Epoch 8163/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5181 - val_loss: -175.7620\n",
      "\n",
      "Epoch 08163: loss did not improve from -176.99685\n",
      "Epoch 8164/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5789 - val_loss: -175.8691\n",
      "\n",
      "Epoch 08164: loss did not improve from -176.99685\n",
      "Epoch 8165/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6949 - val_loss: -175.7857\n",
      "\n",
      "Epoch 08165: loss did not improve from -176.99685\n",
      "Epoch 8166/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7048 - val_loss: -175.8192\n",
      "\n",
      "Epoch 08166: loss did not improve from -176.99685\n",
      "Epoch 8167/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7317 - val_loss: -175.7132\n",
      "\n",
      "Epoch 08167: loss did not improve from -176.99685\n",
      "Epoch 8168/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6972 - val_loss: -175.8373\n",
      "\n",
      "Epoch 08168: loss did not improve from -176.99685\n",
      "Epoch 8169/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5390 - val_loss: -175.7693\n",
      "\n",
      "Epoch 08169: loss did not improve from -176.99685\n",
      "Epoch 8170/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8095 - val_loss: -175.8536\n",
      "\n",
      "Epoch 08170: loss did not improve from -176.99685\n",
      "Epoch 8171/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8289 - val_loss: -175.8435\n",
      "\n",
      "Epoch 08171: loss did not improve from -176.99685\n",
      "Epoch 8172/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7549 - val_loss: -175.9639\n",
      "\n",
      "Epoch 08172: loss did not improve from -176.99685\n",
      "Epoch 8173/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5948 - val_loss: -175.7949\n",
      "\n",
      "Epoch 08173: loss did not improve from -176.99685\n",
      "Epoch 8174/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6224 - val_loss: -175.6953\n",
      "\n",
      "Epoch 08174: loss did not improve from -176.99685\n",
      "Epoch 8175/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7500 - val_loss: -175.8243\n",
      "\n",
      "Epoch 08175: loss did not improve from -176.99685\n",
      "Epoch 8176/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4281 - val_loss: -175.6424\n",
      "\n",
      "Epoch 08176: loss did not improve from -176.99685\n",
      "Epoch 8177/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7364 - val_loss: -175.8689\n",
      "\n",
      "Epoch 08177: loss did not improve from -176.99685\n",
      "Epoch 8178/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7577 - val_loss: -175.9731\n",
      "\n",
      "Epoch 08178: loss did not improve from -176.99685\n",
      "Epoch 8179/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8644 - val_loss: -175.7735\n",
      "\n",
      "Epoch 08179: loss did not improve from -176.99685\n",
      "Epoch 8180/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7723 - val_loss: -175.9252\n",
      "\n",
      "Epoch 08180: loss did not improve from -176.99685\n",
      "Epoch 8181/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7971 - val_loss: -175.7598\n",
      "\n",
      "Epoch 08181: loss did not improve from -176.99685\n",
      "Epoch 8182/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -176.6333 - val_loss: -175.8546\n",
      "\n",
      "Epoch 08182: loss did not improve from -176.99685\n",
      "Epoch 8183/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -176.8079 - val_loss: -175.7994\n",
      "\n",
      "Epoch 08183: loss did not improve from -176.99685\n",
      "Epoch 8184/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6628 - val_loss: -176.0456\n",
      "\n",
      "Epoch 08184: loss did not improve from -176.99685\n",
      "Epoch 8185/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -176.5372 - val_loss: -175.6383\n",
      "\n",
      "Epoch 08185: loss did not improve from -176.99685\n",
      "Epoch 8186/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6702 - val_loss: -175.8768\n",
      "\n",
      "Epoch 08186: loss did not improve from -176.99685\n",
      "Epoch 8187/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -176.3875 - val_loss: -175.6076\n",
      "\n",
      "Epoch 08187: loss did not improve from -176.99685\n",
      "Epoch 8188/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6543 - val_loss: -175.9412\n",
      "\n",
      "Epoch 08188: loss did not improve from -176.99685\n",
      "Epoch 8189/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6449 - val_loss: -175.6749\n",
      "\n",
      "Epoch 08189: loss did not improve from -176.99685\n",
      "Epoch 8190/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6131 - val_loss: -175.9977\n",
      "\n",
      "Epoch 08190: loss did not improve from -176.99685\n",
      "Epoch 8191/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7579 - val_loss: -175.7762\n",
      "\n",
      "Epoch 08191: loss did not improve from -176.99685\n",
      "Epoch 8192/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7948 - val_loss: -175.9120\n",
      "\n",
      "Epoch 08192: loss did not improve from -176.99685\n",
      "Epoch 8193/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7339 - val_loss: -175.7495\n",
      "\n",
      "Epoch 08193: loss did not improve from -176.99685\n",
      "Epoch 8194/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7393 - val_loss: -176.0039\n",
      "\n",
      "Epoch 08194: loss did not improve from -176.99685\n",
      "Epoch 8195/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9342 - val_loss: -175.8198\n",
      "\n",
      "Epoch 08195: loss did not improve from -176.99685\n",
      "Epoch 8196/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7597 - val_loss: -175.9768\n",
      "\n",
      "Epoch 08196: loss did not improve from -176.99685\n",
      "Epoch 8197/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8592 - val_loss: -175.8390\n",
      "\n",
      "Epoch 08197: loss did not improve from -176.99685\n",
      "Epoch 8198/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5679 - val_loss: -175.6803\n",
      "\n",
      "Epoch 08198: loss did not improve from -176.99685\n",
      "Epoch 8199/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7468 - val_loss: -175.8603\n",
      "\n",
      "Epoch 08199: loss did not improve from -176.99685\n",
      "Epoch 8200/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8451 - val_loss: -175.8878\n",
      "\n",
      "Epoch 08200: loss did not improve from -176.99685\n",
      "Epoch 8201/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7570 - val_loss: -175.9319\n",
      "\n",
      "Epoch 08201: loss did not improve from -176.99685\n",
      "Epoch 8202/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8578 - val_loss: -175.9730\n",
      "\n",
      "Epoch 08202: loss did not improve from -176.99685\n",
      "Epoch 8203/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9457 - val_loss: -175.9423\n",
      "\n",
      "Epoch 08203: loss did not improve from -176.99685\n",
      "Epoch 8204/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6073 - val_loss: -175.8648\n",
      "\n",
      "Epoch 08204: loss did not improve from -176.99685\n",
      "Epoch 8205/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7172 - val_loss: -175.9945\n",
      "\n",
      "Epoch 08205: loss did not improve from -176.99685\n",
      "Epoch 8206/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7563 - val_loss: -175.8854\n",
      "\n",
      "Epoch 08206: loss did not improve from -176.99685\n",
      "Epoch 8207/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9622 - val_loss: -175.8457\n",
      "\n",
      "Epoch 08207: loss did not improve from -176.99685\n",
      "Epoch 8208/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6092 - val_loss: -175.8234\n",
      "\n",
      "Epoch 08208: loss did not improve from -176.99685\n",
      "Epoch 8209/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8288 - val_loss: -175.7708\n",
      "\n",
      "Epoch 08209: loss did not improve from -176.99685\n",
      "Epoch 8210/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7548 - val_loss: -175.9312\n",
      "\n",
      "Epoch 08210: loss did not improve from -176.99685\n",
      "Epoch 8211/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6613 - val_loss: -175.5855\n",
      "\n",
      "Epoch 08211: loss did not improve from -176.99685\n",
      "Epoch 8212/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6521 - val_loss: -175.7693\n",
      "\n",
      "Epoch 08212: loss did not improve from -176.99685\n",
      "Epoch 8213/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5084 - val_loss: -175.4783\n",
      "\n",
      "Epoch 08213: loss did not improve from -176.99685\n",
      "Epoch 8214/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7819 - val_loss: -175.8698\n",
      "\n",
      "Epoch 08214: loss did not improve from -176.99685\n",
      "Epoch 8215/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3565 - val_loss: -175.6624\n",
      "\n",
      "Epoch 08215: loss did not improve from -176.99685\n",
      "Epoch 8216/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.3894 - val_loss: -175.7184\n",
      "\n",
      "Epoch 08216: loss did not improve from -176.99685\n",
      "Epoch 8217/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.4335 - val_loss: -175.9148\n",
      "\n",
      "Epoch 08217: loss did not improve from -176.99685\n",
      "Epoch 8218/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5211 - val_loss: -175.5002\n",
      "\n",
      "Epoch 08218: loss did not improve from -176.99685\n",
      "Epoch 8219/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7093 - val_loss: -175.9787\n",
      "\n",
      "Epoch 08219: loss did not improve from -176.99685\n",
      "Epoch 8220/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7848 - val_loss: -175.5208\n",
      "\n",
      "Epoch 08220: loss did not improve from -176.99685\n",
      "Epoch 8221/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6391 - val_loss: -175.8681\n",
      "\n",
      "Epoch 08221: loss did not improve from -176.99685\n",
      "Epoch 8222/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7428 - val_loss: -175.7030\n",
      "\n",
      "Epoch 08222: loss did not improve from -176.99685\n",
      "Epoch 8223/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6452 - val_loss: -175.8472\n",
      "\n",
      "Epoch 08223: loss did not improve from -176.99685\n",
      "Epoch 8224/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6714 - val_loss: -175.9042\n",
      "\n",
      "Epoch 08224: loss did not improve from -176.99685\n",
      "Epoch 8225/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9151 - val_loss: -175.8990\n",
      "\n",
      "Epoch 08225: loss did not improve from -176.99685\n",
      "Epoch 8226/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8550 - val_loss: -175.9386\n",
      "\n",
      "Epoch 08226: loss did not improve from -176.99685\n",
      "Epoch 8227/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5741 - val_loss: -175.8225\n",
      "\n",
      "Epoch 08227: loss did not improve from -176.99685\n",
      "Epoch 8228/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9930 - val_loss: -175.9380\n",
      "\n",
      "Epoch 08228: loss did not improve from -176.99685\n",
      "Epoch 8229/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9382 - val_loss: -175.9296\n",
      "\n",
      "Epoch 08229: loss did not improve from -176.99685\n",
      "Epoch 8230/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0104 - val_loss: -176.0575\n",
      "\n",
      "Epoch 08230: loss improved from -176.99685 to -177.01044, saving model to gendance.h5\n",
      "Epoch 8231/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7319 - val_loss: -175.9117\n",
      "\n",
      "Epoch 08231: loss did not improve from -177.01044\n",
      "Epoch 8232/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8076 - val_loss: -175.9449\n",
      "\n",
      "Epoch 08232: loss did not improve from -177.01044\n",
      "Epoch 8233/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8064 - val_loss: -175.8049\n",
      "\n",
      "Epoch 08233: loss did not improve from -177.01044\n",
      "Epoch 8234/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0232 - val_loss: -175.9287\n",
      "\n",
      "Epoch 08234: loss improved from -177.01044 to -177.02324, saving model to gendance.h5\n",
      "Epoch 8235/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9766 - val_loss: -175.8918\n",
      "\n",
      "Epoch 08235: loss did not improve from -177.02324\n",
      "Epoch 8236/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7500 - val_loss: -175.7980\n",
      "\n",
      "Epoch 08236: loss did not improve from -177.02324\n",
      "Epoch 8237/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8232 - val_loss: -175.7337\n",
      "\n",
      "Epoch 08237: loss did not improve from -177.02324\n",
      "Epoch 8238/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7245 - val_loss: -175.9575\n",
      "\n",
      "Epoch 08238: loss did not improve from -177.02324\n",
      "Epoch 8239/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6893 - val_loss: -175.8856\n",
      "\n",
      "Epoch 08239: loss did not improve from -177.02324\n",
      "Epoch 8240/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6305 - val_loss: -175.8930\n",
      "\n",
      "Epoch 08240: loss did not improve from -177.02324\n",
      "Epoch 8241/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7856 - val_loss: -175.7546\n",
      "\n",
      "Epoch 08241: loss did not improve from -177.02324\n",
      "Epoch 8242/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8259 - val_loss: -175.9904\n",
      "\n",
      "Epoch 08242: loss did not improve from -177.02324\n",
      "Epoch 8243/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7913 - val_loss: -175.9527\n",
      "\n",
      "Epoch 08243: loss did not improve from -177.02324\n",
      "Epoch 8244/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6563 - val_loss: -175.7992\n",
      "\n",
      "Epoch 08244: loss did not improve from -177.02324\n",
      "Epoch 8245/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8380 - val_loss: -175.9350\n",
      "\n",
      "Epoch 08245: loss did not improve from -177.02324\n",
      "Epoch 8246/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8810 - val_loss: -175.7904\n",
      "\n",
      "Epoch 08246: loss did not improve from -177.02324\n",
      "Epoch 8247/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8489 - val_loss: -175.9322\n",
      "\n",
      "Epoch 08247: loss did not improve from -177.02324\n",
      "Epoch 8248/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7014 - val_loss: -175.7904\n",
      "\n",
      "Epoch 08248: loss did not improve from -177.02324\n",
      "Epoch 8249/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6481 - val_loss: -175.9863\n",
      "\n",
      "Epoch 08249: loss did not improve from -177.02324\n",
      "Epoch 8250/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9894 - val_loss: -175.8815\n",
      "\n",
      "Epoch 08250: loss did not improve from -177.02324\n",
      "Epoch 8251/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6003 - val_loss: -175.8266\n",
      "\n",
      "Epoch 08251: loss did not improve from -177.02324\n",
      "Epoch 8252/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -176.7438 - val_loss: -175.8243\n",
      "\n",
      "Epoch 08252: loss did not improve from -177.02324\n",
      "Epoch 8253/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9168 - val_loss: -175.9740\n",
      "\n",
      "Epoch 08253: loss did not improve from -177.02324\n",
      "Epoch 8254/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0922 - val_loss: -176.0067\n",
      "\n",
      "Epoch 08254: loss improved from -177.02324 to -177.09219, saving model to gendance.h5\n",
      "Epoch 8255/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6733 - val_loss: -175.7736\n",
      "\n",
      "Epoch 08255: loss did not improve from -177.09219\n",
      "Epoch 8256/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7587 - val_loss: -176.0165\n",
      "\n",
      "Epoch 08256: loss did not improve from -177.09219\n",
      "Epoch 8257/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7331 - val_loss: -175.9054\n",
      "\n",
      "Epoch 08257: loss did not improve from -177.09219\n",
      "Epoch 8258/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7673 - val_loss: -175.9339\n",
      "\n",
      "Epoch 08258: loss did not improve from -177.09219\n",
      "Epoch 8259/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8369 - val_loss: -176.0095\n",
      "\n",
      "Epoch 08259: loss did not improve from -177.09219\n",
      "Epoch 8260/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8060 - val_loss: -175.8660\n",
      "\n",
      "Epoch 08260: loss did not improve from -177.09219\n",
      "Epoch 8261/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0485 - val_loss: -175.8680\n",
      "\n",
      "Epoch 08261: loss did not improve from -177.09219\n",
      "Epoch 8262/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7225 - val_loss: -175.9439\n",
      "\n",
      "Epoch 08262: loss did not improve from -177.09219\n",
      "Epoch 8263/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8255 - val_loss: -175.7753\n",
      "\n",
      "Epoch 08263: loss did not improve from -177.09219\n",
      "Epoch 8264/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8063 - val_loss: -176.0835\n",
      "\n",
      "Epoch 08264: loss did not improve from -177.09219\n",
      "Epoch 8265/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6083 - val_loss: -175.5323\n",
      "\n",
      "Epoch 08265: loss did not improve from -177.09219\n",
      "Epoch 8266/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6160 - val_loss: -176.0081\n",
      "\n",
      "Epoch 08266: loss did not improve from -177.09219\n",
      "Epoch 8267/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5252 - val_loss: -175.4129\n",
      "\n",
      "Epoch 08267: loss did not improve from -177.09219\n",
      "Epoch 8268/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8201 - val_loss: -176.0065\n",
      "\n",
      "Epoch 08268: loss did not improve from -177.09219\n",
      "Epoch 8269/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9037 - val_loss: -175.8409\n",
      "\n",
      "Epoch 08269: loss did not improve from -177.09219\n",
      "Epoch 8270/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8544 - val_loss: -175.9541\n",
      "\n",
      "Epoch 08270: loss did not improve from -177.09219\n",
      "Epoch 8271/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7869 - val_loss: -175.8343\n",
      "\n",
      "Epoch 08271: loss did not improve from -177.09219\n",
      "Epoch 8272/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7551 - val_loss: -175.8676\n",
      "\n",
      "Epoch 08272: loss did not improve from -177.09219\n",
      "Epoch 8273/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7234 - val_loss: -175.9028\n",
      "\n",
      "Epoch 08273: loss did not improve from -177.09219\n",
      "Epoch 8274/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7549 - val_loss: -175.8696\n",
      "\n",
      "Epoch 08274: loss did not improve from -177.09219\n",
      "Epoch 8275/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8220 - val_loss: -176.1113\n",
      "\n",
      "Epoch 08275: loss did not improve from -177.09219\n",
      "Epoch 8276/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9555 - val_loss: -175.9957\n",
      "\n",
      "Epoch 08276: loss did not improve from -177.09219\n",
      "Epoch 8277/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8783 - val_loss: -175.9489\n",
      "\n",
      "Epoch 08277: loss did not improve from -177.09219\n",
      "Epoch 8278/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9693 - val_loss: -175.9440\n",
      "\n",
      "Epoch 08278: loss did not improve from -177.09219\n",
      "Epoch 8279/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7176 - val_loss: -175.9086\n",
      "\n",
      "Epoch 08279: loss did not improve from -177.09219\n",
      "Epoch 8280/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1213 - val_loss: -175.9214\n",
      "\n",
      "Epoch 08280: loss improved from -177.09219 to -177.12134, saving model to gendance.h5\n",
      "Epoch 8281/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6207 - val_loss: -175.9699\n",
      "\n",
      "Epoch 08281: loss did not improve from -177.12134\n",
      "Epoch 8282/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7927 - val_loss: -175.9604\n",
      "\n",
      "Epoch 08282: loss did not improve from -177.12134\n",
      "Epoch 8283/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9157 - val_loss: -175.9933\n",
      "\n",
      "Epoch 08283: loss did not improve from -177.12134\n",
      "Epoch 8284/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7587 - val_loss: -175.8602\n",
      "\n",
      "Epoch 08284: loss did not improve from -177.12134\n",
      "Epoch 8285/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7211 - val_loss: -175.9109\n",
      "\n",
      "Epoch 08285: loss did not improve from -177.12134\n",
      "Epoch 8286/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9021 - val_loss: -175.9499\n",
      "\n",
      "Epoch 08286: loss did not improve from -177.12134\n",
      "Epoch 8287/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9371 - val_loss: -175.8866\n",
      "\n",
      "Epoch 08287: loss did not improve from -177.12134\n",
      "Epoch 8288/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8739 - val_loss: -175.9131\n",
      "\n",
      "Epoch 08288: loss did not improve from -177.12134\n",
      "Epoch 8289/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8466 - val_loss: -175.9790\n",
      "\n",
      "Epoch 08289: loss did not improve from -177.12134\n",
      "Epoch 8290/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7536 - val_loss: -175.8845\n",
      "\n",
      "Epoch 08290: loss did not improve from -177.12134\n",
      "Epoch 8291/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7622 - val_loss: -175.9739\n",
      "\n",
      "Epoch 08291: loss did not improve from -177.12134\n",
      "Epoch 8292/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0766 - val_loss: -175.9975\n",
      "\n",
      "Epoch 08292: loss did not improve from -177.12134\n",
      "Epoch 8293/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7514 - val_loss: -175.8421\n",
      "\n",
      "Epoch 08293: loss did not improve from -177.12134\n",
      "Epoch 8294/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6868 - val_loss: -175.9387\n",
      "\n",
      "Epoch 08294: loss did not improve from -177.12134\n",
      "Epoch 8295/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7862 - val_loss: -175.8200\n",
      "\n",
      "Epoch 08295: loss did not improve from -177.12134\n",
      "Epoch 8296/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8468 - val_loss: -175.9317\n",
      "\n",
      "Epoch 08296: loss did not improve from -177.12134\n",
      "Epoch 8297/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8887 - val_loss: -175.6087\n",
      "\n",
      "Epoch 08297: loss did not improve from -177.12134\n",
      "Epoch 8298/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8898 - val_loss: -176.0343\n",
      "\n",
      "Epoch 08298: loss did not improve from -177.12134\n",
      "Epoch 8299/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5301 - val_loss: -175.5069\n",
      "\n",
      "Epoch 08299: loss did not improve from -177.12134\n",
      "Epoch 8300/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6074 - val_loss: -175.9972\n",
      "\n",
      "Epoch 08300: loss did not improve from -177.12134\n",
      "Epoch 8301/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7409 - val_loss: -175.6846\n",
      "\n",
      "Epoch 08301: loss did not improve from -177.12134\n",
      "Epoch 8302/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7003 - val_loss: -175.9523\n",
      "\n",
      "Epoch 08302: loss did not improve from -177.12134\n",
      "Epoch 8303/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9016 - val_loss: -175.8793\n",
      "\n",
      "Epoch 08303: loss did not improve from -177.12134\n",
      "Epoch 8304/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9018 - val_loss: -175.9299\n",
      "\n",
      "Epoch 08304: loss did not improve from -177.12134\n",
      "Epoch 8305/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9602 - val_loss: -175.9492\n",
      "\n",
      "Epoch 08305: loss did not improve from -177.12134\n",
      "Epoch 8306/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8560 - val_loss: -175.9171\n",
      "\n",
      "Epoch 08306: loss did not improve from -177.12134\n",
      "Epoch 8307/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6758 - val_loss: -176.0212\n",
      "\n",
      "Epoch 08307: loss did not improve from -177.12134\n",
      "Epoch 8308/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8031 - val_loss: -175.8808\n",
      "\n",
      "Epoch 08308: loss did not improve from -177.12134\n",
      "Epoch 8309/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8101 - val_loss: -176.0160\n",
      "\n",
      "Epoch 08309: loss did not improve from -177.12134\n",
      "Epoch 8310/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8897 - val_loss: -175.7149\n",
      "\n",
      "Epoch 08310: loss did not improve from -177.12134\n",
      "Epoch 8311/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -176.6936 - val_loss: -175.9444\n",
      "\n",
      "Epoch 08311: loss did not improve from -177.12134\n",
      "Epoch 8312/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8042 - val_loss: -175.7557\n",
      "\n",
      "Epoch 08312: loss did not improve from -177.12134\n",
      "Epoch 8313/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7533 - val_loss: -175.8679\n",
      "\n",
      "Epoch 08313: loss did not improve from -177.12134\n",
      "Epoch 8314/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6955 - val_loss: -175.8437\n",
      "\n",
      "Epoch 08314: loss did not improve from -177.12134\n",
      "Epoch 8315/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9236 - val_loss: -175.9934\n",
      "\n",
      "Epoch 08315: loss did not improve from -177.12134\n",
      "Epoch 8316/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6207 - val_loss: -175.6080\n",
      "\n",
      "Epoch 08316: loss did not improve from -177.12134\n",
      "Epoch 8317/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0231 - val_loss: -175.9772\n",
      "\n",
      "Epoch 08317: loss did not improve from -177.12134\n",
      "Epoch 8318/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -176.6881 - val_loss: -175.7471\n",
      "\n",
      "Epoch 08318: loss did not improve from -177.12134\n",
      "Epoch 8319/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7232 - val_loss: -175.8444\n",
      "\n",
      "Epoch 08319: loss did not improve from -177.12134\n",
      "Epoch 8320/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8323 - val_loss: -175.8798\n",
      "\n",
      "Epoch 08320: loss did not improve from -177.12134\n",
      "Epoch 8321/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8383 - val_loss: -175.9467\n",
      "\n",
      "Epoch 08321: loss did not improve from -177.12134\n",
      "Epoch 8322/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7626 - val_loss: -175.9465\n",
      "\n",
      "Epoch 08322: loss did not improve from -177.12134\n",
      "Epoch 8323/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9899 - val_loss: -175.6951\n",
      "\n",
      "Epoch 08323: loss did not improve from -177.12134\n",
      "Epoch 8324/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6642 - val_loss: -175.8968\n",
      "\n",
      "Epoch 08324: loss did not improve from -177.12134\n",
      "Epoch 8325/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6823 - val_loss: -175.8607\n",
      "\n",
      "Epoch 08325: loss did not improve from -177.12134\n",
      "Epoch 8326/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0898 - val_loss: -175.9859\n",
      "\n",
      "Epoch 08326: loss did not improve from -177.12134\n",
      "Epoch 8327/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8981 - val_loss: -175.9376\n",
      "\n",
      "Epoch 08327: loss did not improve from -177.12134\n",
      "Epoch 8328/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -176.9014 - val_loss: -175.8606\n",
      "\n",
      "Epoch 08328: loss did not improve from -177.12134\n",
      "Epoch 8329/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -176.8246 - val_loss: -175.9169\n",
      "\n",
      "Epoch 08329: loss did not improve from -177.12134\n",
      "Epoch 8330/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9265 - val_loss: -175.9961\n",
      "\n",
      "Epoch 08330: loss did not improve from -177.12134\n",
      "Epoch 8331/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7882 - val_loss: -175.9846\n",
      "\n",
      "Epoch 08331: loss did not improve from -177.12134\n",
      "Epoch 8332/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9364 - val_loss: -175.8816\n",
      "\n",
      "Epoch 08332: loss did not improve from -177.12134\n",
      "Epoch 8333/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9780 - val_loss: -176.0457\n",
      "\n",
      "Epoch 08333: loss did not improve from -177.12134\n",
      "Epoch 8334/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8710 - val_loss: -175.9103\n",
      "\n",
      "Epoch 08334: loss did not improve from -177.12134\n",
      "Epoch 8335/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7942 - val_loss: -175.9494\n",
      "\n",
      "Epoch 08335: loss did not improve from -177.12134\n",
      "Epoch 8336/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0809 - val_loss: -176.0667\n",
      "\n",
      "Epoch 08336: loss did not improve from -177.12134\n",
      "Epoch 8337/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9919 - val_loss: -176.0260\n",
      "\n",
      "Epoch 08337: loss did not improve from -177.12134\n",
      "Epoch 8338/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7940 - val_loss: -175.8146\n",
      "\n",
      "Epoch 08338: loss did not improve from -177.12134\n",
      "Epoch 8339/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8134 - val_loss: -176.0218\n",
      "\n",
      "Epoch 08339: loss did not improve from -177.12134\n",
      "Epoch 8340/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7100 - val_loss: -175.7782\n",
      "\n",
      "Epoch 08340: loss did not improve from -177.12134\n",
      "Epoch 8341/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9457 - val_loss: -175.9500\n",
      "\n",
      "Epoch 08341: loss did not improve from -177.12134\n",
      "Epoch 8342/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8731 - val_loss: -175.7674\n",
      "\n",
      "Epoch 08342: loss did not improve from -177.12134\n",
      "Epoch 8343/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8465 - val_loss: -176.0902\n",
      "\n",
      "Epoch 08343: loss did not improve from -177.12134\n",
      "Epoch 8344/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7500 - val_loss: -175.9670\n",
      "\n",
      "Epoch 08344: loss did not improve from -177.12134\n",
      "Epoch 8345/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8206 - val_loss: -175.9750\n",
      "\n",
      "Epoch 08345: loss did not improve from -177.12134\n",
      "Epoch 8346/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9501 - val_loss: -175.9831\n",
      "\n",
      "Epoch 08346: loss did not improve from -177.12134\n",
      "Epoch 8347/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9087 - val_loss: -176.0281\n",
      "\n",
      "Epoch 08347: loss did not improve from -177.12134\n",
      "Epoch 8348/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7722 - val_loss: -175.8599\n",
      "\n",
      "Epoch 08348: loss did not improve from -177.12134\n",
      "Epoch 8349/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8205 - val_loss: -176.0350\n",
      "\n",
      "Epoch 08349: loss did not improve from -177.12134\n",
      "Epoch 8350/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8921 - val_loss: -175.8273\n",
      "\n",
      "Epoch 08350: loss did not improve from -177.12134\n",
      "Epoch 8351/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0224 - val_loss: -176.0328\n",
      "\n",
      "Epoch 08351: loss did not improve from -177.12134\n",
      "Epoch 8352/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9109 - val_loss: -175.9279\n",
      "\n",
      "Epoch 08352: loss did not improve from -177.12134\n",
      "Epoch 8353/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8769 - val_loss: -175.9049\n",
      "\n",
      "Epoch 08353: loss did not improve from -177.12134\n",
      "Epoch 8354/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9246 - val_loss: -175.9990\n",
      "\n",
      "Epoch 08354: loss did not improve from -177.12134\n",
      "Epoch 8355/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7453 - val_loss: -175.6890\n",
      "\n",
      "Epoch 08355: loss did not improve from -177.12134\n",
      "Epoch 8356/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8218 - val_loss: -176.0174\n",
      "\n",
      "Epoch 08356: loss did not improve from -177.12134\n",
      "Epoch 8357/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6731 - val_loss: -175.5270\n",
      "\n",
      "Epoch 08357: loss did not improve from -177.12134\n",
      "Epoch 8358/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8282 - val_loss: -176.0089\n",
      "\n",
      "Epoch 08358: loss did not improve from -177.12134\n",
      "Epoch 8359/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8467 - val_loss: -175.6980\n",
      "\n",
      "Epoch 08359: loss did not improve from -177.12134\n",
      "Epoch 8360/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7787 - val_loss: -175.8727\n",
      "\n",
      "Epoch 08360: loss did not improve from -177.12134\n",
      "Epoch 8361/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8172 - val_loss: -175.5908\n",
      "\n",
      "Epoch 08361: loss did not improve from -177.12134\n",
      "Epoch 8362/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8730 - val_loss: -176.0014\n",
      "\n",
      "Epoch 08362: loss did not improve from -177.12134\n",
      "Epoch 8363/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0521 - val_loss: -175.8606\n",
      "\n",
      "Epoch 08363: loss did not improve from -177.12134\n",
      "Epoch 8364/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0222 - val_loss: -175.9696\n",
      "\n",
      "Epoch 08364: loss did not improve from -177.12134\n",
      "Epoch 8365/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0303 - val_loss: -176.1355\n",
      "\n",
      "Epoch 08365: loss did not improve from -177.12134\n",
      "Epoch 8366/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0335 - val_loss: -175.9407\n",
      "\n",
      "Epoch 08366: loss did not improve from -177.12134\n",
      "Epoch 8367/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1078 - val_loss: -176.0653\n",
      "\n",
      "Epoch 08367: loss did not improve from -177.12134\n",
      "Epoch 8368/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9321 - val_loss: -175.9074\n",
      "\n",
      "Epoch 08368: loss did not improve from -177.12134\n",
      "Epoch 8369/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8206 - val_loss: -175.9765\n",
      "\n",
      "Epoch 08369: loss did not improve from -177.12134\n",
      "Epoch 8370/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9571 - val_loss: -175.9539\n",
      "\n",
      "Epoch 08370: loss did not improve from -177.12134\n",
      "Epoch 8371/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1875 - val_loss: -176.0840\n",
      "\n",
      "Epoch 08371: loss improved from -177.12134 to -177.18747, saving model to gendance.h5\n",
      "Epoch 8372/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -176.9125 - val_loss: -175.8755\n",
      "\n",
      "Epoch 08372: loss did not improve from -177.18747\n",
      "Epoch 8373/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -176.8410 - val_loss: -176.0835\n",
      "\n",
      "Epoch 08373: loss did not improve from -177.18747\n",
      "Epoch 8374/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1113 - val_loss: -175.9189\n",
      "\n",
      "Epoch 08374: loss did not improve from -177.18747\n",
      "Epoch 8375/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8647 - val_loss: -176.0367\n",
      "\n",
      "Epoch 08375: loss did not improve from -177.18747\n",
      "Epoch 8376/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0439 - val_loss: -175.9056\n",
      "\n",
      "Epoch 08376: loss did not improve from -177.18747\n",
      "Epoch 8377/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8459 - val_loss: -175.9853\n",
      "\n",
      "Epoch 08377: loss did not improve from -177.18747\n",
      "Epoch 8378/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8287 - val_loss: -175.7461\n",
      "\n",
      "Epoch 08378: loss did not improve from -177.18747\n",
      "Epoch 8379/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7379 - val_loss: -176.0247\n",
      "\n",
      "Epoch 08379: loss did not improve from -177.18747\n",
      "Epoch 8380/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8990 - val_loss: -175.7106\n",
      "\n",
      "Epoch 08380: loss did not improve from -177.18747\n",
      "Epoch 8381/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0498 - val_loss: -176.0172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 08381: loss did not improve from -177.18747\n",
      "Epoch 8382/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8931 - val_loss: -175.6774\n",
      "\n",
      "Epoch 08382: loss did not improve from -177.18747\n",
      "Epoch 8383/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9524 - val_loss: -175.9874\n",
      "\n",
      "Epoch 08383: loss did not improve from -177.18747\n",
      "Epoch 8384/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8413 - val_loss: -175.8152\n",
      "\n",
      "Epoch 08384: loss did not improve from -177.18747\n",
      "Epoch 8385/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9392 - val_loss: -176.1027\n",
      "\n",
      "Epoch 08385: loss did not improve from -177.18747\n",
      "Epoch 8386/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8251 - val_loss: -175.7981\n",
      "\n",
      "Epoch 08386: loss did not improve from -177.18747\n",
      "Epoch 8387/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2032 - val_loss: -176.1312\n",
      "\n",
      "Epoch 08387: loss improved from -177.18747 to -177.20319, saving model to gendance.h5\n",
      "Epoch 8388/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9741 - val_loss: -175.8707\n",
      "\n",
      "Epoch 08388: loss did not improve from -177.20319\n",
      "Epoch 8389/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8930 - val_loss: -176.0345\n",
      "\n",
      "Epoch 08389: loss did not improve from -177.20319\n",
      "Epoch 8390/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7888 - val_loss: -175.8565\n",
      "\n",
      "Epoch 08390: loss did not improve from -177.20319\n",
      "Epoch 8391/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0376 - val_loss: -175.9457\n",
      "\n",
      "Epoch 08391: loss did not improve from -177.20319\n",
      "Epoch 8392/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6148 - val_loss: -175.9944\n",
      "\n",
      "Epoch 08392: loss did not improve from -177.20319\n",
      "Epoch 8393/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9252 - val_loss: -175.9251\n",
      "\n",
      "Epoch 08393: loss did not improve from -177.20319\n",
      "Epoch 8394/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8743 - val_loss: -176.0494\n",
      "\n",
      "Epoch 08394: loss did not improve from -177.20319\n",
      "Epoch 8395/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0425 - val_loss: -175.8775\n",
      "\n",
      "Epoch 08395: loss did not improve from -177.20319\n",
      "Epoch 8396/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9011 - val_loss: -176.0797\n",
      "\n",
      "Epoch 08396: loss did not improve from -177.20319\n",
      "Epoch 8397/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9381 - val_loss: -175.9273\n",
      "\n",
      "Epoch 08397: loss did not improve from -177.20319\n",
      "Epoch 8398/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5287 - val_loss: -176.0960\n",
      "\n",
      "Epoch 08398: loss did not improve from -177.20319\n",
      "Epoch 8399/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7886 - val_loss: -175.6318\n",
      "\n",
      "Epoch 08399: loss did not improve from -177.20319\n",
      "Epoch 8400/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9659 - val_loss: -176.0672\n",
      "\n",
      "Epoch 08400: loss did not improve from -177.20319\n",
      "Epoch 8401/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8418 - val_loss: -175.9286\n",
      "\n",
      "Epoch 08401: loss did not improve from -177.20319\n",
      "Epoch 8402/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -176.8830 - val_loss: -176.0612\n",
      "\n",
      "Epoch 08402: loss did not improve from -177.20319\n",
      "Epoch 8403/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0010 - val_loss: -175.9854\n",
      "\n",
      "Epoch 08403: loss did not improve from -177.20319\n",
      "Epoch 8404/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8874 - val_loss: -176.0932\n",
      "\n",
      "Epoch 08404: loss did not improve from -177.20319\n",
      "Epoch 8405/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -176.9306 - val_loss: -175.9818\n",
      "\n",
      "Epoch 08405: loss did not improve from -177.20319\n",
      "Epoch 8406/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9748 - val_loss: -175.9884\n",
      "\n",
      "Epoch 08406: loss did not improve from -177.20319\n",
      "Epoch 8407/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0525 - val_loss: -176.0680\n",
      "\n",
      "Epoch 08407: loss did not improve from -177.20319\n",
      "Epoch 8408/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9539 - val_loss: -176.2022\n",
      "\n",
      "Epoch 08408: loss did not improve from -177.20319\n",
      "Epoch 8409/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1675 - val_loss: -175.9645\n",
      "\n",
      "Epoch 08409: loss did not improve from -177.20319\n",
      "Epoch 8410/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9077 - val_loss: -176.1405\n",
      "\n",
      "Epoch 08410: loss did not improve from -177.20319\n",
      "Epoch 8411/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9421 - val_loss: -176.0141\n",
      "\n",
      "Epoch 08411: loss did not improve from -177.20319\n",
      "Epoch 8412/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7622 - val_loss: -176.0032\n",
      "\n",
      "Epoch 08412: loss did not improve from -177.20319\n",
      "Epoch 8413/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8106 - val_loss: -175.8075\n",
      "\n",
      "Epoch 08413: loss did not improve from -177.20319\n",
      "Epoch 8414/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7882 - val_loss: -176.1529\n",
      "\n",
      "Epoch 08414: loss did not improve from -177.20319\n",
      "Epoch 8415/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9903 - val_loss: -176.0575\n",
      "\n",
      "Epoch 08415: loss did not improve from -177.20319\n",
      "Epoch 8416/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0071 - val_loss: -176.0252\n",
      "\n",
      "Epoch 08416: loss did not improve from -177.20319\n",
      "Epoch 8417/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9634 - val_loss: -175.8943\n",
      "\n",
      "Epoch 08417: loss did not improve from -177.20319\n",
      "Epoch 8418/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7149 - val_loss: -176.0153\n",
      "\n",
      "Epoch 08418: loss did not improve from -177.20319\n",
      "Epoch 8419/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8114 - val_loss: -176.0106\n",
      "\n",
      "Epoch 08419: loss did not improve from -177.20319\n",
      "Epoch 8420/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0194 - val_loss: -176.0363\n",
      "\n",
      "Epoch 08420: loss did not improve from -177.20319\n",
      "Epoch 8421/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9022 - val_loss: -176.1167\n",
      "\n",
      "Epoch 08421: loss did not improve from -177.20319\n",
      "Epoch 8422/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.6739 - val_loss: -175.7135\n",
      "\n",
      "Epoch 08422: loss did not improve from -177.20319\n",
      "Epoch 8423/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8587 - val_loss: -176.1876\n",
      "\n",
      "Epoch 08423: loss did not improve from -177.20319\n",
      "Epoch 8424/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8130 - val_loss: -175.6916\n",
      "\n",
      "Epoch 08424: loss did not improve from -177.20319\n",
      "Epoch 8425/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8725 - val_loss: -176.1193\n",
      "\n",
      "Epoch 08425: loss did not improve from -177.20319\n",
      "Epoch 8426/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -177.2363 - val_loss: -175.8794\n",
      "\n",
      "Epoch 08426: loss improved from -177.20319 to -177.23628, saving model to gendance.h5\n",
      "Epoch 8427/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8008 - val_loss: -176.0273\n",
      "\n",
      "Epoch 08427: loss did not improve from -177.23628\n",
      "Epoch 8428/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8199 - val_loss: -175.9292\n",
      "\n",
      "Epoch 08428: loss did not improve from -177.23628\n",
      "Epoch 8429/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1061 - val_loss: -176.1532\n",
      "\n",
      "Epoch 08429: loss did not improve from -177.23628\n",
      "Epoch 8430/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0119 - val_loss: -176.0818\n",
      "\n",
      "Epoch 08430: loss did not improve from -177.23628\n",
      "Epoch 8431/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0776 - val_loss: -176.1896\n",
      "\n",
      "Epoch 08431: loss did not improve from -177.23628\n",
      "Epoch 8432/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9229 - val_loss: -175.9779\n",
      "\n",
      "Epoch 08432: loss did not improve from -177.23628\n",
      "Epoch 8433/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1465 - val_loss: -176.0888\n",
      "\n",
      "Epoch 08433: loss did not improve from -177.23628\n",
      "Epoch 8434/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8809 - val_loss: -175.9841\n",
      "\n",
      "Epoch 08434: loss did not improve from -177.23628\n",
      "Epoch 8435/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9297 - val_loss: -175.9992\n",
      "\n",
      "Epoch 08435: loss did not improve from -177.23628\n",
      "Epoch 8436/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8871 - val_loss: -176.0345\n",
      "\n",
      "Epoch 08436: loss did not improve from -177.23628\n",
      "Epoch 8437/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0507 - val_loss: -176.0258\n",
      "\n",
      "Epoch 08437: loss did not improve from -177.23628\n",
      "Epoch 8438/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9774 - val_loss: -176.0074\n",
      "\n",
      "Epoch 08438: loss did not improve from -177.23628\n",
      "Epoch 8439/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1332 - val_loss: -176.0797\n",
      "\n",
      "Epoch 08439: loss did not improve from -177.23628\n",
      "Epoch 8440/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0155 - val_loss: -176.0153\n",
      "\n",
      "Epoch 08440: loss did not improve from -177.23628\n",
      "Epoch 8441/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1274 - val_loss: -176.0833\n",
      "\n",
      "Epoch 08441: loss did not improve from -177.23628\n",
      "Epoch 8442/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1680 - val_loss: -176.0610\n",
      "\n",
      "Epoch 08442: loss did not improve from -177.23628\n",
      "Epoch 8443/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8999 - val_loss: -175.6912\n",
      "\n",
      "Epoch 08443: loss did not improve from -177.23628\n",
      "Epoch 8444/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8560 - val_loss: -175.9999\n",
      "\n",
      "Epoch 08444: loss did not improve from -177.23628\n",
      "Epoch 8445/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9398 - val_loss: -176.0288\n",
      "\n",
      "Epoch 08445: loss did not improve from -177.23628\n",
      "Epoch 8446/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -176.8862 - val_loss: -175.9698\n",
      "\n",
      "Epoch 08446: loss did not improve from -177.23628\n",
      "Epoch 8447/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0699 - val_loss: -176.0317\n",
      "\n",
      "Epoch 08447: loss did not improve from -177.23628\n",
      "Epoch 8448/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9392 - val_loss: -175.9573\n",
      "\n",
      "Epoch 08448: loss did not improve from -177.23628\n",
      "Epoch 8449/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9273 - val_loss: -175.9743\n",
      "\n",
      "Epoch 08449: loss did not improve from -177.23628\n",
      "Epoch 8450/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9455 - val_loss: -176.0812\n",
      "\n",
      "Epoch 08450: loss did not improve from -177.23628\n",
      "Epoch 8451/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0301 - val_loss: -175.9665\n",
      "\n",
      "Epoch 08451: loss did not improve from -177.23628\n",
      "Epoch 8452/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0108 - val_loss: -176.0163\n",
      "\n",
      "Epoch 08452: loss did not improve from -177.23628\n",
      "Epoch 8453/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9231 - val_loss: -175.8949\n",
      "\n",
      "Epoch 08453: loss did not improve from -177.23628\n",
      "Epoch 8454/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9209 - val_loss: -175.9966\n",
      "\n",
      "Epoch 08454: loss did not improve from -177.23628\n",
      "Epoch 8455/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1722 - val_loss: -175.8504\n",
      "\n",
      "Epoch 08455: loss did not improve from -177.23628\n",
      "Epoch 8456/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1315 - val_loss: -176.0798\n",
      "\n",
      "Epoch 08456: loss did not improve from -177.23628\n",
      "Epoch 8457/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8281 - val_loss: -175.7216\n",
      "\n",
      "Epoch 08457: loss did not improve from -177.23628\n",
      "Epoch 8458/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9743 - val_loss: -176.0598\n",
      "\n",
      "Epoch 08458: loss did not improve from -177.23628\n",
      "Epoch 8459/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0774 - val_loss: -175.7396\n",
      "\n",
      "Epoch 08459: loss did not improve from -177.23628\n",
      "Epoch 8460/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9041 - val_loss: -175.8562\n",
      "\n",
      "Epoch 08460: loss did not improve from -177.23628\n",
      "Epoch 8461/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8756 - val_loss: -175.8574\n",
      "\n",
      "Epoch 08461: loss did not improve from -177.23628\n",
      "Epoch 8462/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7299 - val_loss: -175.7639\n",
      "\n",
      "Epoch 08462: loss did not improve from -177.23628\n",
      "Epoch 8463/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7048 - val_loss: -175.8856\n",
      "\n",
      "Epoch 08463: loss did not improve from -177.23628\n",
      "Epoch 8464/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.5808 - val_loss: -175.7055\n",
      "\n",
      "Epoch 08464: loss did not improve from -177.23628\n",
      "Epoch 8465/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9354 - val_loss: -175.9912\n",
      "\n",
      "Epoch 08465: loss did not improve from -177.23628\n",
      "Epoch 8466/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8132 - val_loss: -175.5428\n",
      "\n",
      "Epoch 08466: loss did not improve from -177.23628\n",
      "Epoch 8467/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9805 - val_loss: -176.0716\n",
      "\n",
      "Epoch 08467: loss did not improve from -177.23628\n",
      "Epoch 8468/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0100 - val_loss: -175.6775\n",
      "\n",
      "Epoch 08468: loss did not improve from -177.23628\n",
      "Epoch 8469/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0401 - val_loss: -175.8430\n",
      "\n",
      "Epoch 08469: loss did not improve from -177.23628\n",
      "Epoch 8470/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0263 - val_loss: -175.9672\n",
      "\n",
      "Epoch 08470: loss did not improve from -177.23628\n",
      "Epoch 8471/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1769 - val_loss: -175.9237\n",
      "\n",
      "Epoch 08471: loss did not improve from -177.23628\n",
      "Epoch 8472/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0879 - val_loss: -175.9807\n",
      "\n",
      "Epoch 08472: loss did not improve from -177.23628\n",
      "Epoch 8473/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9599 - val_loss: -175.8940\n",
      "\n",
      "Epoch 08473: loss did not improve from -177.23628\n",
      "Epoch 8474/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0233 - val_loss: -176.0012\n",
      "\n",
      "Epoch 08474: loss did not improve from -177.23628\n",
      "Epoch 8475/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0294 - val_loss: -175.8556\n",
      "\n",
      "Epoch 08475: loss did not improve from -177.23628\n",
      "Epoch 8476/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9754 - val_loss: -176.0298\n",
      "\n",
      "Epoch 08476: loss did not improve from -177.23628\n",
      "Epoch 8477/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0492 - val_loss: -175.9387\n",
      "\n",
      "Epoch 08477: loss did not improve from -177.23628\n",
      "Epoch 8478/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0031 - val_loss: -175.9943\n",
      "\n",
      "Epoch 08478: loss did not improve from -177.23628\n",
      "Epoch 8479/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1427 - val_loss: -175.9919\n",
      "\n",
      "Epoch 08479: loss did not improve from -177.23628\n",
      "Epoch 8480/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0266 - val_loss: -175.9946\n",
      "\n",
      "Epoch 08480: loss did not improve from -177.23628\n",
      "Epoch 8481/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2705 - val_loss: -176.0592\n",
      "\n",
      "Epoch 08481: loss improved from -177.23628 to -177.27052, saving model to gendance.h5\n",
      "Epoch 8482/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9070 - val_loss: -175.9470\n",
      "\n",
      "Epoch 08482: loss did not improve from -177.27052\n",
      "Epoch 8483/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9355 - val_loss: -175.9544\n",
      "\n",
      "Epoch 08483: loss did not improve from -177.27052\n",
      "Epoch 8484/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2047 - val_loss: -176.0705\n",
      "\n",
      "Epoch 08484: loss did not improve from -177.27052\n",
      "Epoch 8485/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1310 - val_loss: -175.9684\n",
      "\n",
      "Epoch 08485: loss did not improve from -177.27052\n",
      "Epoch 8486/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2038 - val_loss: -176.1104\n",
      "\n",
      "Epoch 08486: loss did not improve from -177.27052\n",
      "Epoch 8487/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1022 - val_loss: -175.7899\n",
      "\n",
      "Epoch 08487: loss did not improve from -177.27052\n",
      "Epoch 8488/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0236 - val_loss: -175.9344\n",
      "\n",
      "Epoch 08488: loss did not improve from -177.27052\n",
      "Epoch 8489/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8645 - val_loss: -175.9054\n",
      "\n",
      "Epoch 08489: loss did not improve from -177.27052\n",
      "Epoch 8490/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1250 - val_loss: -175.9375\n",
      "\n",
      "Epoch 08490: loss did not improve from -177.27052\n",
      "Epoch 8491/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0282 - val_loss: -175.8688\n",
      "\n",
      "Epoch 08491: loss did not improve from -177.27052\n",
      "Epoch 8492/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.8687 - val_loss: -175.9482\n",
      "\n",
      "Epoch 08492: loss did not improve from -177.27052\n",
      "Epoch 8493/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9190 - val_loss: -175.9567\n",
      "\n",
      "Epoch 08493: loss did not improve from -177.27052\n",
      "Epoch 8494/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0397 - val_loss: -176.0006\n",
      "\n",
      "Epoch 08494: loss did not improve from -177.27052\n",
      "Epoch 8495/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2070 - val_loss: -176.0425\n",
      "\n",
      "Epoch 08495: loss did not improve from -177.27052\n",
      "Epoch 8496/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0760 - val_loss: -175.8540\n",
      "\n",
      "Epoch 08496: loss did not improve from -177.27052\n",
      "Epoch 8497/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1143 - val_loss: -176.0503\n",
      "\n",
      "Epoch 08497: loss did not improve from -177.27052\n",
      "Epoch 8498/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9698 - val_loss: -175.8293\n",
      "\n",
      "Epoch 08498: loss did not improve from -177.27052\n",
      "Epoch 8499/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1367 - val_loss: -175.9837\n",
      "\n",
      "Epoch 08499: loss did not improve from -177.27052\n",
      "Epoch 8500/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0849 - val_loss: -175.7638\n",
      "\n",
      "Epoch 08500: loss did not improve from -177.27052\n",
      "Epoch 8501/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0670 - val_loss: -175.9920\n",
      "\n",
      "Epoch 08501: loss did not improve from -177.27052\n",
      "Epoch 8502/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0753 - val_loss: -175.8473\n",
      "\n",
      "Epoch 08502: loss did not improve from -177.27052\n",
      "Epoch 8503/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0716 - val_loss: -175.9161\n",
      "\n",
      "Epoch 08503: loss did not improve from -177.27052\n",
      "Epoch 8504/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1646 - val_loss: -176.0689\n",
      "\n",
      "Epoch 08504: loss did not improve from -177.27052\n",
      "Epoch 8505/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1008 - val_loss: -175.7283\n",
      "\n",
      "Epoch 08505: loss did not improve from -177.27052\n",
      "Epoch 8506/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0016 - val_loss: -176.0753\n",
      "\n",
      "Epoch 08506: loss did not improve from -177.27052\n",
      "Epoch 8507/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0781 - val_loss: -175.7656\n",
      "\n",
      "Epoch 08507: loss did not improve from -177.27052\n",
      "Epoch 8508/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9865 - val_loss: -175.9690\n",
      "\n",
      "Epoch 08508: loss did not improve from -177.27052\n",
      "Epoch 8509/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1824 - val_loss: -175.9035\n",
      "\n",
      "Epoch 08509: loss did not improve from -177.27052\n",
      "Epoch 8510/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1490 - val_loss: -176.0320\n",
      "\n",
      "Epoch 08510: loss did not improve from -177.27052\n",
      "Epoch 8511/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1704 - val_loss: -175.7856\n",
      "\n",
      "Epoch 08511: loss did not improve from -177.27052\n",
      "Epoch 8512/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1329 - val_loss: -175.9853\n",
      "\n",
      "Epoch 08512: loss did not improve from -177.27052\n",
      "Epoch 8513/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1501 - val_loss: -175.6444\n",
      "\n",
      "Epoch 08513: loss did not improve from -177.27052\n",
      "Epoch 8514/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9353 - val_loss: -176.0106\n",
      "\n",
      "Epoch 08514: loss did not improve from -177.27052\n",
      "Epoch 8515/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1094 - val_loss: -175.7259\n",
      "\n",
      "Epoch 08515: loss did not improve from -177.27052\n",
      "Epoch 8516/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0582 - val_loss: -175.9515\n",
      "\n",
      "Epoch 08516: loss did not improve from -177.27052\n",
      "Epoch 8517/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0612 - val_loss: -175.8587\n",
      "\n",
      "Epoch 08517: loss did not improve from -177.27052\n",
      "Epoch 8518/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0823 - val_loss: -175.9320\n",
      "\n",
      "Epoch 08518: loss did not improve from -177.27052\n",
      "Epoch 8519/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1801 - val_loss: -175.9524\n",
      "\n",
      "Epoch 08519: loss did not improve from -177.27052\n",
      "Epoch 8520/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9316 - val_loss: -175.8390\n",
      "\n",
      "Epoch 08520: loss did not improve from -177.27052\n",
      "Epoch 8521/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1113 - val_loss: -175.9854\n",
      "\n",
      "Epoch 08521: loss did not improve from -177.27052\n",
      "Epoch 8522/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1268 - val_loss: -176.0029\n",
      "\n",
      "Epoch 08522: loss did not improve from -177.27052\n",
      "Epoch 8523/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1234 - val_loss: -175.8760\n",
      "\n",
      "Epoch 08523: loss did not improve from -177.27052\n",
      "Epoch 8524/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2860 - val_loss: -175.9754\n",
      "\n",
      "Epoch 08524: loss improved from -177.27052 to -177.28595, saving model to gendance.h5\n",
      "Epoch 8525/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2246 - val_loss: -175.9838\n",
      "\n",
      "Epoch 08525: loss did not improve from -177.28595\n",
      "Epoch 8526/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0632 - val_loss: -176.0212\n",
      "\n",
      "Epoch 08526: loss did not improve from -177.28595\n",
      "Epoch 8527/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3901 - val_loss: -175.9216\n",
      "\n",
      "Epoch 08527: loss improved from -177.28595 to -177.39007, saving model to gendance.h5\n",
      "Epoch 8528/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1150 - val_loss: -175.7872\n",
      "\n",
      "Epoch 08528: loss did not improve from -177.39007\n",
      "Epoch 8529/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1746 - val_loss: -176.0016\n",
      "\n",
      "Epoch 08529: loss did not improve from -177.39007\n",
      "Epoch 8530/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1737 - val_loss: -176.1028\n",
      "\n",
      "Epoch 08530: loss did not improve from -177.39007\n",
      "Epoch 8531/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1687 - val_loss: -175.8785\n",
      "\n",
      "Epoch 08531: loss did not improve from -177.39007\n",
      "Epoch 8532/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0514 - val_loss: -176.0656\n",
      "\n",
      "Epoch 08532: loss did not improve from -177.39007\n",
      "Epoch 8533/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9721 - val_loss: -175.6816\n",
      "\n",
      "Epoch 08533: loss did not improve from -177.39007\n",
      "Epoch 8534/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9629 - val_loss: -176.0652\n",
      "\n",
      "Epoch 08534: loss did not improve from -177.39007\n",
      "Epoch 8535/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0294 - val_loss: -175.5815\n",
      "\n",
      "Epoch 08535: loss did not improve from -177.39007\n",
      "Epoch 8536/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9200 - val_loss: -175.7878\n",
      "\n",
      "Epoch 08536: loss did not improve from -177.39007\n",
      "Epoch 8537/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9490 - val_loss: -175.7688\n",
      "\n",
      "Epoch 08537: loss did not improve from -177.39007\n",
      "Epoch 8538/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9253 - val_loss: -175.9487\n",
      "\n",
      "Epoch 08538: loss did not improve from -177.39007\n",
      "Epoch 8539/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0008 - val_loss: -175.7311\n",
      "\n",
      "Epoch 08539: loss did not improve from -177.39007\n",
      "Epoch 8540/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0341 - val_loss: -175.9628\n",
      "\n",
      "Epoch 08540: loss did not improve from -177.39007\n",
      "Epoch 8541/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1544 - val_loss: -175.7722\n",
      "\n",
      "Epoch 08541: loss did not improve from -177.39007\n",
      "Epoch 8542/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1101 - val_loss: -175.9928\n",
      "\n",
      "Epoch 08542: loss did not improve from -177.39007\n",
      "Epoch 8543/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1116 - val_loss: -175.8516\n",
      "\n",
      "Epoch 08543: loss did not improve from -177.39007\n",
      "Epoch 8544/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1984 - val_loss: -176.0806\n",
      "\n",
      "Epoch 08544: loss did not improve from -177.39007\n",
      "Epoch 8545/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0642 - val_loss: -175.9569\n",
      "\n",
      "Epoch 08545: loss did not improve from -177.39007\n",
      "Epoch 8546/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2682 - val_loss: -175.9999\n",
      "\n",
      "Epoch 08546: loss did not improve from -177.39007\n",
      "Epoch 8547/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2260 - val_loss: -176.0983\n",
      "\n",
      "Epoch 08547: loss did not improve from -177.39007\n",
      "Epoch 8548/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2806 - val_loss: -175.8644\n",
      "\n",
      "Epoch 08548: loss did not improve from -177.39007\n",
      "Epoch 8549/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0786 - val_loss: -176.0868\n",
      "\n",
      "Epoch 08549: loss did not improve from -177.39007\n",
      "Epoch 8550/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2410 - val_loss: -175.7902\n",
      "\n",
      "Epoch 08550: loss did not improve from -177.39007\n",
      "Epoch 8551/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9511 - val_loss: -176.0999\n",
      "\n",
      "Epoch 08551: loss did not improve from -177.39007\n",
      "Epoch 8552/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2501 - val_loss: -175.7847\n",
      "\n",
      "Epoch 08552: loss did not improve from -177.39007\n",
      "Epoch 8553/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0069 - val_loss: -176.0046\n",
      "\n",
      "Epoch 08553: loss did not improve from -177.39007\n",
      "Epoch 8554/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9911 - val_loss: -175.7119\n",
      "\n",
      "Epoch 08554: loss did not improve from -177.39007\n",
      "Epoch 8555/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1166 - val_loss: -176.0376\n",
      "\n",
      "Epoch 08555: loss did not improve from -177.39007\n",
      "Epoch 8556/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2813 - val_loss: -175.7874\n",
      "\n",
      "Epoch 08556: loss did not improve from -177.39007\n",
      "Epoch 8557/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1715 - val_loss: -176.0428\n",
      "\n",
      "Epoch 08557: loss did not improve from -177.39007\n",
      "Epoch 8558/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3387 - val_loss: -176.0155\n",
      "\n",
      "Epoch 08558: loss did not improve from -177.39007\n",
      "Epoch 8559/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -177.3843 - val_loss: -175.8775\n",
      "\n",
      "Epoch 08559: loss did not improve from -177.39007\n",
      "Epoch 8560/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -177.1744 - val_loss: -176.0648\n",
      "\n",
      "Epoch 08560: loss did not improve from -177.39007\n",
      "Epoch 8561/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3279 - val_loss: -176.0131\n",
      "\n",
      "Epoch 08561: loss did not improve from -177.39007\n",
      "Epoch 8562/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0647 - val_loss: -175.9599\n",
      "\n",
      "Epoch 08562: loss did not improve from -177.39007\n",
      "Epoch 8563/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2030 - val_loss: -175.8916\n",
      "\n",
      "Epoch 08563: loss did not improve from -177.39007\n",
      "Epoch 8564/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3278 - val_loss: -176.0950\n",
      "\n",
      "Epoch 08564: loss did not improve from -177.39007\n",
      "Epoch 8565/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2083 - val_loss: -175.8947\n",
      "\n",
      "Epoch 08565: loss did not improve from -177.39007\n",
      "Epoch 8566/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2001 - val_loss: -176.0852\n",
      "\n",
      "Epoch 08566: loss did not improve from -177.39007\n",
      "Epoch 8567/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1720 - val_loss: -175.8351\n",
      "\n",
      "Epoch 08567: loss did not improve from -177.39007\n",
      "Epoch 8568/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1139 - val_loss: -176.0241\n",
      "\n",
      "Epoch 08568: loss did not improve from -177.39007\n",
      "Epoch 8569/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4609 - val_loss: -175.8456\n",
      "\n",
      "Epoch 08569: loss improved from -177.39007 to -177.46090, saving model to gendance.h5\n",
      "Epoch 8570/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2944 - val_loss: -176.1277\n",
      "\n",
      "Epoch 08570: loss did not improve from -177.46090\n",
      "Epoch 8571/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -177.1002 - val_loss: -175.8070\n",
      "\n",
      "Epoch 08571: loss did not improve from -177.46090\n",
      "Epoch 8572/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0327 - val_loss: -175.9685\n",
      "\n",
      "Epoch 08572: loss did not improve from -177.46090\n",
      "Epoch 8573/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0211 - val_loss: -175.8021\n",
      "\n",
      "Epoch 08573: loss did not improve from -177.46090\n",
      "Epoch 8574/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1767 - val_loss: -176.0573\n",
      "\n",
      "Epoch 08574: loss did not improve from -177.46090\n",
      "Epoch 8575/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1813 - val_loss: -175.8895\n",
      "\n",
      "Epoch 08575: loss did not improve from -177.46090\n",
      "Epoch 8576/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0341 - val_loss: -176.0101\n",
      "\n",
      "Epoch 08576: loss did not improve from -177.46090\n",
      "Epoch 8577/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -177.1676 - val_loss: -175.9891\n",
      "\n",
      "Epoch 08577: loss did not improve from -177.46090\n",
      "Epoch 8578/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2285 - val_loss: -176.0938\n",
      "\n",
      "Epoch 08578: loss did not improve from -177.46090\n",
      "Epoch 8579/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1799 - val_loss: -176.0946\n",
      "\n",
      "Epoch 08579: loss did not improve from -177.46090\n",
      "Epoch 8580/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0344 - val_loss: -175.8875\n",
      "\n",
      "Epoch 08580: loss did not improve from -177.46090\n",
      "Epoch 8581/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1648 - val_loss: -176.0454\n",
      "\n",
      "Epoch 08581: loss did not improve from -177.46090\n",
      "Epoch 8582/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3454 - val_loss: -175.8787\n",
      "\n",
      "Epoch 08582: loss did not improve from -177.46090\n",
      "Epoch 8583/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2627 - val_loss: -176.0725\n",
      "\n",
      "Epoch 08583: loss did not improve from -177.46090\n",
      "Epoch 8584/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0579 - val_loss: -175.9194\n",
      "\n",
      "Epoch 08584: loss did not improve from -177.46090\n",
      "Epoch 8585/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2235 - val_loss: -176.0609\n",
      "\n",
      "Epoch 08585: loss did not improve from -177.46090\n",
      "Epoch 8586/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1404 - val_loss: -175.7603\n",
      "\n",
      "Epoch 08586: loss did not improve from -177.46090\n",
      "Epoch 8587/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2298 - val_loss: -175.9640\n",
      "\n",
      "Epoch 08587: loss did not improve from -177.46090\n",
      "Epoch 8588/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1879 - val_loss: -175.7608\n",
      "\n",
      "Epoch 08588: loss did not improve from -177.46090\n",
      "Epoch 8589/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9957 - val_loss: -175.9953\n",
      "\n",
      "Epoch 08589: loss did not improve from -177.46090\n",
      "Epoch 8590/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1066 - val_loss: -175.8910\n",
      "\n",
      "Epoch 08590: loss did not improve from -177.46090\n",
      "Epoch 8591/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3031 - val_loss: -176.1004\n",
      "\n",
      "Epoch 08591: loss did not improve from -177.46090\n",
      "Epoch 8592/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2073 - val_loss: -175.9344\n",
      "\n",
      "Epoch 08592: loss did not improve from -177.46090\n",
      "Epoch 8593/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2568 - val_loss: -175.9198\n",
      "\n",
      "Epoch 08593: loss did not improve from -177.46090\n",
      "Epoch 8594/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0356 - val_loss: -176.0940\n",
      "\n",
      "Epoch 08594: loss did not improve from -177.46090\n",
      "Epoch 8595/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9931 - val_loss: -175.7299\n",
      "\n",
      "Epoch 08595: loss did not improve from -177.46090\n",
      "Epoch 8596/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0631 - val_loss: -176.0414\n",
      "\n",
      "Epoch 08596: loss did not improve from -177.46090\n",
      "Epoch 8597/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0971 - val_loss: -175.7829\n",
      "\n",
      "Epoch 08597: loss did not improve from -177.46090\n",
      "Epoch 8598/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3183 - val_loss: -175.9850\n",
      "\n",
      "Epoch 08598: loss did not improve from -177.46090\n",
      "Epoch 8599/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2417 - val_loss: -175.7920\n",
      "\n",
      "Epoch 08599: loss did not improve from -177.46090\n",
      "Epoch 8600/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2469 - val_loss: -176.0788\n",
      "\n",
      "Epoch 08600: loss did not improve from -177.46090\n",
      "Epoch 8601/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0680 - val_loss: -175.9444\n",
      "\n",
      "Epoch 08601: loss did not improve from -177.46090\n",
      "Epoch 8602/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4542 - val_loss: -176.0630\n",
      "\n",
      "Epoch 08602: loss did not improve from -177.46090\n",
      "Epoch 8603/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3238 - val_loss: -175.9574\n",
      "\n",
      "Epoch 08603: loss did not improve from -177.46090\n",
      "Epoch 8604/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3949 - val_loss: -176.0075\n",
      "\n",
      "Epoch 08604: loss did not improve from -177.46090\n",
      "Epoch 8605/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0422 - val_loss: -176.0307\n",
      "\n",
      "Epoch 08605: loss did not improve from -177.46090\n",
      "Epoch 8606/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1791 - val_loss: -175.9342\n",
      "\n",
      "Epoch 08606: loss did not improve from -177.46090\n",
      "Epoch 8607/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3373 - val_loss: -175.9176\n",
      "\n",
      "Epoch 08607: loss did not improve from -177.46090\n",
      "Epoch 8608/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9225 - val_loss: -175.8411\n",
      "\n",
      "Epoch 08608: loss did not improve from -177.46090\n",
      "Epoch 8609/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1439 - val_loss: -175.9929\n",
      "\n",
      "Epoch 08609: loss did not improve from -177.46090\n",
      "Epoch 8610/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0242 - val_loss: -175.8843\n",
      "\n",
      "Epoch 08610: loss did not improve from -177.46090\n",
      "Epoch 8611/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1553 - val_loss: -176.1889\n",
      "\n",
      "Epoch 08611: loss did not improve from -177.46090\n",
      "Epoch 8612/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3376 - val_loss: -175.9046\n",
      "\n",
      "Epoch 08612: loss did not improve from -177.46090\n",
      "Epoch 8613/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3592 - val_loss: -176.0015\n",
      "\n",
      "Epoch 08613: loss did not improve from -177.46090\n",
      "Epoch 8614/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2944 - val_loss: -175.8913\n",
      "\n",
      "Epoch 08614: loss did not improve from -177.46090\n",
      "Epoch 8615/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2265 - val_loss: -176.0833\n",
      "\n",
      "Epoch 08615: loss did not improve from -177.46090\n",
      "Epoch 8616/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2993 - val_loss: -176.0295\n",
      "\n",
      "Epoch 08616: loss did not improve from -177.46090\n",
      "Epoch 8617/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1585 - val_loss: -176.1237\n",
      "\n",
      "Epoch 08617: loss did not improve from -177.46090\n",
      "Epoch 8618/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9119 - val_loss: -175.8253\n",
      "\n",
      "Epoch 08618: loss did not improve from -177.46090\n",
      "Epoch 8619/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0408 - val_loss: -176.0047\n",
      "\n",
      "Epoch 08619: loss did not improve from -177.46090\n",
      "Epoch 8620/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2516 - val_loss: -175.9298\n",
      "\n",
      "Epoch 08620: loss did not improve from -177.46090\n",
      "Epoch 8621/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1160 - val_loss: -175.9210\n",
      "\n",
      "Epoch 08621: loss did not improve from -177.46090\n",
      "Epoch 8622/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2439 - val_loss: -175.9253\n",
      "\n",
      "Epoch 08622: loss did not improve from -177.46090\n",
      "Epoch 8623/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2365 - val_loss: -176.0187\n",
      "\n",
      "Epoch 08623: loss did not improve from -177.46090\n",
      "Epoch 8624/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0521 - val_loss: -175.9437\n",
      "\n",
      "Epoch 08624: loss did not improve from -177.46090\n",
      "Epoch 8625/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3244 - val_loss: -175.9856\n",
      "\n",
      "Epoch 08625: loss did not improve from -177.46090\n",
      "Epoch 8626/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9621 - val_loss: -175.8694\n",
      "\n",
      "Epoch 08626: loss did not improve from -177.46090\n",
      "Epoch 8627/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1459 - val_loss: -175.9768\n",
      "\n",
      "Epoch 08627: loss did not improve from -177.46090\n",
      "Epoch 8628/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2254 - val_loss: -176.0718\n",
      "\n",
      "Epoch 08628: loss did not improve from -177.46090\n",
      "Epoch 8629/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -177.3091 - val_loss: -175.7590\n",
      "\n",
      "Epoch 08629: loss did not improve from -177.46090\n",
      "Epoch 8630/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.7898 - val_loss: -176.0623\n",
      "\n",
      "Epoch 08630: loss did not improve from -177.46090\n",
      "Epoch 8631/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0374 - val_loss: -175.5599\n",
      "\n",
      "Epoch 08631: loss did not improve from -177.46090\n",
      "Epoch 8632/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2323 - val_loss: -176.0906\n",
      "\n",
      "Epoch 08632: loss did not improve from -177.46090\n",
      "Epoch 8633/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0971 - val_loss: -175.5827\n",
      "\n",
      "Epoch 08633: loss did not improve from -177.46090\n",
      "Epoch 8634/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0800 - val_loss: -176.1254\n",
      "\n",
      "Epoch 08634: loss did not improve from -177.46090\n",
      "Epoch 8635/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2989 - val_loss: -175.9805\n",
      "\n",
      "Epoch 08635: loss did not improve from -177.46090\n",
      "Epoch 8636/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1359 - val_loss: -176.0871\n",
      "\n",
      "Epoch 08636: loss did not improve from -177.46090\n",
      "Epoch 8637/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1204 - val_loss: -175.9091\n",
      "\n",
      "Epoch 08637: loss did not improve from -177.46090\n",
      "Epoch 8638/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0975 - val_loss: -176.0140\n",
      "\n",
      "Epoch 08638: loss did not improve from -177.46090\n",
      "Epoch 8639/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2024 - val_loss: -175.8384\n",
      "\n",
      "Epoch 08639: loss did not improve from -177.46090\n",
      "Epoch 8640/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3648 - val_loss: -176.1287\n",
      "\n",
      "Epoch 08640: loss did not improve from -177.46090\n",
      "Epoch 8641/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1714 - val_loss: -175.8219\n",
      "\n",
      "Epoch 08641: loss did not improve from -177.46090\n",
      "Epoch 8642/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1583 - val_loss: -175.9786\n",
      "\n",
      "Epoch 08642: loss did not improve from -177.46090\n",
      "Epoch 8643/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2082 - val_loss: -175.9470\n",
      "\n",
      "Epoch 08643: loss did not improve from -177.46090\n",
      "Epoch 8644/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1117 - val_loss: -176.0621\n",
      "\n",
      "Epoch 08644: loss did not improve from -177.46090\n",
      "Epoch 8645/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1522 - val_loss: -175.9195\n",
      "\n",
      "Epoch 08645: loss did not improve from -177.46090\n",
      "Epoch 8646/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0453 - val_loss: -175.8995\n",
      "\n",
      "Epoch 08646: loss did not improve from -177.46090\n",
      "Epoch 8647/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1131 - val_loss: -176.0818\n",
      "\n",
      "Epoch 08647: loss did not improve from -177.46090\n",
      "Epoch 8648/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9928 - val_loss: -175.6547\n",
      "\n",
      "Epoch 08648: loss did not improve from -177.46090\n",
      "Epoch 8649/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0857 - val_loss: -176.0227\n",
      "\n",
      "Epoch 08649: loss did not improve from -177.46090\n",
      "Epoch 8650/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1512 - val_loss: -175.8918\n",
      "\n",
      "Epoch 08650: loss did not improve from -177.46090\n",
      "Epoch 8651/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2319 - val_loss: -176.0009\n",
      "\n",
      "Epoch 08651: loss did not improve from -177.46090\n",
      "Epoch 8652/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -176.9144 - val_loss: -175.6972\n",
      "\n",
      "Epoch 08652: loss did not improve from -177.46090\n",
      "Epoch 8653/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2761 - val_loss: -176.1821\n",
      "\n",
      "Epoch 08653: loss did not improve from -177.46090\n",
      "Epoch 8654/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2702 - val_loss: -175.8745\n",
      "\n",
      "Epoch 08654: loss did not improve from -177.46090\n",
      "Epoch 8655/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1735 - val_loss: -175.9328\n",
      "\n",
      "Epoch 08655: loss did not improve from -177.46090\n",
      "Epoch 8656/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0890 - val_loss: -175.9173\n",
      "\n",
      "Epoch 08656: loss did not improve from -177.46090\n",
      "Epoch 8657/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2995 - val_loss: -175.9757\n",
      "\n",
      "Epoch 08657: loss did not improve from -177.46090\n",
      "Epoch 8658/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1372 - val_loss: -176.0205\n",
      "\n",
      "Epoch 08658: loss did not improve from -177.46090\n",
      "Epoch 8659/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1838 - val_loss: -175.9186\n",
      "\n",
      "Epoch 08659: loss did not improve from -177.46090\n",
      "Epoch 8660/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2062 - val_loss: -175.9788\n",
      "\n",
      "Epoch 08660: loss did not improve from -177.46090\n",
      "Epoch 8661/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1187 - val_loss: -175.9880\n",
      "\n",
      "Epoch 08661: loss did not improve from -177.46090\n",
      "Epoch 8662/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1937 - val_loss: -175.8750\n",
      "\n",
      "Epoch 08662: loss did not improve from -177.46090\n",
      "Epoch 8663/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3575 - val_loss: -175.9449\n",
      "\n",
      "Epoch 08663: loss did not improve from -177.46090\n",
      "Epoch 8664/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0860 - val_loss: -175.9899\n",
      "\n",
      "Epoch 08664: loss did not improve from -177.46090\n",
      "Epoch 8665/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1870 - val_loss: -175.9841\n",
      "\n",
      "Epoch 08665: loss did not improve from -177.46090\n",
      "Epoch 8666/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3995 - val_loss: -176.1924\n",
      "\n",
      "Epoch 08666: loss did not improve from -177.46090\n",
      "Epoch 8667/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3787 - val_loss: -175.9145\n",
      "\n",
      "Epoch 08667: loss did not improve from -177.46090\n",
      "Epoch 8668/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2461 - val_loss: -176.1966\n",
      "\n",
      "Epoch 08668: loss did not improve from -177.46090\n",
      "Epoch 8669/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -177.2509 - val_loss: -175.9978\n",
      "\n",
      "Epoch 08669: loss did not improve from -177.46090\n",
      "Epoch 8670/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -177.3507 - val_loss: -176.0409\n",
      "\n",
      "Epoch 08670: loss did not improve from -177.46090\n",
      "Epoch 8671/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0734 - val_loss: -175.7430\n",
      "\n",
      "Epoch 08671: loss did not improve from -177.46090\n",
      "Epoch 8672/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3400 - val_loss: -175.9861\n",
      "\n",
      "Epoch 08672: loss did not improve from -177.46090\n",
      "Epoch 8673/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3128 - val_loss: -176.0432\n",
      "\n",
      "Epoch 08673: loss did not improve from -177.46090\n",
      "Epoch 8674/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1632 - val_loss: -175.9196\n",
      "\n",
      "Epoch 08674: loss did not improve from -177.46090\n",
      "Epoch 8675/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2612 - val_loss: -176.1344\n",
      "\n",
      "Epoch 08675: loss did not improve from -177.46090\n",
      "Epoch 8676/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1625 - val_loss: -175.7146\n",
      "\n",
      "Epoch 08676: loss did not improve from -177.46090\n",
      "Epoch 8677/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0710 - val_loss: -176.1116\n",
      "\n",
      "Epoch 08677: loss did not improve from -177.46090\n",
      "Epoch 8678/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3941 - val_loss: -175.9369\n",
      "\n",
      "Epoch 08678: loss did not improve from -177.46090\n",
      "Epoch 8679/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2454 - val_loss: -176.0753\n",
      "\n",
      "Epoch 08679: loss did not improve from -177.46090\n",
      "Epoch 8680/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0926 - val_loss: -175.9046\n",
      "\n",
      "Epoch 08680: loss did not improve from -177.46090\n",
      "Epoch 8681/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3868 - val_loss: -176.1724\n",
      "\n",
      "Epoch 08681: loss did not improve from -177.46090\n",
      "Epoch 8682/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -177.2946 - val_loss: -175.9018\n",
      "\n",
      "Epoch 08682: loss did not improve from -177.46090\n",
      "Epoch 8683/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2721 - val_loss: -176.1007\n",
      "\n",
      "Epoch 08683: loss did not improve from -177.46090\n",
      "Epoch 8684/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1943 - val_loss: -175.9795\n",
      "\n",
      "Epoch 08684: loss did not improve from -177.46090\n",
      "Epoch 8685/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0613 - val_loss: -176.0036\n",
      "\n",
      "Epoch 08685: loss did not improve from -177.46090\n",
      "Epoch 8686/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2903 - val_loss: -176.0570\n",
      "\n",
      "Epoch 08686: loss did not improve from -177.46090\n",
      "Epoch 8687/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -177.3382 - val_loss: -176.0538\n",
      "\n",
      "Epoch 08687: loss did not improve from -177.46090\n",
      "Epoch 8688/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3299 - val_loss: -175.8197\n",
      "\n",
      "Epoch 08688: loss did not improve from -177.46090\n",
      "Epoch 8689/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2095 - val_loss: -176.0211\n",
      "\n",
      "Epoch 08689: loss did not improve from -177.46090\n",
      "Epoch 8690/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4937 - val_loss: -176.1406\n",
      "\n",
      "Epoch 08690: loss improved from -177.46090 to -177.49366, saving model to gendance.h5\n",
      "Epoch 8691/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2258 - val_loss: -175.8907\n",
      "\n",
      "Epoch 08691: loss did not improve from -177.49366\n",
      "Epoch 8692/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2784 - val_loss: -176.1351\n",
      "\n",
      "Epoch 08692: loss did not improve from -177.49366\n",
      "Epoch 8693/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4396 - val_loss: -176.0522\n",
      "\n",
      "Epoch 08693: loss did not improve from -177.49366\n",
      "Epoch 8694/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3030 - val_loss: -176.0578\n",
      "\n",
      "Epoch 08694: loss did not improve from -177.49366\n",
      "Epoch 8695/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1923 - val_loss: -175.9985\n",
      "\n",
      "Epoch 08695: loss did not improve from -177.49366\n",
      "Epoch 8696/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2940 - val_loss: -175.9629\n",
      "\n",
      "Epoch 08696: loss did not improve from -177.49366\n",
      "Epoch 8697/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2858 - val_loss: -176.1909\n",
      "\n",
      "Epoch 08697: loss did not improve from -177.49366\n",
      "Epoch 8698/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3710 - val_loss: -176.0674\n",
      "\n",
      "Epoch 08698: loss did not improve from -177.49366\n",
      "Epoch 8699/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3492 - val_loss: -176.0209\n",
      "\n",
      "Epoch 08699: loss did not improve from -177.49366\n",
      "Epoch 8700/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3151 - val_loss: -175.8223\n",
      "\n",
      "Epoch 08700: loss did not improve from -177.49366\n",
      "Epoch 8701/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1501 - val_loss: -176.0954\n",
      "\n",
      "Epoch 08701: loss did not improve from -177.49366\n",
      "Epoch 8702/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2078 - val_loss: -175.6828\n",
      "\n",
      "Epoch 08702: loss did not improve from -177.49366\n",
      "Epoch 8703/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2765 - val_loss: -176.0498\n",
      "\n",
      "Epoch 08703: loss did not improve from -177.49366\n",
      "Epoch 8704/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2380 - val_loss: -175.6757\n",
      "\n",
      "Epoch 08704: loss did not improve from -177.49366\n",
      "Epoch 8705/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1968 - val_loss: -175.9128\n",
      "\n",
      "Epoch 08705: loss did not improve from -177.49366\n",
      "Epoch 8706/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1766 - val_loss: -175.8370\n",
      "\n",
      "Epoch 08706: loss did not improve from -177.49366\n",
      "Epoch 8707/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2683 - val_loss: -176.0043\n",
      "\n",
      "Epoch 08707: loss did not improve from -177.49366\n",
      "Epoch 8708/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2375 - val_loss: -176.0282\n",
      "\n",
      "Epoch 08708: loss did not improve from -177.49366\n",
      "Epoch 8709/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4117 - val_loss: -176.0391\n",
      "\n",
      "Epoch 08709: loss did not improve from -177.49366\n",
      "Epoch 8710/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3279 - val_loss: -176.0981\n",
      "\n",
      "Epoch 08710: loss did not improve from -177.49366\n",
      "Epoch 8711/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1596 - val_loss: -175.9935\n",
      "\n",
      "Epoch 08711: loss did not improve from -177.49366\n",
      "Epoch 8712/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3340 - val_loss: -175.9991\n",
      "\n",
      "Epoch 08712: loss did not improve from -177.49366\n",
      "Epoch 8713/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2623 - val_loss: -176.0058\n",
      "\n",
      "Epoch 08713: loss did not improve from -177.49366\n",
      "Epoch 8714/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0569 - val_loss: -176.0326\n",
      "\n",
      "Epoch 08714: loss did not improve from -177.49366\n",
      "Epoch 8715/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1954 - val_loss: -176.0020\n",
      "\n",
      "Epoch 08715: loss did not improve from -177.49366\n",
      "Epoch 8716/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3902 - val_loss: -176.0506\n",
      "\n",
      "Epoch 08716: loss did not improve from -177.49366\n",
      "Epoch 8717/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5008 - val_loss: -176.1616\n",
      "\n",
      "Epoch 08717: loss improved from -177.49366 to -177.50083, saving model to gendance.h5\n",
      "Epoch 8718/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4821 - val_loss: -176.0675\n",
      "\n",
      "Epoch 08718: loss did not improve from -177.50083\n",
      "Epoch 8719/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4892 - val_loss: -176.1652\n",
      "\n",
      "Epoch 08719: loss did not improve from -177.50083\n",
      "Epoch 8720/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2560 - val_loss: -176.1271\n",
      "\n",
      "Epoch 08720: loss did not improve from -177.50083\n",
      "Epoch 8721/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -177.5236 - val_loss: -176.0282\n",
      "\n",
      "Epoch 08721: loss improved from -177.50083 to -177.52356, saving model to gendance.h5\n",
      "Epoch 8722/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3785 - val_loss: -176.0818\n",
      "\n",
      "Epoch 08722: loss did not improve from -177.52356\n",
      "Epoch 8723/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3107 - val_loss: -175.9855\n",
      "\n",
      "Epoch 08723: loss did not improve from -177.52356\n",
      "Epoch 8724/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3166 - val_loss: -176.0304\n",
      "\n",
      "Epoch 08724: loss did not improve from -177.52356\n",
      "Epoch 8725/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3828 - val_loss: -175.9988\n",
      "\n",
      "Epoch 08725: loss did not improve from -177.52356\n",
      "Epoch 8726/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3104 - val_loss: -176.0368\n",
      "\n",
      "Epoch 08726: loss did not improve from -177.52356\n",
      "Epoch 8727/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2337 - val_loss: -175.8214\n",
      "\n",
      "Epoch 08727: loss did not improve from -177.52356\n",
      "Epoch 8728/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3250 - val_loss: -176.1366\n",
      "\n",
      "Epoch 08728: loss did not improve from -177.52356\n",
      "Epoch 8729/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2746 - val_loss: -175.8746\n",
      "\n",
      "Epoch 08729: loss did not improve from -177.52356\n",
      "Epoch 8730/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1675 - val_loss: -175.9837\n",
      "\n",
      "Epoch 08730: loss did not improve from -177.52356\n",
      "Epoch 8731/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3274 - val_loss: -175.9390\n",
      "\n",
      "Epoch 08731: loss did not improve from -177.52356\n",
      "Epoch 8732/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2149 - val_loss: -175.9382\n",
      "\n",
      "Epoch 08732: loss did not improve from -177.52356\n",
      "Epoch 8733/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3438 - val_loss: -175.8887\n",
      "\n",
      "Epoch 08733: loss did not improve from -177.52356\n",
      "Epoch 8734/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2780 - val_loss: -176.0418\n",
      "\n",
      "Epoch 08734: loss did not improve from -177.52356\n",
      "Epoch 8735/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -177.3203 - val_loss: -176.0855\n",
      "\n",
      "Epoch 08735: loss did not improve from -177.52356\n",
      "Epoch 8736/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2385 - val_loss: -175.8439\n",
      "\n",
      "Epoch 08736: loss did not improve from -177.52356\n",
      "Epoch 8737/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3103 - val_loss: -176.0928\n",
      "\n",
      "Epoch 08737: loss did not improve from -177.52356\n",
      "Epoch 8738/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2697 - val_loss: -175.8506\n",
      "\n",
      "Epoch 08738: loss did not improve from -177.52356\n",
      "Epoch 8739/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1999 - val_loss: -176.1131\n",
      "\n",
      "Epoch 08739: loss did not improve from -177.52356\n",
      "Epoch 8740/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4608 - val_loss: -175.9212\n",
      "\n",
      "Epoch 08740: loss did not improve from -177.52356\n",
      "Epoch 8741/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0440 - val_loss: -175.9911\n",
      "\n",
      "Epoch 08741: loss did not improve from -177.52356\n",
      "Epoch 8742/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4900 - val_loss: -175.9575\n",
      "\n",
      "Epoch 08742: loss did not improve from -177.52356\n",
      "Epoch 8743/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4352 - val_loss: -176.1774\n",
      "\n",
      "Epoch 08743: loss did not improve from -177.52356\n",
      "Epoch 8744/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2589 - val_loss: -175.8328\n",
      "\n",
      "Epoch 08744: loss did not improve from -177.52356\n",
      "Epoch 8745/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0922 - val_loss: -175.9487\n",
      "\n",
      "Epoch 08745: loss did not improve from -177.52356\n",
      "Epoch 8746/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2321 - val_loss: -175.4721\n",
      "\n",
      "Epoch 08746: loss did not improve from -177.52356\n",
      "Epoch 8747/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2033 - val_loss: -176.0264\n",
      "\n",
      "Epoch 08747: loss did not improve from -177.52356\n",
      "Epoch 8748/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2431 - val_loss: -175.7537\n",
      "\n",
      "Epoch 08748: loss did not improve from -177.52356\n",
      "Epoch 8749/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3071 - val_loss: -176.0368\n",
      "\n",
      "Epoch 08749: loss did not improve from -177.52356\n",
      "Epoch 8750/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1153 - val_loss: -175.7627\n",
      "\n",
      "Epoch 08750: loss did not improve from -177.52356\n",
      "Epoch 8751/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0833 - val_loss: -175.9502\n",
      "\n",
      "Epoch 08751: loss did not improve from -177.52356\n",
      "Epoch 8752/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4601 - val_loss: -176.1550\n",
      "\n",
      "Epoch 08752: loss did not improve from -177.52356\n",
      "Epoch 8753/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2957 - val_loss: -176.0206\n",
      "\n",
      "Epoch 08753: loss did not improve from -177.52356\n",
      "Epoch 8754/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2220 - val_loss: -175.9825\n",
      "\n",
      "Epoch 08754: loss did not improve from -177.52356\n",
      "Epoch 8755/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3771 - val_loss: -175.9126\n",
      "\n",
      "Epoch 08755: loss did not improve from -177.52356\n",
      "Epoch 8756/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3149 - val_loss: -176.1196\n",
      "\n",
      "Epoch 08756: loss did not improve from -177.52356\n",
      "Epoch 8757/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2242 - val_loss: -176.0071\n",
      "\n",
      "Epoch 08757: loss did not improve from -177.52356\n",
      "Epoch 8758/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1130 - val_loss: -176.0478\n",
      "\n",
      "Epoch 08758: loss did not improve from -177.52356\n",
      "Epoch 8759/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6214 - val_loss: -175.9588\n",
      "\n",
      "Epoch 08759: loss improved from -177.52356 to -177.62137, saving model to gendance.h5\n",
      "Epoch 8760/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -177.2707 - val_loss: -176.0436\n",
      "\n",
      "Epoch 08760: loss did not improve from -177.62137\n",
      "Epoch 8761/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2413 - val_loss: -175.8181\n",
      "\n",
      "Epoch 08761: loss did not improve from -177.62137\n",
      "Epoch 8762/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4749 - val_loss: -176.0694\n",
      "\n",
      "Epoch 08762: loss did not improve from -177.62137\n",
      "Epoch 8763/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2535 - val_loss: -175.8839\n",
      "\n",
      "Epoch 08763: loss did not improve from -177.62137\n",
      "Epoch 8764/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1571 - val_loss: -176.0857\n",
      "\n",
      "Epoch 08764: loss did not improve from -177.62137\n",
      "Epoch 8765/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4058 - val_loss: -176.0540\n",
      "\n",
      "Epoch 08765: loss did not improve from -177.62137\n",
      "Epoch 8766/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5325 - val_loss: -176.0927\n",
      "\n",
      "Epoch 08766: loss did not improve from -177.62137\n",
      "Epoch 8767/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5446 - val_loss: -176.0128\n",
      "\n",
      "Epoch 08767: loss did not improve from -177.62137\n",
      "Epoch 8768/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3542 - val_loss: -176.1995\n",
      "\n",
      "Epoch 08768: loss did not improve from -177.62137\n",
      "Epoch 8769/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3745 - val_loss: -175.9160\n",
      "\n",
      "Epoch 08769: loss did not improve from -177.62137\n",
      "Epoch 8770/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2115 - val_loss: -175.9495\n",
      "\n",
      "Epoch 08770: loss did not improve from -177.62137\n",
      "Epoch 8771/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6086 - val_loss: -175.9802\n",
      "\n",
      "Epoch 08771: loss did not improve from -177.62137\n",
      "Epoch 8772/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5626 - val_loss: -176.0895\n",
      "\n",
      "Epoch 08772: loss did not improve from -177.62137\n",
      "Epoch 8773/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4568 - val_loss: -176.0329\n",
      "\n",
      "Epoch 08773: loss did not improve from -177.62137\n",
      "Epoch 8774/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2280 - val_loss: -176.0267\n",
      "\n",
      "Epoch 08774: loss did not improve from -177.62137\n",
      "Epoch 8775/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5136 - val_loss: -176.0235\n",
      "\n",
      "Epoch 08775: loss did not improve from -177.62137\n",
      "Epoch 8776/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3371 - val_loss: -176.0610\n",
      "\n",
      "Epoch 08776: loss did not improve from -177.62137\n",
      "Epoch 8777/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4751 - val_loss: -176.0206\n",
      "\n",
      "Epoch 08777: loss did not improve from -177.62137\n",
      "Epoch 8778/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4510 - val_loss: -176.1172\n",
      "\n",
      "Epoch 08778: loss did not improve from -177.62137\n",
      "Epoch 8779/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4259 - val_loss: -175.9029\n",
      "\n",
      "Epoch 08779: loss did not improve from -177.62137\n",
      "Epoch 8780/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4954 - val_loss: -176.1242\n",
      "\n",
      "Epoch 08780: loss did not improve from -177.62137\n",
      "Epoch 8781/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2753 - val_loss: -176.1036\n",
      "\n",
      "Epoch 08781: loss did not improve from -177.62137\n",
      "Epoch 8782/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3709 - val_loss: -176.0383\n",
      "\n",
      "Epoch 08782: loss did not improve from -177.62137\n",
      "Epoch 8783/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2768 - val_loss: -176.0791\n",
      "\n",
      "Epoch 08783: loss did not improve from -177.62137\n",
      "Epoch 8784/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3002 - val_loss: -175.9979\n",
      "\n",
      "Epoch 08784: loss did not improve from -177.62137\n",
      "Epoch 8785/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0907 - val_loss: -176.1324\n",
      "\n",
      "Epoch 08785: loss did not improve from -177.62137\n",
      "Epoch 8786/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3899 - val_loss: -176.0053\n",
      "\n",
      "Epoch 08786: loss did not improve from -177.62137\n",
      "Epoch 8787/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6162 - val_loss: -176.2389\n",
      "\n",
      "Epoch 08787: loss did not improve from -177.62137\n",
      "Epoch 8788/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5466 - val_loss: -175.8703\n",
      "\n",
      "Epoch 08788: loss did not improve from -177.62137\n",
      "Epoch 8789/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2318 - val_loss: -176.0866\n",
      "\n",
      "Epoch 08789: loss did not improve from -177.62137\n",
      "Epoch 8790/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1375 - val_loss: -175.5307\n",
      "\n",
      "Epoch 08790: loss did not improve from -177.62137\n",
      "Epoch 8791/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1771 - val_loss: -176.1287\n",
      "\n",
      "Epoch 08791: loss did not improve from -177.62137\n",
      "Epoch 8792/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4978 - val_loss: -175.7861\n",
      "\n",
      "Epoch 08792: loss did not improve from -177.62137\n",
      "Epoch 8793/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4773 - val_loss: -176.1490\n",
      "\n",
      "Epoch 08793: loss did not improve from -177.62137\n",
      "Epoch 8794/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2250 - val_loss: -175.9000\n",
      "\n",
      "Epoch 08794: loss did not improve from -177.62137\n",
      "Epoch 8795/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6430 - val_loss: -176.1651\n",
      "\n",
      "Epoch 08795: loss improved from -177.62137 to -177.64303, saving model to gendance.h5\n",
      "Epoch 8796/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3496 - val_loss: -176.0074\n",
      "\n",
      "Epoch 08796: loss did not improve from -177.64303\n",
      "Epoch 8797/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4094 - val_loss: -176.0944\n",
      "\n",
      "Epoch 08797: loss did not improve from -177.64303\n",
      "Epoch 8798/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2598 - val_loss: -175.9193\n",
      "\n",
      "Epoch 08798: loss did not improve from -177.64303\n",
      "Epoch 8799/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5363 - val_loss: -176.1216\n",
      "\n",
      "Epoch 08799: loss did not improve from -177.64303\n",
      "Epoch 8800/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3141 - val_loss: -176.1042\n",
      "\n",
      "Epoch 08800: loss did not improve from -177.64303\n",
      "Epoch 8801/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1909 - val_loss: -176.0229\n",
      "\n",
      "Epoch 08801: loss did not improve from -177.64303\n",
      "Epoch 8802/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2561 - val_loss: -175.9437\n",
      "\n",
      "Epoch 08802: loss did not improve from -177.64303\n",
      "Epoch 8803/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4768 - val_loss: -176.0169\n",
      "\n",
      "Epoch 08803: loss did not improve from -177.64303\n",
      "Epoch 8804/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3746 - val_loss: -176.1136\n",
      "\n",
      "Epoch 08804: loss did not improve from -177.64303\n",
      "Epoch 8805/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3536 - val_loss: -176.1096\n",
      "\n",
      "Epoch 08805: loss did not improve from -177.64303\n",
      "Epoch 8806/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5963 - val_loss: -176.2130\n",
      "\n",
      "Epoch 08806: loss did not improve from -177.64303\n",
      "Epoch 8807/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5679 - val_loss: -175.9666\n",
      "\n",
      "Epoch 08807: loss did not improve from -177.64303\n",
      "Epoch 8808/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2590 - val_loss: -176.1206\n",
      "\n",
      "Epoch 08808: loss did not improve from -177.64303\n",
      "Epoch 8809/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2386 - val_loss: -175.9347\n",
      "\n",
      "Epoch 08809: loss did not improve from -177.64303\n",
      "Epoch 8810/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6009 - val_loss: -176.1037\n",
      "\n",
      "Epoch 08810: loss did not improve from -177.64303\n",
      "Epoch 8811/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2317 - val_loss: -175.9358\n",
      "\n",
      "Epoch 08811: loss did not improve from -177.64303\n",
      "Epoch 8812/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5058 - val_loss: -176.0794\n",
      "\n",
      "Epoch 08812: loss did not improve from -177.64303\n",
      "Epoch 8813/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4348 - val_loss: -176.0467\n",
      "\n",
      "Epoch 08813: loss did not improve from -177.64303\n",
      "Epoch 8814/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3653 - val_loss: -176.0428\n",
      "\n",
      "Epoch 08814: loss did not improve from -177.64303\n",
      "Epoch 8815/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1791 - val_loss: -176.0376\n",
      "\n",
      "Epoch 08815: loss did not improve from -177.64303\n",
      "Epoch 8816/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3912 - val_loss: -175.9616\n",
      "\n",
      "Epoch 08816: loss did not improve from -177.64303\n",
      "Epoch 8817/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0788 - val_loss: -175.9761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 08817: loss did not improve from -177.64303\n",
      "Epoch 8818/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4226 - val_loss: -175.9973\n",
      "\n",
      "Epoch 08818: loss did not improve from -177.64303\n",
      "Epoch 8819/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5145 - val_loss: -176.1854\n",
      "\n",
      "Epoch 08819: loss did not improve from -177.64303\n",
      "Epoch 8820/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2449 - val_loss: -175.9486\n",
      "\n",
      "Epoch 08820: loss did not improve from -177.64303\n",
      "Epoch 8821/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -177.3875 - val_loss: -176.1937\n",
      "\n",
      "Epoch 08821: loss did not improve from -177.64303\n",
      "Epoch 8822/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3702 - val_loss: -175.8565\n",
      "\n",
      "Epoch 08822: loss did not improve from -177.64303\n",
      "Epoch 8823/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0979 - val_loss: -176.0473\n",
      "\n",
      "Epoch 08823: loss did not improve from -177.64303\n",
      "Epoch 8824/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3244 - val_loss: -175.9381\n",
      "\n",
      "Epoch 08824: loss did not improve from -177.64303\n",
      "Epoch 8825/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4558 - val_loss: -176.1053\n",
      "\n",
      "Epoch 08825: loss did not improve from -177.64303\n",
      "Epoch 8826/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4762 - val_loss: -176.0968\n",
      "\n",
      "Epoch 08826: loss did not improve from -177.64303\n",
      "Epoch 8827/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3327 - val_loss: -176.1028\n",
      "\n",
      "Epoch 08827: loss did not improve from -177.64303\n",
      "Epoch 8828/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7708 - val_loss: -176.1183\n",
      "\n",
      "Epoch 08828: loss improved from -177.64303 to -177.77085, saving model to gendance.h5\n",
      "Epoch 8829/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -177.5110 - val_loss: -176.0102\n",
      "\n",
      "Epoch 08829: loss did not improve from -177.77085\n",
      "Epoch 8830/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3476 - val_loss: -175.9000\n",
      "\n",
      "Epoch 08830: loss did not improve from -177.77085\n",
      "Epoch 8831/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4110 - val_loss: -176.0872\n",
      "\n",
      "Epoch 08831: loss did not improve from -177.77085\n",
      "Epoch 8832/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4046 - val_loss: -176.1141\n",
      "\n",
      "Epoch 08832: loss did not improve from -177.77085\n",
      "Epoch 8833/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2365 - val_loss: -176.0473\n",
      "\n",
      "Epoch 08833: loss did not improve from -177.77085\n",
      "Epoch 8834/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7160 - val_loss: -175.9969\n",
      "\n",
      "Epoch 08834: loss did not improve from -177.77085\n",
      "Epoch 8835/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3820 - val_loss: -176.1854\n",
      "\n",
      "Epoch 08835: loss did not improve from -177.77085\n",
      "Epoch 8836/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1949 - val_loss: -175.6239\n",
      "\n",
      "Epoch 08836: loss did not improve from -177.77085\n",
      "Epoch 8837/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3559 - val_loss: -176.2188\n",
      "\n",
      "Epoch 08837: loss did not improve from -177.77085\n",
      "Epoch 8838/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4464 - val_loss: -175.9610\n",
      "\n",
      "Epoch 08838: loss did not improve from -177.77085\n",
      "Epoch 8839/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4240 - val_loss: -176.1472\n",
      "\n",
      "Epoch 08839: loss did not improve from -177.77085\n",
      "Epoch 8840/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5935 - val_loss: -176.2932\n",
      "\n",
      "Epoch 08840: loss did not improve from -177.77085\n",
      "Epoch 8841/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6554 - val_loss: -175.9639\n",
      "\n",
      "Epoch 08841: loss did not improve from -177.77085\n",
      "Epoch 8842/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5851 - val_loss: -176.2236\n",
      "\n",
      "Epoch 08842: loss did not improve from -177.77085\n",
      "Epoch 8843/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4319 - val_loss: -176.0962\n",
      "\n",
      "Epoch 08843: loss did not improve from -177.77085\n",
      "Epoch 8844/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4869 - val_loss: -176.2020\n",
      "\n",
      "Epoch 08844: loss did not improve from -177.77085\n",
      "Epoch 8845/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5924 - val_loss: -176.1328\n",
      "\n",
      "Epoch 08845: loss did not improve from -177.77085\n",
      "Epoch 8846/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6629 - val_loss: -176.0746\n",
      "\n",
      "Epoch 08846: loss did not improve from -177.77085\n",
      "Epoch 8847/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4904 - val_loss: -176.1854\n",
      "\n",
      "Epoch 08847: loss did not improve from -177.77085\n",
      "Epoch 8848/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6315 - val_loss: -175.9867\n",
      "\n",
      "Epoch 08848: loss did not improve from -177.77085\n",
      "Epoch 8849/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2602 - val_loss: -176.0619\n",
      "\n",
      "Epoch 08849: loss did not improve from -177.77085\n",
      "Epoch 8850/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4522 - val_loss: -175.9917\n",
      "\n",
      "Epoch 08850: loss did not improve from -177.77085\n",
      "Epoch 8851/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3516 - val_loss: -176.1030\n",
      "\n",
      "Epoch 08851: loss did not improve from -177.77085\n",
      "Epoch 8852/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3231 - val_loss: -175.9076\n",
      "\n",
      "Epoch 08852: loss did not improve from -177.77085\n",
      "Epoch 8853/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3163 - val_loss: -176.1861\n",
      "\n",
      "Epoch 08853: loss did not improve from -177.77085\n",
      "Epoch 8854/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5290 - val_loss: -176.0160\n",
      "\n",
      "Epoch 08854: loss did not improve from -177.77085\n",
      "Epoch 8855/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3850 - val_loss: -176.0675\n",
      "\n",
      "Epoch 08855: loss did not improve from -177.77085\n",
      "Epoch 8856/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4904 - val_loss: -176.0010\n",
      "\n",
      "Epoch 08856: loss did not improve from -177.77085\n",
      "Epoch 8857/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4104 - val_loss: -176.2950\n",
      "\n",
      "Epoch 08857: loss did not improve from -177.77085\n",
      "Epoch 8858/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3320 - val_loss: -176.0129\n",
      "\n",
      "Epoch 08858: loss did not improve from -177.77085\n",
      "Epoch 8859/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3372 - val_loss: -176.0235\n",
      "\n",
      "Epoch 08859: loss did not improve from -177.77085\n",
      "Epoch 8860/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4807 - val_loss: -175.6935\n",
      "\n",
      "Epoch 08860: loss did not improve from -177.77085\n",
      "Epoch 8861/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4477 - val_loss: -176.1766\n",
      "\n",
      "Epoch 08861: loss did not improve from -177.77085\n",
      "Epoch 8862/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1865 - val_loss: -175.7213\n",
      "\n",
      "Epoch 08862: loss did not improve from -177.77085\n",
      "Epoch 8863/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3495 - val_loss: -176.0498\n",
      "\n",
      "Epoch 08863: loss did not improve from -177.77085\n",
      "Epoch 8864/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3870 - val_loss: -175.9738\n",
      "\n",
      "Epoch 08864: loss did not improve from -177.77085\n",
      "Epoch 8865/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3372 - val_loss: -176.0654\n",
      "\n",
      "Epoch 08865: loss did not improve from -177.77085\n",
      "Epoch 8866/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3678 - val_loss: -176.1347\n",
      "\n",
      "Epoch 08866: loss did not improve from -177.77085\n",
      "Epoch 8867/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1997 - val_loss: -175.9987\n",
      "\n",
      "Epoch 08867: loss did not improve from -177.77085\n",
      "Epoch 8868/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4086 - val_loss: -176.1669\n",
      "\n",
      "Epoch 08868: loss did not improve from -177.77085\n",
      "Epoch 8869/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2832 - val_loss: -175.8177\n",
      "\n",
      "Epoch 08869: loss did not improve from -177.77085\n",
      "Epoch 8870/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6673 - val_loss: -176.3088\n",
      "\n",
      "Epoch 08870: loss did not improve from -177.77085\n",
      "Epoch 8871/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1532 - val_loss: -175.8348\n",
      "\n",
      "Epoch 08871: loss did not improve from -177.77085\n",
      "Epoch 8872/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3998 - val_loss: -176.2602\n",
      "\n",
      "Epoch 08872: loss did not improve from -177.77085\n",
      "Epoch 8873/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6346 - val_loss: -176.0914\n",
      "\n",
      "Epoch 08873: loss did not improve from -177.77085\n",
      "Epoch 8874/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4769 - val_loss: -176.2242\n",
      "\n",
      "Epoch 08874: loss did not improve from -177.77085\n",
      "Epoch 8875/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5136 - val_loss: -176.1247\n",
      "\n",
      "Epoch 08875: loss did not improve from -177.77085\n",
      "Epoch 8876/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5267 - val_loss: -176.0954\n",
      "\n",
      "Epoch 08876: loss did not improve from -177.77085\n",
      "Epoch 8877/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4198 - val_loss: -176.0866\n",
      "\n",
      "Epoch 08877: loss did not improve from -177.77085\n",
      "Epoch 8878/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5572 - val_loss: -176.0530\n",
      "\n",
      "Epoch 08878: loss did not improve from -177.77085\n",
      "Epoch 8879/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5946 - val_loss: -176.2794\n",
      "\n",
      "Epoch 08879: loss did not improve from -177.77085\n",
      "Epoch 8880/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5925 - val_loss: -175.9779\n",
      "\n",
      "Epoch 08880: loss did not improve from -177.77085\n",
      "Epoch 8881/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4696 - val_loss: -176.1145\n",
      "\n",
      "Epoch 08881: loss did not improve from -177.77085\n",
      "Epoch 8882/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3619 - val_loss: -176.0406\n",
      "\n",
      "Epoch 08882: loss did not improve from -177.77085\n",
      "Epoch 8883/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5221 - val_loss: -176.0925\n",
      "\n",
      "Epoch 08883: loss did not improve from -177.77085\n",
      "Epoch 8884/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -177.2474 - val_loss: -176.1229\n",
      "\n",
      "Epoch 08884: loss did not improve from -177.77085\n",
      "Epoch 8885/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5358 - val_loss: -175.9945\n",
      "\n",
      "Epoch 08885: loss did not improve from -177.77085\n",
      "Epoch 8886/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3210 - val_loss: -176.0270\n",
      "\n",
      "Epoch 08886: loss did not improve from -177.77085\n",
      "Epoch 8887/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2739 - val_loss: -176.0583\n",
      "\n",
      "Epoch 08887: loss did not improve from -177.77085\n",
      "Epoch 8888/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4541 - val_loss: -176.0124\n",
      "\n",
      "Epoch 08888: loss did not improve from -177.77085\n",
      "Epoch 8889/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6143 - val_loss: -176.1256\n",
      "\n",
      "Epoch 08889: loss did not improve from -177.77085\n",
      "Epoch 8890/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6404 - val_loss: -176.1864\n",
      "\n",
      "Epoch 08890: loss did not improve from -177.77085\n",
      "Epoch 8891/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2400 - val_loss: -175.9432\n",
      "\n",
      "Epoch 08891: loss did not improve from -177.77085\n",
      "Epoch 8892/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -177.3774 - val_loss: -176.0565\n",
      "\n",
      "Epoch 08892: loss did not improve from -177.77085\n",
      "Epoch 8893/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3693 - val_loss: -176.0689\n",
      "\n",
      "Epoch 08893: loss did not improve from -177.77085\n",
      "Epoch 8894/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3601 - val_loss: -175.9939\n",
      "\n",
      "Epoch 08894: loss did not improve from -177.77085\n",
      "Epoch 8895/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4246 - val_loss: -176.0866\n",
      "\n",
      "Epoch 08895: loss did not improve from -177.77085\n",
      "Epoch 8896/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6897 - val_loss: -176.1716\n",
      "\n",
      "Epoch 08896: loss did not improve from -177.77085\n",
      "Epoch 8897/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5091 - val_loss: -176.0749\n",
      "\n",
      "Epoch 08897: loss did not improve from -177.77085\n",
      "Epoch 8898/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4377 - val_loss: -176.0852\n",
      "\n",
      "Epoch 08898: loss did not improve from -177.77085\n",
      "Epoch 8899/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7846 - val_loss: -176.2233\n",
      "\n",
      "Epoch 08899: loss improved from -177.77085 to -177.78458, saving model to gendance.h5\n",
      "Epoch 8900/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -177.4131 - val_loss: -176.1817\n",
      "\n",
      "Epoch 08900: loss did not improve from -177.78458\n",
      "Epoch 8901/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4784 - val_loss: -176.0863\n",
      "\n",
      "Epoch 08901: loss did not improve from -177.78458\n",
      "Epoch 8902/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3484 - val_loss: -176.1001\n",
      "\n",
      "Epoch 08902: loss did not improve from -177.78458\n",
      "Epoch 8903/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6074 - val_loss: -176.0997\n",
      "\n",
      "Epoch 08903: loss did not improve from -177.78458\n",
      "Epoch 8904/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4738 - val_loss: -176.0080\n",
      "\n",
      "Epoch 08904: loss did not improve from -177.78458\n",
      "Epoch 8905/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -177.3079 - val_loss: -176.0795\n",
      "\n",
      "Epoch 08905: loss did not improve from -177.78458\n",
      "Epoch 8906/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3178 - val_loss: -176.1837\n",
      "\n",
      "Epoch 08906: loss did not improve from -177.78458\n",
      "Epoch 8907/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5333 - val_loss: -176.1812\n",
      "\n",
      "Epoch 08907: loss did not improve from -177.78458\n",
      "Epoch 8908/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4488 - val_loss: -176.0462\n",
      "\n",
      "Epoch 08908: loss did not improve from -177.78458\n",
      "Epoch 8909/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4040 - val_loss: -176.0416\n",
      "\n",
      "Epoch 08909: loss did not improve from -177.78458\n",
      "Epoch 8910/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4067 - val_loss: -176.0330\n",
      "\n",
      "Epoch 08910: loss did not improve from -177.78458\n",
      "Epoch 8911/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4837 - val_loss: -176.1620\n",
      "\n",
      "Epoch 08911: loss did not improve from -177.78458\n",
      "Epoch 8912/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -177.7131 - val_loss: -176.1424\n",
      "\n",
      "Epoch 08912: loss did not improve from -177.78458\n",
      "Epoch 8913/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6535 - val_loss: -176.1838\n",
      "\n",
      "Epoch 08913: loss did not improve from -177.78458\n",
      "Epoch 8914/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4295 - val_loss: -176.0059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 08914: loss did not improve from -177.78458\n",
      "Epoch 8915/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4760 - val_loss: -176.0756\n",
      "\n",
      "Epoch 08915: loss did not improve from -177.78458\n",
      "Epoch 8916/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2621 - val_loss: -176.0157\n",
      "\n",
      "Epoch 08916: loss did not improve from -177.78458\n",
      "Epoch 8917/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4488 - val_loss: -176.2608\n",
      "\n",
      "Epoch 08917: loss did not improve from -177.78458\n",
      "Epoch 8918/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3631 - val_loss: -175.8727\n",
      "\n",
      "Epoch 08918: loss did not improve from -177.78458\n",
      "Epoch 8919/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -177.3460 - val_loss: -176.1607\n",
      "\n",
      "Epoch 08919: loss did not improve from -177.78458\n",
      "Epoch 8920/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5083 - val_loss: -175.6619\n",
      "\n",
      "Epoch 08920: loss did not improve from -177.78458\n",
      "Epoch 8921/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5025 - val_loss: -176.2115\n",
      "\n",
      "Epoch 08921: loss did not improve from -177.78458\n",
      "Epoch 8922/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5471 - val_loss: -175.8169\n",
      "\n",
      "Epoch 08922: loss did not improve from -177.78458\n",
      "Epoch 8923/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6024 - val_loss: -176.2456\n",
      "\n",
      "Epoch 08923: loss did not improve from -177.78458\n",
      "Epoch 8924/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3835 - val_loss: -175.8846\n",
      "\n",
      "Epoch 08924: loss did not improve from -177.78458\n",
      "Epoch 8925/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7007 - val_loss: -176.2424\n",
      "\n",
      "Epoch 08925: loss did not improve from -177.78458\n",
      "Epoch 8926/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3392 - val_loss: -175.8614\n",
      "\n",
      "Epoch 08926: loss did not improve from -177.78458\n",
      "Epoch 8927/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5162 - val_loss: -176.2088\n",
      "\n",
      "Epoch 08927: loss did not improve from -177.78458\n",
      "Epoch 8928/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3987 - val_loss: -176.1284\n",
      "\n",
      "Epoch 08928: loss did not improve from -177.78458\n",
      "Epoch 8929/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5377 - val_loss: -176.2548\n",
      "\n",
      "Epoch 08929: loss did not improve from -177.78458\n",
      "Epoch 8930/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6707 - val_loss: -176.0816\n",
      "\n",
      "Epoch 08930: loss did not improve from -177.78458\n",
      "Epoch 8931/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4913 - val_loss: -176.2184\n",
      "\n",
      "Epoch 08931: loss did not improve from -177.78458\n",
      "Epoch 8932/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5592 - val_loss: -176.0624\n",
      "\n",
      "Epoch 08932: loss did not improve from -177.78458\n",
      "Epoch 8933/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4684 - val_loss: -176.2955\n",
      "\n",
      "Epoch 08933: loss did not improve from -177.78458\n",
      "Epoch 8934/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4245 - val_loss: -176.1086\n",
      "\n",
      "Epoch 08934: loss did not improve from -177.78458\n",
      "Epoch 8935/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2778 - val_loss: -176.1846\n",
      "\n",
      "Epoch 08935: loss did not improve from -177.78458\n",
      "Epoch 8936/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4218 - val_loss: -176.1703\n",
      "\n",
      "Epoch 08936: loss did not improve from -177.78458\n",
      "Epoch 8937/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4438 - val_loss: -175.9857\n",
      "\n",
      "Epoch 08937: loss did not improve from -177.78458\n",
      "Epoch 8938/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2589 - val_loss: -176.1766\n",
      "\n",
      "Epoch 08938: loss did not improve from -177.78458\n",
      "Epoch 8939/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4516 - val_loss: -175.8707\n",
      "\n",
      "Epoch 08939: loss did not improve from -177.78458\n",
      "Epoch 8940/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5546 - val_loss: -176.2181\n",
      "\n",
      "Epoch 08940: loss did not improve from -177.78458\n",
      "Epoch 8941/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5080 - val_loss: -175.9829\n",
      "\n",
      "Epoch 08941: loss did not improve from -177.78458\n",
      "Epoch 8942/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5144 - val_loss: -176.1800\n",
      "\n",
      "Epoch 08942: loss did not improve from -177.78458\n",
      "Epoch 8943/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3301 - val_loss: -176.0850\n",
      "\n",
      "Epoch 08943: loss did not improve from -177.78458\n",
      "Epoch 8944/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6616 - val_loss: -176.2042\n",
      "\n",
      "Epoch 08944: loss did not improve from -177.78458\n",
      "Epoch 8945/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6143 - val_loss: -176.0427\n",
      "\n",
      "Epoch 08945: loss did not improve from -177.78458\n",
      "Epoch 8946/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7816 - val_loss: -176.1929\n",
      "\n",
      "Epoch 08946: loss did not improve from -177.78458\n",
      "Epoch 8947/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.0548 - val_loss: -175.7556\n",
      "\n",
      "Epoch 08947: loss did not improve from -177.78458\n",
      "Epoch 8948/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4950 - val_loss: -176.2450\n",
      "\n",
      "Epoch 08948: loss did not improve from -177.78458\n",
      "Epoch 8949/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5209 - val_loss: -175.9713\n",
      "\n",
      "Epoch 08949: loss did not improve from -177.78458\n",
      "Epoch 8950/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4026 - val_loss: -176.1132\n",
      "\n",
      "Epoch 08950: loss did not improve from -177.78458\n",
      "Epoch 8951/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5347 - val_loss: -175.8971\n",
      "\n",
      "Epoch 08951: loss did not improve from -177.78458\n",
      "Epoch 8952/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7388 - val_loss: -176.1485\n",
      "\n",
      "Epoch 08952: loss did not improve from -177.78458\n",
      "Epoch 8953/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4826 - val_loss: -176.0656\n",
      "\n",
      "Epoch 08953: loss did not improve from -177.78458\n",
      "Epoch 8954/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4706 - val_loss: -176.1310\n",
      "\n",
      "Epoch 08954: loss did not improve from -177.78458\n",
      "Epoch 8955/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5888 - val_loss: -176.0472\n",
      "\n",
      "Epoch 08955: loss did not improve from -177.78458\n",
      "Epoch 8956/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5319 - val_loss: -176.0577\n",
      "\n",
      "Epoch 08956: loss did not improve from -177.78458\n",
      "Epoch 8957/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5227 - val_loss: -176.1349\n",
      "\n",
      "Epoch 08957: loss did not improve from -177.78458\n",
      "Epoch 8958/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5027 - val_loss: -176.1395\n",
      "\n",
      "Epoch 08958: loss did not improve from -177.78458\n",
      "Epoch 8959/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5145 - val_loss: -176.2083\n",
      "\n",
      "Epoch 08959: loss did not improve from -177.78458\n",
      "Epoch 8960/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4881 - val_loss: -176.1762\n",
      "\n",
      "Epoch 08960: loss did not improve from -177.78458\n",
      "Epoch 8961/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3003 - val_loss: -176.0492\n",
      "\n",
      "Epoch 08961: loss did not improve from -177.78458\n",
      "Epoch 8962/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3269 - val_loss: -175.9029\n",
      "\n",
      "Epoch 08962: loss did not improve from -177.78458\n",
      "Epoch 8963/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.1957 - val_loss: -176.1356\n",
      "\n",
      "Epoch 08963: loss did not improve from -177.78458\n",
      "Epoch 8964/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4312 - val_loss: -175.9387\n",
      "\n",
      "Epoch 08964: loss did not improve from -177.78458\n",
      "Epoch 8965/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5377 - val_loss: -176.1869\n",
      "\n",
      "Epoch 08965: loss did not improve from -177.78458\n",
      "Epoch 8966/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3995 - val_loss: -175.8942\n",
      "\n",
      "Epoch 08966: loss did not improve from -177.78458\n",
      "Epoch 8967/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6409 - val_loss: -176.2897\n",
      "\n",
      "Epoch 08967: loss did not improve from -177.78458\n",
      "Epoch 8968/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2625 - val_loss: -175.9090\n",
      "\n",
      "Epoch 08968: loss did not improve from -177.78458\n",
      "Epoch 8969/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6254 - val_loss: -176.2517\n",
      "\n",
      "Epoch 08969: loss did not improve from -177.78458\n",
      "Epoch 8970/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6530 - val_loss: -176.1125\n",
      "\n",
      "Epoch 08970: loss did not improve from -177.78458\n",
      "Epoch 8971/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4759 - val_loss: -176.1786\n",
      "\n",
      "Epoch 08971: loss did not improve from -177.78458\n",
      "Epoch 8972/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5871 - val_loss: -176.1446\n",
      "\n",
      "Epoch 08972: loss did not improve from -177.78458\n",
      "Epoch 8973/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6478 - val_loss: -176.0547\n",
      "\n",
      "Epoch 08973: loss did not improve from -177.78458\n",
      "Epoch 8974/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6339 - val_loss: -176.1368\n",
      "\n",
      "Epoch 08974: loss did not improve from -177.78458\n",
      "Epoch 8975/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4806 - val_loss: -175.9987\n",
      "\n",
      "Epoch 08975: loss did not improve from -177.78458\n",
      "Epoch 8976/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4589 - val_loss: -176.0411\n",
      "\n",
      "Epoch 08976: loss did not improve from -177.78458\n",
      "Epoch 8977/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6354 - val_loss: -176.1356\n",
      "\n",
      "Epoch 08977: loss did not improve from -177.78458\n",
      "Epoch 8978/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5668 - val_loss: -176.1731\n",
      "\n",
      "Epoch 08978: loss did not improve from -177.78458\n",
      "Epoch 8979/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4682 - val_loss: -175.9278\n",
      "\n",
      "Epoch 08979: loss did not improve from -177.78458\n",
      "Epoch 8980/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5948 - val_loss: -176.2277\n",
      "\n",
      "Epoch 08980: loss did not improve from -177.78458\n",
      "Epoch 8981/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5792 - val_loss: -175.9619\n",
      "\n",
      "Epoch 08981: loss did not improve from -177.78458\n",
      "Epoch 8982/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6154 - val_loss: -176.2080\n",
      "\n",
      "Epoch 08982: loss did not improve from -177.78458\n",
      "Epoch 8983/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4810 - val_loss: -175.9897\n",
      "\n",
      "Epoch 08983: loss did not improve from -177.78458\n",
      "Epoch 8984/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3739 - val_loss: -176.2049\n",
      "\n",
      "Epoch 08984: loss did not improve from -177.78458\n",
      "Epoch 8985/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6221 - val_loss: -175.9648\n",
      "\n",
      "Epoch 08985: loss did not improve from -177.78458\n",
      "Epoch 8986/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4618 - val_loss: -176.1322\n",
      "\n",
      "Epoch 08986: loss did not improve from -177.78458\n",
      "Epoch 8987/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2664 - val_loss: -175.8963\n",
      "\n",
      "Epoch 08987: loss did not improve from -177.78458\n",
      "Epoch 8988/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5699 - val_loss: -176.1965\n",
      "\n",
      "Epoch 08988: loss did not improve from -177.78458\n",
      "Epoch 8989/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3297 - val_loss: -176.1010\n",
      "\n",
      "Epoch 08989: loss did not improve from -177.78458\n",
      "Epoch 8990/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7144 - val_loss: -176.1611\n",
      "\n",
      "Epoch 08990: loss did not improve from -177.78458\n",
      "Epoch 8991/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5936 - val_loss: -176.2267\n",
      "\n",
      "Epoch 08991: loss did not improve from -177.78458\n",
      "Epoch 8992/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3684 - val_loss: -175.9252\n",
      "\n",
      "Epoch 08992: loss did not improve from -177.78458\n",
      "Epoch 8993/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6308 - val_loss: -176.3227\n",
      "\n",
      "Epoch 08993: loss did not improve from -177.78458\n",
      "Epoch 8994/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5025 - val_loss: -175.9579\n",
      "\n",
      "Epoch 08994: loss did not improve from -177.78458\n",
      "Epoch 8995/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7082 - val_loss: -176.3081\n",
      "\n",
      "Epoch 08995: loss did not improve from -177.78458\n",
      "Epoch 8996/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4199 - val_loss: -175.9001\n",
      "\n",
      "Epoch 08996: loss did not improve from -177.78458\n",
      "Epoch 8997/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4716 - val_loss: -176.2023\n",
      "\n",
      "Epoch 08997: loss did not improve from -177.78458\n",
      "Epoch 8998/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4195 - val_loss: -176.0402\n",
      "\n",
      "Epoch 08998: loss did not improve from -177.78458\n",
      "Epoch 8999/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7188 - val_loss: -176.3507\n",
      "\n",
      "Epoch 08999: loss did not improve from -177.78458\n",
      "Epoch 9000/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4960 - val_loss: -176.1226\n",
      "\n",
      "Epoch 09000: loss did not improve from -177.78458\n",
      "Epoch 9001/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4751 - val_loss: -176.3069\n",
      "\n",
      "Epoch 09001: loss did not improve from -177.78458\n",
      "Epoch 9002/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3815 - val_loss: -176.0857\n",
      "\n",
      "Epoch 09002: loss did not improve from -177.78458\n",
      "Epoch 9003/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4321 - val_loss: -176.1200\n",
      "\n",
      "Epoch 09003: loss did not improve from -177.78458\n",
      "Epoch 9004/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5369 - val_loss: -176.1390\n",
      "\n",
      "Epoch 09004: loss did not improve from -177.78458\n",
      "Epoch 9005/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6336 - val_loss: -176.0332\n",
      "\n",
      "Epoch 09005: loss did not improve from -177.78458\n",
      "Epoch 9006/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2442 - val_loss: -176.0967\n",
      "\n",
      "Epoch 09006: loss did not improve from -177.78458\n",
      "Epoch 9007/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5927 - val_loss: -176.1448\n",
      "\n",
      "Epoch 09007: loss did not improve from -177.78458\n",
      "Epoch 9008/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5519 - val_loss: -176.2636\n",
      "\n",
      "Epoch 09008: loss did not improve from -177.78458\n",
      "Epoch 9009/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4545 - val_loss: -176.1847\n",
      "\n",
      "Epoch 09009: loss did not improve from -177.78458\n",
      "Epoch 9010/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6106 - val_loss: -176.2255\n",
      "\n",
      "Epoch 09010: loss did not improve from -177.78458\n",
      "Epoch 9011/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4565 - val_loss: -176.1595\n",
      "\n",
      "Epoch 09011: loss did not improve from -177.78458\n",
      "Epoch 9012/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5737 - val_loss: -176.2005\n",
      "\n",
      "Epoch 09012: loss did not improve from -177.78458\n",
      "Epoch 9013/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6093 - val_loss: -176.1467\n",
      "\n",
      "Epoch 09013: loss did not improve from -177.78458\n",
      "Epoch 9014/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7367 - val_loss: -176.1580\n",
      "\n",
      "Epoch 09014: loss did not improve from -177.78458\n",
      "Epoch 9015/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6292 - val_loss: -176.2579\n",
      "\n",
      "Epoch 09015: loss did not improve from -177.78458\n",
      "Epoch 9016/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3398 - val_loss: -176.0872\n",
      "\n",
      "Epoch 09016: loss did not improve from -177.78458\n",
      "Epoch 9017/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6090 - val_loss: -176.1638\n",
      "\n",
      "Epoch 09017: loss did not improve from -177.78458\n",
      "Epoch 9018/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6838 - val_loss: -176.0880\n",
      "\n",
      "Epoch 09018: loss did not improve from -177.78458\n",
      "Epoch 9019/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4829 - val_loss: -176.1594\n",
      "\n",
      "Epoch 09019: loss did not improve from -177.78458\n",
      "Epoch 9020/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5555 - val_loss: -175.9536\n",
      "\n",
      "Epoch 09020: loss did not improve from -177.78458\n",
      "Epoch 9021/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3093 - val_loss: -176.2445\n",
      "\n",
      "Epoch 09021: loss did not improve from -177.78458\n",
      "Epoch 9022/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6142 - val_loss: -176.0643\n",
      "\n",
      "Epoch 09022: loss did not improve from -177.78458\n",
      "Epoch 9023/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -177.5967 - val_loss: -176.3044\n",
      "\n",
      "Epoch 09023: loss did not improve from -177.78458\n",
      "Epoch 9024/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6291 - val_loss: -176.0785\n",
      "\n",
      "Epoch 09024: loss did not improve from -177.78458\n",
      "Epoch 9025/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5486 - val_loss: -176.2204\n",
      "\n",
      "Epoch 09025: loss did not improve from -177.78458\n",
      "Epoch 9026/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4516 - val_loss: -176.0535\n",
      "\n",
      "Epoch 09026: loss did not improve from -177.78458\n",
      "Epoch 9027/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7877 - val_loss: -176.3150\n",
      "\n",
      "Epoch 09027: loss improved from -177.78458 to -177.78773, saving model to gendance.h5\n",
      "Epoch 9028/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4825 - val_loss: -176.0103\n",
      "\n",
      "Epoch 09028: loss did not improve from -177.78773\n",
      "Epoch 9029/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8338 - val_loss: -176.4355\n",
      "\n",
      "Epoch 09029: loss improved from -177.78773 to -177.83376, saving model to gendance.h5\n",
      "Epoch 9030/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6484 - val_loss: -175.9310\n",
      "\n",
      "Epoch 09030: loss did not improve from -177.83376\n",
      "Epoch 9031/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4623 - val_loss: -176.1599\n",
      "\n",
      "Epoch 09031: loss did not improve from -177.83376\n",
      "Epoch 9032/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5732 - val_loss: -175.8181\n",
      "\n",
      "Epoch 09032: loss did not improve from -177.83376\n",
      "Epoch 9033/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -177.6777 - val_loss: -176.1410\n",
      "\n",
      "Epoch 09033: loss did not improve from -177.83376\n",
      "Epoch 9034/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5430 - val_loss: -175.9961\n",
      "\n",
      "Epoch 09034: loss did not improve from -177.83376\n",
      "Epoch 9035/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5439 - val_loss: -175.9961\n",
      "\n",
      "Epoch 09035: loss did not improve from -177.83376\n",
      "Epoch 9036/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4692 - val_loss: -176.1264\n",
      "\n",
      "Epoch 09036: loss did not improve from -177.83376\n",
      "Epoch 9037/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7186 - val_loss: -176.1269\n",
      "\n",
      "Epoch 09037: loss did not improve from -177.83376\n",
      "Epoch 9038/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4424 - val_loss: -176.2271\n",
      "\n",
      "Epoch 09038: loss did not improve from -177.83376\n",
      "Epoch 9039/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5589 - val_loss: -176.1115\n",
      "\n",
      "Epoch 09039: loss did not improve from -177.83376\n",
      "Epoch 9040/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3543 - val_loss: -176.2614\n",
      "\n",
      "Epoch 09040: loss did not improve from -177.83376\n",
      "Epoch 9041/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6687 - val_loss: -176.0629\n",
      "\n",
      "Epoch 09041: loss did not improve from -177.83376\n",
      "Epoch 9042/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6870 - val_loss: -176.2308\n",
      "\n",
      "Epoch 09042: loss did not improve from -177.83376\n",
      "Epoch 9043/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5631 - val_loss: -176.0907\n",
      "\n",
      "Epoch 09043: loss did not improve from -177.83376\n",
      "Epoch 9044/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5062 - val_loss: -176.1377\n",
      "\n",
      "Epoch 09044: loss did not improve from -177.83376\n",
      "Epoch 9045/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8255 - val_loss: -176.0744\n",
      "\n",
      "Epoch 09045: loss did not improve from -177.83376\n",
      "Epoch 9046/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6102 - val_loss: -176.1737\n",
      "\n",
      "Epoch 09046: loss did not improve from -177.83376\n",
      "Epoch 9047/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4399 - val_loss: -176.0589\n",
      "\n",
      "Epoch 09047: loss did not improve from -177.83376\n",
      "Epoch 9048/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4945 - val_loss: -176.0853\n",
      "\n",
      "Epoch 09048: loss did not improve from -177.83376\n",
      "Epoch 9049/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7310 - val_loss: -176.1644\n",
      "\n",
      "Epoch 09049: loss did not improve from -177.83376\n",
      "Epoch 9050/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9957 - val_loss: -176.1544\n",
      "\n",
      "Epoch 09050: loss improved from -177.83376 to -177.99566, saving model to gendance.h5\n",
      "Epoch 9051/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5469 - val_loss: -176.1629\n",
      "\n",
      "Epoch 09051: loss did not improve from -177.99566\n",
      "Epoch 9052/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6676 - val_loss: -176.1395\n",
      "\n",
      "Epoch 09052: loss did not improve from -177.99566\n",
      "Epoch 9053/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5848 - val_loss: -176.3363\n",
      "\n",
      "Epoch 09053: loss did not improve from -177.99566\n",
      "Epoch 9054/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6380 - val_loss: -175.9479\n",
      "\n",
      "Epoch 09054: loss did not improve from -177.99566\n",
      "Epoch 9055/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6905 - val_loss: -176.3360\n",
      "\n",
      "Epoch 09055: loss did not improve from -177.99566\n",
      "Epoch 9056/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3527 - val_loss: -176.0074\n",
      "\n",
      "Epoch 09056: loss did not improve from -177.99566\n",
      "Epoch 9057/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5308 - val_loss: -176.2162\n",
      "\n",
      "Epoch 09057: loss did not improve from -177.99566\n",
      "Epoch 9058/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7205 - val_loss: -176.2708\n",
      "\n",
      "Epoch 09058: loss did not improve from -177.99566\n",
      "Epoch 9059/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6736 - val_loss: -176.2622\n",
      "\n",
      "Epoch 09059: loss did not improve from -177.99566\n",
      "Epoch 9060/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5350 - val_loss: -176.1896\n",
      "\n",
      "Epoch 09060: loss did not improve from -177.99566\n",
      "Epoch 9061/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5506 - val_loss: -176.2068\n",
      "\n",
      "Epoch 09061: loss did not improve from -177.99566\n",
      "Epoch 9062/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5126 - val_loss: -176.1358\n",
      "\n",
      "Epoch 09062: loss did not improve from -177.99566\n",
      "Epoch 9063/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -177.4480 - val_loss: -176.1400\n",
      "\n",
      "Epoch 09063: loss did not improve from -177.99566\n",
      "Epoch 9064/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5246 - val_loss: -176.2435\n",
      "\n",
      "Epoch 09064: loss did not improve from -177.99566\n",
      "Epoch 9065/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5271 - val_loss: -176.0676\n",
      "\n",
      "Epoch 09065: loss did not improve from -177.99566\n",
      "Epoch 9066/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5758 - val_loss: -176.1495\n",
      "\n",
      "Epoch 09066: loss did not improve from -177.99566\n",
      "Epoch 9067/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5529 - val_loss: -175.9896\n",
      "\n",
      "Epoch 09067: loss did not improve from -177.99566\n",
      "Epoch 9068/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5785 - val_loss: -176.1255\n",
      "\n",
      "Epoch 09068: loss did not improve from -177.99566\n",
      "Epoch 9069/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5807 - val_loss: -176.1412\n",
      "\n",
      "Epoch 09069: loss did not improve from -177.99566\n",
      "Epoch 9070/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7037 - val_loss: -176.2809\n",
      "\n",
      "Epoch 09070: loss did not improve from -177.99566\n",
      "Epoch 9071/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7379 - val_loss: -176.2161\n",
      "\n",
      "Epoch 09071: loss did not improve from -177.99566\n",
      "Epoch 9072/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6372 - val_loss: -176.1694\n",
      "\n",
      "Epoch 09072: loss did not improve from -177.99566\n",
      "Epoch 9073/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6295 - val_loss: -176.2062\n",
      "\n",
      "Epoch 09073: loss did not improve from -177.99566\n",
      "Epoch 9074/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -177.6894 - val_loss: -175.9681\n",
      "\n",
      "Epoch 09074: loss did not improve from -177.99566\n",
      "Epoch 9075/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8255 - val_loss: -176.2297\n",
      "\n",
      "Epoch 09075: loss did not improve from -177.99566\n",
      "Epoch 9076/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6562 - val_loss: -176.1869\n",
      "\n",
      "Epoch 09076: loss did not improve from -177.99566\n",
      "Epoch 9077/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5102 - val_loss: -176.2256\n",
      "\n",
      "Epoch 09077: loss did not improve from -177.99566\n",
      "Epoch 9078/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6413 - val_loss: -176.1808\n",
      "\n",
      "Epoch 09078: loss did not improve from -177.99566\n",
      "Epoch 9079/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6984 - val_loss: -176.0820\n",
      "\n",
      "Epoch 09079: loss did not improve from -177.99566\n",
      "Epoch 9080/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6615 - val_loss: -176.1914\n",
      "\n",
      "Epoch 09080: loss did not improve from -177.99566\n",
      "Epoch 9081/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7471 - val_loss: -176.1461\n",
      "\n",
      "Epoch 09081: loss did not improve from -177.99566\n",
      "Epoch 9082/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5910 - val_loss: -176.0821\n",
      "\n",
      "Epoch 09082: loss did not improve from -177.99566\n",
      "Epoch 9083/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6071 - val_loss: -176.1717\n",
      "\n",
      "Epoch 09083: loss did not improve from -177.99566\n",
      "Epoch 9084/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7371 - val_loss: -176.2532\n",
      "\n",
      "Epoch 09084: loss did not improve from -177.99566\n",
      "Epoch 9085/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6072 - val_loss: -176.1863\n",
      "\n",
      "Epoch 09085: loss did not improve from -177.99566\n",
      "Epoch 9086/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6349 - val_loss: -176.0780\n",
      "\n",
      "Epoch 09086: loss did not improve from -177.99566\n",
      "Epoch 9087/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -177.7657 - val_loss: -176.2157\n",
      "\n",
      "Epoch 09087: loss did not improve from -177.99566\n",
      "Epoch 9088/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8607 - val_loss: -176.1996\n",
      "\n",
      "Epoch 09088: loss did not improve from -177.99566\n",
      "Epoch 9089/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6260 - val_loss: -176.2066\n",
      "\n",
      "Epoch 09089: loss did not improve from -177.99566\n",
      "Epoch 9090/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6420 - val_loss: -175.9766\n",
      "\n",
      "Epoch 09090: loss did not improve from -177.99566\n",
      "Epoch 9091/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5190 - val_loss: -176.2228\n",
      "\n",
      "Epoch 09091: loss did not improve from -177.99566\n",
      "Epoch 9092/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4559 - val_loss: -175.8692\n",
      "\n",
      "Epoch 09092: loss did not improve from -177.99566\n",
      "Epoch 9093/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6394 - val_loss: -176.3024\n",
      "\n",
      "Epoch 09093: loss did not improve from -177.99566\n",
      "Epoch 9094/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4794 - val_loss: -176.0212\n",
      "\n",
      "Epoch 09094: loss did not improve from -177.99566\n",
      "Epoch 9095/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4749 - val_loss: -176.2406\n",
      "\n",
      "Epoch 09095: loss did not improve from -177.99566\n",
      "Epoch 9096/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4867 - val_loss: -176.0794\n",
      "\n",
      "Epoch 09096: loss did not improve from -177.99566\n",
      "Epoch 9097/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7807 - val_loss: -176.2361\n",
      "\n",
      "Epoch 09097: loss did not improve from -177.99566\n",
      "Epoch 9098/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7632 - val_loss: -176.1511\n",
      "\n",
      "Epoch 09098: loss did not improve from -177.99566\n",
      "Epoch 9099/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5154 - val_loss: -176.2010\n",
      "\n",
      "Epoch 09099: loss did not improve from -177.99566\n",
      "Epoch 9100/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6443 - val_loss: -176.1084\n",
      "\n",
      "Epoch 09100: loss did not improve from -177.99566\n",
      "Epoch 9101/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7973 - val_loss: -176.2455\n",
      "\n",
      "Epoch 09101: loss did not improve from -177.99566\n",
      "Epoch 9102/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6300 - val_loss: -176.2407\n",
      "\n",
      "Epoch 09102: loss did not improve from -177.99566\n",
      "Epoch 9103/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4827 - val_loss: -176.1182\n",
      "\n",
      "Epoch 09103: loss did not improve from -177.99566\n",
      "Epoch 9104/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5072 - val_loss: -176.2085\n",
      "\n",
      "Epoch 09104: loss did not improve from -177.99566\n",
      "Epoch 9105/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5655 - val_loss: -176.2118\n",
      "\n",
      "Epoch 09105: loss did not improve from -177.99566\n",
      "Epoch 9106/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8833 - val_loss: -176.2917\n",
      "\n",
      "Epoch 09106: loss did not improve from -177.99566\n",
      "Epoch 9107/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5112 - val_loss: -175.9736\n",
      "\n",
      "Epoch 09107: loss did not improve from -177.99566\n",
      "Epoch 9108/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5217 - val_loss: -176.1434\n",
      "\n",
      "Epoch 09108: loss did not improve from -177.99566\n",
      "Epoch 9109/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6247 - val_loss: -175.7060\n",
      "\n",
      "Epoch 09109: loss did not improve from -177.99566\n",
      "Epoch 9110/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3086 - val_loss: -176.2147\n",
      "\n",
      "Epoch 09110: loss did not improve from -177.99566\n",
      "Epoch 9111/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4330 - val_loss: -175.9122\n",
      "\n",
      "Epoch 09111: loss did not improve from -177.99566\n",
      "Epoch 9112/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5778 - val_loss: -176.2732\n",
      "\n",
      "Epoch 09112: loss did not improve from -177.99566\n",
      "Epoch 9113/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5721 - val_loss: -176.1362\n",
      "\n",
      "Epoch 09113: loss did not improve from -177.99566\n",
      "Epoch 9114/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5126 - val_loss: -176.1902\n",
      "\n",
      "Epoch 09114: loss did not improve from -177.99566\n",
      "Epoch 9115/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7517 - val_loss: -176.0290\n",
      "\n",
      "Epoch 09115: loss did not improve from -177.99566\n",
      "Epoch 9116/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6210 - val_loss: -176.1555\n",
      "\n",
      "Epoch 09116: loss did not improve from -177.99566\n",
      "Epoch 9117/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3652 - val_loss: -175.9462\n",
      "\n",
      "Epoch 09117: loss did not improve from -177.99566\n",
      "Epoch 9118/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8140 - val_loss: -176.1286\n",
      "\n",
      "Epoch 09118: loss did not improve from -177.99566\n",
      "Epoch 9119/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7499 - val_loss: -176.2383\n",
      "\n",
      "Epoch 09119: loss did not improve from -177.99566\n",
      "Epoch 9120/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6174 - val_loss: -176.0492\n",
      "\n",
      "Epoch 09120: loss did not improve from -177.99566\n",
      "Epoch 9121/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6396 - val_loss: -176.0871\n",
      "\n",
      "Epoch 09121: loss did not improve from -177.99566\n",
      "Epoch 9122/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6207 - val_loss: -176.1152\n",
      "\n",
      "Epoch 09122: loss did not improve from -177.99566\n",
      "Epoch 9123/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8792 - val_loss: -176.2961\n",
      "\n",
      "Epoch 09123: loss did not improve from -177.99566\n",
      "Epoch 9124/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7521 - val_loss: -176.1631\n",
      "\n",
      "Epoch 09124: loss did not improve from -177.99566\n",
      "Epoch 9125/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7294 - val_loss: -176.1936\n",
      "\n",
      "Epoch 09125: loss did not improve from -177.99566\n",
      "Epoch 9126/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5804 - val_loss: -176.1502\n",
      "\n",
      "Epoch 09126: loss did not improve from -177.99566\n",
      "Epoch 9127/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8173 - val_loss: -176.2644\n",
      "\n",
      "Epoch 09127: loss did not improve from -177.99566\n",
      "Epoch 9128/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5147 - val_loss: -176.1666\n",
      "\n",
      "Epoch 09128: loss did not improve from -177.99566\n",
      "Epoch 9129/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -177.7991 - val_loss: -176.2060\n",
      "\n",
      "Epoch 09129: loss did not improve from -177.99566\n",
      "Epoch 9130/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6099 - val_loss: -176.2478\n",
      "\n",
      "Epoch 09130: loss did not improve from -177.99566\n",
      "Epoch 9131/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6884 - val_loss: -176.1427\n",
      "\n",
      "Epoch 09131: loss did not improve from -177.99566\n",
      "Epoch 9132/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6495 - val_loss: -176.1002\n",
      "\n",
      "Epoch 09132: loss did not improve from -177.99566\n",
      "Epoch 9133/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6015 - val_loss: -176.1390\n",
      "\n",
      "Epoch 09133: loss did not improve from -177.99566\n",
      "Epoch 9134/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6843 - val_loss: -176.0645\n",
      "\n",
      "Epoch 09134: loss did not improve from -177.99566\n",
      "Epoch 9135/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7290 - val_loss: -176.1969\n",
      "\n",
      "Epoch 09135: loss did not improve from -177.99566\n",
      "Epoch 9136/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6509 - val_loss: -176.0927\n",
      "\n",
      "Epoch 09136: loss did not improve from -177.99566\n",
      "Epoch 9137/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7760 - val_loss: -176.2520\n",
      "\n",
      "Epoch 09137: loss did not improve from -177.99566\n",
      "Epoch 9138/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8263 - val_loss: -176.1428\n",
      "\n",
      "Epoch 09138: loss did not improve from -177.99566\n",
      "Epoch 9139/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5663 - val_loss: -176.2957\n",
      "\n",
      "Epoch 09139: loss did not improve from -177.99566\n",
      "Epoch 9140/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8065 - val_loss: -176.1732\n",
      "\n",
      "Epoch 09140: loss did not improve from -177.99566\n",
      "Epoch 9141/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7108 - val_loss: -176.2980\n",
      "\n",
      "Epoch 09141: loss did not improve from -177.99566\n",
      "Epoch 9142/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7241 - val_loss: -176.0887\n",
      "\n",
      "Epoch 09142: loss did not improve from -177.99566\n",
      "Epoch 9143/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7369 - val_loss: -176.2539\n",
      "\n",
      "Epoch 09143: loss did not improve from -177.99566\n",
      "Epoch 9144/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6521 - val_loss: -176.1289\n",
      "\n",
      "Epoch 09144: loss did not improve from -177.99566\n",
      "Epoch 9145/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7560 - val_loss: -176.2437\n",
      "\n",
      "Epoch 09145: loss did not improve from -177.99566\n",
      "Epoch 9146/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5997 - val_loss: -176.1061\n",
      "\n",
      "Epoch 09146: loss did not improve from -177.99566\n",
      "Epoch 9147/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6617 - val_loss: -176.2991\n",
      "\n",
      "Epoch 09147: loss did not improve from -177.99566\n",
      "Epoch 9148/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5762 - val_loss: -176.0524\n",
      "\n",
      "Epoch 09148: loss did not improve from -177.99566\n",
      "Epoch 9149/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6631 - val_loss: -176.0947\n",
      "\n",
      "Epoch 09149: loss did not improve from -177.99566\n",
      "Epoch 9150/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -177.8052 - val_loss: -176.2309\n",
      "\n",
      "Epoch 09150: loss did not improve from -177.99566\n",
      "Epoch 9151/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5153 - val_loss: -176.2121\n",
      "\n",
      "Epoch 09151: loss did not improve from -177.99566\n",
      "Epoch 9152/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6475 - val_loss: -176.2635\n",
      "\n",
      "Epoch 09152: loss did not improve from -177.99566\n",
      "Epoch 9153/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5589 - val_loss: -176.0855\n",
      "\n",
      "Epoch 09153: loss did not improve from -177.99566\n",
      "Epoch 9154/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3419 - val_loss: -176.3373\n",
      "\n",
      "Epoch 09154: loss did not improve from -177.99566\n",
      "Epoch 9155/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5559 - val_loss: -175.9711\n",
      "\n",
      "Epoch 09155: loss did not improve from -177.99566\n",
      "Epoch 9156/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -177.8677 - val_loss: -176.3475\n",
      "\n",
      "Epoch 09156: loss did not improve from -177.99566\n",
      "Epoch 9157/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6996 - val_loss: -176.1331\n",
      "\n",
      "Epoch 09157: loss did not improve from -177.99566\n",
      "Epoch 9158/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9573 - val_loss: -176.3790\n",
      "\n",
      "Epoch 09158: loss did not improve from -177.99566\n",
      "Epoch 9159/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5473 - val_loss: -176.1630\n",
      "\n",
      "Epoch 09159: loss did not improve from -177.99566\n",
      "Epoch 9160/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6679 - val_loss: -176.3412\n",
      "\n",
      "Epoch 09160: loss did not improve from -177.99566\n",
      "Epoch 9161/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5280 - val_loss: -176.1818\n",
      "\n",
      "Epoch 09161: loss did not improve from -177.99566\n",
      "Epoch 9162/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7123 - val_loss: -176.2604\n",
      "\n",
      "Epoch 09162: loss did not improve from -177.99566\n",
      "Epoch 9163/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6188 - val_loss: -176.2118\n",
      "\n",
      "Epoch 09163: loss did not improve from -177.99566\n",
      "Epoch 9164/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6171 - val_loss: -176.1784\n",
      "\n",
      "Epoch 09164: loss did not improve from -177.99566\n",
      "Epoch 9165/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7262 - val_loss: -176.2636\n",
      "\n",
      "Epoch 09165: loss did not improve from -177.99566\n",
      "Epoch 9166/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5949 - val_loss: -176.1619\n",
      "\n",
      "Epoch 09166: loss did not improve from -177.99566\n",
      "Epoch 9167/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8368 - val_loss: -176.2853\n",
      "\n",
      "Epoch 09167: loss did not improve from -177.99566\n",
      "Epoch 9168/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6969 - val_loss: -176.1103\n",
      "\n",
      "Epoch 09168: loss did not improve from -177.99566\n",
      "Epoch 9169/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8445 - val_loss: -176.3322\n",
      "\n",
      "Epoch 09169: loss did not improve from -177.99566\n",
      "Epoch 9170/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6220 - val_loss: -176.1830\n",
      "\n",
      "Epoch 09170: loss did not improve from -177.99566\n",
      "Epoch 9171/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7294 - val_loss: -176.3096\n",
      "\n",
      "Epoch 09171: loss did not improve from -177.99566\n",
      "Epoch 9172/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7771 - val_loss: -176.1469\n",
      "\n",
      "Epoch 09172: loss did not improve from -177.99566\n",
      "Epoch 9173/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8324 - val_loss: -176.1836\n",
      "\n",
      "Epoch 09173: loss did not improve from -177.99566\n",
      "Epoch 9174/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5529 - val_loss: -176.1199\n",
      "\n",
      "Epoch 09174: loss did not improve from -177.99566\n",
      "Epoch 9175/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8307 - val_loss: -176.1800\n",
      "\n",
      "Epoch 09175: loss did not improve from -177.99566\n",
      "Epoch 9176/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5613 - val_loss: -176.2137\n",
      "\n",
      "Epoch 09176: loss did not improve from -177.99566\n",
      "Epoch 9177/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8881 - val_loss: -176.2341\n",
      "\n",
      "Epoch 09177: loss did not improve from -177.99566\n",
      "Epoch 9178/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6546 - val_loss: -176.2675\n",
      "\n",
      "Epoch 09178: loss did not improve from -177.99566\n",
      "Epoch 9179/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5964 - val_loss: -176.1432\n",
      "\n",
      "Epoch 09179: loss did not improve from -177.99566\n",
      "Epoch 9180/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5268 - val_loss: -176.1148\n",
      "\n",
      "Epoch 09180: loss did not improve from -177.99566\n",
      "Epoch 9181/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -177.4859 - val_loss: -175.8575\n",
      "\n",
      "Epoch 09181: loss did not improve from -177.99566\n",
      "Epoch 9182/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7529 - val_loss: -176.3138\n",
      "\n",
      "Epoch 09182: loss did not improve from -177.99566\n",
      "Epoch 9183/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7165 - val_loss: -176.0797\n",
      "\n",
      "Epoch 09183: loss did not improve from -177.99566\n",
      "Epoch 9184/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6125 - val_loss: -176.2590\n",
      "\n",
      "Epoch 09184: loss did not improve from -177.99566\n",
      "Epoch 9185/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7146 - val_loss: -176.0671\n",
      "\n",
      "Epoch 09185: loss did not improve from -177.99566\n",
      "Epoch 9186/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8009 - val_loss: -176.2392\n",
      "\n",
      "Epoch 09186: loss did not improve from -177.99566\n",
      "Epoch 9187/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6479 - val_loss: -176.0327\n",
      "\n",
      "Epoch 09187: loss did not improve from -177.99566\n",
      "Epoch 9188/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4529 - val_loss: -176.1140\n",
      "\n",
      "Epoch 09188: loss did not improve from -177.99566\n",
      "Epoch 9189/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -177.6316 - val_loss: -176.1608\n",
      "\n",
      "Epoch 09189: loss did not improve from -177.99566\n",
      "Epoch 9190/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6454 - val_loss: -176.2208\n",
      "\n",
      "Epoch 09190: loss did not improve from -177.99566\n",
      "Epoch 9191/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6707 - val_loss: -176.1231\n",
      "\n",
      "Epoch 09191: loss did not improve from -177.99566\n",
      "Epoch 9192/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7045 - val_loss: -176.2005\n",
      "\n",
      "Epoch 09192: loss did not improve from -177.99566\n",
      "Epoch 9193/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9303 - val_loss: -176.3196\n",
      "\n",
      "Epoch 09193: loss did not improve from -177.99566\n",
      "Epoch 9194/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -177.8629 - val_loss: -176.2590\n",
      "\n",
      "Epoch 09194: loss did not improve from -177.99566\n",
      "Epoch 9195/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7355 - val_loss: -176.1883\n",
      "\n",
      "Epoch 09195: loss did not improve from -177.99566\n",
      "Epoch 9196/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8798 - val_loss: -176.3202\n",
      "\n",
      "Epoch 09196: loss did not improve from -177.99566\n",
      "Epoch 9197/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7786 - val_loss: -176.2160\n",
      "\n",
      "Epoch 09197: loss did not improve from -177.99566\n",
      "Epoch 9198/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5624 - val_loss: -176.2390\n",
      "\n",
      "Epoch 09198: loss did not improve from -177.99566\n",
      "Epoch 9199/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -177.7005 - val_loss: -176.3785\n",
      "\n",
      "Epoch 09199: loss did not improve from -177.99566\n",
      "Epoch 9200/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7323 - val_loss: -176.2171\n",
      "\n",
      "Epoch 09200: loss did not improve from -177.99566\n",
      "Epoch 9201/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7201 - val_loss: -176.1908\n",
      "\n",
      "Epoch 09201: loss did not improve from -177.99566\n",
      "Epoch 9202/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7975 - val_loss: -176.3396\n",
      "\n",
      "Epoch 09202: loss did not improve from -177.99566\n",
      "Epoch 9203/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6423 - val_loss: -176.0210\n",
      "\n",
      "Epoch 09203: loss did not improve from -177.99566\n",
      "Epoch 9204/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5393 - val_loss: -176.1635\n",
      "\n",
      "Epoch 09204: loss did not improve from -177.99566\n",
      "Epoch 9205/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -177.6250 - val_loss: -176.1138\n",
      "\n",
      "Epoch 09205: loss did not improve from -177.99566\n",
      "Epoch 9206/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7199 - val_loss: -176.2673\n",
      "\n",
      "Epoch 09206: loss did not improve from -177.99566\n",
      "Epoch 9207/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5781 - val_loss: -176.1211\n",
      "\n",
      "Epoch 09207: loss did not improve from -177.99566\n",
      "Epoch 9208/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8196 - val_loss: -176.2778\n",
      "\n",
      "Epoch 09208: loss did not improve from -177.99566\n",
      "Epoch 9209/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4676 - val_loss: -176.1828\n",
      "\n",
      "Epoch 09209: loss did not improve from -177.99566\n",
      "Epoch 9210/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -177.8119 - val_loss: -176.2646\n",
      "\n",
      "Epoch 09210: loss did not improve from -177.99566\n",
      "Epoch 9211/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -177.8091 - val_loss: -176.4126\n",
      "\n",
      "Epoch 09211: loss did not improve from -177.99566\n",
      "Epoch 9212/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0145 - val_loss: -176.2046\n",
      "\n",
      "Epoch 09212: loss improved from -177.99566 to -178.01454, saving model to gendance.h5\n",
      "Epoch 9213/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7655 - val_loss: -176.2841\n",
      "\n",
      "Epoch 09213: loss did not improve from -178.01454\n",
      "Epoch 9214/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6483 - val_loss: -176.2562\n",
      "\n",
      "Epoch 09214: loss did not improve from -178.01454\n",
      "Epoch 9215/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8121 - val_loss: -176.2248\n",
      "\n",
      "Epoch 09215: loss did not improve from -178.01454\n",
      "Epoch 9216/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8328 - val_loss: -176.1404\n",
      "\n",
      "Epoch 09216: loss did not improve from -178.01454\n",
      "Epoch 9217/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8560 - val_loss: -176.3069\n",
      "\n",
      "Epoch 09217: loss did not improve from -178.01454\n",
      "Epoch 9218/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9158 - val_loss: -175.9466\n",
      "\n",
      "Epoch 09218: loss did not improve from -178.01454\n",
      "Epoch 9219/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7026 - val_loss: -176.3061\n",
      "\n",
      "Epoch 09219: loss did not improve from -178.01454\n",
      "Epoch 9220/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5778 - val_loss: -176.0031\n",
      "\n",
      "Epoch 09220: loss did not improve from -178.01454\n",
      "Epoch 9221/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7187 - val_loss: -176.3222\n",
      "\n",
      "Epoch 09221: loss did not improve from -178.01454\n",
      "Epoch 9222/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6429 - val_loss: -175.9376\n",
      "\n",
      "Epoch 09222: loss did not improve from -178.01454\n",
      "Epoch 9223/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6637 - val_loss: -176.2013\n",
      "\n",
      "Epoch 09223: loss did not improve from -178.01454\n",
      "Epoch 9224/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.2983 - val_loss: -176.0645\n",
      "\n",
      "Epoch 09224: loss did not improve from -178.01454\n",
      "Epoch 9225/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5650 - val_loss: -176.0584\n",
      "\n",
      "Epoch 09225: loss did not improve from -178.01454\n",
      "Epoch 9226/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4899 - val_loss: -176.2976\n",
      "\n",
      "Epoch 09226: loss did not improve from -178.01454\n",
      "Epoch 9227/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6485 - val_loss: -176.0484\n",
      "\n",
      "Epoch 09227: loss did not improve from -178.01454\n",
      "Epoch 9228/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.3864 - val_loss: -176.3068\n",
      "\n",
      "Epoch 09228: loss did not improve from -178.01454\n",
      "Epoch 9229/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.4409 - val_loss: -176.0689\n",
      "\n",
      "Epoch 09229: loss did not improve from -178.01454\n",
      "Epoch 9230/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7506 - val_loss: -176.4218\n",
      "\n",
      "Epoch 09230: loss did not improve from -178.01454\n",
      "Epoch 9231/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8246 - val_loss: -176.1288\n",
      "\n",
      "Epoch 09231: loss did not improve from -178.01454\n",
      "Epoch 9232/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8449 - val_loss: -176.2972\n",
      "\n",
      "Epoch 09232: loss did not improve from -178.01454\n",
      "Epoch 9233/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8109 - val_loss: -176.1989\n",
      "\n",
      "Epoch 09233: loss did not improve from -178.01454\n",
      "Epoch 9234/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6725 - val_loss: -176.1128\n",
      "\n",
      "Epoch 09234: loss did not improve from -178.01454\n",
      "Epoch 9235/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8369 - val_loss: -176.2845\n",
      "\n",
      "Epoch 09235: loss did not improve from -178.01454\n",
      "Epoch 9236/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9942 - val_loss: -176.3374\n",
      "\n",
      "Epoch 09236: loss did not improve from -178.01454\n",
      "Epoch 9237/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9971 - val_loss: -176.3467\n",
      "\n",
      "Epoch 09237: loss did not improve from -178.01454\n",
      "Epoch 9238/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9174 - val_loss: -176.3880\n",
      "\n",
      "Epoch 09238: loss did not improve from -178.01454\n",
      "Epoch 9239/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7160 - val_loss: -176.1931\n",
      "\n",
      "Epoch 09239: loss did not improve from -178.01454\n",
      "Epoch 9240/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7991 - val_loss: -176.1817\n",
      "\n",
      "Epoch 09240: loss did not improve from -178.01454\n",
      "Epoch 9241/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8093 - val_loss: -176.3309\n",
      "\n",
      "Epoch 09241: loss did not improve from -178.01454\n",
      "Epoch 9242/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6523 - val_loss: -176.2021\n",
      "\n",
      "Epoch 09242: loss did not improve from -178.01454\n",
      "Epoch 9243/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9009 - val_loss: -176.3276\n",
      "\n",
      "Epoch 09243: loss did not improve from -178.01454\n",
      "Epoch 9244/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7637 - val_loss: -176.2638\n",
      "\n",
      "Epoch 09244: loss did not improve from -178.01454\n",
      "Epoch 9245/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6218 - val_loss: -176.2096\n",
      "\n",
      "Epoch 09245: loss did not improve from -178.01454\n",
      "Epoch 9246/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9626 - val_loss: -176.3818\n",
      "\n",
      "Epoch 09246: loss did not improve from -178.01454\n",
      "Epoch 9247/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8628 - val_loss: -176.1972\n",
      "\n",
      "Epoch 09247: loss did not improve from -178.01454\n",
      "Epoch 9248/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8685 - val_loss: -176.3725\n",
      "\n",
      "Epoch 09248: loss did not improve from -178.01454\n",
      "Epoch 9249/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7760 - val_loss: -176.3535\n",
      "\n",
      "Epoch 09249: loss did not improve from -178.01454\n",
      "Epoch 9250/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6991 - val_loss: -176.1977\n",
      "\n",
      "Epoch 09250: loss did not improve from -178.01454\n",
      "Epoch 9251/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8095 - val_loss: -176.2763\n",
      "\n",
      "Epoch 09251: loss did not improve from -178.01454\n",
      "Epoch 9252/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9382 - val_loss: -176.3089\n",
      "\n",
      "Epoch 09252: loss did not improve from -178.01454\n",
      "Epoch 9253/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8588 - val_loss: -176.2997\n",
      "\n",
      "Epoch 09253: loss did not improve from -178.01454\n",
      "Epoch 9254/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6764 - val_loss: -176.0993\n",
      "\n",
      "Epoch 09254: loss did not improve from -178.01454\n",
      "Epoch 9255/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6571 - val_loss: -176.2911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 09255: loss did not improve from -178.01454\n",
      "Epoch 9256/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7193 - val_loss: -176.1355\n",
      "\n",
      "Epoch 09256: loss did not improve from -178.01454\n",
      "Epoch 9257/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7016 - val_loss: -176.3413\n",
      "\n",
      "Epoch 09257: loss did not improve from -178.01454\n",
      "Epoch 9258/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7917 - val_loss: -176.1176\n",
      "\n",
      "Epoch 09258: loss did not improve from -178.01454\n",
      "Epoch 9259/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8653 - val_loss: -176.3338\n",
      "\n",
      "Epoch 09259: loss did not improve from -178.01454\n",
      "Epoch 9260/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7541 - val_loss: -176.2895\n",
      "\n",
      "Epoch 09260: loss did not improve from -178.01454\n",
      "Epoch 9261/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8787 - val_loss: -176.3072\n",
      "\n",
      "Epoch 09261: loss did not improve from -178.01454\n",
      "Epoch 9262/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0306 - val_loss: -176.2888\n",
      "\n",
      "Epoch 09262: loss improved from -178.01454 to -178.03056, saving model to gendance.h5\n",
      "Epoch 9263/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7580 - val_loss: -176.2176\n",
      "\n",
      "Epoch 09263: loss did not improve from -178.03056\n",
      "Epoch 9264/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8213 - val_loss: -176.1042\n",
      "\n",
      "Epoch 09264: loss did not improve from -178.03056\n",
      "Epoch 9265/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8147 - val_loss: -176.2205\n",
      "\n",
      "Epoch 09265: loss did not improve from -178.03056\n",
      "Epoch 9266/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -177.8511 - val_loss: -176.2619\n",
      "\n",
      "Epoch 09266: loss did not improve from -178.03056\n",
      "Epoch 9267/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8201 - val_loss: -176.2556\n",
      "\n",
      "Epoch 09267: loss did not improve from -178.03056\n",
      "Epoch 9268/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -177.6273 - val_loss: -176.1653\n",
      "\n",
      "Epoch 09268: loss did not improve from -178.03056\n",
      "Epoch 9269/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7972 - val_loss: -176.3422\n",
      "\n",
      "Epoch 09269: loss did not improve from -178.03056\n",
      "Epoch 9270/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8070 - val_loss: -176.2205\n",
      "\n",
      "Epoch 09270: loss did not improve from -178.03056\n",
      "Epoch 9271/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8976 - val_loss: -176.3243\n",
      "\n",
      "Epoch 09271: loss did not improve from -178.03056\n",
      "Epoch 9272/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7335 - val_loss: -176.1729\n",
      "\n",
      "Epoch 09272: loss did not improve from -178.03056\n",
      "Epoch 9273/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5462 - val_loss: -176.2126\n",
      "\n",
      "Epoch 09273: loss did not improve from -178.03056\n",
      "Epoch 9274/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7028 - val_loss: -176.2561\n",
      "\n",
      "Epoch 09274: loss did not improve from -178.03056\n",
      "Epoch 9275/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8910 - val_loss: -176.3071\n",
      "\n",
      "Epoch 09275: loss did not improve from -178.03056\n",
      "Epoch 9276/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9104 - val_loss: -176.2268\n",
      "\n",
      "Epoch 09276: loss did not improve from -178.03056\n",
      "Epoch 9277/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8881 - val_loss: -176.4213\n",
      "\n",
      "Epoch 09277: loss did not improve from -178.03056\n",
      "Epoch 9278/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0002 - val_loss: -176.1173\n",
      "\n",
      "Epoch 09278: loss did not improve from -178.03056\n",
      "Epoch 9279/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6818 - val_loss: -176.3518\n",
      "\n",
      "Epoch 09279: loss did not improve from -178.03056\n",
      "Epoch 9280/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6471 - val_loss: -175.9333\n",
      "\n",
      "Epoch 09280: loss did not improve from -178.03056\n",
      "Epoch 9281/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -177.9466 - val_loss: -176.3931\n",
      "\n",
      "Epoch 09281: loss did not improve from -178.03056\n",
      "Epoch 9282/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5640 - val_loss: -175.9694\n",
      "\n",
      "Epoch 09282: loss did not improve from -178.03056\n",
      "Epoch 9283/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5403 - val_loss: -176.1613\n",
      "\n",
      "Epoch 09283: loss did not improve from -178.03056\n",
      "Epoch 9284/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8337 - val_loss: -176.0099\n",
      "\n",
      "Epoch 09284: loss did not improve from -178.03056\n",
      "Epoch 9285/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5601 - val_loss: -176.2841\n",
      "\n",
      "Epoch 09285: loss did not improve from -178.03056\n",
      "Epoch 9286/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7051 - val_loss: -175.9967\n",
      "\n",
      "Epoch 09286: loss did not improve from -178.03056\n",
      "Epoch 9287/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6586 - val_loss: -176.2474\n",
      "\n",
      "Epoch 09287: loss did not improve from -178.03056\n",
      "Epoch 9288/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -177.6039 - val_loss: -176.1061\n",
      "\n",
      "Epoch 09288: loss did not improve from -178.03056\n",
      "Epoch 9289/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7821 - val_loss: -176.2642\n",
      "\n",
      "Epoch 09289: loss did not improve from -178.03056\n",
      "Epoch 9290/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8739 - val_loss: -176.2177\n",
      "\n",
      "Epoch 09290: loss did not improve from -178.03056\n",
      "Epoch 9291/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7105 - val_loss: -176.2435\n",
      "\n",
      "Epoch 09291: loss did not improve from -178.03056\n",
      "Epoch 9292/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9862 - val_loss: -176.4310\n",
      "\n",
      "Epoch 09292: loss did not improve from -178.03056\n",
      "Epoch 9293/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6730 - val_loss: -176.1070\n",
      "\n",
      "Epoch 09293: loss did not improve from -178.03056\n",
      "Epoch 9294/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7140 - val_loss: -176.3917\n",
      "\n",
      "Epoch 09294: loss did not improve from -178.03056\n",
      "Epoch 9295/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5938 - val_loss: -176.1493\n",
      "\n",
      "Epoch 09295: loss did not improve from -178.03056\n",
      "Epoch 9296/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5543 - val_loss: -176.3155\n",
      "\n",
      "Epoch 09296: loss did not improve from -178.03056\n",
      "Epoch 9297/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8753 - val_loss: -176.1830\n",
      "\n",
      "Epoch 09297: loss did not improve from -178.03056\n",
      "Epoch 9298/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6873 - val_loss: -176.2830\n",
      "\n",
      "Epoch 09298: loss did not improve from -178.03056\n",
      "Epoch 9299/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5300 - val_loss: -176.2000\n",
      "\n",
      "Epoch 09299: loss did not improve from -178.03056\n",
      "Epoch 9300/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9082 - val_loss: -176.4163\n",
      "\n",
      "Epoch 09300: loss did not improve from -178.03056\n",
      "Epoch 9301/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8655 - val_loss: -176.2883\n",
      "\n",
      "Epoch 09301: loss did not improve from -178.03056\n",
      "Epoch 9302/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5441 - val_loss: -176.3051\n",
      "\n",
      "Epoch 09302: loss did not improve from -178.03056\n",
      "Epoch 9303/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0256 - val_loss: -176.3725\n",
      "\n",
      "Epoch 09303: loss did not improve from -178.03056\n",
      "Epoch 9304/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8343 - val_loss: -176.3722\n",
      "\n",
      "Epoch 09304: loss did not improve from -178.03056\n",
      "Epoch 9305/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9251 - val_loss: -176.3246\n",
      "\n",
      "Epoch 09305: loss did not improve from -178.03056\n",
      "Epoch 9306/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8778 - val_loss: -176.4276\n",
      "\n",
      "Epoch 09306: loss did not improve from -178.03056\n",
      "Epoch 9307/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7508 - val_loss: -176.3013\n",
      "\n",
      "Epoch 09307: loss did not improve from -178.03056\n",
      "Epoch 9308/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9828 - val_loss: -176.3202\n",
      "\n",
      "Epoch 09308: loss did not improve from -178.03056\n",
      "Epoch 9309/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8829 - val_loss: -176.4193\n",
      "\n",
      "Epoch 09309: loss did not improve from -178.03056\n",
      "Epoch 9310/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8481 - val_loss: -176.2394\n",
      "\n",
      "Epoch 09310: loss did not improve from -178.03056\n",
      "Epoch 9311/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9775 - val_loss: -176.4319\n",
      "\n",
      "Epoch 09311: loss did not improve from -178.03056\n",
      "Epoch 9312/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7763 - val_loss: -176.0680\n",
      "\n",
      "Epoch 09312: loss did not improve from -178.03056\n",
      "Epoch 9313/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8382 - val_loss: -176.4020\n",
      "\n",
      "Epoch 09313: loss did not improve from -178.03056\n",
      "Epoch 9314/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8541 - val_loss: -176.3219\n",
      "\n",
      "Epoch 09314: loss did not improve from -178.03056\n",
      "Epoch 9315/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7464 - val_loss: -176.3959\n",
      "\n",
      "Epoch 09315: loss did not improve from -178.03056\n",
      "Epoch 9316/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7637 - val_loss: -176.3064\n",
      "\n",
      "Epoch 09316: loss did not improve from -178.03056\n",
      "Epoch 9317/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9736 - val_loss: -176.4652\n",
      "\n",
      "Epoch 09317: loss did not improve from -178.03056\n",
      "Epoch 9318/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9429 - val_loss: -176.3737\n",
      "\n",
      "Epoch 09318: loss did not improve from -178.03056\n",
      "Epoch 9319/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8640 - val_loss: -176.3711\n",
      "\n",
      "Epoch 09319: loss did not improve from -178.03056\n",
      "Epoch 9320/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6738 - val_loss: -176.4246\n",
      "\n",
      "Epoch 09320: loss did not improve from -178.03056\n",
      "Epoch 9321/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8806 - val_loss: -176.2507\n",
      "\n",
      "Epoch 09321: loss did not improve from -178.03056\n",
      "Epoch 9322/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8266 - val_loss: -176.3416\n",
      "\n",
      "Epoch 09322: loss did not improve from -178.03056\n",
      "Epoch 9323/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7528 - val_loss: -176.2248\n",
      "\n",
      "Epoch 09323: loss did not improve from -178.03056\n",
      "Epoch 9324/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8522 - val_loss: -176.3498\n",
      "\n",
      "Epoch 09324: loss did not improve from -178.03056\n",
      "Epoch 9325/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7796 - val_loss: -176.3617\n",
      "\n",
      "Epoch 09325: loss did not improve from -178.03056\n",
      "Epoch 9326/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8394 - val_loss: -176.3680\n",
      "\n",
      "Epoch 09326: loss did not improve from -178.03056\n",
      "Epoch 9327/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0498 - val_loss: -176.4476\n",
      "\n",
      "Epoch 09327: loss improved from -178.03056 to -178.04985, saving model to gendance.h5\n",
      "Epoch 9328/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9169 - val_loss: -176.3403\n",
      "\n",
      "Epoch 09328: loss did not improve from -178.04985\n",
      "Epoch 9329/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8121 - val_loss: -176.2551\n",
      "\n",
      "Epoch 09329: loss did not improve from -178.04985\n",
      "Epoch 9330/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7288 - val_loss: -176.3237\n",
      "\n",
      "Epoch 09330: loss did not improve from -178.04985\n",
      "Epoch 9331/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6989 - val_loss: -176.3551\n",
      "\n",
      "Epoch 09331: loss did not improve from -178.04985\n",
      "Epoch 9332/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8947 - val_loss: -176.2697\n",
      "\n",
      "Epoch 09332: loss did not improve from -178.04985\n",
      "Epoch 9333/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8283 - val_loss: -176.4116\n",
      "\n",
      "Epoch 09333: loss did not improve from -178.04985\n",
      "Epoch 9334/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5990 - val_loss: -175.8987\n",
      "\n",
      "Epoch 09334: loss did not improve from -178.04985\n",
      "Epoch 9335/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6366 - val_loss: -176.4403\n",
      "\n",
      "Epoch 09335: loss did not improve from -178.04985\n",
      "Epoch 9336/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7132 - val_loss: -175.8773\n",
      "\n",
      "Epoch 09336: loss did not improve from -178.04985\n",
      "Epoch 9337/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -177.6259 - val_loss: -176.4254\n",
      "\n",
      "Epoch 09337: loss did not improve from -178.04985\n",
      "Epoch 9338/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7420 - val_loss: -176.0519\n",
      "\n",
      "Epoch 09338: loss did not improve from -178.04985\n",
      "Epoch 9339/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5507 - val_loss: -176.2677\n",
      "\n",
      "Epoch 09339: loss did not improve from -178.04985\n",
      "Epoch 9340/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8388 - val_loss: -176.1629\n",
      "\n",
      "Epoch 09340: loss did not improve from -178.04985\n",
      "Epoch 9341/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0383 - val_loss: -176.4290\n",
      "\n",
      "Epoch 09341: loss did not improve from -178.04985\n",
      "Epoch 9342/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0051 - val_loss: -176.3930\n",
      "\n",
      "Epoch 09342: loss did not improve from -178.04985\n",
      "Epoch 9343/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9764 - val_loss: -176.4387\n",
      "\n",
      "Epoch 09343: loss did not improve from -178.04985\n",
      "Epoch 9344/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9281 - val_loss: -176.4138\n",
      "\n",
      "Epoch 09344: loss did not improve from -178.04985\n",
      "Epoch 9345/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8984 - val_loss: -176.3461\n",
      "\n",
      "Epoch 09345: loss did not improve from -178.04985\n",
      "Epoch 9346/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9856 - val_loss: -176.4513\n",
      "\n",
      "Epoch 09346: loss did not improve from -178.04985\n",
      "Epoch 9347/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8278 - val_loss: -176.2942\n",
      "\n",
      "Epoch 09347: loss did not improve from -178.04985\n",
      "Epoch 9348/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8791 - val_loss: -176.5016\n",
      "\n",
      "Epoch 09348: loss did not improve from -178.04985\n",
      "Epoch 9349/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9706 - val_loss: -176.3364\n",
      "\n",
      "Epoch 09349: loss did not improve from -178.04985\n",
      "Epoch 9350/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0463 - val_loss: -176.4782\n",
      "\n",
      "Epoch 09350: loss did not improve from -178.04985\n",
      "Epoch 9351/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9013 - val_loss: -176.3927\n",
      "\n",
      "Epoch 09351: loss did not improve from -178.04985\n",
      "Epoch 9352/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6683 - val_loss: -176.3389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 09352: loss did not improve from -178.04985\n",
      "Epoch 9353/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9388 - val_loss: -176.4522\n",
      "\n",
      "Epoch 09353: loss did not improve from -178.04985\n",
      "Epoch 9354/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1664 - val_loss: -176.4459\n",
      "\n",
      "Epoch 09354: loss improved from -178.04985 to -178.16642, saving model to gendance.h5\n",
      "Epoch 9355/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9333 - val_loss: -176.3202\n",
      "\n",
      "Epoch 09355: loss did not improve from -178.16642\n",
      "Epoch 9356/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9657 - val_loss: -176.3280\n",
      "\n",
      "Epoch 09356: loss did not improve from -178.16642\n",
      "Epoch 9357/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0273 - val_loss: -176.2980\n",
      "\n",
      "Epoch 09357: loss did not improve from -178.16642\n",
      "Epoch 9358/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8588 - val_loss: -176.3590\n",
      "\n",
      "Epoch 09358: loss did not improve from -178.16642\n",
      "Epoch 9359/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8532 - val_loss: -175.8693\n",
      "\n",
      "Epoch 09359: loss did not improve from -178.16642\n",
      "Epoch 9360/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9508 - val_loss: -176.2850\n",
      "\n",
      "Epoch 09360: loss did not improve from -178.16642\n",
      "Epoch 9361/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7619 - val_loss: -176.0751\n",
      "\n",
      "Epoch 09361: loss did not improve from -178.16642\n",
      "Epoch 9362/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8650 - val_loss: -176.4461\n",
      "\n",
      "Epoch 09362: loss did not improve from -178.16642\n",
      "Epoch 9363/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0118 - val_loss: -176.3175\n",
      "\n",
      "Epoch 09363: loss did not improve from -178.16642\n",
      "Epoch 9364/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8592 - val_loss: -176.3586\n",
      "\n",
      "Epoch 09364: loss did not improve from -178.16642\n",
      "Epoch 9365/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7826 - val_loss: -176.3184\n",
      "\n",
      "Epoch 09365: loss did not improve from -178.16642\n",
      "Epoch 9366/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7192 - val_loss: -176.3312\n",
      "\n",
      "Epoch 09366: loss did not improve from -178.16642\n",
      "Epoch 9367/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6878 - val_loss: -176.2800\n",
      "\n",
      "Epoch 09367: loss did not improve from -178.16642\n",
      "Epoch 9368/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8382 - val_loss: -176.3620\n",
      "\n",
      "Epoch 09368: loss did not improve from -178.16642\n",
      "Epoch 9369/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0320 - val_loss: -176.3533\n",
      "\n",
      "Epoch 09369: loss did not improve from -178.16642\n",
      "Epoch 9370/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7351 - val_loss: -176.2418\n",
      "\n",
      "Epoch 09370: loss did not improve from -178.16642\n",
      "Epoch 9371/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -178.0092 - val_loss: -176.4450\n",
      "\n",
      "Epoch 09371: loss did not improve from -178.16642\n",
      "Epoch 9372/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6893 - val_loss: -176.1369\n",
      "\n",
      "Epoch 09372: loss did not improve from -178.16642\n",
      "Epoch 9373/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9191 - val_loss: -176.5078\n",
      "\n",
      "Epoch 09373: loss did not improve from -178.16642\n",
      "Epoch 9374/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8700 - val_loss: -175.9258\n",
      "\n",
      "Epoch 09374: loss did not improve from -178.16642\n",
      "Epoch 9375/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7405 - val_loss: -176.4020\n",
      "\n",
      "Epoch 09375: loss did not improve from -178.16642\n",
      "Epoch 9376/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9490 - val_loss: -176.2174\n",
      "\n",
      "Epoch 09376: loss did not improve from -178.16642\n",
      "Epoch 9377/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8949 - val_loss: -176.3416\n",
      "\n",
      "Epoch 09377: loss did not improve from -178.16642\n",
      "Epoch 9378/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6561 - val_loss: -176.1191\n",
      "\n",
      "Epoch 09378: loss did not improve from -178.16642\n",
      "Epoch 9379/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0083 - val_loss: -176.3742\n",
      "\n",
      "Epoch 09379: loss did not improve from -178.16642\n",
      "Epoch 9380/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8631 - val_loss: -176.1382\n",
      "\n",
      "Epoch 09380: loss did not improve from -178.16642\n",
      "Epoch 9381/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6048 - val_loss: -176.2475\n",
      "\n",
      "Epoch 09381: loss did not improve from -178.16642\n",
      "Epoch 9382/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5733 - val_loss: -176.3009\n",
      "\n",
      "Epoch 09382: loss did not improve from -178.16642\n",
      "Epoch 9383/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5697 - val_loss: -176.2094\n",
      "\n",
      "Epoch 09383: loss did not improve from -178.16642\n",
      "Epoch 9384/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6080 - val_loss: -176.3522\n",
      "\n",
      "Epoch 09384: loss did not improve from -178.16642\n",
      "Epoch 9385/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7724 - val_loss: -176.2799\n",
      "\n",
      "Epoch 09385: loss did not improve from -178.16642\n",
      "Epoch 9386/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8066 - val_loss: -176.4629\n",
      "\n",
      "Epoch 09386: loss did not improve from -178.16642\n",
      "Epoch 9387/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7316 - val_loss: -176.2026\n",
      "\n",
      "Epoch 09387: loss did not improve from -178.16642\n",
      "Epoch 9388/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7781 - val_loss: -176.3917\n",
      "\n",
      "Epoch 09388: loss did not improve from -178.16642\n",
      "Epoch 9389/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9368 - val_loss: -176.1919\n",
      "\n",
      "Epoch 09389: loss did not improve from -178.16642\n",
      "Epoch 9390/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8028 - val_loss: -176.5193\n",
      "\n",
      "Epoch 09390: loss did not improve from -178.16642\n",
      "Epoch 9391/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8237 - val_loss: -176.3288\n",
      "\n",
      "Epoch 09391: loss did not improve from -178.16642\n",
      "Epoch 9392/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7804 - val_loss: -176.3332\n",
      "\n",
      "Epoch 09392: loss did not improve from -178.16642\n",
      "Epoch 9393/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9608 - val_loss: -176.3171\n",
      "\n",
      "Epoch 09393: loss did not improve from -178.16642\n",
      "Epoch 9394/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0129 - val_loss: -176.3967\n",
      "\n",
      "Epoch 09394: loss did not improve from -178.16642\n",
      "Epoch 9395/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9488 - val_loss: -176.3724\n",
      "\n",
      "Epoch 09395: loss did not improve from -178.16642\n",
      "Epoch 9396/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7031 - val_loss: -176.2835\n",
      "\n",
      "Epoch 09396: loss did not improve from -178.16642\n",
      "Epoch 9397/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9236 - val_loss: -176.4343\n",
      "\n",
      "Epoch 09397: loss did not improve from -178.16642\n",
      "Epoch 9398/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8678 - val_loss: -176.3593\n",
      "\n",
      "Epoch 09398: loss did not improve from -178.16642\n",
      "Epoch 9399/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6528 - val_loss: -176.2206\n",
      "\n",
      "Epoch 09399: loss did not improve from -178.16642\n",
      "Epoch 9400/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8050 - val_loss: -176.4162\n",
      "\n",
      "Epoch 09400: loss did not improve from -178.16642\n",
      "Epoch 9401/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -177.8766 - val_loss: -176.4272\n",
      "\n",
      "Epoch 09401: loss did not improve from -178.16642\n",
      "Epoch 9402/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0708 - val_loss: -176.4658\n",
      "\n",
      "Epoch 09402: loss did not improve from -178.16642\n",
      "Epoch 9403/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9974 - val_loss: -176.4689\n",
      "\n",
      "Epoch 09403: loss did not improve from -178.16642\n",
      "Epoch 9404/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9892 - val_loss: -176.3741\n",
      "\n",
      "Epoch 09404: loss did not improve from -178.16642\n",
      "Epoch 9405/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0018 - val_loss: -176.5130\n",
      "\n",
      "Epoch 09405: loss did not improve from -178.16642\n",
      "Epoch 9406/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1214 - val_loss: -176.4824\n",
      "\n",
      "Epoch 09406: loss did not improve from -178.16642\n",
      "Epoch 9407/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9126 - val_loss: -176.5068\n",
      "\n",
      "Epoch 09407: loss did not improve from -178.16642\n",
      "Epoch 9408/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7107 - val_loss: -176.3382\n",
      "\n",
      "Epoch 09408: loss did not improve from -178.16642\n",
      "Epoch 9409/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0840 - val_loss: -176.4144\n",
      "\n",
      "Epoch 09409: loss did not improve from -178.16642\n",
      "Epoch 9410/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8406 - val_loss: -176.3297\n",
      "\n",
      "Epoch 09410: loss did not improve from -178.16642\n",
      "Epoch 9411/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9454 - val_loss: -176.4524\n",
      "\n",
      "Epoch 09411: loss did not improve from -178.16642\n",
      "Epoch 9412/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8430 - val_loss: -176.2963\n",
      "\n",
      "Epoch 09412: loss did not improve from -178.16642\n",
      "Epoch 9413/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9666 - val_loss: -176.4429\n",
      "\n",
      "Epoch 09413: loss did not improve from -178.16642\n",
      "Epoch 9414/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6181 - val_loss: -176.3702\n",
      "\n",
      "Epoch 09414: loss did not improve from -178.16642\n",
      "Epoch 9415/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8365 - val_loss: -176.4154\n",
      "\n",
      "Epoch 09415: loss did not improve from -178.16642\n",
      "Epoch 9416/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1050 - val_loss: -176.3715\n",
      "\n",
      "Epoch 09416: loss did not improve from -178.16642\n",
      "Epoch 9417/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7730 - val_loss: -176.4232\n",
      "\n",
      "Epoch 09417: loss did not improve from -178.16642\n",
      "Epoch 9418/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0513 - val_loss: -176.4310\n",
      "\n",
      "Epoch 09418: loss did not improve from -178.16642\n",
      "Epoch 9419/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8895 - val_loss: -176.4549\n",
      "\n",
      "Epoch 09419: loss did not improve from -178.16642\n",
      "Epoch 9420/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9187 - val_loss: -176.5013\n",
      "\n",
      "Epoch 09420: loss did not improve from -178.16642\n",
      "Epoch 9421/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0734 - val_loss: -176.6064\n",
      "\n",
      "Epoch 09421: loss did not improve from -178.16642\n",
      "Epoch 9422/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9862 - val_loss: -176.4912\n",
      "\n",
      "Epoch 09422: loss did not improve from -178.16642\n",
      "Epoch 9423/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8620 - val_loss: -176.4736\n",
      "\n",
      "Epoch 09423: loss did not improve from -178.16642\n",
      "Epoch 9424/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8293 - val_loss: -176.3646\n",
      "\n",
      "Epoch 09424: loss did not improve from -178.16642\n",
      "Epoch 9425/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8222 - val_loss: -176.3749\n",
      "\n",
      "Epoch 09425: loss did not improve from -178.16642\n",
      "Epoch 9426/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9938 - val_loss: -176.4289\n",
      "\n",
      "Epoch 09426: loss did not improve from -178.16642\n",
      "Epoch 9427/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8070 - val_loss: -176.2639\n",
      "\n",
      "Epoch 09427: loss did not improve from -178.16642\n",
      "Epoch 9428/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8485 - val_loss: -176.4395\n",
      "\n",
      "Epoch 09428: loss did not improve from -178.16642\n",
      "Epoch 9429/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9421 - val_loss: -176.4804\n",
      "\n",
      "Epoch 09429: loss did not improve from -178.16642\n",
      "Epoch 9430/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0353 - val_loss: -176.3287\n",
      "\n",
      "Epoch 09430: loss did not improve from -178.16642\n",
      "Epoch 9431/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9263 - val_loss: -176.3395\n",
      "\n",
      "Epoch 09431: loss did not improve from -178.16642\n",
      "Epoch 9432/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9025 - val_loss: -176.4404\n",
      "\n",
      "Epoch 09432: loss did not improve from -178.16642\n",
      "Epoch 9433/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9804 - val_loss: -176.3758\n",
      "\n",
      "Epoch 09433: loss did not improve from -178.16642\n",
      "Epoch 9434/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8586 - val_loss: -176.4465\n",
      "\n",
      "Epoch 09434: loss did not improve from -178.16642\n",
      "Epoch 9435/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9722 - val_loss: -176.2540\n",
      "\n",
      "Epoch 09435: loss did not improve from -178.16642\n",
      "Epoch 9436/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0095 - val_loss: -176.3664\n",
      "\n",
      "Epoch 09436: loss did not improve from -178.16642\n",
      "Epoch 9437/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0644 - val_loss: -176.5013\n",
      "\n",
      "Epoch 09437: loss did not improve from -178.16642\n",
      "Epoch 9438/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1632 - val_loss: -176.4769\n",
      "\n",
      "Epoch 09438: loss did not improve from -178.16642\n",
      "Epoch 9439/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9083 - val_loss: -176.4787\n",
      "\n",
      "Epoch 09439: loss did not improve from -178.16642\n",
      "Epoch 9440/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8059 - val_loss: -176.4344\n",
      "\n",
      "Epoch 09440: loss did not improve from -178.16642\n",
      "Epoch 9441/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9844 - val_loss: -176.4243\n",
      "\n",
      "Epoch 09441: loss did not improve from -178.16642\n",
      "Epoch 9442/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9274 - val_loss: -176.2806\n",
      "\n",
      "Epoch 09442: loss did not improve from -178.16642\n",
      "Epoch 9443/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0190 - val_loss: -176.5008\n",
      "\n",
      "Epoch 09443: loss did not improve from -178.16642\n",
      "Epoch 9444/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9535 - val_loss: -176.2583\n",
      "\n",
      "Epoch 09444: loss did not improve from -178.16642\n",
      "Epoch 9445/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0021 - val_loss: -176.6400\n",
      "\n",
      "Epoch 09445: loss did not improve from -178.16642\n",
      "Epoch 9446/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7590 - val_loss: -176.1595\n",
      "\n",
      "Epoch 09446: loss did not improve from -178.16642\n",
      "Epoch 9447/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8506 - val_loss: -176.5038\n",
      "\n",
      "Epoch 09447: loss did not improve from -178.16642\n",
      "Epoch 9448/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8894 - val_loss: -176.1568\n",
      "\n",
      "Epoch 09448: loss did not improve from -178.16642\n",
      "Epoch 9449/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7812 - val_loss: -176.4073\n",
      "\n",
      "Epoch 09449: loss did not improve from -178.16642\n",
      "Epoch 9450/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9497 - val_loss: -176.2772\n",
      "\n",
      "Epoch 09450: loss did not improve from -178.16642\n",
      "Epoch 9451/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9630 - val_loss: -176.4895\n",
      "\n",
      "Epoch 09451: loss did not improve from -178.16642\n",
      "Epoch 9452/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0277 - val_loss: -176.2731\n",
      "\n",
      "Epoch 09452: loss did not improve from -178.16642\n",
      "Epoch 9453/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0853 - val_loss: -176.4827\n",
      "\n",
      "Epoch 09453: loss did not improve from -178.16642\n",
      "Epoch 9454/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9216 - val_loss: -175.9932\n",
      "\n",
      "Epoch 09454: loss did not improve from -178.16642\n",
      "Epoch 9455/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8650 - val_loss: -176.3847\n",
      "\n",
      "Epoch 09455: loss did not improve from -178.16642\n",
      "Epoch 9456/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7615 - val_loss: -176.0334\n",
      "\n",
      "Epoch 09456: loss did not improve from -178.16642\n",
      "Epoch 9457/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7601 - val_loss: -176.3406\n",
      "\n",
      "Epoch 09457: loss did not improve from -178.16642\n",
      "Epoch 9458/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7316 - val_loss: -175.9774\n",
      "\n",
      "Epoch 09458: loss did not improve from -178.16642\n",
      "Epoch 9459/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6830 - val_loss: -176.3576\n",
      "\n",
      "Epoch 09459: loss did not improve from -178.16642\n",
      "Epoch 9460/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6677 - val_loss: -176.2173\n",
      "\n",
      "Epoch 09460: loss did not improve from -178.16642\n",
      "Epoch 9461/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8406 - val_loss: -176.3653\n",
      "\n",
      "Epoch 09461: loss did not improve from -178.16642\n",
      "Epoch 9462/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.6728 - val_loss: -176.4349\n",
      "\n",
      "Epoch 09462: loss did not improve from -178.16642\n",
      "Epoch 9463/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.5800 - val_loss: -176.1183\n",
      "\n",
      "Epoch 09463: loss did not improve from -178.16642\n",
      "Epoch 9464/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0013 - val_loss: -176.3682\n",
      "\n",
      "Epoch 09464: loss did not improve from -178.16642\n",
      "Epoch 9465/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -177.6725 - val_loss: -176.0868\n",
      "\n",
      "Epoch 09465: loss did not improve from -178.16642\n",
      "Epoch 9466/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7652 - val_loss: -176.3237\n",
      "\n",
      "Epoch 09466: loss did not improve from -178.16642\n",
      "Epoch 9467/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0723 - val_loss: -176.3777\n",
      "\n",
      "Epoch 09467: loss did not improve from -178.16642\n",
      "Epoch 9468/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9237 - val_loss: -176.1535\n",
      "\n",
      "Epoch 09468: loss did not improve from -178.16642\n",
      "Epoch 9469/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0272 - val_loss: -176.2708\n",
      "\n",
      "Epoch 09469: loss did not improve from -178.16642\n",
      "Epoch 9470/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8544 - val_loss: -176.2824\n",
      "\n",
      "Epoch 09470: loss did not improve from -178.16642\n",
      "Epoch 9471/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9951 - val_loss: -176.4627\n",
      "\n",
      "Epoch 09471: loss did not improve from -178.16642\n",
      "Epoch 9472/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1300 - val_loss: -176.3302\n",
      "\n",
      "Epoch 09472: loss did not improve from -178.16642\n",
      "Epoch 9473/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0840 - val_loss: -176.3103\n",
      "\n",
      "Epoch 09473: loss did not improve from -178.16642\n",
      "Epoch 9474/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8872 - val_loss: -176.2988\n",
      "\n",
      "Epoch 09474: loss did not improve from -178.16642\n",
      "Epoch 9475/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1598 - val_loss: -176.3638\n",
      "\n",
      "Epoch 09475: loss did not improve from -178.16642\n",
      "Epoch 9476/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9643 - val_loss: -176.2759\n",
      "\n",
      "Epoch 09476: loss did not improve from -178.16642\n",
      "Epoch 9477/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8061 - val_loss: -176.4044\n",
      "\n",
      "Epoch 09477: loss did not improve from -178.16642\n",
      "Epoch 9478/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1547 - val_loss: -176.3435\n",
      "\n",
      "Epoch 09478: loss did not improve from -178.16642\n",
      "Epoch 9479/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1164 - val_loss: -176.3793\n",
      "\n",
      "Epoch 09479: loss did not improve from -178.16642\n",
      "Epoch 9480/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9993 - val_loss: -176.3916\n",
      "\n",
      "Epoch 09480: loss did not improve from -178.16642\n",
      "Epoch 9481/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9798 - val_loss: -176.2153\n",
      "\n",
      "Epoch 09481: loss did not improve from -178.16642\n",
      "Epoch 9482/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9345 - val_loss: -176.4147\n",
      "\n",
      "Epoch 09482: loss did not improve from -178.16642\n",
      "Epoch 9483/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8872 - val_loss: -176.3421\n",
      "\n",
      "Epoch 09483: loss did not improve from -178.16642\n",
      "Epoch 9484/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9911 - val_loss: -176.5205\n",
      "\n",
      "Epoch 09484: loss did not improve from -178.16642\n",
      "Epoch 9485/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8333 - val_loss: -176.1993\n",
      "\n",
      "Epoch 09485: loss did not improve from -178.16642\n",
      "Epoch 9486/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0638 - val_loss: -176.3794\n",
      "\n",
      "Epoch 09486: loss did not improve from -178.16642\n",
      "Epoch 9487/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8194 - val_loss: -176.2803\n",
      "\n",
      "Epoch 09487: loss did not improve from -178.16642\n",
      "Epoch 9488/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0356 - val_loss: -176.3858\n",
      "\n",
      "Epoch 09488: loss did not improve from -178.16642\n",
      "Epoch 9489/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9018 - val_loss: -176.3647\n",
      "\n",
      "Epoch 09489: loss did not improve from -178.16642\n",
      "Epoch 9490/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9940 - val_loss: -176.3887\n",
      "\n",
      "Epoch 09490: loss did not improve from -178.16642\n",
      "Epoch 9491/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8509 - val_loss: -176.3022\n",
      "\n",
      "Epoch 09491: loss did not improve from -178.16642\n",
      "Epoch 9492/10000\n",
      "16167/16167 [==============================] - 1s 31us/step - loss: -177.9353 - val_loss: -176.3076\n",
      "\n",
      "Epoch 09492: loss did not improve from -178.16642\n",
      "Epoch 9493/10000\n",
      "16167/16167 [==============================] - 1s 32us/step - loss: -178.1040 - val_loss: -176.2891\n",
      "\n",
      "Epoch 09493: loss did not improve from -178.16642\n",
      "Epoch 9494/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8732 - val_loss: -176.2839\n",
      "\n",
      "Epoch 09494: loss did not improve from -178.16642\n",
      "Epoch 9495/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1900 - val_loss: -176.4242\n",
      "\n",
      "Epoch 09495: loss improved from -178.16642 to -178.19000, saving model to gendance.h5\n",
      "Epoch 9496/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -177.9253 - val_loss: -176.3233\n",
      "\n",
      "Epoch 09496: loss did not improve from -178.19000\n",
      "Epoch 9497/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0535 - val_loss: -176.4074\n",
      "\n",
      "Epoch 09497: loss did not improve from -178.19000\n",
      "Epoch 9498/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9134 - val_loss: -176.2330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 09498: loss did not improve from -178.19000\n",
      "Epoch 9499/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1583 - val_loss: -176.3607\n",
      "\n",
      "Epoch 09499: loss did not improve from -178.19000\n",
      "Epoch 9500/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9371 - val_loss: -176.2042\n",
      "\n",
      "Epoch 09500: loss did not improve from -178.19000\n",
      "Epoch 9501/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0770 - val_loss: -176.4334\n",
      "\n",
      "Epoch 09501: loss did not improve from -178.19000\n",
      "Epoch 9502/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1555 - val_loss: -176.2227\n",
      "\n",
      "Epoch 09502: loss did not improve from -178.19000\n",
      "Epoch 9503/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0418 - val_loss: -176.4759\n",
      "\n",
      "Epoch 09503: loss did not improve from -178.19000\n",
      "Epoch 9504/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9197 - val_loss: -176.1904\n",
      "\n",
      "Epoch 09504: loss did not improve from -178.19000\n",
      "Epoch 9505/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0263 - val_loss: -176.3682\n",
      "\n",
      "Epoch 09505: loss did not improve from -178.19000\n",
      "Epoch 9506/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0566 - val_loss: -176.0552\n",
      "\n",
      "Epoch 09506: loss did not improve from -178.19000\n",
      "Epoch 9507/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7328 - val_loss: -176.3554\n",
      "\n",
      "Epoch 09507: loss did not improve from -178.19000\n",
      "Epoch 9508/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9506 - val_loss: -175.9942\n",
      "\n",
      "Epoch 09508: loss did not improve from -178.19000\n",
      "Epoch 9509/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7672 - val_loss: -176.3179\n",
      "\n",
      "Epoch 09509: loss did not improve from -178.19000\n",
      "Epoch 9510/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8040 - val_loss: -175.9819\n",
      "\n",
      "Epoch 09510: loss did not improve from -178.19000\n",
      "Epoch 9511/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8708 - val_loss: -176.3530\n",
      "\n",
      "Epoch 09511: loss did not improve from -178.19000\n",
      "Epoch 9512/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8949 - val_loss: -176.1113\n",
      "\n",
      "Epoch 09512: loss did not improve from -178.19000\n",
      "Epoch 9513/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0515 - val_loss: -176.5101\n",
      "\n",
      "Epoch 09513: loss did not improve from -178.19000\n",
      "Epoch 9514/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0749 - val_loss: -176.0751\n",
      "\n",
      "Epoch 09514: loss did not improve from -178.19000\n",
      "Epoch 9515/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1298 - val_loss: -176.4287\n",
      "\n",
      "Epoch 09515: loss did not improve from -178.19000\n",
      "Epoch 9516/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3165 - val_loss: -176.1571\n",
      "\n",
      "Epoch 09516: loss improved from -178.19000 to -178.31646, saving model to gendance.h5\n",
      "Epoch 9517/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9097 - val_loss: -176.2438\n",
      "\n",
      "Epoch 09517: loss did not improve from -178.31646\n",
      "Epoch 9518/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9321 - val_loss: -176.2916\n",
      "\n",
      "Epoch 09518: loss did not improve from -178.31646\n",
      "Epoch 9519/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9849 - val_loss: -176.3336\n",
      "\n",
      "Epoch 09519: loss did not improve from -178.31646\n",
      "Epoch 9520/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9520 - val_loss: -176.4685\n",
      "\n",
      "Epoch 09520: loss did not improve from -178.31646\n",
      "Epoch 9521/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9698 - val_loss: -176.2411\n",
      "\n",
      "Epoch 09521: loss did not improve from -178.31646\n",
      "Epoch 9522/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1521 - val_loss: -176.4268\n",
      "\n",
      "Epoch 09522: loss did not improve from -178.31646\n",
      "Epoch 9523/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8277 - val_loss: -176.2021\n",
      "\n",
      "Epoch 09523: loss did not improve from -178.31646\n",
      "Epoch 9524/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0566 - val_loss: -176.4813\n",
      "\n",
      "Epoch 09524: loss did not improve from -178.31646\n",
      "Epoch 9525/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1584 - val_loss: -176.2204\n",
      "\n",
      "Epoch 09525: loss did not improve from -178.31646\n",
      "Epoch 9526/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0453 - val_loss: -176.4053\n",
      "\n",
      "Epoch 09526: loss did not improve from -178.31646\n",
      "Epoch 9527/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -178.1008 - val_loss: -176.2572\n",
      "\n",
      "Epoch 09527: loss did not improve from -178.31646\n",
      "Epoch 9528/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9611 - val_loss: -176.5382\n",
      "\n",
      "Epoch 09528: loss did not improve from -178.31646\n",
      "Epoch 9529/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -178.0369 - val_loss: -176.3215\n",
      "\n",
      "Epoch 09529: loss did not improve from -178.31646\n",
      "Epoch 9530/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0950 - val_loss: -176.4099\n",
      "\n",
      "Epoch 09530: loss did not improve from -178.31646\n",
      "Epoch 9531/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9581 - val_loss: -176.1628\n",
      "\n",
      "Epoch 09531: loss did not improve from -178.31646\n",
      "Epoch 9532/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -177.9397 - val_loss: -176.3623\n",
      "\n",
      "Epoch 09532: loss did not improve from -178.31646\n",
      "Epoch 9533/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9285 - val_loss: -176.2259\n",
      "\n",
      "Epoch 09533: loss did not improve from -178.31646\n",
      "Epoch 9534/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1595 - val_loss: -176.3400\n",
      "\n",
      "Epoch 09534: loss did not improve from -178.31646\n",
      "Epoch 9535/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8017 - val_loss: -176.1806\n",
      "\n",
      "Epoch 09535: loss did not improve from -178.31646\n",
      "Epoch 9536/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9004 - val_loss: -176.2837\n",
      "\n",
      "Epoch 09536: loss did not improve from -178.31646\n",
      "Epoch 9537/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0082 - val_loss: -176.3787\n",
      "\n",
      "Epoch 09537: loss did not improve from -178.31646\n",
      "Epoch 9538/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9203 - val_loss: -176.3629\n",
      "\n",
      "Epoch 09538: loss did not improve from -178.31646\n",
      "Epoch 9539/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3503 - val_loss: -176.4946\n",
      "\n",
      "Epoch 09539: loss improved from -178.31646 to -178.35027, saving model to gendance.h5\n",
      "Epoch 9540/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0161 - val_loss: -176.2367\n",
      "\n",
      "Epoch 09540: loss did not improve from -178.35027\n",
      "Epoch 9541/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1754 - val_loss: -176.4253\n",
      "\n",
      "Epoch 09541: loss did not improve from -178.35027\n",
      "Epoch 9542/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1196 - val_loss: -176.3400\n",
      "\n",
      "Epoch 09542: loss did not improve from -178.35027\n",
      "Epoch 9543/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0849 - val_loss: -176.4243\n",
      "\n",
      "Epoch 09543: loss did not improve from -178.35027\n",
      "Epoch 9544/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2065 - val_loss: -176.2274\n",
      "\n",
      "Epoch 09544: loss did not improve from -178.35027\n",
      "Epoch 9545/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1242 - val_loss: -176.4127\n",
      "\n",
      "Epoch 09545: loss did not improve from -178.35027\n",
      "Epoch 9546/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -178.0857 - val_loss: -176.2401\n",
      "\n",
      "Epoch 09546: loss did not improve from -178.35027\n",
      "Epoch 9547/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0017 - val_loss: -176.4009\n",
      "\n",
      "Epoch 09547: loss did not improve from -178.35027\n",
      "Epoch 9548/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0146 - val_loss: -176.2240\n",
      "\n",
      "Epoch 09548: loss did not improve from -178.35027\n",
      "Epoch 9549/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1180 - val_loss: -176.4786\n",
      "\n",
      "Epoch 09549: loss did not improve from -178.35027\n",
      "Epoch 9550/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0479 - val_loss: -176.2312\n",
      "\n",
      "Epoch 09550: loss did not improve from -178.35027\n",
      "Epoch 9551/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4386 - val_loss: -176.4540\n",
      "\n",
      "Epoch 09551: loss improved from -178.35027 to -178.43865, saving model to gendance.h5\n",
      "Epoch 9552/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -177.8297 - val_loss: -176.3496\n",
      "\n",
      "Epoch 09552: loss did not improve from -178.43865\n",
      "Epoch 9553/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1880 - val_loss: -176.4679\n",
      "\n",
      "Epoch 09553: loss did not improve from -178.43865\n",
      "Epoch 9554/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0944 - val_loss: -176.2753\n",
      "\n",
      "Epoch 09554: loss did not improve from -178.43865\n",
      "Epoch 9555/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1374 - val_loss: -176.2765\n",
      "\n",
      "Epoch 09555: loss did not improve from -178.43865\n",
      "Epoch 9556/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9733 - val_loss: -176.2183\n",
      "\n",
      "Epoch 09556: loss did not improve from -178.43865\n",
      "Epoch 9557/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0570 - val_loss: -176.2638\n",
      "\n",
      "Epoch 09557: loss did not improve from -178.43865\n",
      "Epoch 9558/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0380 - val_loss: -176.3459\n",
      "\n",
      "Epoch 09558: loss did not improve from -178.43865\n",
      "Epoch 9559/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1803 - val_loss: -176.3376\n",
      "\n",
      "Epoch 09559: loss did not improve from -178.43865\n",
      "Epoch 9560/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2459 - val_loss: -176.4296\n",
      "\n",
      "Epoch 09560: loss did not improve from -178.43865\n",
      "Epoch 9561/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0519 - val_loss: -176.3135\n",
      "\n",
      "Epoch 09561: loss did not improve from -178.43865\n",
      "Epoch 9562/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9811 - val_loss: -176.3890\n",
      "\n",
      "Epoch 09562: loss did not improve from -178.43865\n",
      "Epoch 9563/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9255 - val_loss: -176.4906\n",
      "\n",
      "Epoch 09563: loss did not improve from -178.43865\n",
      "Epoch 9564/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9715 - val_loss: -176.2779\n",
      "\n",
      "Epoch 09564: loss did not improve from -178.43865\n",
      "Epoch 9565/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1320 - val_loss: -176.4031\n",
      "\n",
      "Epoch 09565: loss did not improve from -178.43865\n",
      "Epoch 9566/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9752 - val_loss: -176.0632\n",
      "\n",
      "Epoch 09566: loss did not improve from -178.43865\n",
      "Epoch 9567/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9528 - val_loss: -176.3268\n",
      "\n",
      "Epoch 09567: loss did not improve from -178.43865\n",
      "Epoch 9568/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0472 - val_loss: -176.0274\n",
      "\n",
      "Epoch 09568: loss did not improve from -178.43865\n",
      "Epoch 9569/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2337 - val_loss: -176.4249\n",
      "\n",
      "Epoch 09569: loss did not improve from -178.43865\n",
      "Epoch 9570/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2026 - val_loss: -176.2122\n",
      "\n",
      "Epoch 09570: loss did not improve from -178.43865\n",
      "Epoch 9571/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0554 - val_loss: -176.3698\n",
      "\n",
      "Epoch 09571: loss did not improve from -178.43865\n",
      "Epoch 9572/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9333 - val_loss: -176.2288\n",
      "\n",
      "Epoch 09572: loss did not improve from -178.43865\n",
      "Epoch 9573/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0557 - val_loss: -176.3835\n",
      "\n",
      "Epoch 09573: loss did not improve from -178.43865\n",
      "Epoch 9574/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3498 - val_loss: -176.3285\n",
      "\n",
      "Epoch 09574: loss did not improve from -178.43865\n",
      "Epoch 9575/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9094 - val_loss: -176.1690\n",
      "\n",
      "Epoch 09575: loss did not improve from -178.43865\n",
      "Epoch 9576/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0706 - val_loss: -176.3638\n",
      "\n",
      "Epoch 09576: loss did not improve from -178.43865\n",
      "Epoch 9577/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -177.9646 - val_loss: -176.2088\n",
      "\n",
      "Epoch 09577: loss did not improve from -178.43865\n",
      "Epoch 9578/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9198 - val_loss: -176.3689\n",
      "\n",
      "Epoch 09578: loss did not improve from -178.43865\n",
      "Epoch 9579/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9713 - val_loss: -176.1203\n",
      "\n",
      "Epoch 09579: loss did not improve from -178.43865\n",
      "Epoch 9580/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1355 - val_loss: -176.4496\n",
      "\n",
      "Epoch 09580: loss did not improve from -178.43865\n",
      "Epoch 9581/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0468 - val_loss: -176.2892\n",
      "\n",
      "Epoch 09581: loss did not improve from -178.43865\n",
      "Epoch 9582/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0848 - val_loss: -176.3518\n",
      "\n",
      "Epoch 09582: loss did not improve from -178.43865\n",
      "Epoch 9583/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0566 - val_loss: -176.1702\n",
      "\n",
      "Epoch 09583: loss did not improve from -178.43865\n",
      "Epoch 9584/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8896 - val_loss: -176.2984\n",
      "\n",
      "Epoch 09584: loss did not improve from -178.43865\n",
      "Epoch 9585/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8626 - val_loss: -176.0952\n",
      "\n",
      "Epoch 09585: loss did not improve from -178.43865\n",
      "Epoch 9586/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9282 - val_loss: -176.1868\n",
      "\n",
      "Epoch 09586: loss did not improve from -178.43865\n",
      "Epoch 9587/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1384 - val_loss: -176.5026\n",
      "\n",
      "Epoch 09587: loss did not improve from -178.43865\n",
      "Epoch 9588/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3680 - val_loss: -176.2790\n",
      "\n",
      "Epoch 09588: loss did not improve from -178.43865\n",
      "Epoch 9589/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2675 - val_loss: -176.5022\n",
      "\n",
      "Epoch 09589: loss did not improve from -178.43865\n",
      "Epoch 9590/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4542 - val_loss: -176.3353\n",
      "\n",
      "Epoch 09590: loss improved from -178.43865 to -178.45419, saving model to gendance.h5\n",
      "Epoch 9591/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3066 - val_loss: -176.5754\n",
      "\n",
      "Epoch 09591: loss did not improve from -178.45419\n",
      "Epoch 9592/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1591 - val_loss: -176.3485\n",
      "\n",
      "Epoch 09592: loss did not improve from -178.45419\n",
      "Epoch 9593/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9362 - val_loss: -176.3569\n",
      "\n",
      "Epoch 09593: loss did not improve from -178.45419\n",
      "Epoch 9594/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1048 - val_loss: -176.5044\n",
      "\n",
      "Epoch 09594: loss did not improve from -178.45419\n",
      "Epoch 9595/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1209 - val_loss: -176.3321\n",
      "\n",
      "Epoch 09595: loss did not improve from -178.45419\n",
      "Epoch 9596/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1660 - val_loss: -176.3833\n",
      "\n",
      "Epoch 09596: loss did not improve from -178.45419\n",
      "Epoch 9597/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9295 - val_loss: -176.3305\n",
      "\n",
      "Epoch 09597: loss did not improve from -178.45419\n",
      "Epoch 9598/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9969 - val_loss: -176.4517\n",
      "\n",
      "Epoch 09598: loss did not improve from -178.45419\n",
      "Epoch 9599/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1375 - val_loss: -176.3690\n",
      "\n",
      "Epoch 09599: loss did not improve from -178.45419\n",
      "Epoch 9600/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2299 - val_loss: -176.4086\n",
      "\n",
      "Epoch 09600: loss did not improve from -178.45419\n",
      "Epoch 9601/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0153 - val_loss: -176.3163\n",
      "\n",
      "Epoch 09601: loss did not improve from -178.45419\n",
      "Epoch 9602/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2155 - val_loss: -176.2974\n",
      "\n",
      "Epoch 09602: loss did not improve from -178.45419\n",
      "Epoch 9603/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0205 - val_loss: -176.2985\n",
      "\n",
      "Epoch 09603: loss did not improve from -178.45419\n",
      "Epoch 9604/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9675 - val_loss: -176.3235\n",
      "\n",
      "Epoch 09604: loss did not improve from -178.45419\n",
      "Epoch 9605/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -177.9347 - val_loss: -176.1774\n",
      "\n",
      "Epoch 09605: loss did not improve from -178.45419\n",
      "Epoch 9606/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0640 - val_loss: -176.3785\n",
      "\n",
      "Epoch 09606: loss did not improve from -178.45419\n",
      "Epoch 9607/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1279 - val_loss: -176.1576\n",
      "\n",
      "Epoch 09607: loss did not improve from -178.45419\n",
      "Epoch 9608/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8865 - val_loss: -176.2843\n",
      "\n",
      "Epoch 09608: loss did not improve from -178.45419\n",
      "Epoch 9609/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9375 - val_loss: -176.0983\n",
      "\n",
      "Epoch 09609: loss did not improve from -178.45419\n",
      "Epoch 9610/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2216 - val_loss: -176.5461\n",
      "\n",
      "Epoch 09610: loss did not improve from -178.45419\n",
      "Epoch 9611/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -178.4042 - val_loss: -176.2974\n",
      "\n",
      "Epoch 09611: loss did not improve from -178.45419\n",
      "Epoch 9612/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2554 - val_loss: -176.5083\n",
      "\n",
      "Epoch 09612: loss did not improve from -178.45419\n",
      "Epoch 9613/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1066 - val_loss: -176.3614\n",
      "\n",
      "Epoch 09613: loss did not improve from -178.45419\n",
      "Epoch 9614/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9605 - val_loss: -176.3163\n",
      "\n",
      "Epoch 09614: loss did not improve from -178.45419\n",
      "Epoch 9615/10000\n",
      "16167/16167 [==============================] - 1s 31us/step - loss: -178.0557 - val_loss: -176.2171\n",
      "\n",
      "Epoch 09615: loss did not improve from -178.45419\n",
      "Epoch 9616/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9674 - val_loss: -176.1931\n",
      "\n",
      "Epoch 09616: loss did not improve from -178.45419\n",
      "Epoch 9617/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0661 - val_loss: -176.4255\n",
      "\n",
      "Epoch 09617: loss did not improve from -178.45419\n",
      "Epoch 9618/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1435 - val_loss: -176.2738\n",
      "\n",
      "Epoch 09618: loss did not improve from -178.45419\n",
      "Epoch 9619/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1024 - val_loss: -176.3047\n",
      "\n",
      "Epoch 09619: loss did not improve from -178.45419\n",
      "Epoch 9620/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0966 - val_loss: -176.2860\n",
      "\n",
      "Epoch 09620: loss did not improve from -178.45419\n",
      "Epoch 9621/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9004 - val_loss: -176.2286\n",
      "\n",
      "Epoch 09621: loss did not improve from -178.45419\n",
      "Epoch 9622/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9134 - val_loss: -176.3982\n",
      "\n",
      "Epoch 09622: loss did not improve from -178.45419\n",
      "Epoch 9623/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1434 - val_loss: -175.9721\n",
      "\n",
      "Epoch 09623: loss did not improve from -178.45419\n",
      "Epoch 9624/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8842 - val_loss: -176.1911\n",
      "\n",
      "Epoch 09624: loss did not improve from -178.45419\n",
      "Epoch 9625/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0394 - val_loss: -176.1521\n",
      "\n",
      "Epoch 09625: loss did not improve from -178.45419\n",
      "Epoch 9626/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0460 - val_loss: -176.4343\n",
      "\n",
      "Epoch 09626: loss did not improve from -178.45419\n",
      "Epoch 9627/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.7465 - val_loss: -176.0168\n",
      "\n",
      "Epoch 09627: loss did not improve from -178.45419\n",
      "Epoch 9628/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9931 - val_loss: -176.3748\n",
      "\n",
      "Epoch 09628: loss did not improve from -178.45419\n",
      "Epoch 9629/10000\n",
      "16167/16167 [==============================] - 1s 32us/step - loss: -178.0971 - val_loss: -176.2197\n",
      "\n",
      "Epoch 09629: loss did not improve from -178.45419\n",
      "Epoch 9630/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1850 - val_loss: -176.3447\n",
      "\n",
      "Epoch 09630: loss did not improve from -178.45419\n",
      "Epoch 9631/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0050 - val_loss: -176.4733\n",
      "\n",
      "Epoch 09631: loss did not improve from -178.45419\n",
      "Epoch 9632/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2726 - val_loss: -176.3292\n",
      "\n",
      "Epoch 09632: loss did not improve from -178.45419\n",
      "Epoch 9633/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1365 - val_loss: -176.3067\n",
      "\n",
      "Epoch 09633: loss did not improve from -178.45419\n",
      "Epoch 9634/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1741 - val_loss: -176.3227\n",
      "\n",
      "Epoch 09634: loss did not improve from -178.45419\n",
      "Epoch 9635/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1925 - val_loss: -176.4112\n",
      "\n",
      "Epoch 09635: loss did not improve from -178.45419\n",
      "Epoch 9636/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3765 - val_loss: -176.3394\n",
      "\n",
      "Epoch 09636: loss did not improve from -178.45419\n",
      "Epoch 9637/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1306 - val_loss: -176.3406\n",
      "\n",
      "Epoch 09637: loss did not improve from -178.45419\n",
      "Epoch 9638/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3473 - val_loss: -176.3531\n",
      "\n",
      "Epoch 09638: loss did not improve from -178.45419\n",
      "Epoch 9639/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4054 - val_loss: -176.3813\n",
      "\n",
      "Epoch 09639: loss did not improve from -178.45419\n",
      "Epoch 9640/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2454 - val_loss: -176.2311\n",
      "\n",
      "Epoch 09640: loss did not improve from -178.45419\n",
      "Epoch 9641/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2238 - val_loss: -176.3556\n",
      "\n",
      "Epoch 09641: loss did not improve from -178.45419\n",
      "Epoch 9642/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1844 - val_loss: -176.3768\n",
      "\n",
      "Epoch 09642: loss did not improve from -178.45419\n",
      "Epoch 9643/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -178.0276 - val_loss: -176.3031\n",
      "\n",
      "Epoch 09643: loss did not improve from -178.45419\n",
      "Epoch 9644/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2216 - val_loss: -176.2319\n",
      "\n",
      "Epoch 09644: loss did not improve from -178.45419\n",
      "Epoch 9645/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1570 - val_loss: -176.3397\n",
      "\n",
      "Epoch 09645: loss did not improve from -178.45419\n",
      "Epoch 9646/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9945 - val_loss: -176.3108\n",
      "\n",
      "Epoch 09646: loss did not improve from -178.45419\n",
      "Epoch 9647/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1259 - val_loss: -176.3624\n",
      "\n",
      "Epoch 09647: loss did not improve from -178.45419\n",
      "Epoch 9648/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9933 - val_loss: -176.3149\n",
      "\n",
      "Epoch 09648: loss did not improve from -178.45419\n",
      "Epoch 9649/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.8933 - val_loss: -176.1519\n",
      "\n",
      "Epoch 09649: loss did not improve from -178.45419\n",
      "Epoch 9650/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0460 - val_loss: -176.4536\n",
      "\n",
      "Epoch 09650: loss did not improve from -178.45419\n",
      "Epoch 9651/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3597 - val_loss: -176.2570\n",
      "\n",
      "Epoch 09651: loss did not improve from -178.45419\n",
      "Epoch 9652/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2382 - val_loss: -176.3695\n",
      "\n",
      "Epoch 09652: loss did not improve from -178.45419\n",
      "Epoch 9653/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0221 - val_loss: -176.1167\n",
      "\n",
      "Epoch 09653: loss did not improve from -178.45419\n",
      "Epoch 9654/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2121 - val_loss: -176.3606\n",
      "\n",
      "Epoch 09654: loss did not improve from -178.45419\n",
      "Epoch 9655/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0964 - val_loss: -176.2756\n",
      "\n",
      "Epoch 09655: loss did not improve from -178.45419\n",
      "Epoch 9656/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0790 - val_loss: -176.3578\n",
      "\n",
      "Epoch 09656: loss did not improve from -178.45419\n",
      "Epoch 9657/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.6430 - val_loss: -176.4642\n",
      "\n",
      "Epoch 09657: loss improved from -178.45419 to -178.64296, saving model to gendance.h5\n",
      "Epoch 9658/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1922 - val_loss: -176.2925\n",
      "\n",
      "Epoch 09658: loss did not improve from -178.64296\n",
      "Epoch 9659/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2677 - val_loss: -176.3399\n",
      "\n",
      "Epoch 09659: loss did not improve from -178.64296\n",
      "Epoch 9660/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1416 - val_loss: -176.2617\n",
      "\n",
      "Epoch 09660: loss did not improve from -178.64296\n",
      "Epoch 9661/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9802 - val_loss: -176.3302\n",
      "\n",
      "Epoch 09661: loss did not improve from -178.64296\n",
      "Epoch 9662/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2783 - val_loss: -176.3266\n",
      "\n",
      "Epoch 09662: loss did not improve from -178.64296\n",
      "Epoch 9663/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9641 - val_loss: -176.3091\n",
      "\n",
      "Epoch 09663: loss did not improve from -178.64296\n",
      "Epoch 9664/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2170 - val_loss: -176.2043\n",
      "\n",
      "Epoch 09664: loss did not improve from -178.64296\n",
      "Epoch 9665/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0188 - val_loss: -176.3529\n",
      "\n",
      "Epoch 09665: loss did not improve from -178.64296\n",
      "Epoch 9666/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0628 - val_loss: -176.1856\n",
      "\n",
      "Epoch 09666: loss did not improve from -178.64296\n",
      "Epoch 9667/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0389 - val_loss: -176.3687\n",
      "\n",
      "Epoch 09667: loss did not improve from -178.64296\n",
      "Epoch 9668/10000\n",
      "16167/16167 [==============================] - 1s 33us/step - loss: -178.1276 - val_loss: -176.4206\n",
      "\n",
      "Epoch 09668: loss did not improve from -178.64296\n",
      "Epoch 9669/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0482 - val_loss: -176.2527\n",
      "\n",
      "Epoch 09669: loss did not improve from -178.64296\n",
      "Epoch 9670/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9308 - val_loss: -176.3613\n",
      "\n",
      "Epoch 09670: loss did not improve from -178.64296\n",
      "Epoch 9671/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2034 - val_loss: -176.3169\n",
      "\n",
      "Epoch 09671: loss did not improve from -178.64296\n",
      "Epoch 9672/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1090 - val_loss: -176.3647\n",
      "\n",
      "Epoch 09672: loss did not improve from -178.64296\n",
      "Epoch 9673/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1984 - val_loss: -176.1352\n",
      "\n",
      "Epoch 09673: loss did not improve from -178.64296\n",
      "Epoch 9674/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -178.0369 - val_loss: -176.3769\n",
      "\n",
      "Epoch 09674: loss did not improve from -178.64296\n",
      "Epoch 9675/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1920 - val_loss: -176.3586\n",
      "\n",
      "Epoch 09675: loss did not improve from -178.64296\n",
      "Epoch 9676/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2292 - val_loss: -176.3384\n",
      "\n",
      "Epoch 09676: loss did not improve from -178.64296\n",
      "Epoch 9677/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2225 - val_loss: -176.3658\n",
      "\n",
      "Epoch 09677: loss did not improve from -178.64296\n",
      "Epoch 9678/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2030 - val_loss: -176.3298\n",
      "\n",
      "Epoch 09678: loss did not improve from -178.64296\n",
      "Epoch 9679/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1546 - val_loss: -176.3971\n",
      "\n",
      "Epoch 09679: loss did not improve from -178.64296\n",
      "Epoch 9680/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1881 - val_loss: -176.4091\n",
      "\n",
      "Epoch 09680: loss did not improve from -178.64296\n",
      "Epoch 9681/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2667 - val_loss: -176.3532\n",
      "\n",
      "Epoch 09681: loss did not improve from -178.64296\n",
      "Epoch 9682/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3271 - val_loss: -176.3675\n",
      "\n",
      "Epoch 09682: loss did not improve from -178.64296\n",
      "Epoch 9683/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0843 - val_loss: -176.4145\n",
      "\n",
      "Epoch 09683: loss did not improve from -178.64296\n",
      "Epoch 9684/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1420 - val_loss: -176.3421\n",
      "\n",
      "Epoch 09684: loss did not improve from -178.64296\n",
      "Epoch 9685/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1541 - val_loss: -176.5153\n",
      "\n",
      "Epoch 09685: loss did not improve from -178.64296\n",
      "Epoch 9686/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1673 - val_loss: -176.2282\n",
      "\n",
      "Epoch 09686: loss did not improve from -178.64296\n",
      "Epoch 9687/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0499 - val_loss: -176.4875\n",
      "\n",
      "Epoch 09687: loss did not improve from -178.64296\n",
      "Epoch 9688/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2652 - val_loss: -176.1122\n",
      "\n",
      "Epoch 09688: loss did not improve from -178.64296\n",
      "Epoch 9689/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2419 - val_loss: -176.5246\n",
      "\n",
      "Epoch 09689: loss did not improve from -178.64296\n",
      "Epoch 9690/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1396 - val_loss: -176.1532\n",
      "\n",
      "Epoch 09690: loss did not improve from -178.64296\n",
      "Epoch 9691/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -178.2978 - val_loss: -176.5905\n",
      "\n",
      "Epoch 09691: loss did not improve from -178.64296\n",
      "Epoch 9692/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0389 - val_loss: -176.3171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 09692: loss did not improve from -178.64296\n",
      "Epoch 9693/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2772 - val_loss: -176.4355\n",
      "\n",
      "Epoch 09693: loss did not improve from -178.64296\n",
      "Epoch 9694/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0869 - val_loss: -176.4608\n",
      "\n",
      "Epoch 09694: loss did not improve from -178.64296\n",
      "Epoch 9695/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0647 - val_loss: -176.1341\n",
      "\n",
      "Epoch 09695: loss did not improve from -178.64296\n",
      "Epoch 9696/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1968 - val_loss: -176.5164\n",
      "\n",
      "Epoch 09696: loss did not improve from -178.64296\n",
      "Epoch 9697/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0481 - val_loss: -176.2912\n",
      "\n",
      "Epoch 09697: loss did not improve from -178.64296\n",
      "Epoch 9698/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2335 - val_loss: -176.5024\n",
      "\n",
      "Epoch 09698: loss did not improve from -178.64296\n",
      "Epoch 9699/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1721 - val_loss: -176.1989\n",
      "\n",
      "Epoch 09699: loss did not improve from -178.64296\n",
      "Epoch 9700/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2559 - val_loss: -176.3970\n",
      "\n",
      "Epoch 09700: loss did not improve from -178.64296\n",
      "Epoch 9701/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2451 - val_loss: -176.3654\n",
      "\n",
      "Epoch 09701: loss did not improve from -178.64296\n",
      "Epoch 9702/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4275 - val_loss: -176.4994\n",
      "\n",
      "Epoch 09702: loss did not improve from -178.64296\n",
      "Epoch 9703/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1807 - val_loss: -176.3764\n",
      "\n",
      "Epoch 09703: loss did not improve from -178.64296\n",
      "Epoch 9704/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0727 - val_loss: -176.2862\n",
      "\n",
      "Epoch 09704: loss did not improve from -178.64296\n",
      "Epoch 9705/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1854 - val_loss: -176.3410\n",
      "\n",
      "Epoch 09705: loss did not improve from -178.64296\n",
      "Epoch 9706/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0745 - val_loss: -176.3134\n",
      "\n",
      "Epoch 09706: loss did not improve from -178.64296\n",
      "Epoch 9707/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1252 - val_loss: -176.3644\n",
      "\n",
      "Epoch 09707: loss did not improve from -178.64296\n",
      "Epoch 9708/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2426 - val_loss: -176.3905\n",
      "\n",
      "Epoch 09708: loss did not improve from -178.64296\n",
      "Epoch 9709/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3365 - val_loss: -176.2777\n",
      "\n",
      "Epoch 09709: loss did not improve from -178.64296\n",
      "Epoch 9710/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -178.0470 - val_loss: -176.3637\n",
      "\n",
      "Epoch 09710: loss did not improve from -178.64296\n",
      "Epoch 9711/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9941 - val_loss: -176.1980\n",
      "\n",
      "Epoch 09711: loss did not improve from -178.64296\n",
      "Epoch 9712/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -178.0205 - val_loss: -176.2631\n",
      "\n",
      "Epoch 09712: loss did not improve from -178.64296\n",
      "Epoch 9713/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2858 - val_loss: -176.1752\n",
      "\n",
      "Epoch 09713: loss did not improve from -178.64296\n",
      "Epoch 9714/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1971 - val_loss: -176.3970\n",
      "\n",
      "Epoch 09714: loss did not improve from -178.64296\n",
      "Epoch 9715/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1257 - val_loss: -176.3529\n",
      "\n",
      "Epoch 09715: loss did not improve from -178.64296\n",
      "Epoch 9716/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9467 - val_loss: -176.2395\n",
      "\n",
      "Epoch 09716: loss did not improve from -178.64296\n",
      "Epoch 9717/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0904 - val_loss: -176.4149\n",
      "\n",
      "Epoch 09717: loss did not improve from -178.64296\n",
      "Epoch 9718/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1969 - val_loss: -176.2817\n",
      "\n",
      "Epoch 09718: loss did not improve from -178.64296\n",
      "Epoch 9719/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2143 - val_loss: -176.4985\n",
      "\n",
      "Epoch 09719: loss did not improve from -178.64296\n",
      "Epoch 9720/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1921 - val_loss: -176.3684\n",
      "\n",
      "Epoch 09720: loss did not improve from -178.64296\n",
      "Epoch 9721/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0551 - val_loss: -176.4595\n",
      "\n",
      "Epoch 09721: loss did not improve from -178.64296\n",
      "Epoch 9722/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1323 - val_loss: -176.2981\n",
      "\n",
      "Epoch 09722: loss did not improve from -178.64296\n",
      "Epoch 9723/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3813 - val_loss: -176.4387\n",
      "\n",
      "Epoch 09723: loss did not improve from -178.64296\n",
      "Epoch 9724/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2763 - val_loss: -176.2723\n",
      "\n",
      "Epoch 09724: loss did not improve from -178.64296\n",
      "Epoch 9725/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0259 - val_loss: -176.2984\n",
      "\n",
      "Epoch 09725: loss did not improve from -178.64296\n",
      "Epoch 9726/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4043 - val_loss: -176.3495\n",
      "\n",
      "Epoch 09726: loss did not improve from -178.64296\n",
      "Epoch 9727/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -178.2300 - val_loss: -176.4254\n",
      "\n",
      "Epoch 09727: loss did not improve from -178.64296\n",
      "Epoch 9728/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1560 - val_loss: -176.3739\n",
      "\n",
      "Epoch 09728: loss did not improve from -178.64296\n",
      "Epoch 9729/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1430 - val_loss: -176.5762\n",
      "\n",
      "Epoch 09729: loss did not improve from -178.64296\n",
      "Epoch 9730/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2532 - val_loss: -176.3961\n",
      "\n",
      "Epoch 09730: loss did not improve from -178.64296\n",
      "Epoch 9731/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1944 - val_loss: -176.3567\n",
      "\n",
      "Epoch 09731: loss did not improve from -178.64296\n",
      "Epoch 9732/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2264 - val_loss: -176.4772\n",
      "\n",
      "Epoch 09732: loss did not improve from -178.64296\n",
      "Epoch 9733/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2911 - val_loss: -176.4904\n",
      "\n",
      "Epoch 09733: loss did not improve from -178.64296\n",
      "Epoch 9734/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3184 - val_loss: -176.3289\n",
      "\n",
      "Epoch 09734: loss did not improve from -178.64296\n",
      "Epoch 9735/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0613 - val_loss: -176.2875\n",
      "\n",
      "Epoch 09735: loss did not improve from -178.64296\n",
      "Epoch 9736/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0414 - val_loss: -176.4888\n",
      "\n",
      "Epoch 09736: loss did not improve from -178.64296\n",
      "Epoch 9737/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2034 - val_loss: -176.3952\n",
      "\n",
      "Epoch 09737: loss did not improve from -178.64296\n",
      "Epoch 9738/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1743 - val_loss: -176.3616\n",
      "\n",
      "Epoch 09738: loss did not improve from -178.64296\n",
      "Epoch 9739/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2094 - val_loss: -176.2696\n",
      "\n",
      "Epoch 09739: loss did not improve from -178.64296\n",
      "Epoch 9740/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2780 - val_loss: -176.4441\n",
      "\n",
      "Epoch 09740: loss did not improve from -178.64296\n",
      "Epoch 9741/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2619 - val_loss: -176.3046\n",
      "\n",
      "Epoch 09741: loss did not improve from -178.64296\n",
      "Epoch 9742/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3803 - val_loss: -176.4498\n",
      "\n",
      "Epoch 09742: loss did not improve from -178.64296\n",
      "Epoch 9743/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1418 - val_loss: -176.1064\n",
      "\n",
      "Epoch 09743: loss did not improve from -178.64296\n",
      "Epoch 9744/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1632 - val_loss: -176.3993\n",
      "\n",
      "Epoch 09744: loss did not improve from -178.64296\n",
      "Epoch 9745/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1564 - val_loss: -176.3195\n",
      "\n",
      "Epoch 09745: loss did not improve from -178.64296\n",
      "Epoch 9746/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1630 - val_loss: -176.3239\n",
      "\n",
      "Epoch 09746: loss did not improve from -178.64296\n",
      "Epoch 9747/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2596 - val_loss: -176.3276\n",
      "\n",
      "Epoch 09747: loss did not improve from -178.64296\n",
      "Epoch 9748/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1383 - val_loss: -176.2702\n",
      "\n",
      "Epoch 09748: loss did not improve from -178.64296\n",
      "Epoch 9749/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2742 - val_loss: -176.4613\n",
      "\n",
      "Epoch 09749: loss did not improve from -178.64296\n",
      "Epoch 9750/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -178.0142 - val_loss: -176.1713\n",
      "\n",
      "Epoch 09750: loss did not improve from -178.64296\n",
      "Epoch 9751/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1027 - val_loss: -176.4594\n",
      "\n",
      "Epoch 09751: loss did not improve from -178.64296\n",
      "Epoch 9752/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1551 - val_loss: -176.2561\n",
      "\n",
      "Epoch 09752: loss did not improve from -178.64296\n",
      "Epoch 9753/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3114 - val_loss: -176.4248\n",
      "\n",
      "Epoch 09753: loss did not improve from -178.64296\n",
      "Epoch 9754/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1759 - val_loss: -176.3913\n",
      "\n",
      "Epoch 09754: loss did not improve from -178.64296\n",
      "Epoch 9755/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0803 - val_loss: -176.4711\n",
      "\n",
      "Epoch 09755: loss did not improve from -178.64296\n",
      "Epoch 9756/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4079 - val_loss: -176.4543\n",
      "\n",
      "Epoch 09756: loss did not improve from -178.64296\n",
      "Epoch 9757/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3577 - val_loss: -176.4179\n",
      "\n",
      "Epoch 09757: loss did not improve from -178.64296\n",
      "Epoch 9758/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1972 - val_loss: -176.5288\n",
      "\n",
      "Epoch 09758: loss did not improve from -178.64296\n",
      "Epoch 9759/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4820 - val_loss: -176.4704\n",
      "\n",
      "Epoch 09759: loss did not improve from -178.64296\n",
      "Epoch 9760/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4606 - val_loss: -176.3417\n",
      "\n",
      "Epoch 09760: loss did not improve from -178.64296\n",
      "Epoch 9761/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2748 - val_loss: -176.4427\n",
      "\n",
      "Epoch 09761: loss did not improve from -178.64296\n",
      "Epoch 9762/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3063 - val_loss: -176.4114\n",
      "\n",
      "Epoch 09762: loss did not improve from -178.64296\n",
      "Epoch 9763/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1589 - val_loss: -176.3888\n",
      "\n",
      "Epoch 09763: loss did not improve from -178.64296\n",
      "Epoch 9764/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2009 - val_loss: -176.5301\n",
      "\n",
      "Epoch 09764: loss did not improve from -178.64296\n",
      "Epoch 9765/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2039 - val_loss: -176.1131\n",
      "\n",
      "Epoch 09765: loss did not improve from -178.64296\n",
      "Epoch 9766/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3250 - val_loss: -176.5306\n",
      "\n",
      "Epoch 09766: loss did not improve from -178.64296\n",
      "Epoch 9767/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1983 - val_loss: -176.2433\n",
      "\n",
      "Epoch 09767: loss did not improve from -178.64296\n",
      "Epoch 9768/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2924 - val_loss: -176.5264\n",
      "\n",
      "Epoch 09768: loss did not improve from -178.64296\n",
      "Epoch 9769/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3373 - val_loss: -176.2253\n",
      "\n",
      "Epoch 09769: loss did not improve from -178.64296\n",
      "Epoch 9770/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2093 - val_loss: -176.4163\n",
      "\n",
      "Epoch 09770: loss did not improve from -178.64296\n",
      "Epoch 9771/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9958 - val_loss: -176.1730\n",
      "\n",
      "Epoch 09771: loss did not improve from -178.64296\n",
      "Epoch 9772/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3310 - val_loss: -176.4097\n",
      "\n",
      "Epoch 09772: loss did not improve from -178.64296\n",
      "Epoch 9773/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2784 - val_loss: -176.3426\n",
      "\n",
      "Epoch 09773: loss did not improve from -178.64296\n",
      "Epoch 9774/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3746 - val_loss: -176.3953\n",
      "\n",
      "Epoch 09774: loss did not improve from -178.64296\n",
      "Epoch 9775/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.5481 - val_loss: -176.4946\n",
      "\n",
      "Epoch 09775: loss did not improve from -178.64296\n",
      "Epoch 9776/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3420 - val_loss: -176.4642\n",
      "\n",
      "Epoch 09776: loss did not improve from -178.64296\n",
      "Epoch 9777/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4276 - val_loss: -176.4337\n",
      "\n",
      "Epoch 09777: loss did not improve from -178.64296\n",
      "Epoch 9778/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3512 - val_loss: -176.5448\n",
      "\n",
      "Epoch 09778: loss did not improve from -178.64296\n",
      "Epoch 9779/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3820 - val_loss: -176.4430\n",
      "\n",
      "Epoch 09779: loss did not improve from -178.64296\n",
      "Epoch 9780/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2535 - val_loss: -176.4359\n",
      "\n",
      "Epoch 09780: loss did not improve from -178.64296\n",
      "Epoch 9781/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3412 - val_loss: -176.3402\n",
      "\n",
      "Epoch 09781: loss did not improve from -178.64296\n",
      "Epoch 9782/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3097 - val_loss: -176.4217\n",
      "\n",
      "Epoch 09782: loss did not improve from -178.64296\n",
      "Epoch 9783/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -178.3411 - val_loss: -176.5029\n",
      "\n",
      "Epoch 09783: loss did not improve from -178.64296\n",
      "Epoch 9784/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2359 - val_loss: -176.3061\n",
      "\n",
      "Epoch 09784: loss did not improve from -178.64296\n",
      "Epoch 9785/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2703 - val_loss: -176.4694\n",
      "\n",
      "Epoch 09785: loss did not improve from -178.64296\n",
      "Epoch 9786/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2162 - val_loss: -176.4308\n",
      "\n",
      "Epoch 09786: loss did not improve from -178.64296\n",
      "Epoch 9787/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0474 - val_loss: -176.4179\n",
      "\n",
      "Epoch 09787: loss did not improve from -178.64296\n",
      "Epoch 9788/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1482 - val_loss: -176.2341\n",
      "\n",
      "Epoch 09788: loss did not improve from -178.64296\n",
      "Epoch 9789/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2094 - val_loss: -176.4117\n",
      "\n",
      "Epoch 09789: loss did not improve from -178.64296\n",
      "Epoch 9790/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2951 - val_loss: -176.2509\n",
      "\n",
      "Epoch 09790: loss did not improve from -178.64296\n",
      "Epoch 9791/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2550 - val_loss: -176.4446\n",
      "\n",
      "Epoch 09791: loss did not improve from -178.64296\n",
      "Epoch 9792/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3867 - val_loss: -176.3785\n",
      "\n",
      "Epoch 09792: loss did not improve from -178.64296\n",
      "Epoch 9793/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3374 - val_loss: -176.4666\n",
      "\n",
      "Epoch 09793: loss did not improve from -178.64296\n",
      "Epoch 9794/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2325 - val_loss: -176.4354\n",
      "\n",
      "Epoch 09794: loss did not improve from -178.64296\n",
      "Epoch 9795/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4514 - val_loss: -176.5120\n",
      "\n",
      "Epoch 09795: loss did not improve from -178.64296\n",
      "Epoch 9796/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4099 - val_loss: -176.4785\n",
      "\n",
      "Epoch 09796: loss did not improve from -178.64296\n",
      "Epoch 9797/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -178.4178 - val_loss: -176.5304\n",
      "\n",
      "Epoch 09797: loss did not improve from -178.64296\n",
      "Epoch 9798/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2344 - val_loss: -176.4310\n",
      "\n",
      "Epoch 09798: loss did not improve from -178.64296\n",
      "Epoch 9799/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4779 - val_loss: -176.4640\n",
      "\n",
      "Epoch 09799: loss did not improve from -178.64296\n",
      "Epoch 9800/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1096 - val_loss: -176.3856\n",
      "\n",
      "Epoch 09800: loss did not improve from -178.64296\n",
      "Epoch 9801/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2456 - val_loss: -176.4916\n",
      "\n",
      "Epoch 09801: loss did not improve from -178.64296\n",
      "Epoch 9802/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0067 - val_loss: -176.4652\n",
      "\n",
      "Epoch 09802: loss did not improve from -178.64296\n",
      "Epoch 9803/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4911 - val_loss: -176.2622\n",
      "\n",
      "Epoch 09803: loss did not improve from -178.64296\n",
      "Epoch 9804/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1393 - val_loss: -176.4296\n",
      "\n",
      "Epoch 09804: loss did not improve from -178.64296\n",
      "Epoch 9805/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9859 - val_loss: -175.9349\n",
      "\n",
      "Epoch 09805: loss did not improve from -178.64296\n",
      "Epoch 9806/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2235 - val_loss: -176.4545\n",
      "\n",
      "Epoch 09806: loss did not improve from -178.64296\n",
      "Epoch 9807/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0884 - val_loss: -176.1513\n",
      "\n",
      "Epoch 09807: loss did not improve from -178.64296\n",
      "Epoch 9808/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1313 - val_loss: -176.5286\n",
      "\n",
      "Epoch 09808: loss did not improve from -178.64296\n",
      "Epoch 9809/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0526 - val_loss: -176.3413\n",
      "\n",
      "Epoch 09809: loss did not improve from -178.64296\n",
      "Epoch 9810/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3944 - val_loss: -176.5785\n",
      "\n",
      "Epoch 09810: loss did not improve from -178.64296\n",
      "Epoch 9811/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3102 - val_loss: -176.2628\n",
      "\n",
      "Epoch 09811: loss did not improve from -178.64296\n",
      "Epoch 9812/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2910 - val_loss: -176.5036\n",
      "\n",
      "Epoch 09812: loss did not improve from -178.64296\n",
      "Epoch 9813/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -178.4279 - val_loss: -176.4068\n",
      "\n",
      "Epoch 09813: loss did not improve from -178.64296\n",
      "Epoch 9814/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1988 - val_loss: -176.3240\n",
      "\n",
      "Epoch 09814: loss did not improve from -178.64296\n",
      "Epoch 9815/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.5157 - val_loss: -176.4545\n",
      "\n",
      "Epoch 09815: loss did not improve from -178.64296\n",
      "Epoch 9816/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2184 - val_loss: -176.3926\n",
      "\n",
      "Epoch 09816: loss did not improve from -178.64296\n",
      "Epoch 9817/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1037 - val_loss: -176.3727\n",
      "\n",
      "Epoch 09817: loss did not improve from -178.64296\n",
      "Epoch 9818/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3588 - val_loss: -176.4861\n",
      "\n",
      "Epoch 09818: loss did not improve from -178.64296\n",
      "Epoch 9819/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4688 - val_loss: -176.4580\n",
      "\n",
      "Epoch 09819: loss did not improve from -178.64296\n",
      "Epoch 9820/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4991 - val_loss: -176.4997\n",
      "\n",
      "Epoch 09820: loss did not improve from -178.64296\n",
      "Epoch 9821/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3410 - val_loss: -176.4914\n",
      "\n",
      "Epoch 09821: loss did not improve from -178.64296\n",
      "Epoch 9822/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4150 - val_loss: -176.4659\n",
      "\n",
      "Epoch 09822: loss did not improve from -178.64296\n",
      "Epoch 9823/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3001 - val_loss: -176.3983\n",
      "\n",
      "Epoch 09823: loss did not improve from -178.64296\n",
      "Epoch 9824/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2504 - val_loss: -176.2855\n",
      "\n",
      "Epoch 09824: loss did not improve from -178.64296\n",
      "Epoch 9825/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3703 - val_loss: -176.5222\n",
      "\n",
      "Epoch 09825: loss did not improve from -178.64296\n",
      "Epoch 9826/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.5124 - val_loss: -176.4111\n",
      "\n",
      "Epoch 09826: loss did not improve from -178.64296\n",
      "Epoch 9827/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1980 - val_loss: -176.5317\n",
      "\n",
      "Epoch 09827: loss did not improve from -178.64296\n",
      "Epoch 9828/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3689 - val_loss: -176.4094\n",
      "\n",
      "Epoch 09828: loss did not improve from -178.64296\n",
      "Epoch 9829/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3629 - val_loss: -176.5456\n",
      "\n",
      "Epoch 09829: loss did not improve from -178.64296\n",
      "Epoch 9830/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4343 - val_loss: -176.4924\n",
      "\n",
      "Epoch 09830: loss did not improve from -178.64296\n",
      "Epoch 9831/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3765 - val_loss: -176.4635\n",
      "\n",
      "Epoch 09831: loss did not improve from -178.64296\n",
      "Epoch 9832/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1897 - val_loss: -176.3222\n",
      "\n",
      "Epoch 09832: loss did not improve from -178.64296\n",
      "Epoch 9833/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3329 - val_loss: -176.4752\n",
      "\n",
      "Epoch 09833: loss did not improve from -178.64296\n",
      "Epoch 9834/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -178.5768 - val_loss: -176.3807\n",
      "\n",
      "Epoch 09834: loss did not improve from -178.64296\n",
      "Epoch 9835/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4787 - val_loss: -176.4204\n",
      "\n",
      "Epoch 09835: loss did not improve from -178.64296\n",
      "Epoch 9836/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2632 - val_loss: -176.4977\n",
      "\n",
      "Epoch 09836: loss did not improve from -178.64296\n",
      "Epoch 9837/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4321 - val_loss: -176.3774\n",
      "\n",
      "Epoch 09837: loss did not improve from -178.64296\n",
      "Epoch 9838/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4228 - val_loss: -176.5237\n",
      "\n",
      "Epoch 09838: loss did not improve from -178.64296\n",
      "Epoch 9839/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.5050 - val_loss: -176.5321\n",
      "\n",
      "Epoch 09839: loss did not improve from -178.64296\n",
      "Epoch 9840/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3413 - val_loss: -176.4954\n",
      "\n",
      "Epoch 09840: loss did not improve from -178.64296\n",
      "Epoch 9841/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3811 - val_loss: -176.4717\n",
      "\n",
      "Epoch 09841: loss did not improve from -178.64296\n",
      "Epoch 9842/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3913 - val_loss: -176.5814\n",
      "\n",
      "Epoch 09842: loss did not improve from -178.64296\n",
      "Epoch 9843/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -178.4099 - val_loss: -176.4752\n",
      "\n",
      "Epoch 09843: loss did not improve from -178.64296\n",
      "Epoch 9844/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3294 - val_loss: -176.4424\n",
      "\n",
      "Epoch 09844: loss did not improve from -178.64296\n",
      "Epoch 9845/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0598 - val_loss: -176.2798\n",
      "\n",
      "Epoch 09845: loss did not improve from -178.64296\n",
      "Epoch 9846/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1544 - val_loss: -176.4643\n",
      "\n",
      "Epoch 09846: loss did not improve from -178.64296\n",
      "Epoch 9847/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -178.1835 - val_loss: -176.3993\n",
      "\n",
      "Epoch 09847: loss did not improve from -178.64296\n",
      "Epoch 9848/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2625 - val_loss: -176.4827\n",
      "\n",
      "Epoch 09848: loss did not improve from -178.64296\n",
      "Epoch 9849/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2266 - val_loss: -176.5696\n",
      "\n",
      "Epoch 09849: loss did not improve from -178.64296\n",
      "Epoch 9850/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3498 - val_loss: -176.3241\n",
      "\n",
      "Epoch 09850: loss did not improve from -178.64296\n",
      "Epoch 9851/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3567 - val_loss: -176.4729\n",
      "\n",
      "Epoch 09851: loss did not improve from -178.64296\n",
      "Epoch 9852/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2042 - val_loss: -176.1462\n",
      "\n",
      "Epoch 09852: loss did not improve from -178.64296\n",
      "Epoch 9853/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1526 - val_loss: -176.4894\n",
      "\n",
      "Epoch 09853: loss did not improve from -178.64296\n",
      "Epoch 9854/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4085 - val_loss: -176.2515\n",
      "\n",
      "Epoch 09854: loss did not improve from -178.64296\n",
      "Epoch 9855/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3396 - val_loss: -176.5542\n",
      "\n",
      "Epoch 09855: loss did not improve from -178.64296\n",
      "Epoch 9856/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0875 - val_loss: -176.3124\n",
      "\n",
      "Epoch 09856: loss did not improve from -178.64296\n",
      "Epoch 9857/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2303 - val_loss: -176.3799\n",
      "\n",
      "Epoch 09857: loss did not improve from -178.64296\n",
      "Epoch 9858/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3794 - val_loss: -176.4419\n",
      "\n",
      "Epoch 09858: loss did not improve from -178.64296\n",
      "Epoch 9859/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3561 - val_loss: -176.4832\n",
      "\n",
      "Epoch 09859: loss did not improve from -178.64296\n",
      "Epoch 9860/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.5333 - val_loss: -176.5345\n",
      "\n",
      "Epoch 09860: loss did not improve from -178.64296\n",
      "Epoch 9861/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3383 - val_loss: -176.4838\n",
      "\n",
      "Epoch 09861: loss did not improve from -178.64296\n",
      "Epoch 9862/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4530 - val_loss: -176.5281\n",
      "\n",
      "Epoch 09862: loss did not improve from -178.64296\n",
      "Epoch 9863/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2911 - val_loss: -176.4365\n",
      "\n",
      "Epoch 09863: loss did not improve from -178.64296\n",
      "Epoch 9864/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3353 - val_loss: -176.4334\n",
      "\n",
      "Epoch 09864: loss did not improve from -178.64296\n",
      "Epoch 9865/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1931 - val_loss: -176.3034\n",
      "\n",
      "Epoch 09865: loss did not improve from -178.64296\n",
      "Epoch 9866/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2932 - val_loss: -176.4295\n",
      "\n",
      "Epoch 09866: loss did not improve from -178.64296\n",
      "Epoch 9867/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3955 - val_loss: -176.4269\n",
      "\n",
      "Epoch 09867: loss did not improve from -178.64296\n",
      "Epoch 9868/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3637 - val_loss: -176.4630\n",
      "\n",
      "Epoch 09868: loss did not improve from -178.64296\n",
      "Epoch 9869/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3324 - val_loss: -176.4037\n",
      "\n",
      "Epoch 09869: loss did not improve from -178.64296\n",
      "Epoch 9870/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.5490 - val_loss: -176.6169\n",
      "\n",
      "Epoch 09870: loss did not improve from -178.64296\n",
      "Epoch 9871/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3384 - val_loss: -176.4524\n",
      "\n",
      "Epoch 09871: loss did not improve from -178.64296\n",
      "Epoch 9872/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4174 - val_loss: -176.5002\n",
      "\n",
      "Epoch 09872: loss did not improve from -178.64296\n",
      "Epoch 9873/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2149 - val_loss: -176.3535\n",
      "\n",
      "Epoch 09873: loss did not improve from -178.64296\n",
      "Epoch 9874/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4507 - val_loss: -176.6040\n",
      "\n",
      "Epoch 09874: loss did not improve from -178.64296\n",
      "Epoch 9875/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2887 - val_loss: -176.3645\n",
      "\n",
      "Epoch 09875: loss did not improve from -178.64296\n",
      "Epoch 9876/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4003 - val_loss: -176.4758\n",
      "\n",
      "Epoch 09876: loss did not improve from -178.64296\n",
      "Epoch 9877/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3855 - val_loss: -176.4034\n",
      "\n",
      "Epoch 09877: loss did not improve from -178.64296\n",
      "Epoch 9878/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3132 - val_loss: -176.5508\n",
      "\n",
      "Epoch 09878: loss did not improve from -178.64296\n",
      "Epoch 9879/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4062 - val_loss: -176.4634\n",
      "\n",
      "Epoch 09879: loss did not improve from -178.64296\n",
      "Epoch 9880/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2614 - val_loss: -176.5451\n",
      "\n",
      "Epoch 09880: loss did not improve from -178.64296\n",
      "Epoch 9881/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3878 - val_loss: -176.4393\n",
      "\n",
      "Epoch 09881: loss did not improve from -178.64296\n",
      "Epoch 9882/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4820 - val_loss: -176.6180\n",
      "\n",
      "Epoch 09882: loss did not improve from -178.64296\n",
      "Epoch 9883/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4440 - val_loss: -176.2833\n",
      "\n",
      "Epoch 09883: loss did not improve from -178.64296\n",
      "Epoch 9884/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2766 - val_loss: -176.5164\n",
      "\n",
      "Epoch 09884: loss did not improve from -178.64296\n",
      "Epoch 9885/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2838 - val_loss: -176.3599\n",
      "\n",
      "Epoch 09885: loss did not improve from -178.64296\n",
      "Epoch 9886/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.5218 - val_loss: -176.5796\n",
      "\n",
      "Epoch 09886: loss did not improve from -178.64296\n",
      "Epoch 9887/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3709 - val_loss: -176.3670\n",
      "\n",
      "Epoch 09887: loss did not improve from -178.64296\n",
      "Epoch 9888/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 31us/step - loss: -178.3216 - val_loss: -176.5631\n",
      "\n",
      "Epoch 09888: loss did not improve from -178.64296\n",
      "Epoch 9889/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -178.4574 - val_loss: -176.5630\n",
      "\n",
      "Epoch 09889: loss did not improve from -178.64296\n",
      "Epoch 9890/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3629 - val_loss: -176.4575\n",
      "\n",
      "Epoch 09890: loss did not improve from -178.64296\n",
      "Epoch 9891/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.0959 - val_loss: -176.3883\n",
      "\n",
      "Epoch 09891: loss did not improve from -178.64296\n",
      "Epoch 9892/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4959 - val_loss: -176.6363\n",
      "\n",
      "Epoch 09892: loss did not improve from -178.64296\n",
      "Epoch 9893/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2695 - val_loss: -176.3364\n",
      "\n",
      "Epoch 09893: loss did not improve from -178.64296\n",
      "Epoch 9894/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3332 - val_loss: -176.5738\n",
      "\n",
      "Epoch 09894: loss did not improve from -178.64296\n",
      "Epoch 9895/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4164 - val_loss: -176.4524\n",
      "\n",
      "Epoch 09895: loss did not improve from -178.64296\n",
      "Epoch 9896/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2587 - val_loss: -176.4982\n",
      "\n",
      "Epoch 09896: loss did not improve from -178.64296\n",
      "Epoch 9897/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3123 - val_loss: -176.6069\n",
      "\n",
      "Epoch 09897: loss did not improve from -178.64296\n",
      "Epoch 9898/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3749 - val_loss: -176.3125\n",
      "\n",
      "Epoch 09898: loss did not improve from -178.64296\n",
      "Epoch 9899/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1307 - val_loss: -176.5578\n",
      "\n",
      "Epoch 09899: loss did not improve from -178.64296\n",
      "Epoch 9900/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1421 - val_loss: -176.3525\n",
      "\n",
      "Epoch 09900: loss did not improve from -178.64296\n",
      "Epoch 9901/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2635 - val_loss: -176.4808\n",
      "\n",
      "Epoch 09901: loss did not improve from -178.64296\n",
      "Epoch 9902/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1543 - val_loss: -176.3033\n",
      "\n",
      "Epoch 09902: loss did not improve from -178.64296\n",
      "Epoch 9903/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -177.9572 - val_loss: -176.4380\n",
      "\n",
      "Epoch 09903: loss did not improve from -178.64296\n",
      "Epoch 9904/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2160 - val_loss: -176.2393\n",
      "\n",
      "Epoch 09904: loss did not improve from -178.64296\n",
      "Epoch 9905/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4046 - val_loss: -176.5526\n",
      "\n",
      "Epoch 09905: loss did not improve from -178.64296\n",
      "Epoch 9906/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4224 - val_loss: -176.5686\n",
      "\n",
      "Epoch 09906: loss did not improve from -178.64296\n",
      "Epoch 9907/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4341 - val_loss: -176.5748\n",
      "\n",
      "Epoch 09907: loss did not improve from -178.64296\n",
      "Epoch 9908/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4078 - val_loss: -176.5506\n",
      "\n",
      "Epoch 09908: loss did not improve from -178.64296\n",
      "Epoch 9909/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4811 - val_loss: -176.5935\n",
      "\n",
      "Epoch 09909: loss did not improve from -178.64296\n",
      "Epoch 9910/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4927 - val_loss: -176.5983\n",
      "\n",
      "Epoch 09910: loss did not improve from -178.64296\n",
      "Epoch 9911/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4588 - val_loss: -176.5904\n",
      "\n",
      "Epoch 09911: loss did not improve from -178.64296\n",
      "Epoch 9912/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4661 - val_loss: -176.4838\n",
      "\n",
      "Epoch 09912: loss did not improve from -178.64296\n",
      "Epoch 9913/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2293 - val_loss: -176.5103\n",
      "\n",
      "Epoch 09913: loss did not improve from -178.64296\n",
      "Epoch 9914/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.1834 - val_loss: -176.3751\n",
      "\n",
      "Epoch 09914: loss did not improve from -178.64296\n",
      "Epoch 9915/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.6065 - val_loss: -176.5598\n",
      "\n",
      "Epoch 09915: loss did not improve from -178.64296\n",
      "Epoch 9916/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3825 - val_loss: -176.4585\n",
      "\n",
      "Epoch 09916: loss did not improve from -178.64296\n",
      "Epoch 9917/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2744 - val_loss: -176.5946\n",
      "\n",
      "Epoch 09917: loss did not improve from -178.64296\n",
      "Epoch 9918/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4204 - val_loss: -176.5404\n",
      "\n",
      "Epoch 09918: loss did not improve from -178.64296\n",
      "Epoch 9919/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4653 - val_loss: -176.6233\n",
      "\n",
      "Epoch 09919: loss did not improve from -178.64296\n",
      "Epoch 9920/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4764 - val_loss: -176.3265\n",
      "\n",
      "Epoch 09920: loss did not improve from -178.64296\n",
      "Epoch 9921/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4458 - val_loss: -176.5376\n",
      "\n",
      "Epoch 09921: loss did not improve from -178.64296\n",
      "Epoch 9922/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.6138 - val_loss: -176.3529\n",
      "\n",
      "Epoch 09922: loss did not improve from -178.64296\n",
      "Epoch 9923/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2436 - val_loss: -176.5173\n",
      "\n",
      "Epoch 09923: loss did not improve from -178.64296\n",
      "Epoch 9924/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2593 - val_loss: -176.3921\n",
      "\n",
      "Epoch 09924: loss did not improve from -178.64296\n",
      "Epoch 9925/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.5480 - val_loss: -176.5419\n",
      "\n",
      "Epoch 09925: loss did not improve from -178.64296\n",
      "Epoch 9926/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4020 - val_loss: -176.4625\n",
      "\n",
      "Epoch 09926: loss did not improve from -178.64296\n",
      "Epoch 9927/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.5203 - val_loss: -176.4998\n",
      "\n",
      "Epoch 09927: loss did not improve from -178.64296\n",
      "Epoch 9928/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3097 - val_loss: -176.4631\n",
      "\n",
      "Epoch 09928: loss did not improve from -178.64296\n",
      "Epoch 9929/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -178.3277 - val_loss: -176.4869\n",
      "\n",
      "Epoch 09929: loss did not improve from -178.64296\n",
      "Epoch 9930/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2998 - val_loss: -176.5683\n",
      "\n",
      "Epoch 09930: loss did not improve from -178.64296\n",
      "Epoch 9931/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4707 - val_loss: -176.4405\n",
      "\n",
      "Epoch 09931: loss did not improve from -178.64296\n",
      "Epoch 9932/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4500 - val_loss: -176.5319\n",
      "\n",
      "Epoch 09932: loss did not improve from -178.64296\n",
      "Epoch 9933/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.6243 - val_loss: -176.5153\n",
      "\n",
      "Epoch 09933: loss did not improve from -178.64296\n",
      "Epoch 9934/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4572 - val_loss: -176.5618\n",
      "\n",
      "Epoch 09934: loss did not improve from -178.64296\n",
      "Epoch 9935/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.6426 - val_loss: -176.6831\n",
      "\n",
      "Epoch 09935: loss did not improve from -178.64296\n",
      "Epoch 9936/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4358 - val_loss: -176.5829\n",
      "\n",
      "Epoch 09936: loss did not improve from -178.64296\n",
      "Epoch 9937/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3059 - val_loss: -176.6273\n",
      "\n",
      "Epoch 09937: loss did not improve from -178.64296\n",
      "Epoch 9938/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.5558 - val_loss: -176.5830\n",
      "\n",
      "Epoch 09938: loss did not improve from -178.64296\n",
      "Epoch 9939/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3724 - val_loss: -176.5310\n",
      "\n",
      "Epoch 09939: loss did not improve from -178.64296\n",
      "Epoch 9940/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3994 - val_loss: -176.5378\n",
      "\n",
      "Epoch 09940: loss did not improve from -178.64296\n",
      "Epoch 9941/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -178.4802 - val_loss: -176.3473\n",
      "\n",
      "Epoch 09941: loss did not improve from -178.64296\n",
      "Epoch 9942/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3267 - val_loss: -176.6605\n",
      "\n",
      "Epoch 09942: loss did not improve from -178.64296\n",
      "Epoch 9943/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.5984 - val_loss: -176.4192\n",
      "\n",
      "Epoch 09943: loss did not improve from -178.64296\n",
      "Epoch 9944/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4166 - val_loss: -176.5432\n",
      "\n",
      "Epoch 09944: loss did not improve from -178.64296\n",
      "Epoch 9945/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.5141 - val_loss: -176.4653\n",
      "\n",
      "Epoch 09945: loss did not improve from -178.64296\n",
      "Epoch 9946/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4683 - val_loss: -176.5847\n",
      "\n",
      "Epoch 09946: loss did not improve from -178.64296\n",
      "Epoch 9947/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3100 - val_loss: -176.2813\n",
      "\n",
      "Epoch 09947: loss did not improve from -178.64296\n",
      "Epoch 9948/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3077 - val_loss: -176.6445\n",
      "\n",
      "Epoch 09948: loss did not improve from -178.64296\n",
      "Epoch 9949/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.5594 - val_loss: -176.5166\n",
      "\n",
      "Epoch 09949: loss did not improve from -178.64296\n",
      "Epoch 9950/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3873 - val_loss: -176.5156\n",
      "\n",
      "Epoch 09950: loss did not improve from -178.64296\n",
      "Epoch 9951/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -178.3342 - val_loss: -176.3340\n",
      "\n",
      "Epoch 09951: loss did not improve from -178.64296\n",
      "Epoch 9952/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3199 - val_loss: -176.6350\n",
      "\n",
      "Epoch 09952: loss did not improve from -178.64296\n",
      "Epoch 9953/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4768 - val_loss: -176.5316\n",
      "\n",
      "Epoch 09953: loss did not improve from -178.64296\n",
      "Epoch 9954/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.6183 - val_loss: -176.5769\n",
      "\n",
      "Epoch 09954: loss did not improve from -178.64296\n",
      "Epoch 9955/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.5007 - val_loss: -176.6760\n",
      "\n",
      "Epoch 09955: loss did not improve from -178.64296\n",
      "Epoch 9956/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2846 - val_loss: -176.5224\n",
      "\n",
      "Epoch 09956: loss did not improve from -178.64296\n",
      "Epoch 9957/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2279 - val_loss: -176.6658\n",
      "\n",
      "Epoch 09957: loss did not improve from -178.64296\n",
      "Epoch 9958/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.5812 - val_loss: -176.5332\n",
      "\n",
      "Epoch 09958: loss did not improve from -178.64296\n",
      "Epoch 9959/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.5502 - val_loss: -176.6473\n",
      "\n",
      "Epoch 09959: loss did not improve from -178.64296\n",
      "Epoch 9960/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4596 - val_loss: -176.4386\n",
      "\n",
      "Epoch 09960: loss did not improve from -178.64296\n",
      "Epoch 9961/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3112 - val_loss: -176.4067\n",
      "\n",
      "Epoch 09961: loss did not improve from -178.64296\n",
      "Epoch 9962/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4461 - val_loss: -176.5623\n",
      "\n",
      "Epoch 09962: loss did not improve from -178.64296\n",
      "Epoch 9963/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4551 - val_loss: -176.4470\n",
      "\n",
      "Epoch 09963: loss did not improve from -178.64296\n",
      "Epoch 9964/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3895 - val_loss: -176.6495\n",
      "\n",
      "Epoch 09964: loss did not improve from -178.64296\n",
      "Epoch 9965/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4466 - val_loss: -176.4135\n",
      "\n",
      "Epoch 09965: loss did not improve from -178.64296\n",
      "Epoch 9966/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3752 - val_loss: -176.7103\n",
      "\n",
      "Epoch 09966: loss did not improve from -178.64296\n",
      "Epoch 9967/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.6797 - val_loss: -176.5436\n",
      "\n",
      "Epoch 09967: loss improved from -178.64296 to -178.67967, saving model to gendance.h5\n",
      "Epoch 9968/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3894 - val_loss: -176.6422\n",
      "\n",
      "Epoch 09968: loss did not improve from -178.67967\n",
      "Epoch 9969/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4771 - val_loss: -176.3592\n",
      "\n",
      "Epoch 09969: loss did not improve from -178.67967\n",
      "Epoch 9970/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.5362 - val_loss: -176.6290\n",
      "\n",
      "Epoch 09970: loss did not improve from -178.67967\n",
      "Epoch 9971/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4461 - val_loss: -176.5943\n",
      "\n",
      "Epoch 09971: loss did not improve from -178.67967\n",
      "Epoch 9972/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3330 - val_loss: -176.4978\n",
      "\n",
      "Epoch 09972: loss did not improve from -178.67967\n",
      "Epoch 9973/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4021 - val_loss: -176.5048\n",
      "\n",
      "Epoch 09973: loss did not improve from -178.67967\n",
      "Epoch 9974/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3620 - val_loss: -176.6444\n",
      "\n",
      "Epoch 09974: loss did not improve from -178.67967\n",
      "Epoch 9975/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4509 - val_loss: -176.4320\n",
      "\n",
      "Epoch 09975: loss did not improve from -178.67967\n",
      "Epoch 9976/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4026 - val_loss: -176.5956\n",
      "\n",
      "Epoch 09976: loss did not improve from -178.67967\n",
      "Epoch 9977/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2579 - val_loss: -176.2366\n",
      "\n",
      "Epoch 09977: loss did not improve from -178.67967\n",
      "Epoch 9978/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2447 - val_loss: -176.6374\n",
      "\n",
      "Epoch 09978: loss did not improve from -178.67967\n",
      "Epoch 9979/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3028 - val_loss: -176.3315\n",
      "\n",
      "Epoch 09979: loss did not improve from -178.67967\n",
      "Epoch 9980/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4628 - val_loss: -176.6292\n",
      "\n",
      "Epoch 09980: loss did not improve from -178.67967\n",
      "Epoch 9981/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4805 - val_loss: -176.2476\n",
      "\n",
      "Epoch 09981: loss did not improve from -178.67967\n",
      "Epoch 9982/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2183 - val_loss: -176.5265\n",
      "\n",
      "Epoch 09982: loss did not improve from -178.67967\n",
      "Epoch 9983/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3368 - val_loss: -176.3749\n",
      "\n",
      "Epoch 09983: loss did not improve from -178.67967\n",
      "Epoch 9984/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4949 - val_loss: -176.5546\n",
      "\n",
      "Epoch 09984: loss did not improve from -178.67967\n",
      "Epoch 9985/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -178.3728 - val_loss: -176.2658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 09985: loss did not improve from -178.67967\n",
      "Epoch 9986/10000\n",
      "16167/16167 [==============================] - 0s 31us/step - loss: -178.4337 - val_loss: -176.5105\n",
      "\n",
      "Epoch 09986: loss did not improve from -178.67967\n",
      "Epoch 9987/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2908 - val_loss: -176.4101\n",
      "\n",
      "Epoch 09987: loss did not improve from -178.67967\n",
      "Epoch 9988/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.5940 - val_loss: -176.6320\n",
      "\n",
      "Epoch 09988: loss did not improve from -178.67967\n",
      "Epoch 9989/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3315 - val_loss: -176.5593\n",
      "\n",
      "Epoch 09989: loss did not improve from -178.67967\n",
      "Epoch 9990/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4281 - val_loss: -176.5999\n",
      "\n",
      "Epoch 09990: loss did not improve from -178.67967\n",
      "Epoch 9991/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2493 - val_loss: -176.4938\n",
      "\n",
      "Epoch 09991: loss did not improve from -178.67967\n",
      "Epoch 9992/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4036 - val_loss: -176.5416\n",
      "\n",
      "Epoch 09992: loss did not improve from -178.67967\n",
      "Epoch 9993/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.6545 - val_loss: -176.7167\n",
      "\n",
      "Epoch 09993: loss did not improve from -178.67967\n",
      "Epoch 9994/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4028 - val_loss: -176.3215\n",
      "\n",
      "Epoch 09994: loss did not improve from -178.67967\n",
      "Epoch 9995/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4656 - val_loss: -176.6573\n",
      "\n",
      "Epoch 09995: loss did not improve from -178.67967\n",
      "Epoch 9996/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.2681 - val_loss: -176.2698\n",
      "\n",
      "Epoch 09996: loss did not improve from -178.67967\n",
      "Epoch 9997/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4705 - val_loss: -176.7564\n",
      "\n",
      "Epoch 09997: loss did not improve from -178.67967\n",
      "Epoch 9998/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.4587 - val_loss: -176.3063\n",
      "\n",
      "Epoch 09998: loss did not improve from -178.67967\n",
      "Epoch 9999/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.5498 - val_loss: -176.6769\n",
      "\n",
      "Epoch 09999: loss did not improve from -178.67967\n",
      "Epoch 10000/10000\n",
      "16167/16167 [==============================] - 0s 30us/step - loss: -178.3394 - val_loss: -176.3703\n",
      "\n",
      "Epoch 10000: loss did not improve from -178.67967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f542e7a2a20>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data[0:len(data)-1]\n",
    "Y = data[1:len(data)]\n",
    "checkpoint = keras.callbacks.ModelCheckpoint('gendance.h5', monitor='loss', verbose=1, save_best_only=True, mode='auto')\n",
    "callbacks_list = [checkpoint]\n",
    "model.fit(X,Y,batch_size=1024, verbose=1, shuffle=False, validation_split=0.20, epochs=10000, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.load_weights(\"vae_cnn.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"gendance.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "video = cv2.VideoWriter(\"out.mp4\", fourcc, 30.0, (208, 120))\n",
    "lv_in = data[2000]\n",
    "for i in range(1000):\n",
    "    input = np.array(lv_in).reshape(1,128)\n",
    "    lv_out = model.predict(input)\n",
    "    shape = np.array(lv_out).shape[1]\n",
    "    lv_out = np.array(lv_out).reshape(shape)\n",
    "    lv_out = mdn.sample_from_output(lv_out,128,numComponents,temp=0.05)\n",
    "    lv_out = scaler.inverse_transform(lv_out)\n",
    "    img = decoder.predict(np.array(lv_out).reshape(1,128))\n",
    "    \n",
    "    img = np.array(img).reshape(120,208,1)\n",
    "    img = img * 255\n",
    "    img = np.array(img).astype(\"uint8\")\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_GRAY2RGB)\n",
    "    lv_in = lv_out\n",
    "    video.write(img)\n",
    "video.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
