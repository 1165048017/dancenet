{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import mdn\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20023, 1, 128)\n"
     ]
    }
   ],
   "source": [
    "data = np.load('./lv.npy')\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data).reshape(-1,128)\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler = scaler.fit(data)\n",
    "data =  scaler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "numComponents = 24\n",
    "outputDim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 1, 512)            1312768   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 512)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 1, 512)            2099200   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1, 512)            0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 512)               2099200   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1000)              513000    \n",
      "_________________________________________________________________\n",
      "mdn_1 (MDN)                  (None, 128)               6174168   \n",
      "=================================================================\n",
      "Total params: 12,198,336\n",
      "Trainable params: 12,198,336\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.layers.Input(shape=(128,))\n",
    "x = keras.layers.Reshape((1,128))(inputs)\n",
    "x = keras.layers.LSTM(512, return_sequences=True,input_shape=(1,128))(x)\n",
    "x = keras.layers.Dropout(0.40)(x)\n",
    "x = keras.layers.LSTM(512, return_sequences=True)(x)\n",
    "x = keras.layers.Dropout(0.40)(x)\n",
    "x = keras.layers.LSTM(512)(x)\n",
    "x = keras.layers.Dropout(0.25)(x)\n",
    "x = keras.layers.Dense(1000,activation='relu')(x)\n",
    "outputs = mdn.MDN(outputDim, numComponents)(x)\n",
    "model = keras.models.Model(inputs=inputs,outputs=outputs)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.adam(lr=0.0005)\n",
    "model.compile(loss=mdn.get_mixture_loss_func(outputDim,numComponents),optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_grad.py:249: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Train on 16017 samples, validate on 4005 samples\n",
      "Epoch 1/2000\n",
      "16017/16017 [==============================] - 9s 586us/step - loss: 34.8831 - val_loss: -70.8801\n",
      "\n",
      "Epoch 00001: loss improved from inf to 34.88306, saving model to gendance.h5\n",
      "Epoch 2/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -71.7206 - val_loss: -79.8362\n",
      "\n",
      "Epoch 00002: loss improved from 34.88306 to -71.72057, saving model to gendance.h5\n",
      "Epoch 3/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -75.2558 - val_loss: -78.1746\n",
      "\n",
      "Epoch 00003: loss improved from -71.72057 to -75.25576, saving model to gendance.h5\n",
      "Epoch 4/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -76.3354 - val_loss: -80.7912\n",
      "\n",
      "Epoch 00004: loss improved from -75.25576 to -76.33541, saving model to gendance.h5\n",
      "Epoch 5/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -77.7319 - val_loss: -80.6288\n",
      "\n",
      "Epoch 00005: loss improved from -76.33541 to -77.73191, saving model to gendance.h5\n",
      "Epoch 6/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -78.2915 - val_loss: -80.7760\n",
      "\n",
      "Epoch 00006: loss improved from -77.73191 to -78.29145, saving model to gendance.h5\n",
      "Epoch 7/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -79.0574 - val_loss: -80.7140\n",
      "\n",
      "Epoch 00007: loss improved from -78.29145 to -79.05742, saving model to gendance.h5\n",
      "Epoch 8/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -79.4275 - val_loss: -81.0205\n",
      "\n",
      "Epoch 00008: loss improved from -79.05742 to -79.42748, saving model to gendance.h5\n",
      "Epoch 9/2000\n",
      "16017/16017 [==============================] - 1s 55us/step - loss: -79.5994 - val_loss: -80.9945\n",
      "\n",
      "Epoch 00009: loss improved from -79.42748 to -79.59942, saving model to gendance.h5\n",
      "Epoch 10/2000\n",
      "16017/16017 [==============================] - 1s 54us/step - loss: -79.5957 - val_loss: -80.4497\n",
      "\n",
      "Epoch 00010: loss did not improve from -79.59942\n",
      "Epoch 11/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -79.6816 - val_loss: -81.0464\n",
      "\n",
      "Epoch 00011: loss improved from -79.59942 to -79.68161, saving model to gendance.h5\n",
      "Epoch 12/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -79.8030 - val_loss: -80.9385\n",
      "\n",
      "Epoch 00012: loss improved from -79.68161 to -79.80302, saving model to gendance.h5\n",
      "Epoch 13/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -79.9534 - val_loss: -80.5426\n",
      "\n",
      "Epoch 00013: loss improved from -79.80302 to -79.95342, saving model to gendance.h5\n",
      "Epoch 14/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -79.8067 - val_loss: -80.7252\n",
      "\n",
      "Epoch 00014: loss did not improve from -79.95342\n",
      "Epoch 15/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -79.9487 - val_loss: -80.9467\n",
      "\n",
      "Epoch 00015: loss did not improve from -79.95342\n",
      "Epoch 16/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -80.0670 - val_loss: -80.8802\n",
      "\n",
      "Epoch 00016: loss improved from -79.95342 to -80.06703, saving model to gendance.h5\n",
      "Epoch 17/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -80.1307 - val_loss: -80.9477\n",
      "\n",
      "Epoch 00017: loss improved from -80.06703 to -80.13066, saving model to gendance.h5\n",
      "Epoch 18/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -80.1221 - val_loss: -80.9847\n",
      "\n",
      "Epoch 00018: loss did not improve from -80.13066\n",
      "Epoch 19/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -80.1585 - val_loss: -80.6488\n",
      "\n",
      "Epoch 00019: loss improved from -80.13066 to -80.15847, saving model to gendance.h5\n",
      "Epoch 20/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -80.2179 - val_loss: -80.8084\n",
      "\n",
      "Epoch 00020: loss improved from -80.15847 to -80.21787, saving model to gendance.h5\n",
      "Epoch 21/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -80.2743 - val_loss: -80.9253\n",
      "\n",
      "Epoch 00021: loss improved from -80.21787 to -80.27430, saving model to gendance.h5\n",
      "Epoch 22/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -80.3411 - val_loss: -80.8568\n",
      "\n",
      "Epoch 00022: loss improved from -80.27430 to -80.34107, saving model to gendance.h5\n",
      "Epoch 23/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -80.3363 - val_loss: -81.1381\n",
      "\n",
      "Epoch 00023: loss did not improve from -80.34107\n",
      "Epoch 24/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -80.4920 - val_loss: -81.1318\n",
      "\n",
      "Epoch 00024: loss improved from -80.34107 to -80.49200, saving model to gendance.h5\n",
      "Epoch 25/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -80.5282 - val_loss: -81.2551\n",
      "\n",
      "Epoch 00025: loss improved from -80.49200 to -80.52820, saving model to gendance.h5\n",
      "Epoch 26/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -80.6595 - val_loss: -81.3078\n",
      "\n",
      "Epoch 00026: loss improved from -80.52820 to -80.65946, saving model to gendance.h5\n",
      "Epoch 27/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -80.7595 - val_loss: -81.2695\n",
      "\n",
      "Epoch 00027: loss improved from -80.65946 to -80.75955, saving model to gendance.h5\n",
      "Epoch 28/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -81.0946 - val_loss: -81.9269\n",
      "\n",
      "Epoch 00028: loss improved from -80.75955 to -81.09456, saving model to gendance.h5\n",
      "Epoch 29/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -81.8568 - val_loss: -83.1744\n",
      "\n",
      "Epoch 00029: loss improved from -81.09456 to -81.85678, saving model to gendance.h5\n",
      "Epoch 30/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -82.8937 - val_loss: -84.4803\n",
      "\n",
      "Epoch 00030: loss improved from -81.85678 to -82.89366, saving model to gendance.h5\n",
      "Epoch 31/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -84.3706 - val_loss: -84.9828\n",
      "\n",
      "Epoch 00031: loss improved from -82.89366 to -84.37063, saving model to gendance.h5\n",
      "Epoch 32/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -85.2438 - val_loss: -85.5975\n",
      "\n",
      "Epoch 00032: loss improved from -84.37063 to -85.24383, saving model to gendance.h5\n",
      "Epoch 33/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -86.0555 - val_loss: -86.2493\n",
      "\n",
      "Epoch 00033: loss improved from -85.24383 to -86.05552, saving model to gendance.h5\n",
      "Epoch 34/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -86.7226 - val_loss: -86.3990\n",
      "\n",
      "Epoch 00034: loss improved from -86.05552 to -86.72262, saving model to gendance.h5\n",
      "Epoch 35/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -87.4689 - val_loss: -86.7306\n",
      "\n",
      "Epoch 00035: loss improved from -86.72262 to -87.46889, saving model to gendance.h5\n",
      "Epoch 36/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -88.6614 - val_loss: -88.3565\n",
      "\n",
      "Epoch 00036: loss improved from -87.46889 to -88.66137, saving model to gendance.h5\n",
      "Epoch 37/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -89.7848 - val_loss: -89.2108\n",
      "\n",
      "Epoch 00037: loss improved from -88.66137 to -89.78476, saving model to gendance.h5\n",
      "Epoch 38/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -90.8479 - val_loss: -89.4121\n",
      "\n",
      "Epoch 00038: loss improved from -89.78476 to -90.84792, saving model to gendance.h5\n",
      "Epoch 39/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -91.5711 - val_loss: -90.5939\n",
      "\n",
      "Epoch 00039: loss improved from -90.84792 to -91.57106, saving model to gendance.h5\n",
      "Epoch 40/2000\n",
      "16017/16017 [==============================] - 1s 53us/step - loss: -92.4477 - val_loss: -91.4952\n",
      "\n",
      "Epoch 00040: loss improved from -91.57106 to -92.44771, saving model to gendance.h5\n",
      "Epoch 41/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -93.5143 - val_loss: -92.6770\n",
      "\n",
      "Epoch 00041: loss improved from -92.44771 to -93.51430, saving model to gendance.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -94.8994 - val_loss: -94.3569\n",
      "\n",
      "Epoch 00042: loss improved from -93.51430 to -94.89943, saving model to gendance.h5\n",
      "Epoch 43/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -96.7887 - val_loss: -96.5632\n",
      "\n",
      "Epoch 00043: loss improved from -94.89943 to -96.78871, saving model to gendance.h5\n",
      "Epoch 44/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -98.7557 - val_loss: -98.6610\n",
      "\n",
      "Epoch 00044: loss improved from -96.78871 to -98.75567, saving model to gendance.h5\n",
      "Epoch 45/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -100.5300 - val_loss: -100.4646\n",
      "\n",
      "Epoch 00045: loss improved from -98.75567 to -100.53000, saving model to gendance.h5\n",
      "Epoch 46/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -102.3791 - val_loss: -102.3316\n",
      "\n",
      "Epoch 00046: loss improved from -100.53000 to -102.37907, saving model to gendance.h5\n",
      "Epoch 47/2000\n",
      "16017/16017 [==============================] - 1s 53us/step - loss: -104.4858 - val_loss: -104.4881\n",
      "\n",
      "Epoch 00047: loss improved from -102.37907 to -104.48583, saving model to gendance.h5\n",
      "Epoch 48/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -106.0901 - val_loss: -105.9736\n",
      "\n",
      "Epoch 00048: loss improved from -104.48583 to -106.09006, saving model to gendance.h5\n",
      "Epoch 49/2000\n",
      "16017/16017 [==============================] - 1s 56us/step - loss: -107.5830 - val_loss: -108.0549\n",
      "\n",
      "Epoch 00049: loss improved from -106.09006 to -107.58301, saving model to gendance.h5\n",
      "Epoch 50/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -109.3035 - val_loss: -109.4809\n",
      "\n",
      "Epoch 00050: loss improved from -107.58301 to -109.30351, saving model to gendance.h5\n",
      "Epoch 51/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -110.8311 - val_loss: -111.4199\n",
      "\n",
      "Epoch 00051: loss improved from -109.30351 to -110.83112, saving model to gendance.h5\n",
      "Epoch 52/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -112.4382 - val_loss: -113.4534\n",
      "\n",
      "Epoch 00052: loss improved from -110.83112 to -112.43824, saving model to gendance.h5\n",
      "Epoch 53/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -114.0173 - val_loss: -115.1263\n",
      "\n",
      "Epoch 00053: loss improved from -112.43824 to -114.01734, saving model to gendance.h5\n",
      "Epoch 54/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -115.4922 - val_loss: -117.2084\n",
      "\n",
      "Epoch 00054: loss improved from -114.01734 to -115.49225, saving model to gendance.h5\n",
      "Epoch 55/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -116.6446 - val_loss: -118.5202\n",
      "\n",
      "Epoch 00055: loss improved from -115.49225 to -116.64460, saving model to gendance.h5\n",
      "Epoch 56/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -117.7083 - val_loss: -119.6438\n",
      "\n",
      "Epoch 00056: loss improved from -116.64460 to -117.70826, saving model to gendance.h5\n",
      "Epoch 57/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -118.8274 - val_loss: -121.1033\n",
      "\n",
      "Epoch 00057: loss improved from -117.70826 to -118.82743, saving model to gendance.h5\n",
      "Epoch 58/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -119.8009 - val_loss: -121.4936\n",
      "\n",
      "Epoch 00058: loss improved from -118.82743 to -119.80090, saving model to gendance.h5\n",
      "Epoch 59/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -120.4149 - val_loss: -122.9414\n",
      "\n",
      "Epoch 00059: loss improved from -119.80090 to -120.41487, saving model to gendance.h5\n",
      "Epoch 60/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -121.1300 - val_loss: -123.7211\n",
      "\n",
      "Epoch 00060: loss improved from -120.41487 to -121.13002, saving model to gendance.h5\n",
      "Epoch 61/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -121.5602 - val_loss: -123.5536\n",
      "\n",
      "Epoch 00061: loss improved from -121.13002 to -121.56016, saving model to gendance.h5\n",
      "Epoch 62/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -122.0385 - val_loss: -124.8800\n",
      "\n",
      "Epoch 00062: loss improved from -121.56016 to -122.03851, saving model to gendance.h5\n",
      "Epoch 63/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -122.5523 - val_loss: -125.5179\n",
      "\n",
      "Epoch 00063: loss improved from -122.03851 to -122.55233, saving model to gendance.h5\n",
      "Epoch 64/2000\n",
      "16017/16017 [==============================] - 1s 55us/step - loss: -123.1891 - val_loss: -125.4002\n",
      "\n",
      "Epoch 00064: loss improved from -122.55233 to -123.18908, saving model to gendance.h5\n",
      "Epoch 65/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -123.4642 - val_loss: -126.6778\n",
      "\n",
      "Epoch 00065: loss improved from -123.18908 to -123.46419, saving model to gendance.h5\n",
      "Epoch 66/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -123.9288 - val_loss: -126.7323\n",
      "\n",
      "Epoch 00066: loss improved from -123.46419 to -123.92885, saving model to gendance.h5\n",
      "Epoch 67/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -124.4159 - val_loss: -127.1923\n",
      "\n",
      "Epoch 00067: loss improved from -123.92885 to -124.41590, saving model to gendance.h5\n",
      "Epoch 68/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -124.9181 - val_loss: -127.6467\n",
      "\n",
      "Epoch 00068: loss improved from -124.41590 to -124.91811, saving model to gendance.h5\n",
      "Epoch 69/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -125.2519 - val_loss: -128.1571\n",
      "\n",
      "Epoch 00069: loss improved from -124.91811 to -125.25191, saving model to gendance.h5\n",
      "Epoch 70/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -125.4532 - val_loss: -128.3180\n",
      "\n",
      "Epoch 00070: loss improved from -125.25191 to -125.45324, saving model to gendance.h5\n",
      "Epoch 71/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -125.6547 - val_loss: -129.0423\n",
      "\n",
      "Epoch 00071: loss improved from -125.45324 to -125.65474, saving model to gendance.h5\n",
      "Epoch 72/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -126.0507 - val_loss: -128.9212\n",
      "\n",
      "Epoch 00072: loss improved from -125.65474 to -126.05065, saving model to gendance.h5\n",
      "Epoch 73/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -126.4814 - val_loss: -129.5290\n",
      "\n",
      "Epoch 00073: loss improved from -126.05065 to -126.48140, saving model to gendance.h5\n",
      "Epoch 74/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -126.7430 - val_loss: -129.9314\n",
      "\n",
      "Epoch 00074: loss improved from -126.48140 to -126.74295, saving model to gendance.h5\n",
      "Epoch 75/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -127.0254 - val_loss: -130.4671\n",
      "\n",
      "Epoch 00075: loss improved from -126.74295 to -127.02544, saving model to gendance.h5\n",
      "Epoch 76/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -127.3867 - val_loss: -130.4365\n",
      "\n",
      "Epoch 00076: loss improved from -127.02544 to -127.38675, saving model to gendance.h5\n",
      "Epoch 77/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -127.4416 - val_loss: -130.8808\n",
      "\n",
      "Epoch 00077: loss improved from -127.38675 to -127.44157, saving model to gendance.h5\n",
      "Epoch 78/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -127.7427 - val_loss: -131.0593\n",
      "\n",
      "Epoch 00078: loss improved from -127.44157 to -127.74273, saving model to gendance.h5\n",
      "Epoch 79/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -127.9473 - val_loss: -131.7512\n",
      "\n",
      "Epoch 00079: loss improved from -127.74273 to -127.94733, saving model to gendance.h5\n",
      "Epoch 80/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -128.2714 - val_loss: -131.5259\n",
      "\n",
      "Epoch 00080: loss improved from -127.94733 to -128.27141, saving model to gendance.h5\n",
      "Epoch 81/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -128.5543 - val_loss: -132.0717\n",
      "\n",
      "Epoch 00081: loss improved from -128.27141 to -128.55427, saving model to gendance.h5\n",
      "Epoch 82/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -128.9143 - val_loss: -132.0531\n",
      "\n",
      "Epoch 00082: loss improved from -128.55427 to -128.91428, saving model to gendance.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -128.9448 - val_loss: -132.5184\n",
      "\n",
      "Epoch 00083: loss improved from -128.91428 to -128.94482, saving model to gendance.h5\n",
      "Epoch 84/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -129.2165 - val_loss: -132.7101\n",
      "\n",
      "Epoch 00084: loss improved from -128.94482 to -129.21645, saving model to gendance.h5\n",
      "Epoch 85/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -129.2485 - val_loss: -132.9467\n",
      "\n",
      "Epoch 00085: loss improved from -129.21645 to -129.24853, saving model to gendance.h5\n",
      "Epoch 86/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -129.5339 - val_loss: -133.1370\n",
      "\n",
      "Epoch 00086: loss improved from -129.24853 to -129.53388, saving model to gendance.h5\n",
      "Epoch 87/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -129.8168 - val_loss: -133.1012\n",
      "\n",
      "Epoch 00087: loss improved from -129.53388 to -129.81679, saving model to gendance.h5\n",
      "Epoch 88/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -130.0670 - val_loss: -133.0444\n",
      "\n",
      "Epoch 00088: loss improved from -129.81679 to -130.06696, saving model to gendance.h5\n",
      "Epoch 89/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -130.2778 - val_loss: -133.5762\n",
      "\n",
      "Epoch 00089: loss improved from -130.06696 to -130.27776, saving model to gendance.h5\n",
      "Epoch 90/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -130.4490 - val_loss: -134.0554\n",
      "\n",
      "Epoch 00090: loss improved from -130.27776 to -130.44899, saving model to gendance.h5\n",
      "Epoch 91/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -130.6418 - val_loss: -134.3434\n",
      "\n",
      "Epoch 00091: loss improved from -130.44899 to -130.64176, saving model to gendance.h5\n",
      "Epoch 92/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -130.8606 - val_loss: -134.1705\n",
      "\n",
      "Epoch 00092: loss improved from -130.64176 to -130.86060, saving model to gendance.h5\n",
      "Epoch 93/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -131.0465 - val_loss: -133.9012\n",
      "\n",
      "Epoch 00093: loss improved from -130.86060 to -131.04652, saving model to gendance.h5\n",
      "Epoch 94/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -131.2129 - val_loss: -134.6745\n",
      "\n",
      "Epoch 00094: loss improved from -131.04652 to -131.21291, saving model to gendance.h5\n",
      "Epoch 95/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -131.3378 - val_loss: -134.6835\n",
      "\n",
      "Epoch 00095: loss improved from -131.21291 to -131.33777, saving model to gendance.h5\n",
      "Epoch 96/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -131.4675 - val_loss: -135.2121\n",
      "\n",
      "Epoch 00096: loss improved from -131.33777 to -131.46752, saving model to gendance.h5\n",
      "Epoch 97/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -131.7461 - val_loss: -135.0348\n",
      "\n",
      "Epoch 00097: loss improved from -131.46752 to -131.74611, saving model to gendance.h5\n",
      "Epoch 98/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -131.9150 - val_loss: -135.3849\n",
      "\n",
      "Epoch 00098: loss improved from -131.74611 to -131.91498, saving model to gendance.h5\n",
      "Epoch 99/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -132.1502 - val_loss: -135.8291\n",
      "\n",
      "Epoch 00099: loss improved from -131.91498 to -132.15016, saving model to gendance.h5\n",
      "Epoch 100/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -132.3669 - val_loss: -135.9147\n",
      "\n",
      "Epoch 00100: loss improved from -132.15016 to -132.36690, saving model to gendance.h5\n",
      "Epoch 101/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -132.4213 - val_loss: -136.0021\n",
      "\n",
      "Epoch 00101: loss improved from -132.36690 to -132.42128, saving model to gendance.h5\n",
      "Epoch 102/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -132.6496 - val_loss: -136.3276\n",
      "\n",
      "Epoch 00102: loss improved from -132.42128 to -132.64965, saving model to gendance.h5\n",
      "Epoch 103/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -132.9881 - val_loss: -136.2091\n",
      "\n",
      "Epoch 00103: loss improved from -132.64965 to -132.98811, saving model to gendance.h5\n",
      "Epoch 104/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -133.1105 - val_loss: -136.4185\n",
      "\n",
      "Epoch 00104: loss improved from -132.98811 to -133.11046, saving model to gendance.h5\n",
      "Epoch 105/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -133.2090 - val_loss: -136.5139\n",
      "\n",
      "Epoch 00105: loss improved from -133.11046 to -133.20897, saving model to gendance.h5\n",
      "Epoch 106/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -133.3559 - val_loss: -136.8403\n",
      "\n",
      "Epoch 00106: loss improved from -133.20897 to -133.35591, saving model to gendance.h5\n",
      "Epoch 107/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -133.6617 - val_loss: -136.9405\n",
      "\n",
      "Epoch 00107: loss improved from -133.35591 to -133.66167, saving model to gendance.h5\n",
      "Epoch 108/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -133.8219 - val_loss: -137.4833\n",
      "\n",
      "Epoch 00108: loss improved from -133.66167 to -133.82194, saving model to gendance.h5\n",
      "Epoch 109/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -133.9114 - val_loss: -137.0551\n",
      "\n",
      "Epoch 00109: loss improved from -133.82194 to -133.91143, saving model to gendance.h5\n",
      "Epoch 110/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -134.2374 - val_loss: -137.5169\n",
      "\n",
      "Epoch 00110: loss improved from -133.91143 to -134.23736, saving model to gendance.h5\n",
      "Epoch 111/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -134.4644 - val_loss: -137.8887\n",
      "\n",
      "Epoch 00111: loss improved from -134.23736 to -134.46444, saving model to gendance.h5\n",
      "Epoch 112/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -134.5269 - val_loss: -138.0743\n",
      "\n",
      "Epoch 00112: loss improved from -134.46444 to -134.52693, saving model to gendance.h5\n",
      "Epoch 113/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -134.8655 - val_loss: -138.4845\n",
      "\n",
      "Epoch 00113: loss improved from -134.52693 to -134.86545, saving model to gendance.h5\n",
      "Epoch 114/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -135.0779 - val_loss: -138.2732\n",
      "\n",
      "Epoch 00114: loss improved from -134.86545 to -135.07794, saving model to gendance.h5\n",
      "Epoch 115/2000\n",
      "16017/16017 [==============================] - 1s 56us/step - loss: -135.1165 - val_loss: -138.7058\n",
      "\n",
      "Epoch 00115: loss improved from -135.07794 to -135.11648, saving model to gendance.h5\n",
      "Epoch 116/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -135.3974 - val_loss: -138.8364\n",
      "\n",
      "Epoch 00116: loss improved from -135.11648 to -135.39744, saving model to gendance.h5\n",
      "Epoch 117/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -135.3362 - val_loss: -139.0003\n",
      "\n",
      "Epoch 00117: loss did not improve from -135.39744\n",
      "Epoch 118/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -135.6789 - val_loss: -139.0129\n",
      "\n",
      "Epoch 00118: loss improved from -135.39744 to -135.67893, saving model to gendance.h5\n",
      "Epoch 119/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -135.8783 - val_loss: -139.2804\n",
      "\n",
      "Epoch 00119: loss improved from -135.67893 to -135.87827, saving model to gendance.h5\n",
      "Epoch 120/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -136.0898 - val_loss: -139.5556\n",
      "\n",
      "Epoch 00120: loss improved from -135.87827 to -136.08977, saving model to gendance.h5\n",
      "Epoch 121/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -136.3057 - val_loss: -139.3913\n",
      "\n",
      "Epoch 00121: loss improved from -136.08977 to -136.30569, saving model to gendance.h5\n",
      "Epoch 122/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -136.3974 - val_loss: -139.3047\n",
      "\n",
      "Epoch 00122: loss improved from -136.30569 to -136.39739, saving model to gendance.h5\n",
      "Epoch 123/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -136.6469 - val_loss: -139.8777\n",
      "\n",
      "Epoch 00123: loss improved from -136.39739 to -136.64694, saving model to gendance.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -136.7930 - val_loss: -140.2373\n",
      "\n",
      "Epoch 00124: loss improved from -136.64694 to -136.79297, saving model to gendance.h5\n",
      "Epoch 125/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -137.0063 - val_loss: -140.3013\n",
      "\n",
      "Epoch 00125: loss improved from -136.79297 to -137.00628, saving model to gendance.h5\n",
      "Epoch 126/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -137.1463 - val_loss: -140.1877\n",
      "\n",
      "Epoch 00126: loss improved from -137.00628 to -137.14629, saving model to gendance.h5\n",
      "Epoch 127/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -137.2026 - val_loss: -141.1927\n",
      "\n",
      "Epoch 00127: loss improved from -137.14629 to -137.20259, saving model to gendance.h5\n",
      "Epoch 128/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -137.4367 - val_loss: -140.7168\n",
      "\n",
      "Epoch 00128: loss improved from -137.20259 to -137.43669, saving model to gendance.h5\n",
      "Epoch 129/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -137.6415 - val_loss: -140.9535\n",
      "\n",
      "Epoch 00129: loss improved from -137.43669 to -137.64153, saving model to gendance.h5\n",
      "Epoch 130/2000\n",
      "16017/16017 [==============================] - 1s 53us/step - loss: -137.6780 - val_loss: -141.3670\n",
      "\n",
      "Epoch 00130: loss improved from -137.64153 to -137.67799, saving model to gendance.h5\n",
      "Epoch 131/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -137.9306 - val_loss: -141.3422\n",
      "\n",
      "Epoch 00131: loss improved from -137.67799 to -137.93061, saving model to gendance.h5\n",
      "Epoch 132/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -138.1661 - val_loss: -141.5154\n",
      "\n",
      "Epoch 00132: loss improved from -137.93061 to -138.16607, saving model to gendance.h5\n",
      "Epoch 133/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -138.2490 - val_loss: -141.7500\n",
      "\n",
      "Epoch 00133: loss improved from -138.16607 to -138.24903, saving model to gendance.h5\n",
      "Epoch 134/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -138.4869 - val_loss: -141.9262\n",
      "\n",
      "Epoch 00134: loss improved from -138.24903 to -138.48689, saving model to gendance.h5\n",
      "Epoch 135/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -138.8132 - val_loss: -142.0107\n",
      "\n",
      "Epoch 00135: loss improved from -138.48689 to -138.81324, saving model to gendance.h5\n",
      "Epoch 136/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -138.7886 - val_loss: -142.0123\n",
      "\n",
      "Epoch 00136: loss did not improve from -138.81324\n",
      "Epoch 137/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -139.0792 - val_loss: -142.5590\n",
      "\n",
      "Epoch 00137: loss improved from -138.81324 to -139.07922, saving model to gendance.h5\n",
      "Epoch 138/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -139.2047 - val_loss: -142.6682\n",
      "\n",
      "Epoch 00138: loss improved from -139.07922 to -139.20473, saving model to gendance.h5\n",
      "Epoch 139/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -139.4875 - val_loss: -142.4838\n",
      "\n",
      "Epoch 00139: loss improved from -139.20473 to -139.48753, saving model to gendance.h5\n",
      "Epoch 140/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -139.5888 - val_loss: -143.0224\n",
      "\n",
      "Epoch 00140: loss improved from -139.48753 to -139.58880, saving model to gendance.h5\n",
      "Epoch 141/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -139.7158 - val_loss: -143.0797\n",
      "\n",
      "Epoch 00141: loss improved from -139.58880 to -139.71578, saving model to gendance.h5\n",
      "Epoch 142/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -139.7737 - val_loss: -143.6359\n",
      "\n",
      "Epoch 00142: loss improved from -139.71578 to -139.77367, saving model to gendance.h5\n",
      "Epoch 143/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -139.9773 - val_loss: -143.2822\n",
      "\n",
      "Epoch 00143: loss improved from -139.77367 to -139.97728, saving model to gendance.h5\n",
      "Epoch 144/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -140.2228 - val_loss: -143.3086\n",
      "\n",
      "Epoch 00144: loss improved from -139.97728 to -140.22284, saving model to gendance.h5\n",
      "Epoch 145/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -140.4076 - val_loss: -143.9516\n",
      "\n",
      "Epoch 00145: loss improved from -140.22284 to -140.40757, saving model to gendance.h5\n",
      "Epoch 146/2000\n",
      "16017/16017 [==============================] - 1s 55us/step - loss: -140.5949 - val_loss: -143.7134\n",
      "\n",
      "Epoch 00146: loss improved from -140.40757 to -140.59488, saving model to gendance.h5\n",
      "Epoch 147/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -140.5994 - val_loss: -143.9397\n",
      "\n",
      "Epoch 00147: loss improved from -140.59488 to -140.59935, saving model to gendance.h5\n",
      "Epoch 148/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -140.8660 - val_loss: -144.0288\n",
      "\n",
      "Epoch 00148: loss improved from -140.59935 to -140.86604, saving model to gendance.h5\n",
      "Epoch 149/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -140.9900 - val_loss: -144.3191\n",
      "\n",
      "Epoch 00149: loss improved from -140.86604 to -140.98999, saving model to gendance.h5\n",
      "Epoch 150/2000\n",
      "16017/16017 [==============================] - 1s 56us/step - loss: -141.3779 - val_loss: -144.5985\n",
      "\n",
      "Epoch 00150: loss improved from -140.98999 to -141.37795, saving model to gendance.h5\n",
      "Epoch 151/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -141.4607 - val_loss: -144.5961\n",
      "\n",
      "Epoch 00151: loss improved from -141.37795 to -141.46073, saving model to gendance.h5\n",
      "Epoch 152/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -141.3250 - val_loss: -145.0935\n",
      "\n",
      "Epoch 00152: loss did not improve from -141.46073\n",
      "Epoch 153/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -141.8106 - val_loss: -145.2885\n",
      "\n",
      "Epoch 00153: loss improved from -141.46073 to -141.81060, saving model to gendance.h5\n",
      "Epoch 154/2000\n",
      "16017/16017 [==============================] - 1s 55us/step - loss: -141.8115 - val_loss: -145.1724\n",
      "\n",
      "Epoch 00154: loss improved from -141.81060 to -141.81148, saving model to gendance.h5\n",
      "Epoch 155/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -141.9748 - val_loss: -145.4592\n",
      "\n",
      "Epoch 00155: loss improved from -141.81148 to -141.97482, saving model to gendance.h5\n",
      "Epoch 156/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -142.1385 - val_loss: -145.4041\n",
      "\n",
      "Epoch 00156: loss improved from -141.97482 to -142.13848, saving model to gendance.h5\n",
      "Epoch 157/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -142.2088 - val_loss: -145.8971\n",
      "\n",
      "Epoch 00157: loss improved from -142.13848 to -142.20879, saving model to gendance.h5\n",
      "Epoch 158/2000\n",
      "16017/16017 [==============================] - 1s 53us/step - loss: -142.4372 - val_loss: -146.0022\n",
      "\n",
      "Epoch 00158: loss improved from -142.20879 to -142.43719, saving model to gendance.h5\n",
      "Epoch 159/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -142.6016 - val_loss: -146.2961\n",
      "\n",
      "Epoch 00159: loss improved from -142.43719 to -142.60160, saving model to gendance.h5\n",
      "Epoch 160/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -142.7498 - val_loss: -146.2520\n",
      "\n",
      "Epoch 00160: loss improved from -142.60160 to -142.74978, saving model to gendance.h5\n",
      "Epoch 161/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -142.9714 - val_loss: -146.4529\n",
      "\n",
      "Epoch 00161: loss improved from -142.74978 to -142.97144, saving model to gendance.h5\n",
      "Epoch 162/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -143.0943 - val_loss: -146.6136\n",
      "\n",
      "Epoch 00162: loss improved from -142.97144 to -143.09431, saving model to gendance.h5\n",
      "Epoch 163/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -143.1984 - val_loss: -146.7937\n",
      "\n",
      "Epoch 00163: loss improved from -143.09431 to -143.19839, saving model to gendance.h5\n",
      "Epoch 164/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -143.4546 - val_loss: -146.8945\n",
      "\n",
      "Epoch 00164: loss improved from -143.19839 to -143.45458, saving model to gendance.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -143.4238 - val_loss: -146.7447\n",
      "\n",
      "Epoch 00165: loss did not improve from -143.45458\n",
      "Epoch 166/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -143.6513 - val_loss: -146.9248\n",
      "\n",
      "Epoch 00166: loss improved from -143.45458 to -143.65131, saving model to gendance.h5\n",
      "Epoch 167/2000\n",
      "16017/16017 [==============================] - 1s 57us/step - loss: -143.6614 - val_loss: -147.2173\n",
      "\n",
      "Epoch 00167: loss improved from -143.65131 to -143.66145, saving model to gendance.h5\n",
      "Epoch 168/2000\n",
      "16017/16017 [==============================] - 1s 57us/step - loss: -143.8339 - val_loss: -147.4874\n",
      "\n",
      "Epoch 00168: loss improved from -143.66145 to -143.83386, saving model to gendance.h5\n",
      "Epoch 169/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -144.0941 - val_loss: -147.9358\n",
      "\n",
      "Epoch 00169: loss improved from -143.83386 to -144.09413, saving model to gendance.h5\n",
      "Epoch 170/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -144.1952 - val_loss: -147.7983\n",
      "\n",
      "Epoch 00170: loss improved from -144.09413 to -144.19516, saving model to gendance.h5\n",
      "Epoch 171/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -144.5917 - val_loss: -147.6214\n",
      "\n",
      "Epoch 00171: loss improved from -144.19516 to -144.59167, saving model to gendance.h5\n",
      "Epoch 172/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -144.5815 - val_loss: -148.1561\n",
      "\n",
      "Epoch 00172: loss did not improve from -144.59167\n",
      "Epoch 173/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -144.5606 - val_loss: -147.8131\n",
      "\n",
      "Epoch 00173: loss did not improve from -144.59167\n",
      "Epoch 174/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -144.7576 - val_loss: -148.2762\n",
      "\n",
      "Epoch 00174: loss improved from -144.59167 to -144.75761, saving model to gendance.h5\n",
      "Epoch 175/2000\n",
      "16017/16017 [==============================] - 1s 54us/step - loss: -144.9863 - val_loss: -148.4458\n",
      "\n",
      "Epoch 00175: loss improved from -144.75761 to -144.98632, saving model to gendance.h5\n",
      "Epoch 176/2000\n",
      "16017/16017 [==============================] - 1s 53us/step - loss: -144.9755 - val_loss: -148.5723\n",
      "\n",
      "Epoch 00176: loss did not improve from -144.98632\n",
      "Epoch 177/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -145.2572 - val_loss: -148.8324\n",
      "\n",
      "Epoch 00177: loss improved from -144.98632 to -145.25716, saving model to gendance.h5\n",
      "Epoch 178/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -145.6358 - val_loss: -148.8885\n",
      "\n",
      "Epoch 00178: loss improved from -145.25716 to -145.63579, saving model to gendance.h5\n",
      "Epoch 179/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -145.4826 - val_loss: -148.9381\n",
      "\n",
      "Epoch 00179: loss did not improve from -145.63579\n",
      "Epoch 180/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -145.4739 - val_loss: -149.3292\n",
      "\n",
      "Epoch 00180: loss did not improve from -145.63579\n",
      "Epoch 181/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -145.7503 - val_loss: -149.0545\n",
      "\n",
      "Epoch 00181: loss improved from -145.63579 to -145.75029, saving model to gendance.h5\n",
      "Epoch 182/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -145.7063 - val_loss: -149.1799\n",
      "\n",
      "Epoch 00182: loss did not improve from -145.75029\n",
      "Epoch 183/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -145.8943 - val_loss: -149.5163\n",
      "\n",
      "Epoch 00183: loss improved from -145.75029 to -145.89431, saving model to gendance.h5\n",
      "Epoch 184/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -146.1634 - val_loss: -149.5435\n",
      "\n",
      "Epoch 00184: loss improved from -145.89431 to -146.16343, saving model to gendance.h5\n",
      "Epoch 185/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -146.1434 - val_loss: -149.5291\n",
      "\n",
      "Epoch 00185: loss did not improve from -146.16343\n",
      "Epoch 186/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -146.1252 - val_loss: -150.0275\n",
      "\n",
      "Epoch 00186: loss did not improve from -146.16343\n",
      "Epoch 187/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -146.5520 - val_loss: -150.1629\n",
      "\n",
      "Epoch 00187: loss improved from -146.16343 to -146.55195, saving model to gendance.h5\n",
      "Epoch 188/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -146.7007 - val_loss: -149.8587\n",
      "\n",
      "Epoch 00188: loss improved from -146.55195 to -146.70073, saving model to gendance.h5\n",
      "Epoch 189/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -146.7345 - val_loss: -150.1528\n",
      "\n",
      "Epoch 00189: loss improved from -146.70073 to -146.73453, saving model to gendance.h5\n",
      "Epoch 190/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -146.8429 - val_loss: -150.6312\n",
      "\n",
      "Epoch 00190: loss improved from -146.73453 to -146.84288, saving model to gendance.h5\n",
      "Epoch 191/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -146.9745 - val_loss: -150.9522\n",
      "\n",
      "Epoch 00191: loss improved from -146.84288 to -146.97451, saving model to gendance.h5\n",
      "Epoch 192/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -147.2226 - val_loss: -150.7922\n",
      "\n",
      "Epoch 00192: loss improved from -146.97451 to -147.22257, saving model to gendance.h5\n",
      "Epoch 193/2000\n",
      "16017/16017 [==============================] - 1s 55us/step - loss: -147.3364 - val_loss: -150.8666\n",
      "\n",
      "Epoch 00193: loss improved from -147.22257 to -147.33637, saving model to gendance.h5\n",
      "Epoch 194/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -147.4893 - val_loss: -150.9265\n",
      "\n",
      "Epoch 00194: loss improved from -147.33637 to -147.48935, saving model to gendance.h5\n",
      "Epoch 195/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -147.5774 - val_loss: -150.4777\n",
      "\n",
      "Epoch 00195: loss improved from -147.48935 to -147.57740, saving model to gendance.h5\n",
      "Epoch 196/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -147.6222 - val_loss: -151.5098\n",
      "\n",
      "Epoch 00196: loss improved from -147.57740 to -147.62215, saving model to gendance.h5\n",
      "Epoch 197/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -147.5069 - val_loss: -151.4773\n",
      "\n",
      "Epoch 00197: loss did not improve from -147.62215\n",
      "Epoch 198/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -147.7308 - val_loss: -151.4452\n",
      "\n",
      "Epoch 00198: loss improved from -147.62215 to -147.73083, saving model to gendance.h5\n",
      "Epoch 199/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -147.8939 - val_loss: -151.5272\n",
      "\n",
      "Epoch 00199: loss improved from -147.73083 to -147.89392, saving model to gendance.h5\n",
      "Epoch 200/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -148.0348 - val_loss: -151.6236\n",
      "\n",
      "Epoch 00200: loss improved from -147.89392 to -148.03475, saving model to gendance.h5\n",
      "Epoch 201/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -148.2455 - val_loss: -151.6017\n",
      "\n",
      "Epoch 00201: loss improved from -148.03475 to -148.24552, saving model to gendance.h5\n",
      "Epoch 202/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -148.1735 - val_loss: -152.0410\n",
      "\n",
      "Epoch 00202: loss did not improve from -148.24552\n",
      "Epoch 203/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -148.3324 - val_loss: -151.6894\n",
      "\n",
      "Epoch 00203: loss improved from -148.24552 to -148.33245, saving model to gendance.h5\n",
      "Epoch 204/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -148.4484 - val_loss: -152.2067\n",
      "\n",
      "Epoch 00204: loss improved from -148.33245 to -148.44840, saving model to gendance.h5\n",
      "Epoch 205/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -148.7134 - val_loss: -152.3950\n",
      "\n",
      "Epoch 00205: loss improved from -148.44840 to -148.71345, saving model to gendance.h5\n",
      "Epoch 206/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -148.6748 - val_loss: -152.4428\n",
      "\n",
      "Epoch 00206: loss did not improve from -148.71345\n",
      "Epoch 207/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -148.9722 - val_loss: -152.3304\n",
      "\n",
      "Epoch 00207: loss improved from -148.71345 to -148.97222, saving model to gendance.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 208/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -148.8858 - val_loss: -152.9264\n",
      "\n",
      "Epoch 00208: loss did not improve from -148.97222\n",
      "Epoch 209/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -148.8093 - val_loss: -152.3665\n",
      "\n",
      "Epoch 00209: loss did not improve from -148.97222\n",
      "Epoch 210/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -149.0711 - val_loss: -152.6366\n",
      "\n",
      "Epoch 00210: loss improved from -148.97222 to -149.07114, saving model to gendance.h5\n",
      "Epoch 211/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -149.0334 - val_loss: -152.3957\n",
      "\n",
      "Epoch 00211: loss did not improve from -149.07114\n",
      "Epoch 212/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -149.2131 - val_loss: -153.0799\n",
      "\n",
      "Epoch 00212: loss improved from -149.07114 to -149.21312, saving model to gendance.h5\n",
      "Epoch 213/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -149.3996 - val_loss: -153.4510\n",
      "\n",
      "Epoch 00213: loss improved from -149.21312 to -149.39960, saving model to gendance.h5\n",
      "Epoch 214/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -149.6616 - val_loss: -153.2566\n",
      "\n",
      "Epoch 00214: loss improved from -149.39960 to -149.66157, saving model to gendance.h5\n",
      "Epoch 215/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -149.6556 - val_loss: -153.7102\n",
      "\n",
      "Epoch 00215: loss did not improve from -149.66157\n",
      "Epoch 216/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -149.7888 - val_loss: -153.1919\n",
      "\n",
      "Epoch 00216: loss improved from -149.66157 to -149.78875, saving model to gendance.h5\n",
      "Epoch 217/2000\n",
      "16017/16017 [==============================] - 1s 53us/step - loss: -149.9034 - val_loss: -153.5319\n",
      "\n",
      "Epoch 00217: loss improved from -149.78875 to -149.90343, saving model to gendance.h5\n",
      "Epoch 218/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -149.7500 - val_loss: -153.1287\n",
      "\n",
      "Epoch 00218: loss did not improve from -149.90343\n",
      "Epoch 219/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -150.0297 - val_loss: -153.7749\n",
      "\n",
      "Epoch 00219: loss improved from -149.90343 to -150.02967, saving model to gendance.h5\n",
      "Epoch 220/2000\n",
      "16017/16017 [==============================] - 1s 58us/step - loss: -150.1830 - val_loss: -153.9754\n",
      "\n",
      "Epoch 00220: loss improved from -150.02967 to -150.18301, saving model to gendance.h5\n",
      "Epoch 221/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -150.1933 - val_loss: -154.1794\n",
      "\n",
      "Epoch 00221: loss improved from -150.18301 to -150.19334, saving model to gendance.h5\n",
      "Epoch 222/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -150.1923 - val_loss: -154.3286\n",
      "\n",
      "Epoch 00222: loss did not improve from -150.19334\n",
      "Epoch 223/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -150.3625 - val_loss: -154.0631\n",
      "\n",
      "Epoch 00223: loss improved from -150.19334 to -150.36249, saving model to gendance.h5\n",
      "Epoch 224/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -150.4204 - val_loss: -154.4421\n",
      "\n",
      "Epoch 00224: loss improved from -150.36249 to -150.42044, saving model to gendance.h5\n",
      "Epoch 225/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -150.6757 - val_loss: -154.0994\n",
      "\n",
      "Epoch 00225: loss improved from -150.42044 to -150.67566, saving model to gendance.h5\n",
      "Epoch 226/2000\n",
      "16017/16017 [==============================] - 1s 53us/step - loss: -150.8802 - val_loss: -154.5533\n",
      "\n",
      "Epoch 00226: loss improved from -150.67566 to -150.88023, saving model to gendance.h5\n",
      "Epoch 227/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -150.9019 - val_loss: -154.7448\n",
      "\n",
      "Epoch 00227: loss improved from -150.88023 to -150.90193, saving model to gendance.h5\n",
      "Epoch 228/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -150.9123 - val_loss: -154.5519\n",
      "\n",
      "Epoch 00228: loss improved from -150.90193 to -150.91233, saving model to gendance.h5\n",
      "Epoch 229/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -150.9719 - val_loss: -154.5200\n",
      "\n",
      "Epoch 00229: loss improved from -150.91233 to -150.97186, saving model to gendance.h5\n",
      "Epoch 230/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -150.9505 - val_loss: -154.8655\n",
      "\n",
      "Epoch 00230: loss did not improve from -150.97186\n",
      "Epoch 231/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -151.2235 - val_loss: -155.0483\n",
      "\n",
      "Epoch 00231: loss improved from -150.97186 to -151.22352, saving model to gendance.h5\n",
      "Epoch 232/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -151.0473 - val_loss: -154.9156\n",
      "\n",
      "Epoch 00232: loss did not improve from -151.22352\n",
      "Epoch 233/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -151.5551 - val_loss: -154.8127\n",
      "\n",
      "Epoch 00233: loss improved from -151.22352 to -151.55510, saving model to gendance.h5\n",
      "Epoch 234/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -151.1543 - val_loss: -155.0325\n",
      "\n",
      "Epoch 00234: loss did not improve from -151.55510\n",
      "Epoch 235/2000\n",
      "16017/16017 [==============================] - 1s 54us/step - loss: -151.3921 - val_loss: -155.1874\n",
      "\n",
      "Epoch 00235: loss did not improve from -151.55510\n",
      "Epoch 236/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -151.6878 - val_loss: -155.5468\n",
      "\n",
      "Epoch 00236: loss improved from -151.55510 to -151.68782, saving model to gendance.h5\n",
      "Epoch 237/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -151.7936 - val_loss: -155.6003\n",
      "\n",
      "Epoch 00237: loss improved from -151.68782 to -151.79360, saving model to gendance.h5\n",
      "Epoch 238/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -151.9045 - val_loss: -155.5589\n",
      "\n",
      "Epoch 00238: loss improved from -151.79360 to -151.90454, saving model to gendance.h5\n",
      "Epoch 239/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -151.7141 - val_loss: -155.5667\n",
      "\n",
      "Epoch 00239: loss did not improve from -151.90454\n",
      "Epoch 240/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -152.0182 - val_loss: -155.7446\n",
      "\n",
      "Epoch 00240: loss improved from -151.90454 to -152.01820, saving model to gendance.h5\n",
      "Epoch 241/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -152.0056 - val_loss: -155.6761\n",
      "\n",
      "Epoch 00241: loss did not improve from -152.01820\n",
      "Epoch 242/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -152.1868 - val_loss: -155.7862\n",
      "\n",
      "Epoch 00242: loss improved from -152.01820 to -152.18676, saving model to gendance.h5\n",
      "Epoch 243/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -152.2817 - val_loss: -156.4283\n",
      "\n",
      "Epoch 00243: loss improved from -152.18676 to -152.28166, saving model to gendance.h5\n",
      "Epoch 244/2000\n",
      "16017/16017 [==============================] - 1s 53us/step - loss: -152.0716 - val_loss: -156.0561\n",
      "\n",
      "Epoch 00244: loss did not improve from -152.28166\n",
      "Epoch 245/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -152.2528 - val_loss: -155.7406\n",
      "\n",
      "Epoch 00245: loss did not improve from -152.28166\n",
      "Epoch 246/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -152.3347 - val_loss: -156.6845\n",
      "\n",
      "Epoch 00246: loss improved from -152.28166 to -152.33467, saving model to gendance.h5\n",
      "Epoch 247/2000\n",
      "16017/16017 [==============================] - 1s 55us/step - loss: -152.5006 - val_loss: -156.3598\n",
      "\n",
      "Epoch 00247: loss improved from -152.33467 to -152.50060, saving model to gendance.h5\n",
      "Epoch 248/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -152.6216 - val_loss: -156.5254\n",
      "\n",
      "Epoch 00248: loss improved from -152.50060 to -152.62162, saving model to gendance.h5\n",
      "Epoch 249/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -152.7389 - val_loss: -156.4235\n",
      "\n",
      "Epoch 00249: loss improved from -152.62162 to -152.73891, saving model to gendance.h5\n",
      "Epoch 250/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -152.5842 - val_loss: -156.1915\n",
      "\n",
      "Epoch 00250: loss did not improve from -152.73891\n",
      "Epoch 251/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16017/16017 [==============================] - 1s 52us/step - loss: -152.8752 - val_loss: -156.8891\n",
      "\n",
      "Epoch 00251: loss improved from -152.73891 to -152.87521, saving model to gendance.h5\n",
      "Epoch 252/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -152.9298 - val_loss: -156.2978\n",
      "\n",
      "Epoch 00252: loss improved from -152.87521 to -152.92975, saving model to gendance.h5\n",
      "Epoch 253/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -152.9767 - val_loss: -156.8900\n",
      "\n",
      "Epoch 00253: loss improved from -152.92975 to -152.97670, saving model to gendance.h5\n",
      "Epoch 254/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -153.1708 - val_loss: -156.6021\n",
      "\n",
      "Epoch 00254: loss improved from -152.97670 to -153.17075, saving model to gendance.h5\n",
      "Epoch 255/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -153.1187 - val_loss: -156.9799\n",
      "\n",
      "Epoch 00255: loss did not improve from -153.17075\n",
      "Epoch 256/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -153.1411 - val_loss: -157.2465\n",
      "\n",
      "Epoch 00256: loss did not improve from -153.17075\n",
      "Epoch 257/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -153.2247 - val_loss: -157.0679\n",
      "\n",
      "Epoch 00257: loss improved from -153.17075 to -153.22471, saving model to gendance.h5\n",
      "Epoch 258/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -153.0873 - val_loss: -157.2030\n",
      "\n",
      "Epoch 00258: loss did not improve from -153.22471\n",
      "Epoch 259/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -153.4828 - val_loss: -157.3690\n",
      "\n",
      "Epoch 00259: loss improved from -153.22471 to -153.48277, saving model to gendance.h5\n",
      "Epoch 260/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -153.5583 - val_loss: -157.6613\n",
      "\n",
      "Epoch 00260: loss improved from -153.48277 to -153.55833, saving model to gendance.h5\n",
      "Epoch 261/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -153.5075 - val_loss: -157.2724\n",
      "\n",
      "Epoch 00261: loss did not improve from -153.55833\n",
      "Epoch 262/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -153.5490 - val_loss: -157.5195\n",
      "\n",
      "Epoch 00262: loss did not improve from -153.55833\n",
      "Epoch 263/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -153.6776 - val_loss: -157.1317\n",
      "\n",
      "Epoch 00263: loss improved from -153.55833 to -153.67759, saving model to gendance.h5\n",
      "Epoch 264/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -153.6735 - val_loss: -157.6689\n",
      "\n",
      "Epoch 00264: loss did not improve from -153.67759\n",
      "Epoch 265/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -153.7780 - val_loss: -157.7556\n",
      "\n",
      "Epoch 00265: loss improved from -153.67759 to -153.77803, saving model to gendance.h5\n",
      "Epoch 266/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -153.9647 - val_loss: -157.7438\n",
      "\n",
      "Epoch 00266: loss improved from -153.77803 to -153.96470, saving model to gendance.h5\n",
      "Epoch 267/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -154.1410 - val_loss: -157.9573\n",
      "\n",
      "Epoch 00267: loss improved from -153.96470 to -154.14099, saving model to gendance.h5\n",
      "Epoch 268/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -154.0922 - val_loss: -158.3250\n",
      "\n",
      "Epoch 00268: loss did not improve from -154.14099\n",
      "Epoch 269/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -154.1779 - val_loss: -158.3468\n",
      "\n",
      "Epoch 00269: loss improved from -154.14099 to -154.17786, saving model to gendance.h5\n",
      "Epoch 270/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -154.1792 - val_loss: -157.6034\n",
      "\n",
      "Epoch 00270: loss improved from -154.17786 to -154.17918, saving model to gendance.h5\n",
      "Epoch 271/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -154.0579 - val_loss: -158.0307\n",
      "\n",
      "Epoch 00271: loss did not improve from -154.17918\n",
      "Epoch 272/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -154.2483 - val_loss: -158.3854\n",
      "\n",
      "Epoch 00272: loss improved from -154.17918 to -154.24834, saving model to gendance.h5\n",
      "Epoch 273/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -154.4640 - val_loss: -158.2556\n",
      "\n",
      "Epoch 00273: loss improved from -154.24834 to -154.46398, saving model to gendance.h5\n",
      "Epoch 274/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -154.3721 - val_loss: -158.1677\n",
      "\n",
      "Epoch 00274: loss did not improve from -154.46398\n",
      "Epoch 275/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -154.4675 - val_loss: -158.6483\n",
      "\n",
      "Epoch 00275: loss improved from -154.46398 to -154.46747, saving model to gendance.h5\n",
      "Epoch 276/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -154.5459 - val_loss: -158.2298\n",
      "\n",
      "Epoch 00276: loss improved from -154.46747 to -154.54591, saving model to gendance.h5\n",
      "Epoch 277/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -154.7237 - val_loss: -158.6573\n",
      "\n",
      "Epoch 00277: loss improved from -154.54591 to -154.72366, saving model to gendance.h5\n",
      "Epoch 278/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -154.5854 - val_loss: -158.8523\n",
      "\n",
      "Epoch 00278: loss did not improve from -154.72366\n",
      "Epoch 279/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -154.8199 - val_loss: -158.8370\n",
      "\n",
      "Epoch 00279: loss improved from -154.72366 to -154.81987, saving model to gendance.h5\n",
      "Epoch 280/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -154.7063 - val_loss: -158.7452\n",
      "\n",
      "Epoch 00280: loss did not improve from -154.81987\n",
      "Epoch 281/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -154.8951 - val_loss: -159.0236\n",
      "\n",
      "Epoch 00281: loss improved from -154.81987 to -154.89515, saving model to gendance.h5\n",
      "Epoch 282/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -154.6525 - val_loss: -158.6449\n",
      "\n",
      "Epoch 00282: loss did not improve from -154.89515\n",
      "Epoch 283/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -155.1754 - val_loss: -159.0165\n",
      "\n",
      "Epoch 00283: loss improved from -154.89515 to -155.17540, saving model to gendance.h5\n",
      "Epoch 284/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -154.9952 - val_loss: -158.8029\n",
      "\n",
      "Epoch 00284: loss did not improve from -155.17540\n",
      "Epoch 285/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -155.0434 - val_loss: -158.9979\n",
      "\n",
      "Epoch 00285: loss did not improve from -155.17540\n",
      "Epoch 286/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -155.0204 - val_loss: -159.1927\n",
      "\n",
      "Epoch 00286: loss did not improve from -155.17540\n",
      "Epoch 287/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -155.3744 - val_loss: -159.2006\n",
      "\n",
      "Epoch 00287: loss improved from -155.17540 to -155.37440, saving model to gendance.h5\n",
      "Epoch 288/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -155.2812 - val_loss: -159.4829\n",
      "\n",
      "Epoch 00288: loss did not improve from -155.37440\n",
      "Epoch 289/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -155.4184 - val_loss: -159.2219\n",
      "\n",
      "Epoch 00289: loss improved from -155.37440 to -155.41843, saving model to gendance.h5\n",
      "Epoch 290/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -155.5210 - val_loss: -159.3268\n",
      "\n",
      "Epoch 00290: loss improved from -155.41843 to -155.52098, saving model to gendance.h5\n",
      "Epoch 291/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -155.5406 - val_loss: -159.4385\n",
      "\n",
      "Epoch 00291: loss improved from -155.52098 to -155.54059, saving model to gendance.h5\n",
      "Epoch 292/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -155.5444 - val_loss: -159.4850\n",
      "\n",
      "Epoch 00292: loss improved from -155.54059 to -155.54436, saving model to gendance.h5\n",
      "Epoch 293/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -155.7988 - val_loss: -159.7498\n",
      "\n",
      "Epoch 00293: loss improved from -155.54436 to -155.79884, saving model to gendance.h5\n",
      "Epoch 294/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -155.7138 - val_loss: -159.7378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00294: loss did not improve from -155.79884\n",
      "Epoch 295/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -155.7004 - val_loss: -159.4391\n",
      "\n",
      "Epoch 00295: loss did not improve from -155.79884\n",
      "Epoch 296/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -155.6113 - val_loss: -159.8289\n",
      "\n",
      "Epoch 00296: loss did not improve from -155.79884\n",
      "Epoch 297/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -155.7216 - val_loss: -159.3645\n",
      "\n",
      "Epoch 00297: loss did not improve from -155.79884\n",
      "Epoch 298/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -155.8839 - val_loss: -159.4918\n",
      "\n",
      "Epoch 00298: loss improved from -155.79884 to -155.88386, saving model to gendance.h5\n",
      "Epoch 299/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -155.8776 - val_loss: -160.0267\n",
      "\n",
      "Epoch 00299: loss did not improve from -155.88386\n",
      "Epoch 300/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -155.9936 - val_loss: -159.9118\n",
      "\n",
      "Epoch 00300: loss improved from -155.88386 to -155.99355, saving model to gendance.h5\n",
      "Epoch 301/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -156.0180 - val_loss: -159.9498\n",
      "\n",
      "Epoch 00301: loss improved from -155.99355 to -156.01796, saving model to gendance.h5\n",
      "Epoch 302/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -155.8228 - val_loss: -160.2494\n",
      "\n",
      "Epoch 00302: loss did not improve from -156.01796\n",
      "Epoch 303/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -156.0045 - val_loss: -160.3452\n",
      "\n",
      "Epoch 00303: loss did not improve from -156.01796\n",
      "Epoch 304/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -156.2558 - val_loss: -160.2903\n",
      "\n",
      "Epoch 00304: loss improved from -156.01796 to -156.25579, saving model to gendance.h5\n",
      "Epoch 305/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -156.2166 - val_loss: -160.5467\n",
      "\n",
      "Epoch 00305: loss did not improve from -156.25579\n",
      "Epoch 306/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -156.3037 - val_loss: -160.6331\n",
      "\n",
      "Epoch 00306: loss improved from -156.25579 to -156.30367, saving model to gendance.h5\n",
      "Epoch 307/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -156.2202 - val_loss: -160.7522\n",
      "\n",
      "Epoch 00307: loss did not improve from -156.30367\n",
      "Epoch 308/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -156.2781 - val_loss: -160.1660\n",
      "\n",
      "Epoch 00308: loss did not improve from -156.30367\n",
      "Epoch 309/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -156.2385 - val_loss: -160.0997\n",
      "\n",
      "Epoch 00309: loss did not improve from -156.30367\n",
      "Epoch 310/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -156.4375 - val_loss: -160.6632\n",
      "\n",
      "Epoch 00310: loss improved from -156.30367 to -156.43748, saving model to gendance.h5\n",
      "Epoch 311/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -156.4710 - val_loss: -160.2762\n",
      "\n",
      "Epoch 00311: loss improved from -156.43748 to -156.47099, saving model to gendance.h5\n",
      "Epoch 312/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -156.5046 - val_loss: -160.8525\n",
      "\n",
      "Epoch 00312: loss improved from -156.47099 to -156.50463, saving model to gendance.h5\n",
      "Epoch 313/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -156.8212 - val_loss: -160.5853\n",
      "\n",
      "Epoch 00313: loss improved from -156.50463 to -156.82124, saving model to gendance.h5\n",
      "Epoch 314/2000\n",
      "16017/16017 [==============================] - 1s 53us/step - loss: -156.6894 - val_loss: -160.6211\n",
      "\n",
      "Epoch 00314: loss did not improve from -156.82124\n",
      "Epoch 315/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -156.7177 - val_loss: -160.5481\n",
      "\n",
      "Epoch 00315: loss did not improve from -156.82124\n",
      "Epoch 316/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -156.6398 - val_loss: -160.5242\n",
      "\n",
      "Epoch 00316: loss did not improve from -156.82124\n",
      "Epoch 317/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -156.7334 - val_loss: -160.6865\n",
      "\n",
      "Epoch 00317: loss did not improve from -156.82124\n",
      "Epoch 318/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -156.7615 - val_loss: -161.1868\n",
      "\n",
      "Epoch 00318: loss did not improve from -156.82124\n",
      "Epoch 319/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -157.1672 - val_loss: -161.1928\n",
      "\n",
      "Epoch 00319: loss improved from -156.82124 to -157.16721, saving model to gendance.h5\n",
      "Epoch 320/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -157.0294 - val_loss: -161.1606\n",
      "\n",
      "Epoch 00320: loss did not improve from -157.16721\n",
      "Epoch 321/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -157.0499 - val_loss: -161.1517\n",
      "\n",
      "Epoch 00321: loss did not improve from -157.16721\n",
      "Epoch 322/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -157.2560 - val_loss: -161.5513\n",
      "\n",
      "Epoch 00322: loss improved from -157.16721 to -157.25602, saving model to gendance.h5\n",
      "Epoch 323/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -157.1111 - val_loss: -161.2745\n",
      "\n",
      "Epoch 00323: loss did not improve from -157.25602\n",
      "Epoch 324/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -157.1145 - val_loss: -161.6583\n",
      "\n",
      "Epoch 00324: loss did not improve from -157.25602\n",
      "Epoch 325/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -157.1983 - val_loss: -161.5805\n",
      "\n",
      "Epoch 00325: loss did not improve from -157.25602\n",
      "Epoch 326/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -157.1259 - val_loss: -161.5617\n",
      "\n",
      "Epoch 00326: loss did not improve from -157.25602\n",
      "Epoch 327/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -157.3690 - val_loss: -161.4177\n",
      "\n",
      "Epoch 00327: loss improved from -157.25602 to -157.36899, saving model to gendance.h5\n",
      "Epoch 328/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -157.3065 - val_loss: -160.9337\n",
      "\n",
      "Epoch 00328: loss did not improve from -157.36899\n",
      "Epoch 329/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -157.1613 - val_loss: -161.6253\n",
      "\n",
      "Epoch 00329: loss did not improve from -157.36899\n",
      "Epoch 330/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -157.5020 - val_loss: -161.8092\n",
      "\n",
      "Epoch 00330: loss improved from -157.36899 to -157.50197, saving model to gendance.h5\n",
      "Epoch 331/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -157.7153 - val_loss: -161.5300\n",
      "\n",
      "Epoch 00331: loss improved from -157.50197 to -157.71535, saving model to gendance.h5\n",
      "Epoch 332/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -157.6293 - val_loss: -161.7027\n",
      "\n",
      "Epoch 00332: loss did not improve from -157.71535\n",
      "Epoch 333/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -157.6074 - val_loss: -161.4809\n",
      "\n",
      "Epoch 00333: loss did not improve from -157.71535\n",
      "Epoch 334/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -157.7023 - val_loss: -161.7364\n",
      "\n",
      "Epoch 00334: loss did not improve from -157.71535\n",
      "Epoch 335/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -157.5197 - val_loss: -161.7409\n",
      "\n",
      "Epoch 00335: loss did not improve from -157.71535\n",
      "Epoch 336/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -157.6658 - val_loss: -161.6951\n",
      "\n",
      "Epoch 00336: loss did not improve from -157.71535\n",
      "Epoch 337/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -157.6811 - val_loss: -161.5764\n",
      "\n",
      "Epoch 00337: loss did not improve from -157.71535\n",
      "Epoch 338/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -158.0259 - val_loss: -162.2751\n",
      "\n",
      "Epoch 00338: loss improved from -157.71535 to -158.02588, saving model to gendance.h5\n",
      "Epoch 339/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -157.8251 - val_loss: -161.8292\n",
      "\n",
      "Epoch 00339: loss did not improve from -158.02588\n",
      "Epoch 340/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -158.0894 - val_loss: -161.8854\n",
      "\n",
      "Epoch 00340: loss improved from -158.02588 to -158.08944, saving model to gendance.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 341/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -157.8297 - val_loss: -162.3210\n",
      "\n",
      "Epoch 00341: loss did not improve from -158.08944\n",
      "Epoch 342/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -158.1415 - val_loss: -162.2346\n",
      "\n",
      "Epoch 00342: loss improved from -158.08944 to -158.14153, saving model to gendance.h5\n",
      "Epoch 343/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -157.9513 - val_loss: -162.1610\n",
      "\n",
      "Epoch 00343: loss did not improve from -158.14153\n",
      "Epoch 344/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -158.1114 - val_loss: -162.2572\n",
      "\n",
      "Epoch 00344: loss did not improve from -158.14153\n",
      "Epoch 345/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -158.1469 - val_loss: -162.5428\n",
      "\n",
      "Epoch 00345: loss improved from -158.14153 to -158.14690, saving model to gendance.h5\n",
      "Epoch 346/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -158.2208 - val_loss: -162.6972\n",
      "\n",
      "Epoch 00346: loss improved from -158.14690 to -158.22080, saving model to gendance.h5\n",
      "Epoch 347/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -158.2577 - val_loss: -162.7926\n",
      "\n",
      "Epoch 00347: loss improved from -158.22080 to -158.25768, saving model to gendance.h5\n",
      "Epoch 348/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -158.1238 - val_loss: -162.2128\n",
      "\n",
      "Epoch 00348: loss did not improve from -158.25768\n",
      "Epoch 349/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -158.2760 - val_loss: -162.7816\n",
      "\n",
      "Epoch 00349: loss improved from -158.25768 to -158.27598, saving model to gendance.h5\n",
      "Epoch 350/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -158.2914 - val_loss: -162.6657\n",
      "\n",
      "Epoch 00350: loss improved from -158.27598 to -158.29137, saving model to gendance.h5\n",
      "Epoch 351/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -158.2364 - val_loss: -162.3203\n",
      "\n",
      "Epoch 00351: loss did not improve from -158.29137\n",
      "Epoch 352/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -158.5925 - val_loss: -162.8578\n",
      "\n",
      "Epoch 00352: loss improved from -158.29137 to -158.59250, saving model to gendance.h5\n",
      "Epoch 353/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -158.7110 - val_loss: -163.1184\n",
      "\n",
      "Epoch 00353: loss improved from -158.59250 to -158.71098, saving model to gendance.h5\n",
      "Epoch 354/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -158.4096 - val_loss: -162.3811\n",
      "\n",
      "Epoch 00354: loss did not improve from -158.71098\n",
      "Epoch 355/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -158.6167 - val_loss: -162.9771\n",
      "\n",
      "Epoch 00355: loss did not improve from -158.71098\n",
      "Epoch 356/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -158.5196 - val_loss: -162.5216\n",
      "\n",
      "Epoch 00356: loss did not improve from -158.71098\n",
      "Epoch 357/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -158.5188 - val_loss: -162.7387\n",
      "\n",
      "Epoch 00357: loss did not improve from -158.71098\n",
      "Epoch 358/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -158.7456 - val_loss: -162.4912\n",
      "\n",
      "Epoch 00358: loss improved from -158.71098 to -158.74559, saving model to gendance.h5\n",
      "Epoch 359/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -158.6268 - val_loss: -162.6421\n",
      "\n",
      "Epoch 00359: loss did not improve from -158.74559\n",
      "Epoch 360/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -158.7372 - val_loss: -163.1892\n",
      "\n",
      "Epoch 00360: loss did not improve from -158.74559\n",
      "Epoch 361/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -158.9590 - val_loss: -163.2911\n",
      "\n",
      "Epoch 00361: loss improved from -158.74559 to -158.95896, saving model to gendance.h5\n",
      "Epoch 362/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -158.8422 - val_loss: -162.8704\n",
      "\n",
      "Epoch 00362: loss did not improve from -158.95896\n",
      "Epoch 363/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -158.8559 - val_loss: -163.4439\n",
      "\n",
      "Epoch 00363: loss did not improve from -158.95896\n",
      "Epoch 364/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -159.1457 - val_loss: -163.0978\n",
      "\n",
      "Epoch 00364: loss improved from -158.95896 to -159.14574, saving model to gendance.h5\n",
      "Epoch 365/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -158.9781 - val_loss: -163.1191\n",
      "\n",
      "Epoch 00365: loss did not improve from -159.14574\n",
      "Epoch 366/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -158.9031 - val_loss: -163.0312\n",
      "\n",
      "Epoch 00366: loss did not improve from -159.14574\n",
      "Epoch 367/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -159.1289 - val_loss: -163.1415\n",
      "\n",
      "Epoch 00367: loss did not improve from -159.14574\n",
      "Epoch 368/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -159.1109 - val_loss: -163.5784\n",
      "\n",
      "Epoch 00368: loss did not improve from -159.14574\n",
      "Epoch 369/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -159.2287 - val_loss: -163.6100\n",
      "\n",
      "Epoch 00369: loss improved from -159.14574 to -159.22873, saving model to gendance.h5\n",
      "Epoch 370/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -159.0676 - val_loss: -163.4335\n",
      "\n",
      "Epoch 00370: loss did not improve from -159.22873\n",
      "Epoch 371/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -159.1647 - val_loss: -163.3352\n",
      "\n",
      "Epoch 00371: loss did not improve from -159.22873\n",
      "Epoch 372/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -159.3312 - val_loss: -163.6402\n",
      "\n",
      "Epoch 00372: loss improved from -159.22873 to -159.33115, saving model to gendance.h5\n",
      "Epoch 373/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -159.3074 - val_loss: -163.7737\n",
      "\n",
      "Epoch 00373: loss did not improve from -159.33115\n",
      "Epoch 374/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -159.3029 - val_loss: -163.6224\n",
      "\n",
      "Epoch 00374: loss did not improve from -159.33115\n",
      "Epoch 375/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -159.2872 - val_loss: -163.7934\n",
      "\n",
      "Epoch 00375: loss did not improve from -159.33115\n",
      "Epoch 376/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -159.2007 - val_loss: -163.5992\n",
      "\n",
      "Epoch 00376: loss did not improve from -159.33115\n",
      "Epoch 377/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -159.3883 - val_loss: -163.9479\n",
      "\n",
      "Epoch 00377: loss improved from -159.33115 to -159.38830, saving model to gendance.h5\n",
      "Epoch 378/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -159.4405 - val_loss: -163.3387\n",
      "\n",
      "Epoch 00378: loss improved from -159.38830 to -159.44049, saving model to gendance.h5\n",
      "Epoch 379/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -159.5519 - val_loss: -163.8182\n",
      "\n",
      "Epoch 00379: loss improved from -159.44049 to -159.55193, saving model to gendance.h5\n",
      "Epoch 380/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -159.6570 - val_loss: -163.7589\n",
      "\n",
      "Epoch 00380: loss improved from -159.55193 to -159.65702, saving model to gendance.h5\n",
      "Epoch 381/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -159.7768 - val_loss: -163.5257\n",
      "\n",
      "Epoch 00381: loss improved from -159.65702 to -159.77677, saving model to gendance.h5\n",
      "Epoch 382/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -159.7652 - val_loss: -163.9078\n",
      "\n",
      "Epoch 00382: loss did not improve from -159.77677\n",
      "Epoch 383/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -159.5832 - val_loss: -163.6557\n",
      "\n",
      "Epoch 00383: loss did not improve from -159.77677\n",
      "Epoch 384/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -159.5378 - val_loss: -163.8274\n",
      "\n",
      "Epoch 00384: loss did not improve from -159.77677\n",
      "Epoch 385/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -159.7988 - val_loss: -164.0770\n",
      "\n",
      "Epoch 00385: loss improved from -159.77677 to -159.79878, saving model to gendance.h5\n",
      "Epoch 386/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16017/16017 [==============================] - 1s 52us/step - loss: -159.8374 - val_loss: -164.0043\n",
      "\n",
      "Epoch 00386: loss improved from -159.79878 to -159.83744, saving model to gendance.h5\n",
      "Epoch 387/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -159.9911 - val_loss: -164.2917\n",
      "\n",
      "Epoch 00387: loss improved from -159.83744 to -159.99107, saving model to gendance.h5\n",
      "Epoch 388/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -159.9528 - val_loss: -163.9650\n",
      "\n",
      "Epoch 00388: loss did not improve from -159.99107\n",
      "Epoch 389/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -160.0794 - val_loss: -164.3286\n",
      "\n",
      "Epoch 00389: loss improved from -159.99107 to -160.07935, saving model to gendance.h5\n",
      "Epoch 390/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -160.1085 - val_loss: -164.2140\n",
      "\n",
      "Epoch 00390: loss improved from -160.07935 to -160.10850, saving model to gendance.h5\n",
      "Epoch 391/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -160.0725 - val_loss: -164.3249\n",
      "\n",
      "Epoch 00391: loss did not improve from -160.10850\n",
      "Epoch 392/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -160.1219 - val_loss: -164.6812\n",
      "\n",
      "Epoch 00392: loss improved from -160.10850 to -160.12187, saving model to gendance.h5\n",
      "Epoch 393/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -160.1072 - val_loss: -164.1706\n",
      "\n",
      "Epoch 00393: loss did not improve from -160.12187\n",
      "Epoch 394/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -160.1180 - val_loss: -163.9858\n",
      "\n",
      "Epoch 00394: loss did not improve from -160.12187\n",
      "Epoch 395/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -160.1223 - val_loss: -164.3172\n",
      "\n",
      "Epoch 00395: loss improved from -160.12187 to -160.12232, saving model to gendance.h5\n",
      "Epoch 396/2000\n",
      "16017/16017 [==============================] - 1s 54us/step - loss: -160.3886 - val_loss: -164.2074\n",
      "\n",
      "Epoch 00396: loss improved from -160.12232 to -160.38863, saving model to gendance.h5\n",
      "Epoch 397/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -160.0708 - val_loss: -164.4037\n",
      "\n",
      "Epoch 00397: loss did not improve from -160.38863\n",
      "Epoch 398/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -160.1259 - val_loss: -164.6507\n",
      "\n",
      "Epoch 00398: loss did not improve from -160.38863\n",
      "Epoch 399/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -160.5660 - val_loss: -164.8315\n",
      "\n",
      "Epoch 00399: loss improved from -160.38863 to -160.56599, saving model to gendance.h5\n",
      "Epoch 400/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -160.4510 - val_loss: -164.7595\n",
      "\n",
      "Epoch 00400: loss did not improve from -160.56599\n",
      "Epoch 401/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -160.2209 - val_loss: -164.3638\n",
      "\n",
      "Epoch 00401: loss did not improve from -160.56599\n",
      "Epoch 402/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -160.2536 - val_loss: -164.6891\n",
      "\n",
      "Epoch 00402: loss did not improve from -160.56599\n",
      "Epoch 403/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -160.1707 - val_loss: -164.1926\n",
      "\n",
      "Epoch 00403: loss did not improve from -160.56599\n",
      "Epoch 404/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -160.2456 - val_loss: -164.6084\n",
      "\n",
      "Epoch 00404: loss did not improve from -160.56599\n",
      "Epoch 405/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -160.4275 - val_loss: -164.3523\n",
      "\n",
      "Epoch 00405: loss did not improve from -160.56599\n",
      "Epoch 406/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -160.3794 - val_loss: -165.0063\n",
      "\n",
      "Epoch 00406: loss did not improve from -160.56599\n",
      "Epoch 407/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -160.6642 - val_loss: -164.8725\n",
      "\n",
      "Epoch 00407: loss improved from -160.56599 to -160.66419, saving model to gendance.h5\n",
      "Epoch 408/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -160.6804 - val_loss: -165.0029\n",
      "\n",
      "Epoch 00408: loss improved from -160.66419 to -160.68044, saving model to gendance.h5\n",
      "Epoch 409/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -160.6416 - val_loss: -165.1527\n",
      "\n",
      "Epoch 00409: loss did not improve from -160.68044\n",
      "Epoch 410/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -160.7590 - val_loss: -164.6990\n",
      "\n",
      "Epoch 00410: loss improved from -160.68044 to -160.75902, saving model to gendance.h5\n",
      "Epoch 411/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -160.6431 - val_loss: -164.8482\n",
      "\n",
      "Epoch 00411: loss did not improve from -160.75902\n",
      "Epoch 412/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -160.7672 - val_loss: -164.8773\n",
      "\n",
      "Epoch 00412: loss improved from -160.75902 to -160.76724, saving model to gendance.h5\n",
      "Epoch 413/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -160.6299 - val_loss: -164.9663\n",
      "\n",
      "Epoch 00413: loss did not improve from -160.76724\n",
      "Epoch 414/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -160.7538 - val_loss: -165.1415\n",
      "\n",
      "Epoch 00414: loss did not improve from -160.76724\n",
      "Epoch 415/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -160.9015 - val_loss: -165.0675\n",
      "\n",
      "Epoch 00415: loss improved from -160.76724 to -160.90146, saving model to gendance.h5\n",
      "Epoch 416/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -160.7084 - val_loss: -164.9764\n",
      "\n",
      "Epoch 00416: loss did not improve from -160.90146\n",
      "Epoch 417/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -160.9319 - val_loss: -165.0296\n",
      "\n",
      "Epoch 00417: loss improved from -160.90146 to -160.93192, saving model to gendance.h5\n",
      "Epoch 418/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -160.9709 - val_loss: -165.2326\n",
      "\n",
      "Epoch 00418: loss improved from -160.93192 to -160.97094, saving model to gendance.h5\n",
      "Epoch 419/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -160.7842 - val_loss: -164.7664\n",
      "\n",
      "Epoch 00419: loss did not improve from -160.97094\n",
      "Epoch 420/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -161.2600 - val_loss: -165.6237\n",
      "\n",
      "Epoch 00420: loss improved from -160.97094 to -161.26001, saving model to gendance.h5\n",
      "Epoch 421/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -160.8023 - val_loss: -165.2728\n",
      "\n",
      "Epoch 00421: loss did not improve from -161.26001\n",
      "Epoch 422/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -160.8344 - val_loss: -164.8058\n",
      "\n",
      "Epoch 00422: loss did not improve from -161.26001\n",
      "Epoch 423/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -160.9220 - val_loss: -165.4665\n",
      "\n",
      "Epoch 00423: loss did not improve from -161.26001\n",
      "Epoch 424/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -161.1424 - val_loss: -165.2035\n",
      "\n",
      "Epoch 00424: loss did not improve from -161.26001\n",
      "Epoch 425/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -161.0747 - val_loss: -165.0228\n",
      "\n",
      "Epoch 00425: loss did not improve from -161.26001\n",
      "Epoch 426/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -160.9949 - val_loss: -165.3708\n",
      "\n",
      "Epoch 00426: loss did not improve from -161.26001\n",
      "Epoch 427/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -161.0484 - val_loss: -165.5935\n",
      "\n",
      "Epoch 00427: loss did not improve from -161.26001\n",
      "Epoch 428/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -161.1468 - val_loss: -165.8100\n",
      "\n",
      "Epoch 00428: loss did not improve from -161.26001\n",
      "Epoch 429/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -161.1918 - val_loss: -165.4487\n",
      "\n",
      "Epoch 00429: loss did not improve from -161.26001\n",
      "Epoch 430/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -161.3386 - val_loss: -165.4998\n",
      "\n",
      "Epoch 00430: loss improved from -161.26001 to -161.33862, saving model to gendance.h5\n",
      "Epoch 431/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -161.2453 - val_loss: -165.3611\n",
      "\n",
      "Epoch 00431: loss did not improve from -161.33862\n",
      "Epoch 432/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16017/16017 [==============================] - 1s 51us/step - loss: -161.3479 - val_loss: -165.8699\n",
      "\n",
      "Epoch 00432: loss improved from -161.33862 to -161.34789, saving model to gendance.h5\n",
      "Epoch 433/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -161.3747 - val_loss: -165.7956\n",
      "\n",
      "Epoch 00433: loss improved from -161.34789 to -161.37466, saving model to gendance.h5\n",
      "Epoch 434/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -161.4428 - val_loss: -165.5385\n",
      "\n",
      "Epoch 00434: loss improved from -161.37466 to -161.44284, saving model to gendance.h5\n",
      "Epoch 435/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -161.2444 - val_loss: -166.0044\n",
      "\n",
      "Epoch 00435: loss did not improve from -161.44284\n",
      "Epoch 436/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -161.4554 - val_loss: -165.7539\n",
      "\n",
      "Epoch 00436: loss improved from -161.44284 to -161.45543, saving model to gendance.h5\n",
      "Epoch 437/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -161.3724 - val_loss: -166.2209\n",
      "\n",
      "Epoch 00437: loss did not improve from -161.45543\n",
      "Epoch 438/2000\n",
      "16017/16017 [==============================] - 1s 53us/step - loss: -161.4248 - val_loss: -165.5737\n",
      "\n",
      "Epoch 00438: loss did not improve from -161.45543\n",
      "Epoch 439/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -161.5227 - val_loss: -165.9402\n",
      "\n",
      "Epoch 00439: loss improved from -161.45543 to -161.52271, saving model to gendance.h5\n",
      "Epoch 440/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -161.4849 - val_loss: -165.8582\n",
      "\n",
      "Epoch 00440: loss did not improve from -161.52271\n",
      "Epoch 441/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -161.7799 - val_loss: -165.7142\n",
      "\n",
      "Epoch 00441: loss improved from -161.52271 to -161.77986, saving model to gendance.h5\n",
      "Epoch 442/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -161.6185 - val_loss: -165.6920\n",
      "\n",
      "Epoch 00442: loss did not improve from -161.77986\n",
      "Epoch 443/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -161.6339 - val_loss: -166.0917\n",
      "\n",
      "Epoch 00443: loss did not improve from -161.77986\n",
      "Epoch 444/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -161.7829 - val_loss: -165.8423\n",
      "\n",
      "Epoch 00444: loss improved from -161.77986 to -161.78293, saving model to gendance.h5\n",
      "Epoch 445/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -161.8706 - val_loss: -166.1906\n",
      "\n",
      "Epoch 00445: loss improved from -161.78293 to -161.87064, saving model to gendance.h5\n",
      "Epoch 446/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -161.8176 - val_loss: -166.0074\n",
      "\n",
      "Epoch 00446: loss did not improve from -161.87064\n",
      "Epoch 447/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -161.9696 - val_loss: -166.1823\n",
      "\n",
      "Epoch 00447: loss improved from -161.87064 to -161.96963, saving model to gendance.h5\n",
      "Epoch 448/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -161.6260 - val_loss: -165.7041\n",
      "\n",
      "Epoch 00448: loss did not improve from -161.96963\n",
      "Epoch 449/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -161.8284 - val_loss: -166.7078\n",
      "\n",
      "Epoch 00449: loss did not improve from -161.96963\n",
      "Epoch 450/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -161.7732 - val_loss: -166.3980\n",
      "\n",
      "Epoch 00450: loss did not improve from -161.96963\n",
      "Epoch 451/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -161.8647 - val_loss: -166.0945\n",
      "\n",
      "Epoch 00451: loss did not improve from -161.96963\n",
      "Epoch 452/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -161.9003 - val_loss: -166.4115\n",
      "\n",
      "Epoch 00452: loss did not improve from -161.96963\n",
      "Epoch 453/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -161.8115 - val_loss: -166.5595\n",
      "\n",
      "Epoch 00453: loss did not improve from -161.96963\n",
      "Epoch 454/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -162.0685 - val_loss: -166.5385\n",
      "\n",
      "Epoch 00454: loss improved from -161.96963 to -162.06851, saving model to gendance.h5\n",
      "Epoch 455/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -162.0623 - val_loss: -166.6466\n",
      "\n",
      "Epoch 00455: loss did not improve from -162.06851\n",
      "Epoch 456/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -162.1119 - val_loss: -166.1554\n",
      "\n",
      "Epoch 00456: loss improved from -162.06851 to -162.11193, saving model to gendance.h5\n",
      "Epoch 457/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -162.1503 - val_loss: -166.6127\n",
      "\n",
      "Epoch 00457: loss improved from -162.11193 to -162.15028, saving model to gendance.h5\n",
      "Epoch 458/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -162.2419 - val_loss: -166.6112\n",
      "\n",
      "Epoch 00458: loss improved from -162.15028 to -162.24195, saving model to gendance.h5\n",
      "Epoch 459/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -162.2269 - val_loss: -166.5015\n",
      "\n",
      "Epoch 00459: loss did not improve from -162.24195\n",
      "Epoch 460/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -162.2181 - val_loss: -166.8196\n",
      "\n",
      "Epoch 00460: loss did not improve from -162.24195\n",
      "Epoch 461/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -161.9244 - val_loss: -166.7438\n",
      "\n",
      "Epoch 00461: loss did not improve from -162.24195\n",
      "Epoch 462/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -162.1584 - val_loss: -166.8866\n",
      "\n",
      "Epoch 00462: loss did not improve from -162.24195\n",
      "Epoch 463/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -162.1167 - val_loss: -166.8792\n",
      "\n",
      "Epoch 00463: loss did not improve from -162.24195\n",
      "Epoch 464/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -162.1731 - val_loss: -166.6425\n",
      "\n",
      "Epoch 00464: loss did not improve from -162.24195\n",
      "Epoch 465/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -162.2675 - val_loss: -167.0125\n",
      "\n",
      "Epoch 00465: loss improved from -162.24195 to -162.26746, saving model to gendance.h5\n",
      "Epoch 466/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -162.2874 - val_loss: -166.4658\n",
      "\n",
      "Epoch 00466: loss improved from -162.26746 to -162.28740, saving model to gendance.h5\n",
      "Epoch 467/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -162.5026 - val_loss: -166.5567\n",
      "\n",
      "Epoch 00467: loss improved from -162.28740 to -162.50256, saving model to gendance.h5\n",
      "Epoch 468/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -162.3181 - val_loss: -166.6761\n",
      "\n",
      "Epoch 00468: loss did not improve from -162.50256\n",
      "Epoch 469/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -162.3024 - val_loss: -166.9908\n",
      "\n",
      "Epoch 00469: loss did not improve from -162.50256\n",
      "Epoch 470/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -162.4858 - val_loss: -166.9199\n",
      "\n",
      "Epoch 00470: loss did not improve from -162.50256\n",
      "Epoch 471/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -162.3537 - val_loss: -166.6423\n",
      "\n",
      "Epoch 00471: loss did not improve from -162.50256\n",
      "Epoch 472/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -162.4342 - val_loss: -167.0626\n",
      "\n",
      "Epoch 00472: loss did not improve from -162.50256\n",
      "Epoch 473/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -162.5134 - val_loss: -167.2946\n",
      "\n",
      "Epoch 00473: loss improved from -162.50256 to -162.51343, saving model to gendance.h5\n",
      "Epoch 474/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -162.3982 - val_loss: -167.1483\n",
      "\n",
      "Epoch 00474: loss did not improve from -162.51343\n",
      "Epoch 475/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -162.4860 - val_loss: -167.1000\n",
      "\n",
      "Epoch 00475: loss did not improve from -162.51343\n",
      "Epoch 476/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -162.7503 - val_loss: -167.4118\n",
      "\n",
      "Epoch 00476: loss improved from -162.51343 to -162.75032, saving model to gendance.h5\n",
      "Epoch 477/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -162.6467 - val_loss: -167.2210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00477: loss did not improve from -162.75032\n",
      "Epoch 478/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -162.7467 - val_loss: -166.8835\n",
      "\n",
      "Epoch 00478: loss did not improve from -162.75032\n",
      "Epoch 479/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -163.1185 - val_loss: -167.5333\n",
      "\n",
      "Epoch 00479: loss improved from -162.75032 to -163.11846, saving model to gendance.h5\n",
      "Epoch 480/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -162.6740 - val_loss: -167.3409\n",
      "\n",
      "Epoch 00480: loss did not improve from -163.11846\n",
      "Epoch 481/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -162.7419 - val_loss: -167.1860\n",
      "\n",
      "Epoch 00481: loss did not improve from -163.11846\n",
      "Epoch 482/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -163.0693 - val_loss: -167.6463\n",
      "\n",
      "Epoch 00482: loss did not improve from -163.11846\n",
      "Epoch 483/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -162.9422 - val_loss: -167.3428\n",
      "\n",
      "Epoch 00483: loss did not improve from -163.11846\n",
      "Epoch 484/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -162.7328 - val_loss: -167.2318\n",
      "\n",
      "Epoch 00484: loss did not improve from -163.11846\n",
      "Epoch 485/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -162.8342 - val_loss: -167.7645\n",
      "\n",
      "Epoch 00485: loss did not improve from -163.11846\n",
      "Epoch 486/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -162.9293 - val_loss: -167.3070\n",
      "\n",
      "Epoch 00486: loss did not improve from -163.11846\n",
      "Epoch 487/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -162.8536 - val_loss: -166.8827\n",
      "\n",
      "Epoch 00487: loss did not improve from -163.11846\n",
      "Epoch 488/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -162.9418 - val_loss: -167.3979\n",
      "\n",
      "Epoch 00488: loss did not improve from -163.11846\n",
      "Epoch 489/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -162.9616 - val_loss: -167.8178\n",
      "\n",
      "Epoch 00489: loss did not improve from -163.11846\n",
      "Epoch 490/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -163.0658 - val_loss: -167.4077\n",
      "\n",
      "Epoch 00490: loss did not improve from -163.11846\n",
      "Epoch 491/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -163.1154 - val_loss: -167.5382\n",
      "\n",
      "Epoch 00491: loss did not improve from -163.11846\n",
      "Epoch 492/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -163.1303 - val_loss: -167.8132\n",
      "\n",
      "Epoch 00492: loss improved from -163.11846 to -163.13029, saving model to gendance.h5\n",
      "Epoch 493/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -163.1292 - val_loss: -167.5553\n",
      "\n",
      "Epoch 00493: loss did not improve from -163.13029\n",
      "Epoch 494/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -163.1930 - val_loss: -167.4620\n",
      "\n",
      "Epoch 00494: loss improved from -163.13029 to -163.19298, saving model to gendance.h5\n",
      "Epoch 495/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -163.1752 - val_loss: -167.7206\n",
      "\n",
      "Epoch 00495: loss did not improve from -163.19298\n",
      "Epoch 496/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -163.1862 - val_loss: -167.4760\n",
      "\n",
      "Epoch 00496: loss did not improve from -163.19298\n",
      "Epoch 497/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -163.2814 - val_loss: -167.5623\n",
      "\n",
      "Epoch 00497: loss improved from -163.19298 to -163.28141, saving model to gendance.h5\n",
      "Epoch 498/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -163.0702 - val_loss: -167.4631\n",
      "\n",
      "Epoch 00498: loss did not improve from -163.28141\n",
      "Epoch 499/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -163.1234 - val_loss: -167.3847\n",
      "\n",
      "Epoch 00499: loss did not improve from -163.28141\n",
      "Epoch 500/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -163.2270 - val_loss: -167.7074\n",
      "\n",
      "Epoch 00500: loss did not improve from -163.28141\n",
      "Epoch 501/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -163.2256 - val_loss: -167.8202\n",
      "\n",
      "Epoch 00501: loss did not improve from -163.28141\n",
      "Epoch 502/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -163.3814 - val_loss: -167.8920\n",
      "\n",
      "Epoch 00502: loss improved from -163.28141 to -163.38140, saving model to gendance.h5\n",
      "Epoch 503/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -163.3746 - val_loss: -167.8327\n",
      "\n",
      "Epoch 00503: loss did not improve from -163.38140\n",
      "Epoch 504/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -163.4101 - val_loss: -167.7038\n",
      "\n",
      "Epoch 00504: loss improved from -163.38140 to -163.41011, saving model to gendance.h5\n",
      "Epoch 505/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -163.6691 - val_loss: -167.9860\n",
      "\n",
      "Epoch 00505: loss improved from -163.41011 to -163.66913, saving model to gendance.h5\n",
      "Epoch 506/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -163.2477 - val_loss: -167.4814\n",
      "\n",
      "Epoch 00506: loss did not improve from -163.66913\n",
      "Epoch 507/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -163.6099 - val_loss: -168.0999\n",
      "\n",
      "Epoch 00507: loss did not improve from -163.66913\n",
      "Epoch 508/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -163.5350 - val_loss: -167.8759\n",
      "\n",
      "Epoch 00508: loss did not improve from -163.66913\n",
      "Epoch 509/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -163.3714 - val_loss: -167.8236\n",
      "\n",
      "Epoch 00509: loss did not improve from -163.66913\n",
      "Epoch 510/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -163.5335 - val_loss: -167.8649\n",
      "\n",
      "Epoch 00510: loss did not improve from -163.66913\n",
      "Epoch 511/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -163.5769 - val_loss: -168.0750\n",
      "\n",
      "Epoch 00511: loss did not improve from -163.66913\n",
      "Epoch 512/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -163.4278 - val_loss: -167.9808\n",
      "\n",
      "Epoch 00512: loss did not improve from -163.66913\n",
      "Epoch 513/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -163.6910 - val_loss: -167.7323\n",
      "\n",
      "Epoch 00513: loss improved from -163.66913 to -163.69104, saving model to gendance.h5\n",
      "Epoch 514/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -163.3356 - val_loss: -168.4526\n",
      "\n",
      "Epoch 00514: loss did not improve from -163.69104\n",
      "Epoch 515/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -163.5849 - val_loss: -168.3149\n",
      "\n",
      "Epoch 00515: loss did not improve from -163.69104\n",
      "Epoch 516/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -163.5437 - val_loss: -168.0980\n",
      "\n",
      "Epoch 00516: loss did not improve from -163.69104\n",
      "Epoch 517/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -163.6784 - val_loss: -168.5245\n",
      "\n",
      "Epoch 00517: loss did not improve from -163.69104\n",
      "Epoch 518/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -163.7892 - val_loss: -168.3999\n",
      "\n",
      "Epoch 00518: loss improved from -163.69104 to -163.78921, saving model to gendance.h5\n",
      "Epoch 519/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -163.8631 - val_loss: -168.1377\n",
      "\n",
      "Epoch 00519: loss improved from -163.78921 to -163.86313, saving model to gendance.h5\n",
      "Epoch 520/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -163.7103 - val_loss: -168.4358\n",
      "\n",
      "Epoch 00520: loss did not improve from -163.86313\n",
      "Epoch 521/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -163.7349 - val_loss: -168.0280\n",
      "\n",
      "Epoch 00521: loss did not improve from -163.86313\n",
      "Epoch 522/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -163.8372 - val_loss: -168.1757\n",
      "\n",
      "Epoch 00522: loss did not improve from -163.86313\n",
      "Epoch 523/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -163.7563 - val_loss: -168.2187\n",
      "\n",
      "Epoch 00523: loss did not improve from -163.86313\n",
      "Epoch 524/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -163.8035 - val_loss: -168.5242\n",
      "\n",
      "Epoch 00524: loss did not improve from -163.86313\n",
      "Epoch 525/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16017/16017 [==============================] - 1s 52us/step - loss: -163.7753 - val_loss: -168.1400\n",
      "\n",
      "Epoch 00525: loss did not improve from -163.86313\n",
      "Epoch 526/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -163.9340 - val_loss: -168.4465\n",
      "\n",
      "Epoch 00526: loss improved from -163.86313 to -163.93396, saving model to gendance.h5\n",
      "Epoch 527/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -163.6440 - val_loss: -168.5015\n",
      "\n",
      "Epoch 00527: loss did not improve from -163.93396\n",
      "Epoch 528/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -163.8519 - val_loss: -168.5194\n",
      "\n",
      "Epoch 00528: loss did not improve from -163.93396\n",
      "Epoch 529/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -163.9883 - val_loss: -168.5563\n",
      "\n",
      "Epoch 00529: loss improved from -163.93396 to -163.98831, saving model to gendance.h5\n",
      "Epoch 530/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -163.9674 - val_loss: -168.5879\n",
      "\n",
      "Epoch 00530: loss did not improve from -163.98831\n",
      "Epoch 531/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -164.2520 - val_loss: -168.5213\n",
      "\n",
      "Epoch 00531: loss improved from -163.98831 to -164.25201, saving model to gendance.h5\n",
      "Epoch 532/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -164.0111 - val_loss: -168.9485\n",
      "\n",
      "Epoch 00532: loss did not improve from -164.25201\n",
      "Epoch 533/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -164.0930 - val_loss: -168.5559\n",
      "\n",
      "Epoch 00533: loss did not improve from -164.25201\n",
      "Epoch 534/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -163.9863 - val_loss: -168.4292\n",
      "\n",
      "Epoch 00534: loss did not improve from -164.25201\n",
      "Epoch 535/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -164.1075 - val_loss: -168.5610\n",
      "\n",
      "Epoch 00535: loss did not improve from -164.25201\n",
      "Epoch 536/2000\n",
      "16017/16017 [==============================] - 1s 55us/step - loss: -164.1420 - val_loss: -168.5665\n",
      "\n",
      "Epoch 00536: loss did not improve from -164.25201\n",
      "Epoch 537/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -164.2333 - val_loss: -168.8106\n",
      "\n",
      "Epoch 00537: loss did not improve from -164.25201\n",
      "Epoch 538/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -164.0864 - val_loss: -168.4050\n",
      "\n",
      "Epoch 00538: loss did not improve from -164.25201\n",
      "Epoch 539/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -164.1728 - val_loss: -168.8412\n",
      "\n",
      "Epoch 00539: loss did not improve from -164.25201\n",
      "Epoch 540/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -164.0974 - val_loss: -168.2643\n",
      "\n",
      "Epoch 00540: loss did not improve from -164.25201\n",
      "Epoch 541/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -164.2105 - val_loss: -169.0158\n",
      "\n",
      "Epoch 00541: loss did not improve from -164.25201\n",
      "Epoch 542/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -164.3686 - val_loss: -168.7234\n",
      "\n",
      "Epoch 00542: loss improved from -164.25201 to -164.36859, saving model to gendance.h5\n",
      "Epoch 543/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -164.2738 - val_loss: -169.1247\n",
      "\n",
      "Epoch 00543: loss did not improve from -164.36859\n",
      "Epoch 544/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -164.2957 - val_loss: -168.8647\n",
      "\n",
      "Epoch 00544: loss did not improve from -164.36859\n",
      "Epoch 545/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -164.3013 - val_loss: -169.0178\n",
      "\n",
      "Epoch 00545: loss did not improve from -164.36859\n",
      "Epoch 546/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -164.4120 - val_loss: -169.3428\n",
      "\n",
      "Epoch 00546: loss improved from -164.36859 to -164.41204, saving model to gendance.h5\n",
      "Epoch 547/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -164.2420 - val_loss: -168.7427\n",
      "\n",
      "Epoch 00547: loss did not improve from -164.41204\n",
      "Epoch 548/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -164.4814 - val_loss: -168.8408\n",
      "\n",
      "Epoch 00548: loss improved from -164.41204 to -164.48141, saving model to gendance.h5\n",
      "Epoch 549/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -164.3154 - val_loss: -168.7963\n",
      "\n",
      "Epoch 00549: loss did not improve from -164.48141\n",
      "Epoch 550/2000\n",
      "16017/16017 [==============================] - 1s 53us/step - loss: -164.4469 - val_loss: -169.1524\n",
      "\n",
      "Epoch 00550: loss did not improve from -164.48141\n",
      "Epoch 551/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -164.4965 - val_loss: -168.9371\n",
      "\n",
      "Epoch 00551: loss improved from -164.48141 to -164.49650, saving model to gendance.h5\n",
      "Epoch 552/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -164.5319 - val_loss: -169.1852\n",
      "\n",
      "Epoch 00552: loss improved from -164.49650 to -164.53188, saving model to gendance.h5\n",
      "Epoch 553/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -164.6744 - val_loss: -169.2087\n",
      "\n",
      "Epoch 00553: loss improved from -164.53188 to -164.67441, saving model to gendance.h5\n",
      "Epoch 554/2000\n",
      "16017/16017 [==============================] - 1s 56us/step - loss: -164.5025 - val_loss: -168.9713\n",
      "\n",
      "Epoch 00554: loss did not improve from -164.67441\n",
      "Epoch 555/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -164.7184 - val_loss: -169.2658\n",
      "\n",
      "Epoch 00555: loss improved from -164.67441 to -164.71839, saving model to gendance.h5\n",
      "Epoch 556/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -164.6421 - val_loss: -169.1459\n",
      "\n",
      "Epoch 00556: loss did not improve from -164.71839\n",
      "Epoch 557/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -164.9350 - val_loss: -169.4919\n",
      "\n",
      "Epoch 00557: loss improved from -164.71839 to -164.93503, saving model to gendance.h5\n",
      "Epoch 558/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -164.6262 - val_loss: -169.3385\n",
      "\n",
      "Epoch 00558: loss did not improve from -164.93503\n",
      "Epoch 559/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -164.7688 - val_loss: -169.4720\n",
      "\n",
      "Epoch 00559: loss did not improve from -164.93503\n",
      "Epoch 560/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -164.6151 - val_loss: -169.2249\n",
      "\n",
      "Epoch 00560: loss did not improve from -164.93503\n",
      "Epoch 561/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -164.8770 - val_loss: -169.0949\n",
      "\n",
      "Epoch 00561: loss did not improve from -164.93503\n",
      "Epoch 562/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -164.6316 - val_loss: -168.9303\n",
      "\n",
      "Epoch 00562: loss did not improve from -164.93503\n",
      "Epoch 563/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -164.9328 - val_loss: -169.2005\n",
      "\n",
      "Epoch 00563: loss did not improve from -164.93503\n",
      "Epoch 564/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -164.7696 - val_loss: -169.1096\n",
      "\n",
      "Epoch 00564: loss did not improve from -164.93503\n",
      "Epoch 565/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -164.7846 - val_loss: -169.3738\n",
      "\n",
      "Epoch 00565: loss did not improve from -164.93503\n",
      "Epoch 566/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -164.8791 - val_loss: -169.2574\n",
      "\n",
      "Epoch 00566: loss did not improve from -164.93503\n",
      "Epoch 567/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -164.7860 - val_loss: -168.7539\n",
      "\n",
      "Epoch 00567: loss did not improve from -164.93503\n",
      "Epoch 568/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -164.5407 - val_loss: -169.4084\n",
      "\n",
      "Epoch 00568: loss did not improve from -164.93503\n",
      "Epoch 569/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -164.9698 - val_loss: -169.5254\n",
      "\n",
      "Epoch 00569: loss improved from -164.93503 to -164.96981, saving model to gendance.h5\n",
      "Epoch 570/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -164.9122 - val_loss: -169.8876\n",
      "\n",
      "Epoch 00570: loss did not improve from -164.96981\n",
      "Epoch 571/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -164.8432 - val_loss: -169.1739\n",
      "\n",
      "Epoch 00571: loss did not improve from -164.96981\n",
      "Epoch 572/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16017/16017 [==============================] - 1s 52us/step - loss: -164.8192 - val_loss: -169.2005\n",
      "\n",
      "Epoch 00572: loss did not improve from -164.96981\n",
      "Epoch 573/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -164.9323 - val_loss: -169.6836\n",
      "\n",
      "Epoch 00573: loss did not improve from -164.96981\n",
      "Epoch 574/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -165.0143 - val_loss: -169.3663\n",
      "\n",
      "Epoch 00574: loss improved from -164.96981 to -165.01431, saving model to gendance.h5\n",
      "Epoch 575/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -164.9790 - val_loss: -169.6997\n",
      "\n",
      "Epoch 00575: loss did not improve from -165.01431\n",
      "Epoch 576/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -164.9312 - val_loss: -169.7442\n",
      "\n",
      "Epoch 00576: loss did not improve from -165.01431\n",
      "Epoch 577/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -165.2495 - val_loss: -169.8952\n",
      "\n",
      "Epoch 00577: loss improved from -165.01431 to -165.24950, saving model to gendance.h5\n",
      "Epoch 578/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -164.8766 - val_loss: -169.3327\n",
      "\n",
      "Epoch 00578: loss did not improve from -165.24950\n",
      "Epoch 579/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -164.9267 - val_loss: -169.9903\n",
      "\n",
      "Epoch 00579: loss did not improve from -165.24950\n",
      "Epoch 580/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -164.9534 - val_loss: -169.6738\n",
      "\n",
      "Epoch 00580: loss did not improve from -165.24950\n",
      "Epoch 581/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -165.1982 - val_loss: -169.8763\n",
      "\n",
      "Epoch 00581: loss did not improve from -165.24950\n",
      "Epoch 582/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -165.2930 - val_loss: -169.4736\n",
      "\n",
      "Epoch 00582: loss improved from -165.24950 to -165.29300, saving model to gendance.h5\n",
      "Epoch 583/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -165.3482 - val_loss: -170.1788\n",
      "\n",
      "Epoch 00583: loss improved from -165.29300 to -165.34816, saving model to gendance.h5\n",
      "Epoch 584/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -165.2079 - val_loss: -169.9638\n",
      "\n",
      "Epoch 00584: loss did not improve from -165.34816\n",
      "Epoch 585/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -165.3317 - val_loss: -169.9256\n",
      "\n",
      "Epoch 00585: loss did not improve from -165.34816\n",
      "Epoch 586/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -165.2993 - val_loss: -170.1654\n",
      "\n",
      "Epoch 00586: loss did not improve from -165.34816\n",
      "Epoch 587/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -165.2910 - val_loss: -169.7858\n",
      "\n",
      "Epoch 00587: loss did not improve from -165.34816\n",
      "Epoch 588/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -165.1564 - val_loss: -170.0738\n",
      "\n",
      "Epoch 00588: loss did not improve from -165.34816\n",
      "Epoch 589/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -165.2956 - val_loss: -169.9414\n",
      "\n",
      "Epoch 00589: loss did not improve from -165.34816\n",
      "Epoch 590/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -165.3364 - val_loss: -170.1816\n",
      "\n",
      "Epoch 00590: loss did not improve from -165.34816\n",
      "Epoch 591/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -165.3325 - val_loss: -169.9440\n",
      "\n",
      "Epoch 00591: loss did not improve from -165.34816\n",
      "Epoch 592/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -165.3318 - val_loss: -169.9801\n",
      "\n",
      "Epoch 00592: loss did not improve from -165.34816\n",
      "Epoch 593/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -165.3207 - val_loss: -169.9575\n",
      "\n",
      "Epoch 00593: loss did not improve from -165.34816\n",
      "Epoch 594/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -165.3059 - val_loss: -169.9269\n",
      "\n",
      "Epoch 00594: loss did not improve from -165.34816\n",
      "Epoch 595/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -165.4096 - val_loss: -170.0097\n",
      "\n",
      "Epoch 00595: loss improved from -165.34816 to -165.40961, saving model to gendance.h5\n",
      "Epoch 596/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -165.4686 - val_loss: -170.1473\n",
      "\n",
      "Epoch 00596: loss improved from -165.40961 to -165.46862, saving model to gendance.h5\n",
      "Epoch 597/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -165.6513 - val_loss: -170.3142\n",
      "\n",
      "Epoch 00597: loss improved from -165.46862 to -165.65129, saving model to gendance.h5\n",
      "Epoch 598/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -165.5634 - val_loss: -170.3556\n",
      "\n",
      "Epoch 00598: loss did not improve from -165.65129\n",
      "Epoch 599/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -165.5539 - val_loss: -170.3488\n",
      "\n",
      "Epoch 00599: loss did not improve from -165.65129\n",
      "Epoch 600/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -165.4902 - val_loss: -170.1204\n",
      "\n",
      "Epoch 00600: loss did not improve from -165.65129\n",
      "Epoch 601/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -165.4030 - val_loss: -170.1442\n",
      "\n",
      "Epoch 00601: loss did not improve from -165.65129\n",
      "Epoch 602/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -165.5357 - val_loss: -170.1626\n",
      "\n",
      "Epoch 00602: loss did not improve from -165.65129\n",
      "Epoch 603/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -165.6712 - val_loss: -170.1396\n",
      "\n",
      "Epoch 00603: loss improved from -165.65129 to -165.67117, saving model to gendance.h5\n",
      "Epoch 604/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -165.5731 - val_loss: -170.7168\n",
      "\n",
      "Epoch 00604: loss did not improve from -165.67117\n",
      "Epoch 605/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -165.6051 - val_loss: -170.0081\n",
      "\n",
      "Epoch 00605: loss did not improve from -165.67117\n",
      "Epoch 606/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -165.6194 - val_loss: -170.1464\n",
      "\n",
      "Epoch 00606: loss did not improve from -165.67117\n",
      "Epoch 607/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -165.7514 - val_loss: -170.4007\n",
      "\n",
      "Epoch 00607: loss improved from -165.67117 to -165.75142, saving model to gendance.h5\n",
      "Epoch 608/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -165.8244 - val_loss: -170.2140\n",
      "\n",
      "Epoch 00608: loss improved from -165.75142 to -165.82444, saving model to gendance.h5\n",
      "Epoch 609/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -165.8260 - val_loss: -170.6934\n",
      "\n",
      "Epoch 00609: loss improved from -165.82444 to -165.82595, saving model to gendance.h5\n",
      "Epoch 610/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -165.7457 - val_loss: -170.4841\n",
      "\n",
      "Epoch 00610: loss did not improve from -165.82595\n",
      "Epoch 611/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -165.7212 - val_loss: -170.5196\n",
      "\n",
      "Epoch 00611: loss did not improve from -165.82595\n",
      "Epoch 612/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -165.7977 - val_loss: -170.6028\n",
      "\n",
      "Epoch 00612: loss did not improve from -165.82595\n",
      "Epoch 613/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -165.9479 - val_loss: -170.7008\n",
      "\n",
      "Epoch 00613: loss improved from -165.82595 to -165.94792, saving model to gendance.h5\n",
      "Epoch 614/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -165.8048 - val_loss: -170.4938\n",
      "\n",
      "Epoch 00614: loss did not improve from -165.94792\n",
      "Epoch 615/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -165.7781 - val_loss: -170.4240\n",
      "\n",
      "Epoch 00615: loss did not improve from -165.94792\n",
      "Epoch 616/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -166.0441 - val_loss: -170.8552\n",
      "\n",
      "Epoch 00616: loss improved from -165.94792 to -166.04412, saving model to gendance.h5\n",
      "Epoch 617/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -166.0801 - val_loss: -170.6455\n",
      "\n",
      "Epoch 00617: loss improved from -166.04412 to -166.08014, saving model to gendance.h5\n",
      "Epoch 618/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16017/16017 [==============================] - 1s 52us/step - loss: -165.8550 - val_loss: -170.7082\n",
      "\n",
      "Epoch 00618: loss did not improve from -166.08014\n",
      "Epoch 619/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -165.9121 - val_loss: -170.5795\n",
      "\n",
      "Epoch 00619: loss did not improve from -166.08014\n",
      "Epoch 620/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -166.1180 - val_loss: -170.7198\n",
      "\n",
      "Epoch 00620: loss improved from -166.08014 to -166.11796, saving model to gendance.h5\n",
      "Epoch 621/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -165.8794 - val_loss: -170.5403\n",
      "\n",
      "Epoch 00621: loss did not improve from -166.11796\n",
      "Epoch 622/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -165.8731 - val_loss: -170.3214\n",
      "\n",
      "Epoch 00622: loss did not improve from -166.11796\n",
      "Epoch 623/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -166.0357 - val_loss: -170.5649\n",
      "\n",
      "Epoch 00623: loss did not improve from -166.11796\n",
      "Epoch 624/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -165.9673 - val_loss: -170.4525\n",
      "\n",
      "Epoch 00624: loss did not improve from -166.11796\n",
      "Epoch 625/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -166.0249 - val_loss: -170.6400\n",
      "\n",
      "Epoch 00625: loss did not improve from -166.11796\n",
      "Epoch 626/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -166.1066 - val_loss: -171.2730\n",
      "\n",
      "Epoch 00626: loss did not improve from -166.11796\n",
      "Epoch 627/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -166.1854 - val_loss: -170.6091\n",
      "\n",
      "Epoch 00627: loss improved from -166.11796 to -166.18536, saving model to gendance.h5\n",
      "Epoch 628/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -166.1726 - val_loss: -170.9501\n",
      "\n",
      "Epoch 00628: loss did not improve from -166.18536\n",
      "Epoch 629/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -165.9989 - val_loss: -170.6302\n",
      "\n",
      "Epoch 00629: loss did not improve from -166.18536\n",
      "Epoch 630/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -166.1552 - val_loss: -170.7929\n",
      "\n",
      "Epoch 00630: loss did not improve from -166.18536\n",
      "Epoch 631/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -166.2070 - val_loss: -170.8040\n",
      "\n",
      "Epoch 00631: loss improved from -166.18536 to -166.20697, saving model to gendance.h5\n",
      "Epoch 632/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -166.4133 - val_loss: -170.7714\n",
      "\n",
      "Epoch 00632: loss improved from -166.20697 to -166.41330, saving model to gendance.h5\n",
      "Epoch 633/2000\n",
      "16017/16017 [==============================] - 1s 54us/step - loss: -166.1450 - val_loss: -170.9087\n",
      "\n",
      "Epoch 00633: loss did not improve from -166.41330\n",
      "Epoch 634/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -166.1005 - val_loss: -170.8600\n",
      "\n",
      "Epoch 00634: loss did not improve from -166.41330\n",
      "Epoch 635/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -166.1197 - val_loss: -170.7701\n",
      "\n",
      "Epoch 00635: loss did not improve from -166.41330\n",
      "Epoch 636/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -166.5043 - val_loss: -171.1885\n",
      "\n",
      "Epoch 00636: loss improved from -166.41330 to -166.50429, saving model to gendance.h5\n",
      "Epoch 637/2000\n",
      "16017/16017 [==============================] - 1s 53us/step - loss: -166.2507 - val_loss: -170.8789\n",
      "\n",
      "Epoch 00637: loss did not improve from -166.50429\n",
      "Epoch 638/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -166.3280 - val_loss: -170.9591\n",
      "\n",
      "Epoch 00638: loss did not improve from -166.50429\n",
      "Epoch 639/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -166.2480 - val_loss: -171.1135\n",
      "\n",
      "Epoch 00639: loss did not improve from -166.50429\n",
      "Epoch 640/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -166.2367 - val_loss: -170.9609\n",
      "\n",
      "Epoch 00640: loss did not improve from -166.50429\n",
      "Epoch 641/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -166.3984 - val_loss: -170.9079\n",
      "\n",
      "Epoch 00641: loss did not improve from -166.50429\n",
      "Epoch 642/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -166.2799 - val_loss: -171.0608\n",
      "\n",
      "Epoch 00642: loss did not improve from -166.50429\n",
      "Epoch 643/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -166.3449 - val_loss: -171.0714\n",
      "\n",
      "Epoch 00643: loss did not improve from -166.50429\n",
      "Epoch 644/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -166.3083 - val_loss: -170.7478\n",
      "\n",
      "Epoch 00644: loss did not improve from -166.50429\n",
      "Epoch 645/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -166.2593 - val_loss: -171.3567\n",
      "\n",
      "Epoch 00645: loss did not improve from -166.50429\n",
      "Epoch 646/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -166.4236 - val_loss: -171.3804\n",
      "\n",
      "Epoch 00646: loss did not improve from -166.50429\n",
      "Epoch 647/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -166.2740 - val_loss: -171.3256\n",
      "\n",
      "Epoch 00647: loss did not improve from -166.50429\n",
      "Epoch 648/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -166.6454 - val_loss: -171.4776\n",
      "\n",
      "Epoch 00648: loss improved from -166.50429 to -166.64539, saving model to gendance.h5\n",
      "Epoch 649/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -166.5968 - val_loss: -171.0081\n",
      "\n",
      "Epoch 00649: loss did not improve from -166.64539\n",
      "Epoch 650/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -166.3987 - val_loss: -171.1620\n",
      "\n",
      "Epoch 00650: loss did not improve from -166.64539\n",
      "Epoch 651/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -166.5818 - val_loss: -171.1740\n",
      "\n",
      "Epoch 00651: loss did not improve from -166.64539\n",
      "Epoch 652/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -166.6504 - val_loss: -171.1655\n",
      "\n",
      "Epoch 00652: loss improved from -166.64539 to -166.65042, saving model to gendance.h5\n",
      "Epoch 653/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -166.5424 - val_loss: -171.2722\n",
      "\n",
      "Epoch 00653: loss did not improve from -166.65042\n",
      "Epoch 654/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -166.5260 - val_loss: -171.2229\n",
      "\n",
      "Epoch 00654: loss did not improve from -166.65042\n",
      "Epoch 655/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -166.4651 - val_loss: -170.8826\n",
      "\n",
      "Epoch 00655: loss did not improve from -166.65042\n",
      "Epoch 656/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -166.6202 - val_loss: -171.4173\n",
      "\n",
      "Epoch 00656: loss did not improve from -166.65042\n",
      "Epoch 657/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -166.8177 - val_loss: -171.0158\n",
      "\n",
      "Epoch 00657: loss improved from -166.65042 to -166.81773, saving model to gendance.h5\n",
      "Epoch 658/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -166.4885 - val_loss: -171.7171\n",
      "\n",
      "Epoch 00658: loss did not improve from -166.81773\n",
      "Epoch 659/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -166.4767 - val_loss: -171.6670\n",
      "\n",
      "Epoch 00659: loss did not improve from -166.81773\n",
      "Epoch 660/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -166.6688 - val_loss: -171.0753\n",
      "\n",
      "Epoch 00660: loss did not improve from -166.81773\n",
      "Epoch 661/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -166.6308 - val_loss: -171.3597\n",
      "\n",
      "Epoch 00661: loss did not improve from -166.81773\n",
      "Epoch 662/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -166.8494 - val_loss: -171.5028\n",
      "\n",
      "Epoch 00662: loss improved from -166.81773 to -166.84940, saving model to gendance.h5\n",
      "Epoch 663/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -166.7494 - val_loss: -171.3797\n",
      "\n",
      "Epoch 00663: loss did not improve from -166.84940\n",
      "Epoch 664/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -166.6921 - val_loss: -171.7212\n",
      "\n",
      "Epoch 00664: loss did not improve from -166.84940\n",
      "Epoch 665/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16017/16017 [==============================] - 1s 51us/step - loss: -166.6115 - val_loss: -171.4399\n",
      "\n",
      "Epoch 00665: loss did not improve from -166.84940\n",
      "Epoch 666/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -166.7413 - val_loss: -171.3368\n",
      "\n",
      "Epoch 00666: loss did not improve from -166.84940\n",
      "Epoch 667/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -166.8077 - val_loss: -171.3505\n",
      "\n",
      "Epoch 00667: loss did not improve from -166.84940\n",
      "Epoch 668/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -166.8809 - val_loss: -171.6247\n",
      "\n",
      "Epoch 00668: loss improved from -166.84940 to -166.88090, saving model to gendance.h5\n",
      "Epoch 669/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -166.9514 - val_loss: -171.3842\n",
      "\n",
      "Epoch 00669: loss improved from -166.88090 to -166.95141, saving model to gendance.h5\n",
      "Epoch 670/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -166.7797 - val_loss: -171.8445\n",
      "\n",
      "Epoch 00670: loss did not improve from -166.95141\n",
      "Epoch 671/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -166.7566 - val_loss: -171.5381\n",
      "\n",
      "Epoch 00671: loss did not improve from -166.95141\n",
      "Epoch 672/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.0079 - val_loss: -171.9607\n",
      "\n",
      "Epoch 00672: loss improved from -166.95141 to -167.00787, saving model to gendance.h5\n",
      "Epoch 673/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.0893 - val_loss: -171.6656\n",
      "\n",
      "Epoch 00673: loss improved from -167.00787 to -167.08935, saving model to gendance.h5\n",
      "Epoch 674/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -166.9207 - val_loss: -171.6621\n",
      "\n",
      "Epoch 00674: loss did not improve from -167.08935\n",
      "Epoch 675/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -166.9665 - val_loss: -171.7750\n",
      "\n",
      "Epoch 00675: loss did not improve from -167.08935\n",
      "Epoch 676/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -166.6907 - val_loss: -172.0858\n",
      "\n",
      "Epoch 00676: loss did not improve from -167.08935\n",
      "Epoch 677/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.0441 - val_loss: -171.6664\n",
      "\n",
      "Epoch 00677: loss did not improve from -167.08935\n",
      "Epoch 678/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.2019 - val_loss: -171.7831\n",
      "\n",
      "Epoch 00678: loss improved from -167.08935 to -167.20191, saving model to gendance.h5\n",
      "Epoch 679/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -166.8272 - val_loss: -171.4384\n",
      "\n",
      "Epoch 00679: loss did not improve from -167.20191\n",
      "Epoch 680/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -166.9305 - val_loss: -171.8066\n",
      "\n",
      "Epoch 00680: loss did not improve from -167.20191\n",
      "Epoch 681/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -167.1974 - val_loss: -171.8405\n",
      "\n",
      "Epoch 00681: loss did not improve from -167.20191\n",
      "Epoch 682/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.0597 - val_loss: -171.7435\n",
      "\n",
      "Epoch 00682: loss did not improve from -167.20191\n",
      "Epoch 683/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.2217 - val_loss: -171.6903\n",
      "\n",
      "Epoch 00683: loss improved from -167.20191 to -167.22171, saving model to gendance.h5\n",
      "Epoch 684/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.2172 - val_loss: -171.6173\n",
      "\n",
      "Epoch 00684: loss did not improve from -167.22171\n",
      "Epoch 685/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -166.9595 - val_loss: -172.2339\n",
      "\n",
      "Epoch 00685: loss did not improve from -167.22171\n",
      "Epoch 686/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.1511 - val_loss: -171.9953\n",
      "\n",
      "Epoch 00686: loss did not improve from -167.22171\n",
      "Epoch 687/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -167.2761 - val_loss: -172.3724\n",
      "\n",
      "Epoch 00687: loss improved from -167.22171 to -167.27609, saving model to gendance.h5\n",
      "Epoch 688/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -166.9319 - val_loss: -171.5944\n",
      "\n",
      "Epoch 00688: loss did not improve from -167.27609\n",
      "Epoch 689/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.3596 - val_loss: -172.1297\n",
      "\n",
      "Epoch 00689: loss improved from -167.27609 to -167.35960, saving model to gendance.h5\n",
      "Epoch 690/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.3444 - val_loss: -171.9019\n",
      "\n",
      "Epoch 00690: loss did not improve from -167.35960\n",
      "Epoch 691/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.2836 - val_loss: -171.8097\n",
      "\n",
      "Epoch 00691: loss did not improve from -167.35960\n",
      "Epoch 692/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -167.1977 - val_loss: -172.0237\n",
      "\n",
      "Epoch 00692: loss did not improve from -167.35960\n",
      "Epoch 693/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.1636 - val_loss: -171.6410\n",
      "\n",
      "Epoch 00693: loss did not improve from -167.35960\n",
      "Epoch 694/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.4260 - val_loss: -172.2555\n",
      "\n",
      "Epoch 00694: loss improved from -167.35960 to -167.42597, saving model to gendance.h5\n",
      "Epoch 695/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.2777 - val_loss: -171.5977\n",
      "\n",
      "Epoch 00695: loss did not improve from -167.42597\n",
      "Epoch 696/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.3906 - val_loss: -172.2285\n",
      "\n",
      "Epoch 00696: loss did not improve from -167.42597\n",
      "Epoch 697/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.2375 - val_loss: -172.2761\n",
      "\n",
      "Epoch 00697: loss did not improve from -167.42597\n",
      "Epoch 698/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.3739 - val_loss: -172.3208\n",
      "\n",
      "Epoch 00698: loss did not improve from -167.42597\n",
      "Epoch 699/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.4061 - val_loss: -172.1626\n",
      "\n",
      "Epoch 00699: loss did not improve from -167.42597\n",
      "Epoch 700/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.4745 - val_loss: -172.2645\n",
      "\n",
      "Epoch 00700: loss improved from -167.42597 to -167.47452, saving model to gendance.h5\n",
      "Epoch 701/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.3890 - val_loss: -172.4292\n",
      "\n",
      "Epoch 00701: loss did not improve from -167.47452\n",
      "Epoch 702/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.3847 - val_loss: -171.9820\n",
      "\n",
      "Epoch 00702: loss did not improve from -167.47452\n",
      "Epoch 703/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.3947 - val_loss: -172.2857\n",
      "\n",
      "Epoch 00703: loss did not improve from -167.47452\n",
      "Epoch 704/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.4848 - val_loss: -172.3744\n",
      "\n",
      "Epoch 00704: loss improved from -167.47452 to -167.48482, saving model to gendance.h5\n",
      "Epoch 705/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.5787 - val_loss: -172.2889\n",
      "\n",
      "Epoch 00705: loss improved from -167.48482 to -167.57875, saving model to gendance.h5\n",
      "Epoch 706/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.6840 - val_loss: -172.3966\n",
      "\n",
      "Epoch 00706: loss improved from -167.57875 to -167.68402, saving model to gendance.h5\n",
      "Epoch 707/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.5787 - val_loss: -172.3105\n",
      "\n",
      "Epoch 00707: loss did not improve from -167.68402\n",
      "Epoch 708/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.4372 - val_loss: -172.3214\n",
      "\n",
      "Epoch 00708: loss did not improve from -167.68402\n",
      "Epoch 709/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -167.7750 - val_loss: -172.4765\n",
      "\n",
      "Epoch 00709: loss improved from -167.68402 to -167.77503, saving model to gendance.h5\n",
      "Epoch 710/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.6151 - val_loss: -172.8029\n",
      "\n",
      "Epoch 00710: loss did not improve from -167.77503\n",
      "Epoch 711/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.6688 - val_loss: -172.4638\n",
      "\n",
      "Epoch 00711: loss did not improve from -167.77503\n",
      "Epoch 712/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.7633 - val_loss: -172.4827\n",
      "\n",
      "Epoch 00712: loss did not improve from -167.77503\n",
      "Epoch 713/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.7036 - val_loss: -172.2252\n",
      "\n",
      "Epoch 00713: loss did not improve from -167.77503\n",
      "Epoch 714/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.4356 - val_loss: -172.5963\n",
      "\n",
      "Epoch 00714: loss did not improve from -167.77503\n",
      "Epoch 715/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.5680 - val_loss: -172.4113\n",
      "\n",
      "Epoch 00715: loss did not improve from -167.77503\n",
      "Epoch 716/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.5805 - val_loss: -171.9162\n",
      "\n",
      "Epoch 00716: loss did not improve from -167.77503\n",
      "Epoch 717/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.6617 - val_loss: -172.8745\n",
      "\n",
      "Epoch 00717: loss did not improve from -167.77503\n",
      "Epoch 718/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -167.6509 - val_loss: -172.5902\n",
      "\n",
      "Epoch 00718: loss did not improve from -167.77503\n",
      "Epoch 719/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.9288 - val_loss: -172.8295\n",
      "\n",
      "Epoch 00719: loss improved from -167.77503 to -167.92876, saving model to gendance.h5\n",
      "Epoch 720/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.5820 - val_loss: -172.0305\n",
      "\n",
      "Epoch 00720: loss did not improve from -167.92876\n",
      "Epoch 721/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.5431 - val_loss: -172.4292\n",
      "\n",
      "Epoch 00721: loss did not improve from -167.92876\n",
      "Epoch 722/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.6659 - val_loss: -172.2763\n",
      "\n",
      "Epoch 00722: loss did not improve from -167.92876\n",
      "Epoch 723/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.6592 - val_loss: -172.3836\n",
      "\n",
      "Epoch 00723: loss did not improve from -167.92876\n",
      "Epoch 724/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.7073 - val_loss: -172.5450\n",
      "\n",
      "Epoch 00724: loss did not improve from -167.92876\n",
      "Epoch 725/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.7080 - val_loss: -172.8668\n",
      "\n",
      "Epoch 00725: loss did not improve from -167.92876\n",
      "Epoch 726/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.9426 - val_loss: -172.5281\n",
      "\n",
      "Epoch 00726: loss improved from -167.92876 to -167.94257, saving model to gendance.h5\n",
      "Epoch 727/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.9902 - val_loss: -172.7798\n",
      "\n",
      "Epoch 00727: loss improved from -167.94257 to -167.99017, saving model to gendance.h5\n",
      "Epoch 728/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.8634 - val_loss: -172.8527\n",
      "\n",
      "Epoch 00728: loss did not improve from -167.99017\n",
      "Epoch 729/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.7947 - val_loss: -172.9260\n",
      "\n",
      "Epoch 00729: loss did not improve from -167.99017\n",
      "Epoch 730/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.8665 - val_loss: -172.7862\n",
      "\n",
      "Epoch 00730: loss did not improve from -167.99017\n",
      "Epoch 731/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.9766 - val_loss: -172.8171\n",
      "\n",
      "Epoch 00731: loss did not improve from -167.99017\n",
      "Epoch 732/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -167.8304 - val_loss: -172.6392\n",
      "\n",
      "Epoch 00732: loss did not improve from -167.99017\n",
      "Epoch 733/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.6813 - val_loss: -172.7672\n",
      "\n",
      "Epoch 00733: loss did not improve from -167.99017\n",
      "Epoch 734/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.9686 - val_loss: -172.6271\n",
      "\n",
      "Epoch 00734: loss did not improve from -167.99017\n",
      "Epoch 735/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.9195 - val_loss: -172.9183\n",
      "\n",
      "Epoch 00735: loss did not improve from -167.99017\n",
      "Epoch 736/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.0982 - val_loss: -172.3608\n",
      "\n",
      "Epoch 00736: loss improved from -167.99017 to -168.09821, saving model to gendance.h5\n",
      "Epoch 737/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.9266 - val_loss: -172.7618\n",
      "\n",
      "Epoch 00737: loss did not improve from -168.09821\n",
      "Epoch 738/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.8940 - val_loss: -172.5401\n",
      "\n",
      "Epoch 00738: loss did not improve from -168.09821\n",
      "Epoch 739/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.0765 - val_loss: -173.0768\n",
      "\n",
      "Epoch 00739: loss did not improve from -168.09821\n",
      "Epoch 740/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.0873 - val_loss: -172.8121\n",
      "\n",
      "Epoch 00740: loss did not improve from -168.09821\n",
      "Epoch 741/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.7275 - val_loss: -172.7727\n",
      "\n",
      "Epoch 00741: loss did not improve from -168.09821\n",
      "Epoch 742/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.2134 - val_loss: -172.6120\n",
      "\n",
      "Epoch 00742: loss improved from -168.09821 to -168.21344, saving model to gendance.h5\n",
      "Epoch 743/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.2599 - val_loss: -173.4403\n",
      "\n",
      "Epoch 00743: loss improved from -168.21344 to -168.25992, saving model to gendance.h5\n",
      "Epoch 744/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.2626 - val_loss: -172.6167\n",
      "\n",
      "Epoch 00744: loss improved from -168.25992 to -168.26258, saving model to gendance.h5\n",
      "Epoch 745/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.0380 - val_loss: -172.6623\n",
      "\n",
      "Epoch 00745: loss did not improve from -168.26258\n",
      "Epoch 746/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -167.9876 - val_loss: -172.8643\n",
      "\n",
      "Epoch 00746: loss did not improve from -168.26258\n",
      "Epoch 747/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.3008 - val_loss: -173.2426\n",
      "\n",
      "Epoch 00747: loss improved from -168.26258 to -168.30078, saving model to gendance.h5\n",
      "Epoch 748/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.1023 - val_loss: -172.8222\n",
      "\n",
      "Epoch 00748: loss did not improve from -168.30078\n",
      "Epoch 749/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.2115 - val_loss: -173.1328\n",
      "\n",
      "Epoch 00749: loss did not improve from -168.30078\n",
      "Epoch 750/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -168.2442 - val_loss: -173.0377\n",
      "\n",
      "Epoch 00750: loss did not improve from -168.30078\n",
      "Epoch 751/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.3366 - val_loss: -173.2278\n",
      "\n",
      "Epoch 00751: loss improved from -168.30078 to -168.33665, saving model to gendance.h5\n",
      "Epoch 752/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.4033 - val_loss: -173.1950\n",
      "\n",
      "Epoch 00752: loss improved from -168.33665 to -168.40333, saving model to gendance.h5\n",
      "Epoch 753/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.3111 - val_loss: -173.0464\n",
      "\n",
      "Epoch 00753: loss did not improve from -168.40333\n",
      "Epoch 754/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.2902 - val_loss: -172.7759\n",
      "\n",
      "Epoch 00754: loss did not improve from -168.40333\n",
      "Epoch 755/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.1571 - val_loss: -173.1194\n",
      "\n",
      "Epoch 00755: loss did not improve from -168.40333\n",
      "Epoch 756/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -168.2471 - val_loss: -173.3897\n",
      "\n",
      "Epoch 00756: loss did not improve from -168.40333\n",
      "Epoch 757/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.2648 - val_loss: -173.2456\n",
      "\n",
      "Epoch 00757: loss did not improve from -168.40333\n",
      "Epoch 758/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.5026 - val_loss: -173.1168\n",
      "\n",
      "Epoch 00758: loss improved from -168.40333 to -168.50258, saving model to gendance.h5\n",
      "Epoch 759/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.3669 - val_loss: -173.4131\n",
      "\n",
      "Epoch 00759: loss did not improve from -168.50258\n",
      "Epoch 760/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.3754 - val_loss: -172.7275\n",
      "\n",
      "Epoch 00760: loss did not improve from -168.50258\n",
      "Epoch 761/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.2497 - val_loss: -173.0854\n",
      "\n",
      "Epoch 00761: loss did not improve from -168.50258\n",
      "Epoch 762/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.0715 - val_loss: -173.3159\n",
      "\n",
      "Epoch 00762: loss did not improve from -168.50258\n",
      "Epoch 763/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.0787 - val_loss: -173.0320\n",
      "\n",
      "Epoch 00763: loss did not improve from -168.50258\n",
      "Epoch 764/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.4029 - val_loss: -173.5055\n",
      "\n",
      "Epoch 00764: loss did not improve from -168.50258\n",
      "Epoch 765/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.4539 - val_loss: -173.0275\n",
      "\n",
      "Epoch 00765: loss did not improve from -168.50258\n",
      "Epoch 766/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.6012 - val_loss: -173.3952\n",
      "\n",
      "Epoch 00766: loss improved from -168.50258 to -168.60123, saving model to gendance.h5\n",
      "Epoch 767/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.1250 - val_loss: -173.5073\n",
      "\n",
      "Epoch 00767: loss did not improve from -168.60123\n",
      "Epoch 768/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.4858 - val_loss: -173.4467\n",
      "\n",
      "Epoch 00768: loss did not improve from -168.60123\n",
      "Epoch 769/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.5303 - val_loss: -173.1097\n",
      "\n",
      "Epoch 00769: loss did not improve from -168.60123\n",
      "Epoch 770/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.3625 - val_loss: -173.3399\n",
      "\n",
      "Epoch 00770: loss did not improve from -168.60123\n",
      "Epoch 771/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.7357 - val_loss: -173.4479\n",
      "\n",
      "Epoch 00771: loss improved from -168.60123 to -168.73574, saving model to gendance.h5\n",
      "Epoch 772/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.5676 - val_loss: -173.7102\n",
      "\n",
      "Epoch 00772: loss did not improve from -168.73574\n",
      "Epoch 773/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.5775 - val_loss: -173.2052\n",
      "\n",
      "Epoch 00773: loss did not improve from -168.73574\n",
      "Epoch 774/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.4649 - val_loss: -173.3112\n",
      "\n",
      "Epoch 00774: loss did not improve from -168.73574\n",
      "Epoch 775/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.5514 - val_loss: -173.2067\n",
      "\n",
      "Epoch 00775: loss did not improve from -168.73574\n",
      "Epoch 776/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.7085 - val_loss: -173.4316\n",
      "\n",
      "Epoch 00776: loss did not improve from -168.73574\n",
      "Epoch 777/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.5927 - val_loss: -173.1356\n",
      "\n",
      "Epoch 00777: loss did not improve from -168.73574\n",
      "Epoch 778/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.6375 - val_loss: -173.3158\n",
      "\n",
      "Epoch 00778: loss did not improve from -168.73574\n",
      "Epoch 779/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.5739 - val_loss: -173.6341\n",
      "\n",
      "Epoch 00779: loss did not improve from -168.73574\n",
      "Epoch 780/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.5253 - val_loss: -173.2549\n",
      "\n",
      "Epoch 00780: loss did not improve from -168.73574\n",
      "Epoch 781/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.7934 - val_loss: -173.6182\n",
      "\n",
      "Epoch 00781: loss improved from -168.73574 to -168.79342, saving model to gendance.h5\n",
      "Epoch 782/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.5680 - val_loss: -173.5307\n",
      "\n",
      "Epoch 00782: loss did not improve from -168.79342\n",
      "Epoch 783/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.6704 - val_loss: -173.3092\n",
      "\n",
      "Epoch 00783: loss did not improve from -168.79342\n",
      "Epoch 784/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.7921 - val_loss: -173.5925\n",
      "\n",
      "Epoch 00784: loss did not improve from -168.79342\n",
      "Epoch 785/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.7921 - val_loss: -173.6150\n",
      "\n",
      "Epoch 00785: loss did not improve from -168.79342\n",
      "Epoch 786/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -168.5893 - val_loss: -173.7913\n",
      "\n",
      "Epoch 00786: loss did not improve from -168.79342\n",
      "Epoch 787/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.5018 - val_loss: -173.4943\n",
      "\n",
      "Epoch 00787: loss did not improve from -168.79342\n",
      "Epoch 788/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.8514 - val_loss: -173.7670\n",
      "\n",
      "Epoch 00788: loss improved from -168.79342 to -168.85140, saving model to gendance.h5\n",
      "Epoch 789/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.7912 - val_loss: -173.6223\n",
      "\n",
      "Epoch 00789: loss did not improve from -168.85140\n",
      "Epoch 790/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.9571 - val_loss: -173.8284\n",
      "\n",
      "Epoch 00790: loss improved from -168.85140 to -168.95712, saving model to gendance.h5\n",
      "Epoch 791/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.7582 - val_loss: -173.8049\n",
      "\n",
      "Epoch 00791: loss did not improve from -168.95712\n",
      "Epoch 792/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.7187 - val_loss: -173.4682\n",
      "\n",
      "Epoch 00792: loss did not improve from -168.95712\n",
      "Epoch 793/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.7018 - val_loss: -173.7282\n",
      "\n",
      "Epoch 00793: loss did not improve from -168.95712\n",
      "Epoch 794/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -168.8759 - val_loss: -174.0261\n",
      "\n",
      "Epoch 00794: loss did not improve from -168.95712\n",
      "Epoch 795/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.6503 - val_loss: -173.6899\n",
      "\n",
      "Epoch 00795: loss did not improve from -168.95712\n",
      "Epoch 796/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.6770 - val_loss: -173.5150\n",
      "\n",
      "Epoch 00796: loss did not improve from -168.95712\n",
      "Epoch 797/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.6551 - val_loss: -173.6209\n",
      "\n",
      "Epoch 00797: loss did not improve from -168.95712\n",
      "Epoch 798/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.8270 - val_loss: -173.7218\n",
      "\n",
      "Epoch 00798: loss did not improve from -168.95712\n",
      "Epoch 799/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.8818 - val_loss: -173.6261\n",
      "\n",
      "Epoch 00799: loss did not improve from -168.95712\n",
      "Epoch 800/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.9399 - val_loss: -173.7158\n",
      "\n",
      "Epoch 00800: loss did not improve from -168.95712\n",
      "Epoch 801/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.8815 - val_loss: -173.3793\n",
      "\n",
      "Epoch 00801: loss did not improve from -168.95712\n",
      "Epoch 802/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -168.9388 - val_loss: -173.7851\n",
      "\n",
      "Epoch 00802: loss did not improve from -168.95712\n",
      "Epoch 803/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -168.9184 - val_loss: -173.7963\n",
      "\n",
      "Epoch 00803: loss did not improve from -168.95712\n",
      "Epoch 804/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.7083 - val_loss: -173.6696\n",
      "\n",
      "Epoch 00804: loss did not improve from -168.95712\n",
      "Epoch 805/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.1070 - val_loss: -173.8860\n",
      "\n",
      "Epoch 00805: loss improved from -168.95712 to -169.10696, saving model to gendance.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 806/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.9230 - val_loss: -174.1163\n",
      "\n",
      "Epoch 00806: loss did not improve from -169.10696\n",
      "Epoch 807/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.9537 - val_loss: -173.5636\n",
      "\n",
      "Epoch 00807: loss did not improve from -169.10696\n",
      "Epoch 808/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.0435 - val_loss: -173.8860\n",
      "\n",
      "Epoch 00808: loss did not improve from -169.10696\n",
      "Epoch 809/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.1276 - val_loss: -173.6893\n",
      "\n",
      "Epoch 00809: loss improved from -169.10696 to -169.12757, saving model to gendance.h5\n",
      "Epoch 810/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.9422 - val_loss: -174.1987\n",
      "\n",
      "Epoch 00810: loss did not improve from -169.12757\n",
      "Epoch 811/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.9984 - val_loss: -173.8803\n",
      "\n",
      "Epoch 00811: loss did not improve from -169.12757\n",
      "Epoch 812/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.9423 - val_loss: -173.7201\n",
      "\n",
      "Epoch 00812: loss did not improve from -169.12757\n",
      "Epoch 813/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.2088 - val_loss: -173.7975\n",
      "\n",
      "Epoch 00813: loss improved from -169.12757 to -169.20877, saving model to gendance.h5\n",
      "Epoch 814/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -168.9489 - val_loss: -173.7323\n",
      "\n",
      "Epoch 00814: loss did not improve from -169.20877\n",
      "Epoch 815/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.0657 - val_loss: -174.0326\n",
      "\n",
      "Epoch 00815: loss did not improve from -169.20877\n",
      "Epoch 816/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.2728 - val_loss: -174.1688\n",
      "\n",
      "Epoch 00816: loss improved from -169.20877 to -169.27278, saving model to gendance.h5\n",
      "Epoch 817/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.2315 - val_loss: -174.0127\n",
      "\n",
      "Epoch 00817: loss did not improve from -169.27278\n",
      "Epoch 818/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.0760 - val_loss: -173.8635\n",
      "\n",
      "Epoch 00818: loss did not improve from -169.27278\n",
      "Epoch 819/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.0147 - val_loss: -174.0830\n",
      "\n",
      "Epoch 00819: loss did not improve from -169.27278\n",
      "Epoch 820/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.3023 - val_loss: -174.3764\n",
      "\n",
      "Epoch 00820: loss improved from -169.27278 to -169.30226, saving model to gendance.h5\n",
      "Epoch 821/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.1928 - val_loss: -173.9018\n",
      "\n",
      "Epoch 00821: loss did not improve from -169.30226\n",
      "Epoch 822/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.2805 - val_loss: -174.3926\n",
      "\n",
      "Epoch 00822: loss did not improve from -169.30226\n",
      "Epoch 823/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -169.1212 - val_loss: -174.0042\n",
      "\n",
      "Epoch 00823: loss did not improve from -169.30226\n",
      "Epoch 824/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.0995 - val_loss: -173.9861\n",
      "\n",
      "Epoch 00824: loss did not improve from -169.30226\n",
      "Epoch 825/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.1146 - val_loss: -174.2070\n",
      "\n",
      "Epoch 00825: loss did not improve from -169.30226\n",
      "Epoch 826/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.2740 - val_loss: -174.3150\n",
      "\n",
      "Epoch 00826: loss did not improve from -169.30226\n",
      "Epoch 827/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.4191 - val_loss: -174.3253\n",
      "\n",
      "Epoch 00827: loss improved from -169.30226 to -169.41908, saving model to gendance.h5\n",
      "Epoch 828/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.4721 - val_loss: -174.0360\n",
      "\n",
      "Epoch 00828: loss improved from -169.41908 to -169.47208, saving model to gendance.h5\n",
      "Epoch 829/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.3876 - val_loss: -174.1884\n",
      "\n",
      "Epoch 00829: loss did not improve from -169.47208\n",
      "Epoch 830/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.1996 - val_loss: -174.1741\n",
      "\n",
      "Epoch 00830: loss did not improve from -169.47208\n",
      "Epoch 831/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -169.1999 - val_loss: -174.3496\n",
      "\n",
      "Epoch 00831: loss did not improve from -169.47208\n",
      "Epoch 832/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.2820 - val_loss: -173.9618\n",
      "\n",
      "Epoch 00832: loss did not improve from -169.47208\n",
      "Epoch 833/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.4708 - val_loss: -174.2309\n",
      "\n",
      "Epoch 00833: loss did not improve from -169.47208\n",
      "Epoch 834/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.2600 - val_loss: -174.2889\n",
      "\n",
      "Epoch 00834: loss did not improve from -169.47208\n",
      "Epoch 835/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.2539 - val_loss: -174.1863\n",
      "\n",
      "Epoch 00835: loss did not improve from -169.47208\n",
      "Epoch 836/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.4426 - val_loss: -174.4210\n",
      "\n",
      "Epoch 00836: loss did not improve from -169.47208\n",
      "Epoch 837/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.4375 - val_loss: -174.1684\n",
      "\n",
      "Epoch 00837: loss did not improve from -169.47208\n",
      "Epoch 838/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.2458 - val_loss: -174.5634\n",
      "\n",
      "Epoch 00838: loss did not improve from -169.47208\n",
      "Epoch 839/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.3968 - val_loss: -174.4296\n",
      "\n",
      "Epoch 00839: loss did not improve from -169.47208\n",
      "Epoch 840/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.3749 - val_loss: -174.1423\n",
      "\n",
      "Epoch 00840: loss did not improve from -169.47208\n",
      "Epoch 841/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.3895 - val_loss: -174.3690\n",
      "\n",
      "Epoch 00841: loss did not improve from -169.47208\n",
      "Epoch 842/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -169.4228 - val_loss: -174.2668\n",
      "\n",
      "Epoch 00842: loss did not improve from -169.47208\n",
      "Epoch 843/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.3234 - val_loss: -174.0077\n",
      "\n",
      "Epoch 00843: loss did not improve from -169.47208\n",
      "Epoch 844/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.4466 - val_loss: -174.5361\n",
      "\n",
      "Epoch 00844: loss did not improve from -169.47208\n",
      "Epoch 845/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.5625 - val_loss: -174.0204\n",
      "\n",
      "Epoch 00845: loss improved from -169.47208 to -169.56246, saving model to gendance.h5\n",
      "Epoch 846/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.5115 - val_loss: -174.8515\n",
      "\n",
      "Epoch 00846: loss did not improve from -169.56246\n",
      "Epoch 847/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.5106 - val_loss: -174.5205\n",
      "\n",
      "Epoch 00847: loss did not improve from -169.56246\n",
      "Epoch 848/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.5539 - val_loss: -174.3438\n",
      "\n",
      "Epoch 00848: loss did not improve from -169.56246\n",
      "Epoch 849/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.5942 - val_loss: -174.3577\n",
      "\n",
      "Epoch 00849: loss improved from -169.56246 to -169.59425, saving model to gendance.h5\n",
      "Epoch 850/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.4742 - val_loss: -174.6982\n",
      "\n",
      "Epoch 00850: loss did not improve from -169.59425\n",
      "Epoch 851/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.6391 - val_loss: -174.5824\n",
      "\n",
      "Epoch 00851: loss improved from -169.59425 to -169.63915, saving model to gendance.h5\n",
      "Epoch 852/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.7556 - val_loss: -174.4676\n",
      "\n",
      "Epoch 00852: loss improved from -169.63915 to -169.75556, saving model to gendance.h5\n",
      "Epoch 853/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.7202 - val_loss: -174.3872\n",
      "\n",
      "Epoch 00853: loss did not improve from -169.75556\n",
      "Epoch 854/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.6356 - val_loss: -174.4786\n",
      "\n",
      "Epoch 00854: loss did not improve from -169.75556\n",
      "Epoch 855/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.5721 - val_loss: -174.4828\n",
      "\n",
      "Epoch 00855: loss did not improve from -169.75556\n",
      "Epoch 856/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.5294 - val_loss: -174.5719\n",
      "\n",
      "Epoch 00856: loss did not improve from -169.75556\n",
      "Epoch 857/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.5808 - val_loss: -174.7578\n",
      "\n",
      "Epoch 00857: loss did not improve from -169.75556\n",
      "Epoch 858/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.7156 - val_loss: -174.6784\n",
      "\n",
      "Epoch 00858: loss did not improve from -169.75556\n",
      "Epoch 859/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -169.5069 - val_loss: -174.4179\n",
      "\n",
      "Epoch 00859: loss did not improve from -169.75556\n",
      "Epoch 860/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.8463 - val_loss: -174.3624\n",
      "\n",
      "Epoch 00860: loss improved from -169.75556 to -169.84631, saving model to gendance.h5\n",
      "Epoch 861/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.4956 - val_loss: -174.5095\n",
      "\n",
      "Epoch 00861: loss did not improve from -169.84631\n",
      "Epoch 862/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.5258 - val_loss: -174.2911\n",
      "\n",
      "Epoch 00862: loss did not improve from -169.84631\n",
      "Epoch 863/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.6040 - val_loss: -174.4781\n",
      "\n",
      "Epoch 00863: loss did not improve from -169.84631\n",
      "Epoch 864/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -169.8149 - val_loss: -174.7552\n",
      "\n",
      "Epoch 00864: loss did not improve from -169.84631\n",
      "Epoch 865/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.6411 - val_loss: -174.8344\n",
      "\n",
      "Epoch 00865: loss did not improve from -169.84631\n",
      "Epoch 866/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.6429 - val_loss: -174.7234\n",
      "\n",
      "Epoch 00866: loss did not improve from -169.84631\n",
      "Epoch 867/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.7157 - val_loss: -174.7227\n",
      "\n",
      "Epoch 00867: loss did not improve from -169.84631\n",
      "Epoch 868/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -169.4617 - val_loss: -174.4936\n",
      "\n",
      "Epoch 00868: loss did not improve from -169.84631\n",
      "Epoch 869/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.0184 - val_loss: -174.9412\n",
      "\n",
      "Epoch 00869: loss improved from -169.84631 to -170.01844, saving model to gendance.h5\n",
      "Epoch 870/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.6583 - val_loss: -174.3516\n",
      "\n",
      "Epoch 00870: loss did not improve from -170.01844\n",
      "Epoch 871/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.7018 - val_loss: -174.6315\n",
      "\n",
      "Epoch 00871: loss did not improve from -170.01844\n",
      "Epoch 872/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.6611 - val_loss: -174.3728\n",
      "\n",
      "Epoch 00872: loss did not improve from -170.01844\n",
      "Epoch 873/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.8616 - val_loss: -174.5264\n",
      "\n",
      "Epoch 00873: loss did not improve from -170.01844\n",
      "Epoch 874/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.8754 - val_loss: -175.0600\n",
      "\n",
      "Epoch 00874: loss did not improve from -170.01844\n",
      "Epoch 875/2000\n",
      "16017/16017 [==============================] - 1s 53us/step - loss: -169.7316 - val_loss: -174.9235\n",
      "\n",
      "Epoch 00875: loss did not improve from -170.01844\n",
      "Epoch 876/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.8271 - val_loss: -175.1038\n",
      "\n",
      "Epoch 00876: loss did not improve from -170.01844\n",
      "Epoch 877/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -169.8872 - val_loss: -175.0614\n",
      "\n",
      "Epoch 00877: loss did not improve from -170.01844\n",
      "Epoch 878/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.7812 - val_loss: -174.8743\n",
      "\n",
      "Epoch 00878: loss did not improve from -170.01844\n",
      "Epoch 879/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -169.8529 - val_loss: -174.6756\n",
      "\n",
      "Epoch 00879: loss did not improve from -170.01844\n",
      "Epoch 880/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -169.7725 - val_loss: -174.7764\n",
      "\n",
      "Epoch 00880: loss did not improve from -170.01844\n",
      "Epoch 881/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.8836 - val_loss: -174.6946\n",
      "\n",
      "Epoch 00881: loss did not improve from -170.01844\n",
      "Epoch 882/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.8503 - val_loss: -175.0617\n",
      "\n",
      "Epoch 00882: loss did not improve from -170.01844\n",
      "Epoch 883/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -169.9281 - val_loss: -174.6955\n",
      "\n",
      "Epoch 00883: loss did not improve from -170.01844\n",
      "Epoch 884/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.0032 - val_loss: -175.0216\n",
      "\n",
      "Epoch 00884: loss did not improve from -170.01844\n",
      "Epoch 885/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.8334 - val_loss: -174.4869\n",
      "\n",
      "Epoch 00885: loss did not improve from -170.01844\n",
      "Epoch 886/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.0075 - val_loss: -175.0490\n",
      "\n",
      "Epoch 00886: loss did not improve from -170.01844\n",
      "Epoch 887/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.0370 - val_loss: -175.0507\n",
      "\n",
      "Epoch 00887: loss improved from -170.01844 to -170.03701, saving model to gendance.h5\n",
      "Epoch 888/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.9993 - val_loss: -175.0311\n",
      "\n",
      "Epoch 00888: loss did not improve from -170.03701\n",
      "Epoch 889/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.1300 - val_loss: -175.1969\n",
      "\n",
      "Epoch 00889: loss improved from -170.03701 to -170.13003, saving model to gendance.h5\n",
      "Epoch 890/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.8533 - val_loss: -174.9436\n",
      "\n",
      "Epoch 00890: loss did not improve from -170.13003\n",
      "Epoch 891/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.8714 - val_loss: -174.8485\n",
      "\n",
      "Epoch 00891: loss did not improve from -170.13003\n",
      "Epoch 892/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.1592 - val_loss: -175.0777\n",
      "\n",
      "Epoch 00892: loss improved from -170.13003 to -170.15919, saving model to gendance.h5\n",
      "Epoch 893/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.0246 - val_loss: -174.7774\n",
      "\n",
      "Epoch 00893: loss did not improve from -170.15919\n",
      "Epoch 894/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.0452 - val_loss: -175.1355\n",
      "\n",
      "Epoch 00894: loss did not improve from -170.15919\n",
      "Epoch 895/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.0612 - val_loss: -175.1261\n",
      "\n",
      "Epoch 00895: loss did not improve from -170.15919\n",
      "Epoch 896/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -169.9936 - val_loss: -174.9242\n",
      "\n",
      "Epoch 00896: loss did not improve from -170.15919\n",
      "Epoch 897/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -170.2134 - val_loss: -175.0513\n",
      "\n",
      "Epoch 00897: loss improved from -170.15919 to -170.21343, saving model to gendance.h5\n",
      "Epoch 898/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.2609 - val_loss: -174.9749\n",
      "\n",
      "Epoch 00898: loss improved from -170.21343 to -170.26095, saving model to gendance.h5\n",
      "Epoch 899/2000\n",
      "16017/16017 [==============================] - 1s 53us/step - loss: -170.0978 - val_loss: -174.9630\n",
      "\n",
      "Epoch 00899: loss did not improve from -170.26095\n",
      "Epoch 900/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.1784 - val_loss: -175.2109\n",
      "\n",
      "Epoch 00900: loss did not improve from -170.26095\n",
      "Epoch 901/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.2121 - val_loss: -174.7431\n",
      "\n",
      "Epoch 00901: loss did not improve from -170.26095\n",
      "Epoch 902/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -170.0406 - val_loss: -175.0466\n",
      "\n",
      "Epoch 00902: loss did not improve from -170.26095\n",
      "Epoch 903/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.3861 - val_loss: -175.5059\n",
      "\n",
      "Epoch 00903: loss improved from -170.26095 to -170.38608, saving model to gendance.h5\n",
      "Epoch 904/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.2595 - val_loss: -175.0265\n",
      "\n",
      "Epoch 00904: loss did not improve from -170.38608\n",
      "Epoch 905/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.0273 - val_loss: -175.4001\n",
      "\n",
      "Epoch 00905: loss did not improve from -170.38608\n",
      "Epoch 906/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.0351 - val_loss: -174.9145\n",
      "\n",
      "Epoch 00906: loss did not improve from -170.38608\n",
      "Epoch 907/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.2522 - val_loss: -175.2371\n",
      "\n",
      "Epoch 00907: loss did not improve from -170.38608\n",
      "Epoch 908/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.2168 - val_loss: -175.3556\n",
      "\n",
      "Epoch 00908: loss did not improve from -170.38608\n",
      "Epoch 909/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.2778 - val_loss: -175.0906\n",
      "\n",
      "Epoch 00909: loss did not improve from -170.38608\n",
      "Epoch 910/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.2022 - val_loss: -175.1436\n",
      "\n",
      "Epoch 00910: loss did not improve from -170.38608\n",
      "Epoch 911/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.3594 - val_loss: -175.4322\n",
      "\n",
      "Epoch 00911: loss did not improve from -170.38608\n",
      "Epoch 912/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.2122 - val_loss: -174.9741\n",
      "\n",
      "Epoch 00912: loss did not improve from -170.38608\n",
      "Epoch 913/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.4217 - val_loss: -175.1577\n",
      "\n",
      "Epoch 00913: loss improved from -170.38608 to -170.42165, saving model to gendance.h5\n",
      "Epoch 914/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.3161 - val_loss: -175.2667\n",
      "\n",
      "Epoch 00914: loss did not improve from -170.42165\n",
      "Epoch 915/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.1581 - val_loss: -175.4005\n",
      "\n",
      "Epoch 00915: loss did not improve from -170.42165\n",
      "Epoch 916/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.3612 - val_loss: -174.9984\n",
      "\n",
      "Epoch 00916: loss did not improve from -170.42165\n",
      "Epoch 917/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.1119 - val_loss: -175.1577\n",
      "\n",
      "Epoch 00917: loss did not improve from -170.42165\n",
      "Epoch 918/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.6392 - val_loss: -175.2644\n",
      "\n",
      "Epoch 00918: loss improved from -170.42165 to -170.63924, saving model to gendance.h5\n",
      "Epoch 919/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.2567 - val_loss: -175.2721\n",
      "\n",
      "Epoch 00919: loss did not improve from -170.63924\n",
      "Epoch 920/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.3529 - val_loss: -175.2261\n",
      "\n",
      "Epoch 00920: loss did not improve from -170.63924\n",
      "Epoch 921/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.3704 - val_loss: -175.4658\n",
      "\n",
      "Epoch 00921: loss did not improve from -170.63924\n",
      "Epoch 922/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.3683 - val_loss: -175.1863\n",
      "\n",
      "Epoch 00922: loss did not improve from -170.63924\n",
      "Epoch 923/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.3631 - val_loss: -175.2059\n",
      "\n",
      "Epoch 00923: loss did not improve from -170.63924\n",
      "Epoch 924/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.3213 - val_loss: -175.0655\n",
      "\n",
      "Epoch 00924: loss did not improve from -170.63924\n",
      "Epoch 925/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.4205 - val_loss: -175.5128\n",
      "\n",
      "Epoch 00925: loss did not improve from -170.63924\n",
      "Epoch 926/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.4229 - val_loss: -175.7048\n",
      "\n",
      "Epoch 00926: loss did not improve from -170.63924\n",
      "Epoch 927/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -170.4723 - val_loss: -175.3071\n",
      "\n",
      "Epoch 00927: loss did not improve from -170.63924\n",
      "Epoch 928/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.5673 - val_loss: -175.4916\n",
      "\n",
      "Epoch 00928: loss did not improve from -170.63924\n",
      "Epoch 929/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.3854 - val_loss: -175.3691\n",
      "\n",
      "Epoch 00929: loss did not improve from -170.63924\n",
      "Epoch 930/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.3145 - val_loss: -175.4333\n",
      "\n",
      "Epoch 00930: loss did not improve from -170.63924\n",
      "Epoch 931/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.6637 - val_loss: -176.0359\n",
      "\n",
      "Epoch 00931: loss improved from -170.63924 to -170.66373, saving model to gendance.h5\n",
      "Epoch 932/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.4409 - val_loss: -175.3302\n",
      "\n",
      "Epoch 00932: loss did not improve from -170.66373\n",
      "Epoch 933/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.6844 - val_loss: -175.8782\n",
      "\n",
      "Epoch 00933: loss improved from -170.66373 to -170.68438, saving model to gendance.h5\n",
      "Epoch 934/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.5851 - val_loss: -175.4264\n",
      "\n",
      "Epoch 00934: loss did not improve from -170.68438\n",
      "Epoch 935/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.4852 - val_loss: -175.2913\n",
      "\n",
      "Epoch 00935: loss did not improve from -170.68438\n",
      "Epoch 936/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.4903 - val_loss: -175.6081\n",
      "\n",
      "Epoch 00936: loss did not improve from -170.68438\n",
      "Epoch 937/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.5066 - val_loss: -175.7022\n",
      "\n",
      "Epoch 00937: loss did not improve from -170.68438\n",
      "Epoch 938/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.4271 - val_loss: -175.7337\n",
      "\n",
      "Epoch 00938: loss did not improve from -170.68438\n",
      "Epoch 939/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.6178 - val_loss: -175.3066\n",
      "\n",
      "Epoch 00939: loss did not improve from -170.68438\n",
      "Epoch 940/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.4764 - val_loss: -175.5032\n",
      "\n",
      "Epoch 00940: loss did not improve from -170.68438\n",
      "Epoch 941/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.4310 - val_loss: -175.8103\n",
      "\n",
      "Epoch 00941: loss did not improve from -170.68438\n",
      "Epoch 942/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.4057 - val_loss: -175.1506\n",
      "\n",
      "Epoch 00942: loss did not improve from -170.68438\n",
      "Epoch 943/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.6316 - val_loss: -175.6373\n",
      "\n",
      "Epoch 00943: loss did not improve from -170.68438\n",
      "Epoch 944/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.6226 - val_loss: -175.6506\n",
      "\n",
      "Epoch 00944: loss did not improve from -170.68438\n",
      "Epoch 945/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.5934 - val_loss: -175.4478\n",
      "\n",
      "Epoch 00945: loss did not improve from -170.68438\n",
      "Epoch 946/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.6454 - val_loss: -175.7027\n",
      "\n",
      "Epoch 00946: loss did not improve from -170.68438\n",
      "Epoch 947/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.7977 - val_loss: -175.7045\n",
      "\n",
      "Epoch 00947: loss improved from -170.68438 to -170.79768, saving model to gendance.h5\n",
      "Epoch 948/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.7190 - val_loss: -175.9696\n",
      "\n",
      "Epoch 00948: loss did not improve from -170.79768\n",
      "Epoch 949/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.6546 - val_loss: -175.9417\n",
      "\n",
      "Epoch 00949: loss did not improve from -170.79768\n",
      "Epoch 950/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.7087 - val_loss: -176.0177\n",
      "\n",
      "Epoch 00950: loss did not improve from -170.79768\n",
      "Epoch 951/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.7005 - val_loss: -176.0031\n",
      "\n",
      "Epoch 00951: loss did not improve from -170.79768\n",
      "Epoch 952/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -170.8487 - val_loss: -175.7913\n",
      "\n",
      "Epoch 00952: loss improved from -170.79768 to -170.84873, saving model to gendance.h5\n",
      "Epoch 953/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.8018 - val_loss: -175.5865\n",
      "\n",
      "Epoch 00953: loss did not improve from -170.84873\n",
      "Epoch 954/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.8074 - val_loss: -175.3883\n",
      "\n",
      "Epoch 00954: loss did not improve from -170.84873\n",
      "Epoch 955/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.6121 - val_loss: -175.5970\n",
      "\n",
      "Epoch 00955: loss did not improve from -170.84873\n",
      "Epoch 956/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -170.7376 - val_loss: -175.6136\n",
      "\n",
      "Epoch 00956: loss did not improve from -170.84873\n",
      "Epoch 957/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.7052 - val_loss: -175.7240\n",
      "\n",
      "Epoch 00957: loss did not improve from -170.84873\n",
      "Epoch 958/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.6732 - val_loss: -176.0159\n",
      "\n",
      "Epoch 00958: loss did not improve from -170.84873\n",
      "Epoch 959/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.6286 - val_loss: -175.8096\n",
      "\n",
      "Epoch 00959: loss did not improve from -170.84873\n",
      "Epoch 960/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.9167 - val_loss: -175.6842\n",
      "\n",
      "Epoch 00960: loss improved from -170.84873 to -170.91671, saving model to gendance.h5\n",
      "Epoch 961/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.7760 - val_loss: -175.9087\n",
      "\n",
      "Epoch 00961: loss did not improve from -170.91671\n",
      "Epoch 962/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.8545 - val_loss: -175.7988\n",
      "\n",
      "Epoch 00962: loss did not improve from -170.91671\n",
      "Epoch 963/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.8509 - val_loss: -175.8961\n",
      "\n",
      "Epoch 00963: loss did not improve from -170.91671\n",
      "Epoch 964/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.8907 - val_loss: -175.6828\n",
      "\n",
      "Epoch 00964: loss did not improve from -170.91671\n",
      "Epoch 965/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.8130 - val_loss: -176.0145\n",
      "\n",
      "Epoch 00965: loss did not improve from -170.91671\n",
      "Epoch 966/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -170.8526 - val_loss: -175.6125\n",
      "\n",
      "Epoch 00966: loss did not improve from -170.91671\n",
      "Epoch 967/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.7545 - val_loss: -175.4616\n",
      "\n",
      "Epoch 00967: loss did not improve from -170.91671\n",
      "Epoch 968/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.7223 - val_loss: -175.9901\n",
      "\n",
      "Epoch 00968: loss did not improve from -170.91671\n",
      "Epoch 969/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.0576 - val_loss: -175.6502\n",
      "\n",
      "Epoch 00969: loss improved from -170.91671 to -171.05757, saving model to gendance.h5\n",
      "Epoch 970/2000\n",
      "16017/16017 [==============================] - 1s 54us/step - loss: -170.9093 - val_loss: -175.7072\n",
      "\n",
      "Epoch 00970: loss did not improve from -171.05757\n",
      "Epoch 971/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.7591 - val_loss: -175.9995\n",
      "\n",
      "Epoch 00971: loss did not improve from -171.05757\n",
      "Epoch 972/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.8089 - val_loss: -176.0936\n",
      "\n",
      "Epoch 00972: loss did not improve from -171.05757\n",
      "Epoch 973/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.9281 - val_loss: -175.6912\n",
      "\n",
      "Epoch 00973: loss did not improve from -171.05757\n",
      "Epoch 974/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.8826 - val_loss: -176.1234\n",
      "\n",
      "Epoch 00974: loss did not improve from -171.05757\n",
      "Epoch 975/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.0562 - val_loss: -176.1416\n",
      "\n",
      "Epoch 00975: loss did not improve from -171.05757\n",
      "Epoch 976/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.7894 - val_loss: -175.9715\n",
      "\n",
      "Epoch 00976: loss did not improve from -171.05757\n",
      "Epoch 977/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.9455 - val_loss: -175.9127\n",
      "\n",
      "Epoch 00977: loss did not improve from -171.05757\n",
      "Epoch 978/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.0354 - val_loss: -175.7895\n",
      "\n",
      "Epoch 00978: loss did not improve from -171.05757\n",
      "Epoch 979/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.9985 - val_loss: -176.0809\n",
      "\n",
      "Epoch 00979: loss did not improve from -171.05757\n",
      "Epoch 980/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.7485 - val_loss: -175.6271\n",
      "\n",
      "Epoch 00980: loss did not improve from -171.05757\n",
      "Epoch 981/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -171.1103 - val_loss: -176.0961\n",
      "\n",
      "Epoch 00981: loss improved from -171.05757 to -171.11027, saving model to gendance.h5\n",
      "Epoch 982/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.8472 - val_loss: -175.3528\n",
      "\n",
      "Epoch 00982: loss did not improve from -171.11027\n",
      "Epoch 983/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -171.0382 - val_loss: -176.1557\n",
      "\n",
      "Epoch 00983: loss did not improve from -171.11027\n",
      "Epoch 984/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.9832 - val_loss: -175.8780\n",
      "\n",
      "Epoch 00984: loss did not improve from -171.11027\n",
      "Epoch 985/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.1107 - val_loss: -175.9152\n",
      "\n",
      "Epoch 00985: loss improved from -171.11027 to -171.11068, saving model to gendance.h5\n",
      "Epoch 986/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.9557 - val_loss: -176.1779\n",
      "\n",
      "Epoch 00986: loss did not improve from -171.11068\n",
      "Epoch 987/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.0982 - val_loss: -176.1792\n",
      "\n",
      "Epoch 00987: loss did not improve from -171.11068\n",
      "Epoch 988/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.2112 - val_loss: -176.0243\n",
      "\n",
      "Epoch 00988: loss improved from -171.11068 to -171.21122, saving model to gendance.h5\n",
      "Epoch 989/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.1865 - val_loss: -175.8034\n",
      "\n",
      "Epoch 00989: loss did not improve from -171.21122\n",
      "Epoch 990/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -171.0899 - val_loss: -176.3112\n",
      "\n",
      "Epoch 00990: loss did not improve from -171.21122\n",
      "Epoch 991/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.1533 - val_loss: -176.2048\n",
      "\n",
      "Epoch 00991: loss did not improve from -171.21122\n",
      "Epoch 992/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.0139 - val_loss: -176.2433\n",
      "\n",
      "Epoch 00992: loss did not improve from -171.21122\n",
      "Epoch 993/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -170.9409 - val_loss: -176.2331\n",
      "\n",
      "Epoch 00993: loss did not improve from -171.21122\n",
      "Epoch 994/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.0221 - val_loss: -176.0965\n",
      "\n",
      "Epoch 00994: loss did not improve from -171.21122\n",
      "Epoch 995/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.1533 - val_loss: -176.0570\n",
      "\n",
      "Epoch 00995: loss did not improve from -171.21122\n",
      "Epoch 996/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.0760 - val_loss: -176.3855\n",
      "\n",
      "Epoch 00996: loss did not improve from -171.21122\n",
      "Epoch 997/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.2306 - val_loss: -176.3530\n",
      "\n",
      "Epoch 00997: loss improved from -171.21122 to -171.23056, saving model to gendance.h5\n",
      "Epoch 998/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.1040 - val_loss: -175.8736\n",
      "\n",
      "Epoch 00998: loss did not improve from -171.23056\n",
      "Epoch 999/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.0268 - val_loss: -176.2536\n",
      "\n",
      "Epoch 00999: loss did not improve from -171.23056\n",
      "Epoch 1000/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.1112 - val_loss: -176.4445\n",
      "\n",
      "Epoch 01000: loss did not improve from -171.23056\n",
      "Epoch 1001/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.4568 - val_loss: -176.5379\n",
      "\n",
      "Epoch 01001: loss improved from -171.23056 to -171.45684, saving model to gendance.h5\n",
      "Epoch 1002/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.1108 - val_loss: -175.9849\n",
      "\n",
      "Epoch 01002: loss did not improve from -171.45684\n",
      "Epoch 1003/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.2248 - val_loss: -176.3657\n",
      "\n",
      "Epoch 01003: loss did not improve from -171.45684\n",
      "Epoch 1004/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.1190 - val_loss: -176.1882\n",
      "\n",
      "Epoch 01004: loss did not improve from -171.45684\n",
      "Epoch 1005/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.2864 - val_loss: -176.3646\n",
      "\n",
      "Epoch 01005: loss did not improve from -171.45684\n",
      "Epoch 1006/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.0540 - val_loss: -175.9864\n",
      "\n",
      "Epoch 01006: loss did not improve from -171.45684\n",
      "Epoch 1007/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.1580 - val_loss: -176.2064\n",
      "\n",
      "Epoch 01007: loss did not improve from -171.45684\n",
      "Epoch 1008/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.0422 - val_loss: -176.2235\n",
      "\n",
      "Epoch 01008: loss did not improve from -171.45684\n",
      "Epoch 1009/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.0874 - val_loss: -176.2552\n",
      "\n",
      "Epoch 01009: loss did not improve from -171.45684\n",
      "Epoch 1010/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.1455 - val_loss: -176.9860\n",
      "\n",
      "Epoch 01010: loss did not improve from -171.45684\n",
      "Epoch 1011/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.5414 - val_loss: -176.4361\n",
      "\n",
      "Epoch 01011: loss improved from -171.45684 to -171.54144, saving model to gendance.h5\n",
      "Epoch 1012/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.2612 - val_loss: -176.2175\n",
      "\n",
      "Epoch 01012: loss did not improve from -171.54144\n",
      "Epoch 1013/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.4540 - val_loss: -176.3772\n",
      "\n",
      "Epoch 01013: loss did not improve from -171.54144\n",
      "Epoch 1014/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.2299 - val_loss: -176.3530\n",
      "\n",
      "Epoch 01014: loss did not improve from -171.54144\n",
      "Epoch 1015/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.3673 - val_loss: -176.5947\n",
      "\n",
      "Epoch 01015: loss did not improve from -171.54144\n",
      "Epoch 1016/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.2319 - val_loss: -176.7622\n",
      "\n",
      "Epoch 01016: loss did not improve from -171.54144\n",
      "Epoch 1017/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.3934 - val_loss: -176.3900\n",
      "\n",
      "Epoch 01017: loss did not improve from -171.54144\n",
      "Epoch 1018/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.5994 - val_loss: -176.7095\n",
      "\n",
      "Epoch 01018: loss improved from -171.54144 to -171.59940, saving model to gendance.h5\n",
      "Epoch 1019/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.4677 - val_loss: -176.6559\n",
      "\n",
      "Epoch 01019: loss did not improve from -171.59940\n",
      "Epoch 1020/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.1642 - val_loss: -176.2911\n",
      "\n",
      "Epoch 01020: loss did not improve from -171.59940\n",
      "Epoch 1021/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.4012 - val_loss: -176.1980\n",
      "\n",
      "Epoch 01021: loss did not improve from -171.59940\n",
      "Epoch 1022/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.5342 - val_loss: -176.7206\n",
      "\n",
      "Epoch 01022: loss did not improve from -171.59940\n",
      "Epoch 1023/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.2883 - val_loss: -176.5499\n",
      "\n",
      "Epoch 01023: loss did not improve from -171.59940\n",
      "Epoch 1024/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.6341 - val_loss: -176.6656\n",
      "\n",
      "Epoch 01024: loss improved from -171.59940 to -171.63413, saving model to gendance.h5\n",
      "Epoch 1025/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.3067 - val_loss: -176.4745\n",
      "\n",
      "Epoch 01025: loss did not improve from -171.63413\n",
      "Epoch 1026/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.4438 - val_loss: -176.6498\n",
      "\n",
      "Epoch 01026: loss did not improve from -171.63413\n",
      "Epoch 1027/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.3933 - val_loss: -176.4391\n",
      "\n",
      "Epoch 01027: loss did not improve from -171.63413\n",
      "Epoch 1028/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.3604 - val_loss: -176.6931\n",
      "\n",
      "Epoch 01028: loss did not improve from -171.63413\n",
      "Epoch 1029/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.4353 - val_loss: -176.3425\n",
      "\n",
      "Epoch 01029: loss did not improve from -171.63413\n",
      "Epoch 1030/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -171.2983 - val_loss: -176.0316\n",
      "\n",
      "Epoch 01030: loss did not improve from -171.63413\n",
      "Epoch 1031/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.3108 - val_loss: -176.7927\n",
      "\n",
      "Epoch 01031: loss did not improve from -171.63413\n",
      "Epoch 1032/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.6807 - val_loss: -176.6114\n",
      "\n",
      "Epoch 01032: loss improved from -171.63413 to -171.68069, saving model to gendance.h5\n",
      "Epoch 1033/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.5454 - val_loss: -176.6783\n",
      "\n",
      "Epoch 01033: loss did not improve from -171.68069\n",
      "Epoch 1034/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.5009 - val_loss: -176.7308\n",
      "\n",
      "Epoch 01034: loss did not improve from -171.68069\n",
      "Epoch 1035/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.3350 - val_loss: -176.4812\n",
      "\n",
      "Epoch 01035: loss did not improve from -171.68069\n",
      "Epoch 1036/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.5397 - val_loss: -176.5376\n",
      "\n",
      "Epoch 01036: loss did not improve from -171.68069\n",
      "Epoch 1037/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.5551 - val_loss: -176.3444\n",
      "\n",
      "Epoch 01037: loss did not improve from -171.68069\n",
      "Epoch 1038/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -171.4790 - val_loss: -176.8381\n",
      "\n",
      "Epoch 01038: loss did not improve from -171.68069\n",
      "Epoch 1039/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.4617 - val_loss: -177.0704\n",
      "\n",
      "Epoch 01039: loss did not improve from -171.68069\n",
      "Epoch 1040/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.3792 - val_loss: -176.6494\n",
      "\n",
      "Epoch 01040: loss did not improve from -171.68069\n",
      "Epoch 1041/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.4063 - val_loss: -176.7889\n",
      "\n",
      "Epoch 01041: loss did not improve from -171.68069\n",
      "Epoch 1042/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.5982 - val_loss: -176.4939\n",
      "\n",
      "Epoch 01042: loss did not improve from -171.68069\n",
      "Epoch 1043/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.5251 - val_loss: -176.7811\n",
      "\n",
      "Epoch 01043: loss did not improve from -171.68069\n",
      "Epoch 1044/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.6980 - val_loss: -176.8199\n",
      "\n",
      "Epoch 01044: loss improved from -171.68069 to -171.69803, saving model to gendance.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1045/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.8499 - val_loss: -176.9553\n",
      "\n",
      "Epoch 01045: loss improved from -171.69803 to -171.84988, saving model to gendance.h5\n",
      "Epoch 1046/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.5226 - val_loss: -176.8500\n",
      "\n",
      "Epoch 01046: loss did not improve from -171.84988\n",
      "Epoch 1047/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.5852 - val_loss: -176.4833\n",
      "\n",
      "Epoch 01047: loss did not improve from -171.84988\n",
      "Epoch 1048/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.5619 - val_loss: -177.0008\n",
      "\n",
      "Epoch 01048: loss did not improve from -171.84988\n",
      "Epoch 1049/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.6659 - val_loss: -177.2781\n",
      "\n",
      "Epoch 01049: loss did not improve from -171.84988\n",
      "Epoch 1050/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.5694 - val_loss: -176.4658\n",
      "\n",
      "Epoch 01050: loss did not improve from -171.84988\n",
      "Epoch 1051/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.4128 - val_loss: -176.7489\n",
      "\n",
      "Epoch 01051: loss did not improve from -171.84988\n",
      "Epoch 1052/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.4726 - val_loss: -176.9798\n",
      "\n",
      "Epoch 01052: loss did not improve from -171.84988\n",
      "Epoch 1053/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -171.5486 - val_loss: -176.6791\n",
      "\n",
      "Epoch 01053: loss did not improve from -171.84988\n",
      "Epoch 1054/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.8616 - val_loss: -176.9176\n",
      "\n",
      "Epoch 01054: loss improved from -171.84988 to -171.86164, saving model to gendance.h5\n",
      "Epoch 1055/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.7197 - val_loss: -176.6719\n",
      "\n",
      "Epoch 01055: loss did not improve from -171.86164\n",
      "Epoch 1056/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.5445 - val_loss: -176.9996\n",
      "\n",
      "Epoch 01056: loss did not improve from -171.86164\n",
      "Epoch 1057/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.4928 - val_loss: -176.7112\n",
      "\n",
      "Epoch 01057: loss did not improve from -171.86164\n",
      "Epoch 1058/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.6281 - val_loss: -176.6689\n",
      "\n",
      "Epoch 01058: loss did not improve from -171.86164\n",
      "Epoch 1059/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.8034 - val_loss: -176.7794\n",
      "\n",
      "Epoch 01059: loss did not improve from -171.86164\n",
      "Epoch 1060/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -171.7260 - val_loss: -176.8303\n",
      "\n",
      "Epoch 01060: loss did not improve from -171.86164\n",
      "Epoch 1061/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.7151 - val_loss: -176.9069\n",
      "\n",
      "Epoch 01061: loss did not improve from -171.86164\n",
      "Epoch 1062/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.8403 - val_loss: -176.7941\n",
      "\n",
      "Epoch 01062: loss did not improve from -171.86164\n",
      "Epoch 1063/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.7302 - val_loss: -176.6595\n",
      "\n",
      "Epoch 01063: loss did not improve from -171.86164\n",
      "Epoch 1064/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.7421 - val_loss: -177.0354\n",
      "\n",
      "Epoch 01064: loss did not improve from -171.86164\n",
      "Epoch 1065/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.6268 - val_loss: -176.7759\n",
      "\n",
      "Epoch 01065: loss did not improve from -171.86164\n",
      "Epoch 1066/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.9517 - val_loss: -176.8802\n",
      "\n",
      "Epoch 01066: loss improved from -171.86164 to -171.95167, saving model to gendance.h5\n",
      "Epoch 1067/2000\n",
      "16017/16017 [==============================] - 1s 54us/step - loss: -171.6908 - val_loss: -176.7629\n",
      "\n",
      "Epoch 01067: loss did not improve from -171.95167\n",
      "Epoch 1068/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.6612 - val_loss: -177.0368\n",
      "\n",
      "Epoch 01068: loss did not improve from -171.95167\n",
      "Epoch 1069/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.9345 - val_loss: -177.0635\n",
      "\n",
      "Epoch 01069: loss did not improve from -171.95167\n",
      "Epoch 1070/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.8204 - val_loss: -176.9306\n",
      "\n",
      "Epoch 01070: loss did not improve from -171.95167\n",
      "Epoch 1071/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.6997 - val_loss: -176.9339\n",
      "\n",
      "Epoch 01071: loss did not improve from -171.95167\n",
      "Epoch 1072/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.8557 - val_loss: -176.7468\n",
      "\n",
      "Epoch 01072: loss did not improve from -171.95167\n",
      "Epoch 1073/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.8435 - val_loss: -177.2155\n",
      "\n",
      "Epoch 01073: loss did not improve from -171.95167\n",
      "Epoch 1074/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.0762 - val_loss: -177.2934\n",
      "\n",
      "Epoch 01074: loss improved from -171.95167 to -172.07619, saving model to gendance.h5\n",
      "Epoch 1075/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.1714 - val_loss: -177.0564\n",
      "\n",
      "Epoch 01075: loss improved from -172.07619 to -172.17139, saving model to gendance.h5\n",
      "Epoch 1076/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.8720 - val_loss: -177.1269\n",
      "\n",
      "Epoch 01076: loss did not improve from -172.17139\n",
      "Epoch 1077/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.0425 - val_loss: -176.9828\n",
      "\n",
      "Epoch 01077: loss did not improve from -172.17139\n",
      "Epoch 1078/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -171.8685 - val_loss: -176.9862\n",
      "\n",
      "Epoch 01078: loss did not improve from -172.17139\n",
      "Epoch 1079/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.9957 - val_loss: -177.2211\n",
      "\n",
      "Epoch 01079: loss did not improve from -172.17139\n",
      "Epoch 1080/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.8683 - val_loss: -176.7625\n",
      "\n",
      "Epoch 01080: loss did not improve from -172.17139\n",
      "Epoch 1081/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.6360 - val_loss: -177.2404\n",
      "\n",
      "Epoch 01081: loss did not improve from -172.17139\n",
      "Epoch 1082/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.8196 - val_loss: -176.8818\n",
      "\n",
      "Epoch 01082: loss did not improve from -172.17139\n",
      "Epoch 1083/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.6287 - val_loss: -177.0137\n",
      "\n",
      "Epoch 01083: loss did not improve from -172.17139\n",
      "Epoch 1084/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -171.9752 - val_loss: -176.8443\n",
      "\n",
      "Epoch 01084: loss did not improve from -172.17139\n",
      "Epoch 1085/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.8246 - val_loss: -177.0637\n",
      "\n",
      "Epoch 01085: loss did not improve from -172.17139\n",
      "Epoch 1086/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.9302 - val_loss: -177.1282\n",
      "\n",
      "Epoch 01086: loss did not improve from -172.17139\n",
      "Epoch 1087/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.0959 - val_loss: -177.1188\n",
      "\n",
      "Epoch 01087: loss did not improve from -172.17139\n",
      "Epoch 1088/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -172.1015 - val_loss: -177.2585\n",
      "\n",
      "Epoch 01088: loss did not improve from -172.17139\n",
      "Epoch 1089/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.0534 - val_loss: -176.8859\n",
      "\n",
      "Epoch 01089: loss did not improve from -172.17139\n",
      "Epoch 1090/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.7162 - val_loss: -177.0292\n",
      "\n",
      "Epoch 01090: loss did not improve from -172.17139\n",
      "Epoch 1091/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.0423 - val_loss: -177.1856\n",
      "\n",
      "Epoch 01091: loss did not improve from -172.17139\n",
      "Epoch 1092/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.9312 - val_loss: -177.0590\n",
      "\n",
      "Epoch 01092: loss did not improve from -172.17139\n",
      "Epoch 1093/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.9690 - val_loss: -177.1999\n",
      "\n",
      "Epoch 01093: loss did not improve from -172.17139\n",
      "Epoch 1094/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.1490 - val_loss: -176.9806\n",
      "\n",
      "Epoch 01094: loss did not improve from -172.17139\n",
      "Epoch 1095/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.0414 - val_loss: -176.9756\n",
      "\n",
      "Epoch 01095: loss did not improve from -172.17139\n",
      "Epoch 1096/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.9274 - val_loss: -177.0458\n",
      "\n",
      "Epoch 01096: loss did not improve from -172.17139\n",
      "Epoch 1097/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -172.1530 - val_loss: -177.1165\n",
      "\n",
      "Epoch 01097: loss did not improve from -172.17139\n",
      "Epoch 1098/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.9956 - val_loss: -176.8696\n",
      "\n",
      "Epoch 01098: loss did not improve from -172.17139\n",
      "Epoch 1099/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.0755 - val_loss: -177.2669\n",
      "\n",
      "Epoch 01099: loss did not improve from -172.17139\n",
      "Epoch 1100/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -172.0014 - val_loss: -177.1077\n",
      "\n",
      "Epoch 01100: loss did not improve from -172.17139\n",
      "Epoch 1101/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.0092 - val_loss: -176.9791\n",
      "\n",
      "Epoch 01101: loss did not improve from -172.17139\n",
      "Epoch 1102/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.1064 - val_loss: -176.9335\n",
      "\n",
      "Epoch 01102: loss did not improve from -172.17139\n",
      "Epoch 1103/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.9941 - val_loss: -176.9239\n",
      "\n",
      "Epoch 01103: loss did not improve from -172.17139\n",
      "Epoch 1104/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.1755 - val_loss: -177.3375\n",
      "\n",
      "Epoch 01104: loss improved from -172.17139 to -172.17546, saving model to gendance.h5\n",
      "Epoch 1105/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.0826 - val_loss: -177.2699\n",
      "\n",
      "Epoch 01105: loss did not improve from -172.17546\n",
      "Epoch 1106/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.0981 - val_loss: -177.4595\n",
      "\n",
      "Epoch 01106: loss did not improve from -172.17546\n",
      "Epoch 1107/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -171.9931 - val_loss: -176.7879\n",
      "\n",
      "Epoch 01107: loss did not improve from -172.17546\n",
      "Epoch 1108/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -172.2437 - val_loss: -176.9898\n",
      "\n",
      "Epoch 01108: loss improved from -172.17546 to -172.24371, saving model to gendance.h5\n",
      "Epoch 1109/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.1482 - val_loss: -177.4756\n",
      "\n",
      "Epoch 01109: loss did not improve from -172.24371\n",
      "Epoch 1110/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.2115 - val_loss: -176.7301\n",
      "\n",
      "Epoch 01110: loss did not improve from -172.24371\n",
      "Epoch 1111/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.1485 - val_loss: -177.4806\n",
      "\n",
      "Epoch 01111: loss did not improve from -172.24371\n",
      "Epoch 1112/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.2290 - val_loss: -177.1583\n",
      "\n",
      "Epoch 01112: loss did not improve from -172.24371\n",
      "Epoch 1113/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.4483 - val_loss: -177.0058\n",
      "\n",
      "Epoch 01113: loss improved from -172.24371 to -172.44834, saving model to gendance.h5\n",
      "Epoch 1114/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.2772 - val_loss: -177.2047\n",
      "\n",
      "Epoch 01114: loss did not improve from -172.44834\n",
      "Epoch 1115/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.1035 - val_loss: -177.0259\n",
      "\n",
      "Epoch 01115: loss did not improve from -172.44834\n",
      "Epoch 1116/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.2205 - val_loss: -177.1621\n",
      "\n",
      "Epoch 01116: loss did not improve from -172.44834\n",
      "Epoch 1117/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.1741 - val_loss: -177.0811\n",
      "\n",
      "Epoch 01117: loss did not improve from -172.44834\n",
      "Epoch 1118/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.1210 - val_loss: -177.1466\n",
      "\n",
      "Epoch 01118: loss did not improve from -172.44834\n",
      "Epoch 1119/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.3054 - val_loss: -177.1818\n",
      "\n",
      "Epoch 01119: loss did not improve from -172.44834\n",
      "Epoch 1120/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.1822 - val_loss: -177.1997\n",
      "\n",
      "Epoch 01120: loss did not improve from -172.44834\n",
      "Epoch 1121/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.2751 - val_loss: -177.1637\n",
      "\n",
      "Epoch 01121: loss did not improve from -172.44834\n",
      "Epoch 1122/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.2304 - val_loss: -177.1880\n",
      "\n",
      "Epoch 01122: loss did not improve from -172.44834\n",
      "Epoch 1123/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.3186 - val_loss: -177.5261\n",
      "\n",
      "Epoch 01123: loss did not improve from -172.44834\n",
      "Epoch 1124/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.3391 - val_loss: -177.4991\n",
      "\n",
      "Epoch 01124: loss did not improve from -172.44834\n",
      "Epoch 1125/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.2259 - val_loss: -177.1167\n",
      "\n",
      "Epoch 01125: loss did not improve from -172.44834\n",
      "Epoch 1126/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.1636 - val_loss: -177.5498\n",
      "\n",
      "Epoch 01126: loss did not improve from -172.44834\n",
      "Epoch 1127/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.2445 - val_loss: -176.9789\n",
      "\n",
      "Epoch 01127: loss did not improve from -172.44834\n",
      "Epoch 1128/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.2174 - val_loss: -177.4276\n",
      "\n",
      "Epoch 01128: loss did not improve from -172.44834\n",
      "Epoch 1129/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.4052 - val_loss: -177.2581\n",
      "\n",
      "Epoch 01129: loss did not improve from -172.44834\n",
      "Epoch 1130/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.3354 - val_loss: -177.2514\n",
      "\n",
      "Epoch 01130: loss did not improve from -172.44834\n",
      "Epoch 1131/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.2408 - val_loss: -177.5366\n",
      "\n",
      "Epoch 01131: loss did not improve from -172.44834\n",
      "Epoch 1132/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.2206 - val_loss: -177.4037\n",
      "\n",
      "Epoch 01132: loss did not improve from -172.44834\n",
      "Epoch 1133/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.2788 - val_loss: -177.4525\n",
      "\n",
      "Epoch 01133: loss did not improve from -172.44834\n",
      "Epoch 1134/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -172.5924 - val_loss: -177.5004\n",
      "\n",
      "Epoch 01134: loss improved from -172.44834 to -172.59239, saving model to gendance.h5\n",
      "Epoch 1135/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.3213 - val_loss: -177.2916\n",
      "\n",
      "Epoch 01135: loss did not improve from -172.59239\n",
      "Epoch 1136/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.4533 - val_loss: -177.5389\n",
      "\n",
      "Epoch 01136: loss did not improve from -172.59239\n",
      "Epoch 1137/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.6353 - val_loss: -177.6010\n",
      "\n",
      "Epoch 01137: loss improved from -172.59239 to -172.63533, saving model to gendance.h5\n",
      "Epoch 1138/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.3485 - val_loss: -177.0054\n",
      "\n",
      "Epoch 01138: loss did not improve from -172.63533\n",
      "Epoch 1139/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.1224 - val_loss: -177.3754\n",
      "\n",
      "Epoch 01139: loss did not improve from -172.63533\n",
      "Epoch 1140/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.3823 - val_loss: -177.7210\n",
      "\n",
      "Epoch 01140: loss did not improve from -172.63533\n",
      "Epoch 1141/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.4438 - val_loss: -177.3337\n",
      "\n",
      "Epoch 01141: loss did not improve from -172.63533\n",
      "Epoch 1142/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.2324 - val_loss: -177.4592\n",
      "\n",
      "Epoch 01142: loss did not improve from -172.63533\n",
      "Epoch 1143/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.5037 - val_loss: -177.3353\n",
      "\n",
      "Epoch 01143: loss did not improve from -172.63533\n",
      "Epoch 1144/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -172.3075 - val_loss: -177.5752\n",
      "\n",
      "Epoch 01144: loss did not improve from -172.63533\n",
      "Epoch 1145/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -172.3507 - val_loss: -177.5332\n",
      "\n",
      "Epoch 01145: loss did not improve from -172.63533\n",
      "Epoch 1146/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.2522 - val_loss: -177.3411\n",
      "\n",
      "Epoch 01146: loss did not improve from -172.63533\n",
      "Epoch 1147/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.4528 - val_loss: -177.5362\n",
      "\n",
      "Epoch 01147: loss did not improve from -172.63533\n",
      "Epoch 1148/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.4916 - val_loss: -177.4254\n",
      "\n",
      "Epoch 01148: loss did not improve from -172.63533\n",
      "Epoch 1149/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.4659 - val_loss: -177.6397\n",
      "\n",
      "Epoch 01149: loss did not improve from -172.63533\n",
      "Epoch 1150/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.5480 - val_loss: -177.4671\n",
      "\n",
      "Epoch 01150: loss did not improve from -172.63533\n",
      "Epoch 1151/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.4790 - val_loss: -177.6243\n",
      "\n",
      "Epoch 01151: loss did not improve from -172.63533\n",
      "Epoch 1152/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.5168 - val_loss: -177.7092\n",
      "\n",
      "Epoch 01152: loss did not improve from -172.63533\n",
      "Epoch 1153/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.7432 - val_loss: -177.5311\n",
      "\n",
      "Epoch 01153: loss improved from -172.63533 to -172.74321, saving model to gendance.h5\n",
      "Epoch 1154/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.4385 - val_loss: -177.6477\n",
      "\n",
      "Epoch 01154: loss did not improve from -172.74321\n",
      "Epoch 1155/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.4315 - val_loss: -177.4026\n",
      "\n",
      "Epoch 01155: loss did not improve from -172.74321\n",
      "Epoch 1156/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.3773 - val_loss: -177.9994\n",
      "\n",
      "Epoch 01156: loss did not improve from -172.74321\n",
      "Epoch 1157/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.2655 - val_loss: -177.2584\n",
      "\n",
      "Epoch 01157: loss did not improve from -172.74321\n",
      "Epoch 1158/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.5003 - val_loss: -178.0092\n",
      "\n",
      "Epoch 01158: loss did not improve from -172.74321\n",
      "Epoch 1159/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.5469 - val_loss: -177.4779\n",
      "\n",
      "Epoch 01159: loss did not improve from -172.74321\n",
      "Epoch 1160/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.3105 - val_loss: -177.4736\n",
      "\n",
      "Epoch 01160: loss did not improve from -172.74321\n",
      "Epoch 1161/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -172.7006 - val_loss: -177.5232\n",
      "\n",
      "Epoch 01161: loss did not improve from -172.74321\n",
      "Epoch 1162/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.6192 - val_loss: -177.6318\n",
      "\n",
      "Epoch 01162: loss did not improve from -172.74321\n",
      "Epoch 1163/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.5154 - val_loss: -177.4903\n",
      "\n",
      "Epoch 01163: loss did not improve from -172.74321\n",
      "Epoch 1164/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -172.4856 - val_loss: -177.3738\n",
      "\n",
      "Epoch 01164: loss did not improve from -172.74321\n",
      "Epoch 1165/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.5367 - val_loss: -177.6894\n",
      "\n",
      "Epoch 01165: loss did not improve from -172.74321\n",
      "Epoch 1166/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.5010 - val_loss: -177.2535\n",
      "\n",
      "Epoch 01166: loss did not improve from -172.74321\n",
      "Epoch 1167/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.2716 - val_loss: -177.5369\n",
      "\n",
      "Epoch 01167: loss did not improve from -172.74321\n",
      "Epoch 1168/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.7958 - val_loss: -177.6325\n",
      "\n",
      "Epoch 01168: loss improved from -172.74321 to -172.79584, saving model to gendance.h5\n",
      "Epoch 1169/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.6478 - val_loss: -177.5845\n",
      "\n",
      "Epoch 01169: loss did not improve from -172.79584\n",
      "Epoch 1170/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.5236 - val_loss: -177.3629\n",
      "\n",
      "Epoch 01170: loss did not improve from -172.79584\n",
      "Epoch 1171/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.6475 - val_loss: -177.6229\n",
      "\n",
      "Epoch 01171: loss did not improve from -172.79584\n",
      "Epoch 1172/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.6358 - val_loss: -177.8267\n",
      "\n",
      "Epoch 01172: loss did not improve from -172.79584\n",
      "Epoch 1173/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.4101 - val_loss: -177.5110\n",
      "\n",
      "Epoch 01173: loss did not improve from -172.79584\n",
      "Epoch 1174/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.6077 - val_loss: -177.5329\n",
      "\n",
      "Epoch 01174: loss did not improve from -172.79584\n",
      "Epoch 1175/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.6840 - val_loss: -177.7963\n",
      "\n",
      "Epoch 01175: loss did not improve from -172.79584\n",
      "Epoch 1176/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.5609 - val_loss: -177.4147\n",
      "\n",
      "Epoch 01176: loss did not improve from -172.79584\n",
      "Epoch 1177/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.5228 - val_loss: -177.9448\n",
      "\n",
      "Epoch 01177: loss did not improve from -172.79584\n",
      "Epoch 1178/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.8205 - val_loss: -178.0314\n",
      "\n",
      "Epoch 01178: loss improved from -172.79584 to -172.82052, saving model to gendance.h5\n",
      "Epoch 1179/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.5229 - val_loss: -177.4306\n",
      "\n",
      "Epoch 01179: loss did not improve from -172.82052\n",
      "Epoch 1180/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.8514 - val_loss: -177.8240\n",
      "\n",
      "Epoch 01180: loss improved from -172.82052 to -172.85136, saving model to gendance.h5\n",
      "Epoch 1181/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.6669 - val_loss: -177.6744\n",
      "\n",
      "Epoch 01181: loss did not improve from -172.85136\n",
      "Epoch 1182/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.6680 - val_loss: -177.2571\n",
      "\n",
      "Epoch 01182: loss did not improve from -172.85136\n",
      "Epoch 1183/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -172.6703 - val_loss: -178.0243\n",
      "\n",
      "Epoch 01183: loss did not improve from -172.85136\n",
      "Epoch 1184/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.6329 - val_loss: -177.8317\n",
      "\n",
      "Epoch 01184: loss did not improve from -172.85136\n",
      "Epoch 1185/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.8798 - val_loss: -177.9625\n",
      "\n",
      "Epoch 01185: loss improved from -172.85136 to -172.87976, saving model to gendance.h5\n",
      "Epoch 1186/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.6182 - val_loss: -177.6972\n",
      "\n",
      "Epoch 01186: loss did not improve from -172.87976\n",
      "Epoch 1187/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.7103 - val_loss: -177.7465\n",
      "\n",
      "Epoch 01187: loss did not improve from -172.87976\n",
      "Epoch 1188/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.8211 - val_loss: -177.6194\n",
      "\n",
      "Epoch 01188: loss did not improve from -172.87976\n",
      "Epoch 1189/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.5555 - val_loss: -177.8426\n",
      "\n",
      "Epoch 01189: loss did not improve from -172.87976\n",
      "Epoch 1190/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.8029 - val_loss: -177.3800\n",
      "\n",
      "Epoch 01190: loss did not improve from -172.87976\n",
      "Epoch 1191/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.7742 - val_loss: -177.8818\n",
      "\n",
      "Epoch 01191: loss did not improve from -172.87976\n",
      "Epoch 1192/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.7723 - val_loss: -177.8232\n",
      "\n",
      "Epoch 01192: loss did not improve from -172.87976\n",
      "Epoch 1193/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.6907 - val_loss: -178.2161\n",
      "\n",
      "Epoch 01193: loss did not improve from -172.87976\n",
      "Epoch 1194/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.7022 - val_loss: -177.9359\n",
      "\n",
      "Epoch 01194: loss did not improve from -172.87976\n",
      "Epoch 1195/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -172.7205 - val_loss: -177.8856\n",
      "\n",
      "Epoch 01195: loss did not improve from -172.87976\n",
      "Epoch 1196/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.8083 - val_loss: -177.8175\n",
      "\n",
      "Epoch 01196: loss did not improve from -172.87976\n",
      "Epoch 1197/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.9899 - val_loss: -178.0226\n",
      "\n",
      "Epoch 01197: loss improved from -172.87976 to -172.98991, saving model to gendance.h5\n",
      "Epoch 1198/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.7993 - val_loss: -178.0355\n",
      "\n",
      "Epoch 01198: loss did not improve from -172.98991\n",
      "Epoch 1199/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -172.8063 - val_loss: -177.7860\n",
      "\n",
      "Epoch 01199: loss did not improve from -172.98991\n",
      "Epoch 1200/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.7540 - val_loss: -178.0670\n",
      "\n",
      "Epoch 01200: loss did not improve from -172.98991\n",
      "Epoch 1201/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.7814 - val_loss: -177.6738\n",
      "\n",
      "Epoch 01201: loss did not improve from -172.98991\n",
      "Epoch 1202/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.1323 - val_loss: -178.0706\n",
      "\n",
      "Epoch 01202: loss improved from -172.98991 to -173.13226, saving model to gendance.h5\n",
      "Epoch 1203/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.8766 - val_loss: -177.8038\n",
      "\n",
      "Epoch 01203: loss did not improve from -173.13226\n",
      "Epoch 1204/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.7658 - val_loss: -177.9171\n",
      "\n",
      "Epoch 01204: loss did not improve from -173.13226\n",
      "Epoch 1205/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.6699 - val_loss: -178.0523\n",
      "\n",
      "Epoch 01205: loss did not improve from -173.13226\n",
      "Epoch 1206/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.9392 - val_loss: -177.9540\n",
      "\n",
      "Epoch 01206: loss did not improve from -173.13226\n",
      "Epoch 1207/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.8901 - val_loss: -178.1814\n",
      "\n",
      "Epoch 01207: loss did not improve from -173.13226\n",
      "Epoch 1208/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.7918 - val_loss: -177.9186\n",
      "\n",
      "Epoch 01208: loss did not improve from -173.13226\n",
      "Epoch 1209/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.8851 - val_loss: -178.1814\n",
      "\n",
      "Epoch 01209: loss did not improve from -173.13226\n",
      "Epoch 1210/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.8451 - val_loss: -177.8995\n",
      "\n",
      "Epoch 01210: loss did not improve from -173.13226\n",
      "Epoch 1211/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.0301 - val_loss: -178.1447\n",
      "\n",
      "Epoch 01211: loss did not improve from -173.13226\n",
      "Epoch 1212/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -172.7724 - val_loss: -177.9014\n",
      "\n",
      "Epoch 01212: loss did not improve from -173.13226\n",
      "Epoch 1213/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.8685 - val_loss: -178.1046\n",
      "\n",
      "Epoch 01213: loss did not improve from -173.13226\n",
      "Epoch 1214/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.9807 - val_loss: -178.0388\n",
      "\n",
      "Epoch 01214: loss did not improve from -173.13226\n",
      "Epoch 1215/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.0611 - val_loss: -178.1837\n",
      "\n",
      "Epoch 01215: loss did not improve from -173.13226\n",
      "Epoch 1216/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.7555 - val_loss: -177.9649\n",
      "\n",
      "Epoch 01216: loss did not improve from -173.13226\n",
      "Epoch 1217/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -172.8480 - val_loss: -178.2382\n",
      "\n",
      "Epoch 01217: loss did not improve from -173.13226\n",
      "Epoch 1218/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.8411 - val_loss: -177.8864\n",
      "\n",
      "Epoch 01218: loss did not improve from -173.13226\n",
      "Epoch 1219/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.0376 - val_loss: -178.0763\n",
      "\n",
      "Epoch 01219: loss did not improve from -173.13226\n",
      "Epoch 1220/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.9077 - val_loss: -177.8165\n",
      "\n",
      "Epoch 01220: loss did not improve from -173.13226\n",
      "Epoch 1221/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.0177 - val_loss: -177.9930\n",
      "\n",
      "Epoch 01221: loss did not improve from -173.13226\n",
      "Epoch 1222/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.1254 - val_loss: -178.2749\n",
      "\n",
      "Epoch 01222: loss did not improve from -173.13226\n",
      "Epoch 1223/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.8010 - val_loss: -177.8012\n",
      "\n",
      "Epoch 01223: loss did not improve from -173.13226\n",
      "Epoch 1224/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.8906 - val_loss: -178.2574\n",
      "\n",
      "Epoch 01224: loss did not improve from -173.13226\n",
      "Epoch 1225/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.8849 - val_loss: -178.1137\n",
      "\n",
      "Epoch 01225: loss did not improve from -173.13226\n",
      "Epoch 1226/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.0069 - val_loss: -178.0442\n",
      "\n",
      "Epoch 01226: loss did not improve from -173.13226\n",
      "Epoch 1227/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.0762 - val_loss: -178.1778\n",
      "\n",
      "Epoch 01227: loss did not improve from -173.13226\n",
      "Epoch 1228/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.1162 - val_loss: -178.0521\n",
      "\n",
      "Epoch 01228: loss did not improve from -173.13226\n",
      "Epoch 1229/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.9548 - val_loss: -178.3097\n",
      "\n",
      "Epoch 01229: loss did not improve from -173.13226\n",
      "Epoch 1230/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.1246 - val_loss: -178.4838\n",
      "\n",
      "Epoch 01230: loss did not improve from -173.13226\n",
      "Epoch 1231/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.9442 - val_loss: -178.0969\n",
      "\n",
      "Epoch 01231: loss did not improve from -173.13226\n",
      "Epoch 1232/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.7748 - val_loss: -178.0568\n",
      "\n",
      "Epoch 01232: loss did not improve from -173.13226\n",
      "Epoch 1233/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.1235 - val_loss: -178.1160\n",
      "\n",
      "Epoch 01233: loss did not improve from -173.13226\n",
      "Epoch 1234/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.2710 - val_loss: -178.3109\n",
      "\n",
      "Epoch 01234: loss improved from -173.13226 to -173.27098, saving model to gendance.h5\n",
      "Epoch 1235/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.8546 - val_loss: -178.1204\n",
      "\n",
      "Epoch 01235: loss did not improve from -173.27098\n",
      "Epoch 1236/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.9612 - val_loss: -177.9934\n",
      "\n",
      "Epoch 01236: loss did not improve from -173.27098\n",
      "Epoch 1237/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.9853 - val_loss: -178.3609\n",
      "\n",
      "Epoch 01237: loss did not improve from -173.27098\n",
      "Epoch 1238/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -173.2586 - val_loss: -178.3043\n",
      "\n",
      "Epoch 01238: loss did not improve from -173.27098\n",
      "Epoch 1239/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.0727 - val_loss: -178.2745\n",
      "\n",
      "Epoch 01239: loss did not improve from -173.27098\n",
      "Epoch 1240/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.1040 - val_loss: -178.3738\n",
      "\n",
      "Epoch 01240: loss did not improve from -173.27098\n",
      "Epoch 1241/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.3237 - val_loss: -178.5169\n",
      "\n",
      "Epoch 01241: loss improved from -173.27098 to -173.32369, saving model to gendance.h5\n",
      "Epoch 1242/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.2234 - val_loss: -178.3841\n",
      "\n",
      "Epoch 01242: loss did not improve from -173.32369\n",
      "Epoch 1243/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.9388 - val_loss: -178.0973\n",
      "\n",
      "Epoch 01243: loss did not improve from -173.32369\n",
      "Epoch 1244/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.2619 - val_loss: -178.2889\n",
      "\n",
      "Epoch 01244: loss did not improve from -173.32369\n",
      "Epoch 1245/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.1913 - val_loss: -178.4749\n",
      "\n",
      "Epoch 01245: loss did not improve from -173.32369\n",
      "Epoch 1246/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.1367 - val_loss: -178.2843\n",
      "\n",
      "Epoch 01246: loss did not improve from -173.32369\n",
      "Epoch 1247/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.1361 - val_loss: -178.2864\n",
      "\n",
      "Epoch 01247: loss did not improve from -173.32369\n",
      "Epoch 1248/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.1009 - val_loss: -178.0320\n",
      "\n",
      "Epoch 01248: loss did not improve from -173.32369\n",
      "Epoch 1249/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.2723 - val_loss: -178.3731\n",
      "\n",
      "Epoch 01249: loss did not improve from -173.32369\n",
      "Epoch 1250/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -173.5066 - val_loss: -178.4365\n",
      "\n",
      "Epoch 01250: loss improved from -173.32369 to -173.50661, saving model to gendance.h5\n",
      "Epoch 1251/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.2845 - val_loss: -178.3996\n",
      "\n",
      "Epoch 01251: loss did not improve from -173.50661\n",
      "Epoch 1252/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.2345 - val_loss: -177.9716\n",
      "\n",
      "Epoch 01252: loss did not improve from -173.50661\n",
      "Epoch 1253/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.0682 - val_loss: -178.5585\n",
      "\n",
      "Epoch 01253: loss did not improve from -173.50661\n",
      "Epoch 1254/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.2564 - val_loss: -178.2945\n",
      "\n",
      "Epoch 01254: loss did not improve from -173.50661\n",
      "Epoch 1255/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.0868 - val_loss: -178.3674\n",
      "\n",
      "Epoch 01255: loss did not improve from -173.50661\n",
      "Epoch 1256/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -173.2528 - val_loss: -178.2993\n",
      "\n",
      "Epoch 01256: loss did not improve from -173.50661\n",
      "Epoch 1257/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.2537 - val_loss: -178.2346\n",
      "\n",
      "Epoch 01257: loss did not improve from -173.50661\n",
      "Epoch 1258/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.2857 - val_loss: -178.5481\n",
      "\n",
      "Epoch 01258: loss did not improve from -173.50661\n",
      "Epoch 1259/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.2106 - val_loss: -178.2127\n",
      "\n",
      "Epoch 01259: loss did not improve from -173.50661\n",
      "Epoch 1260/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -172.9833 - val_loss: -178.3130\n",
      "\n",
      "Epoch 01260: loss did not improve from -173.50661\n",
      "Epoch 1261/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.3393 - val_loss: -178.3490\n",
      "\n",
      "Epoch 01261: loss did not improve from -173.50661\n",
      "Epoch 1262/2000\n",
      "16017/16017 [==============================] - 1s 54us/step - loss: -173.1997 - val_loss: -177.9376\n",
      "\n",
      "Epoch 01262: loss did not improve from -173.50661\n",
      "Epoch 1263/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.3008 - val_loss: -178.5610\n",
      "\n",
      "Epoch 01263: loss did not improve from -173.50661\n",
      "Epoch 1264/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.4657 - val_loss: -178.4869\n",
      "\n",
      "Epoch 01264: loss did not improve from -173.50661\n",
      "Epoch 1265/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.3669 - val_loss: -178.7157\n",
      "\n",
      "Epoch 01265: loss did not improve from -173.50661\n",
      "Epoch 1266/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -173.3407 - val_loss: -178.3448\n",
      "\n",
      "Epoch 01266: loss did not improve from -173.50661\n",
      "Epoch 1267/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -173.2232 - val_loss: -178.5221\n",
      "\n",
      "Epoch 01267: loss did not improve from -173.50661\n",
      "Epoch 1268/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.4242 - val_loss: -178.6827\n",
      "\n",
      "Epoch 01268: loss did not improve from -173.50661\n",
      "Epoch 1269/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.2265 - val_loss: -178.3811\n",
      "\n",
      "Epoch 01269: loss did not improve from -173.50661\n",
      "Epoch 1270/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.4184 - val_loss: -178.4633\n",
      "\n",
      "Epoch 01270: loss did not improve from -173.50661\n",
      "Epoch 1271/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.2668 - val_loss: -178.7123\n",
      "\n",
      "Epoch 01271: loss did not improve from -173.50661\n",
      "Epoch 1272/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.2547 - val_loss: -178.5520\n",
      "\n",
      "Epoch 01272: loss did not improve from -173.50661\n",
      "Epoch 1273/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.6492 - val_loss: -178.1548\n",
      "\n",
      "Epoch 01273: loss improved from -173.50661 to -173.64919, saving model to gendance.h5\n",
      "Epoch 1274/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.4666 - val_loss: -178.3810\n",
      "\n",
      "Epoch 01274: loss did not improve from -173.64919\n",
      "Epoch 1275/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.0438 - val_loss: -178.5765\n",
      "\n",
      "Epoch 01275: loss did not improve from -173.64919\n",
      "Epoch 1276/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.5125 - val_loss: -178.7372\n",
      "\n",
      "Epoch 01276: loss did not improve from -173.64919\n",
      "Epoch 1277/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.4078 - val_loss: -178.9092\n",
      "\n",
      "Epoch 01277: loss did not improve from -173.64919\n",
      "Epoch 1278/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.6954 - val_loss: -178.8518\n",
      "\n",
      "Epoch 01278: loss improved from -173.64919 to -173.69539, saving model to gendance.h5\n",
      "Epoch 1279/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.5180 - val_loss: -178.2748\n",
      "\n",
      "Epoch 01279: loss did not improve from -173.69539\n",
      "Epoch 1280/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.2183 - val_loss: -178.5487\n",
      "\n",
      "Epoch 01280: loss did not improve from -173.69539\n",
      "Epoch 1281/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.4954 - val_loss: -178.7462\n",
      "\n",
      "Epoch 01281: loss did not improve from -173.69539\n",
      "Epoch 1282/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.2471 - val_loss: -178.3113\n",
      "\n",
      "Epoch 01282: loss did not improve from -173.69539\n",
      "Epoch 1283/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.3887 - val_loss: -178.4625\n",
      "\n",
      "Epoch 01283: loss did not improve from -173.69539\n",
      "Epoch 1284/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.4806 - val_loss: -178.5426\n",
      "\n",
      "Epoch 01284: loss did not improve from -173.69539\n",
      "Epoch 1285/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16017/16017 [==============================] - 1s 51us/step - loss: -173.4415 - val_loss: -178.4621\n",
      "\n",
      "Epoch 01285: loss did not improve from -173.69539\n",
      "Epoch 1286/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.4658 - val_loss: -178.9148\n",
      "\n",
      "Epoch 01286: loss did not improve from -173.69539\n",
      "Epoch 1287/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.3999 - val_loss: -178.6801\n",
      "\n",
      "Epoch 01287: loss did not improve from -173.69539\n",
      "Epoch 1288/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.2046 - val_loss: -178.4595\n",
      "\n",
      "Epoch 01288: loss did not improve from -173.69539\n",
      "Epoch 1289/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.4937 - val_loss: -178.5104\n",
      "\n",
      "Epoch 01289: loss did not improve from -173.69539\n",
      "Epoch 1290/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.2273 - val_loss: -178.4994\n",
      "\n",
      "Epoch 01290: loss did not improve from -173.69539\n",
      "Epoch 1291/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.4931 - val_loss: -179.0057\n",
      "\n",
      "Epoch 01291: loss did not improve from -173.69539\n",
      "Epoch 1292/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.2554 - val_loss: -178.0587\n",
      "\n",
      "Epoch 01292: loss did not improve from -173.69539\n",
      "Epoch 1293/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.3262 - val_loss: -178.6340\n",
      "\n",
      "Epoch 01293: loss did not improve from -173.69539\n",
      "Epoch 1294/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.3861 - val_loss: -178.4630\n",
      "\n",
      "Epoch 01294: loss did not improve from -173.69539\n",
      "Epoch 1295/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.2685 - val_loss: -178.3260\n",
      "\n",
      "Epoch 01295: loss did not improve from -173.69539\n",
      "Epoch 1296/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.4200 - val_loss: -178.6372\n",
      "\n",
      "Epoch 01296: loss did not improve from -173.69539\n",
      "Epoch 1297/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.4260 - val_loss: -178.7198\n",
      "\n",
      "Epoch 01297: loss did not improve from -173.69539\n",
      "Epoch 1298/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.5335 - val_loss: -178.7739\n",
      "\n",
      "Epoch 01298: loss did not improve from -173.69539\n",
      "Epoch 1299/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.6237 - val_loss: -178.6286\n",
      "\n",
      "Epoch 01299: loss did not improve from -173.69539\n",
      "Epoch 1300/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -173.6320 - val_loss: -178.8367\n",
      "\n",
      "Epoch 01300: loss did not improve from -173.69539\n",
      "Epoch 1301/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.4429 - val_loss: -179.0314\n",
      "\n",
      "Epoch 01301: loss did not improve from -173.69539\n",
      "Epoch 1302/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.6144 - val_loss: -178.5042\n",
      "\n",
      "Epoch 01302: loss did not improve from -173.69539\n",
      "Epoch 1303/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.1701 - val_loss: -178.3716\n",
      "\n",
      "Epoch 01303: loss did not improve from -173.69539\n",
      "Epoch 1304/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.7083 - val_loss: -178.8469\n",
      "\n",
      "Epoch 01304: loss improved from -173.69539 to -173.70827, saving model to gendance.h5\n",
      "Epoch 1305/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.4845 - val_loss: -178.6123\n",
      "\n",
      "Epoch 01305: loss did not improve from -173.70827\n",
      "Epoch 1306/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.6026 - val_loss: -178.6438\n",
      "\n",
      "Epoch 01306: loss did not improve from -173.70827\n",
      "Epoch 1307/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.4000 - val_loss: -178.4300\n",
      "\n",
      "Epoch 01307: loss did not improve from -173.70827\n",
      "Epoch 1308/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.5282 - val_loss: -178.4628\n",
      "\n",
      "Epoch 01308: loss did not improve from -173.70827\n",
      "Epoch 1309/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -173.5733 - val_loss: -178.5943\n",
      "\n",
      "Epoch 01309: loss did not improve from -173.70827\n",
      "Epoch 1310/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.3363 - val_loss: -178.4807\n",
      "\n",
      "Epoch 01310: loss did not improve from -173.70827\n",
      "Epoch 1311/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.6936 - val_loss: -178.7736\n",
      "\n",
      "Epoch 01311: loss did not improve from -173.70827\n",
      "Epoch 1312/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.5198 - val_loss: -178.7594\n",
      "\n",
      "Epoch 01312: loss did not improve from -173.70827\n",
      "Epoch 1313/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.6475 - val_loss: -178.7376\n",
      "\n",
      "Epoch 01313: loss did not improve from -173.70827\n",
      "Epoch 1314/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.4759 - val_loss: -178.4628\n",
      "\n",
      "Epoch 01314: loss did not improve from -173.70827\n",
      "Epoch 1315/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.5876 - val_loss: -178.5325\n",
      "\n",
      "Epoch 01315: loss did not improve from -173.70827\n",
      "Epoch 1316/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.6751 - val_loss: -178.6704\n",
      "\n",
      "Epoch 01316: loss did not improve from -173.70827\n",
      "Epoch 1317/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.5814 - val_loss: -178.4924\n",
      "\n",
      "Epoch 01317: loss did not improve from -173.70827\n",
      "Epoch 1318/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.3627 - val_loss: -178.7605\n",
      "\n",
      "Epoch 01318: loss did not improve from -173.70827\n",
      "Epoch 1319/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.8700 - val_loss: -179.1249\n",
      "\n",
      "Epoch 01319: loss improved from -173.70827 to -173.86995, saving model to gendance.h5\n",
      "Epoch 1320/2000\n",
      "16017/16017 [==============================] - 1s 53us/step - loss: -173.6428 - val_loss: -178.6842\n",
      "\n",
      "Epoch 01320: loss did not improve from -173.86995\n",
      "Epoch 1321/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.7653 - val_loss: -179.0106\n",
      "\n",
      "Epoch 01321: loss did not improve from -173.86995\n",
      "Epoch 1322/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.3501 - val_loss: -178.7222\n",
      "\n",
      "Epoch 01322: loss did not improve from -173.86995\n",
      "Epoch 1323/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.5743 - val_loss: -178.7009\n",
      "\n",
      "Epoch 01323: loss did not improve from -173.86995\n",
      "Epoch 1324/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.5647 - val_loss: -178.8108\n",
      "\n",
      "Epoch 01324: loss did not improve from -173.86995\n",
      "Epoch 1325/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.8997 - val_loss: -179.1452\n",
      "\n",
      "Epoch 01325: loss improved from -173.86995 to -173.89971, saving model to gendance.h5\n",
      "Epoch 1326/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.4936 - val_loss: -178.8910\n",
      "\n",
      "Epoch 01326: loss did not improve from -173.89971\n",
      "Epoch 1327/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.6864 - val_loss: -178.7342\n",
      "\n",
      "Epoch 01327: loss did not improve from -173.89971\n",
      "Epoch 1328/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.4979 - val_loss: -178.8119\n",
      "\n",
      "Epoch 01328: loss did not improve from -173.89971\n",
      "Epoch 1329/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.0165 - val_loss: -178.9665\n",
      "\n",
      "Epoch 01329: loss improved from -173.89971 to -174.01653, saving model to gendance.h5\n",
      "Epoch 1330/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.6831 - val_loss: -178.6426\n",
      "\n",
      "Epoch 01330: loss did not improve from -174.01653\n",
      "Epoch 1331/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.7794 - val_loss: -178.9574\n",
      "\n",
      "Epoch 01331: loss did not improve from -174.01653\n",
      "Epoch 1332/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -173.6274 - val_loss: -178.6863\n",
      "\n",
      "Epoch 01332: loss did not improve from -174.01653\n",
      "Epoch 1333/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.5365 - val_loss: -178.8901\n",
      "\n",
      "Epoch 01333: loss did not improve from -174.01653\n",
      "Epoch 1334/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.6239 - val_loss: -179.1463\n",
      "\n",
      "Epoch 01334: loss did not improve from -174.01653\n",
      "Epoch 1335/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.7373 - val_loss: -178.5864\n",
      "\n",
      "Epoch 01335: loss did not improve from -174.01653\n",
      "Epoch 1336/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.5601 - val_loss: -179.0368\n",
      "\n",
      "Epoch 01336: loss did not improve from -174.01653\n",
      "Epoch 1337/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.6846 - val_loss: -178.9781\n",
      "\n",
      "Epoch 01337: loss did not improve from -174.01653\n",
      "Epoch 1338/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.6269 - val_loss: -178.8228\n",
      "\n",
      "Epoch 01338: loss did not improve from -174.01653\n",
      "Epoch 1339/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.9182 - val_loss: -178.9225\n",
      "\n",
      "Epoch 01339: loss did not improve from -174.01653\n",
      "Epoch 1340/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.5472 - val_loss: -178.7456\n",
      "\n",
      "Epoch 01340: loss did not improve from -174.01653\n",
      "Epoch 1341/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.5125 - val_loss: -179.1847\n",
      "\n",
      "Epoch 01341: loss did not improve from -174.01653\n",
      "Epoch 1342/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.7463 - val_loss: -179.1000\n",
      "\n",
      "Epoch 01342: loss did not improve from -174.01653\n",
      "Epoch 1343/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.7691 - val_loss: -179.0335\n",
      "\n",
      "Epoch 01343: loss did not improve from -174.01653\n",
      "Epoch 1344/2000\n",
      "16017/16017 [==============================] - 1s 54us/step - loss: -173.7113 - val_loss: -178.7759\n",
      "\n",
      "Epoch 01344: loss did not improve from -174.01653\n",
      "Epoch 1345/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -173.4044 - val_loss: -179.1194\n",
      "\n",
      "Epoch 01345: loss did not improve from -174.01653\n",
      "Epoch 1346/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.9853 - val_loss: -179.1647\n",
      "\n",
      "Epoch 01346: loss did not improve from -174.01653\n",
      "Epoch 1347/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.5475 - val_loss: -178.5688\n",
      "\n",
      "Epoch 01347: loss did not improve from -174.01653\n",
      "Epoch 1348/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.8607 - val_loss: -178.8373\n",
      "\n",
      "Epoch 01348: loss did not improve from -174.01653\n",
      "Epoch 1349/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.7361 - val_loss: -178.6147\n",
      "\n",
      "Epoch 01349: loss did not improve from -174.01653\n",
      "Epoch 1350/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.7169 - val_loss: -178.9640\n",
      "\n",
      "Epoch 01350: loss did not improve from -174.01653\n",
      "Epoch 1351/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.8806 - val_loss: -178.6825\n",
      "\n",
      "Epoch 01351: loss did not improve from -174.01653\n",
      "Epoch 1352/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.8173 - val_loss: -178.9240\n",
      "\n",
      "Epoch 01352: loss did not improve from -174.01653\n",
      "Epoch 1353/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.8256 - val_loss: -179.3529\n",
      "\n",
      "Epoch 01353: loss did not improve from -174.01653\n",
      "Epoch 1354/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.9013 - val_loss: -178.8515\n",
      "\n",
      "Epoch 01354: loss did not improve from -174.01653\n",
      "Epoch 1355/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -173.5647 - val_loss: -178.6753\n",
      "\n",
      "Epoch 01355: loss did not improve from -174.01653\n",
      "Epoch 1356/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.0524 - val_loss: -178.9374\n",
      "\n",
      "Epoch 01356: loss improved from -174.01653 to -174.05240, saving model to gendance.h5\n",
      "Epoch 1357/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.7596 - val_loss: -178.8356\n",
      "\n",
      "Epoch 01357: loss did not improve from -174.05240\n",
      "Epoch 1358/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.7144 - val_loss: -179.1286\n",
      "\n",
      "Epoch 01358: loss did not improve from -174.05240\n",
      "Epoch 1359/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.8545 - val_loss: -178.9689\n",
      "\n",
      "Epoch 01359: loss did not improve from -174.05240\n",
      "Epoch 1360/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.7724 - val_loss: -178.6781\n",
      "\n",
      "Epoch 01360: loss did not improve from -174.05240\n",
      "Epoch 1361/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.8699 - val_loss: -179.1713\n",
      "\n",
      "Epoch 01361: loss did not improve from -174.05240\n",
      "Epoch 1362/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.8661 - val_loss: -178.9963\n",
      "\n",
      "Epoch 01362: loss did not improve from -174.05240\n",
      "Epoch 1363/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.0656 - val_loss: -179.0570\n",
      "\n",
      "Epoch 01363: loss improved from -174.05240 to -174.06556, saving model to gendance.h5\n",
      "Epoch 1364/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.6949 - val_loss: -178.7986\n",
      "\n",
      "Epoch 01364: loss did not improve from -174.06556\n",
      "Epoch 1365/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.9800 - val_loss: -179.0527\n",
      "\n",
      "Epoch 01365: loss did not improve from -174.06556\n",
      "Epoch 1366/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.8637 - val_loss: -178.8970\n",
      "\n",
      "Epoch 01366: loss did not improve from -174.06556\n",
      "Epoch 1367/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.0839 - val_loss: -178.8801\n",
      "\n",
      "Epoch 01367: loss improved from -174.06556 to -174.08386, saving model to gendance.h5\n",
      "Epoch 1368/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.0242 - val_loss: -178.9803\n",
      "\n",
      "Epoch 01368: loss did not improve from -174.08386\n",
      "Epoch 1369/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.9390 - val_loss: -179.2374\n",
      "\n",
      "Epoch 01369: loss did not improve from -174.08386\n",
      "Epoch 1370/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.9596 - val_loss: -178.8000\n",
      "\n",
      "Epoch 01370: loss did not improve from -174.08386\n",
      "Epoch 1371/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.0731 - val_loss: -179.2446\n",
      "\n",
      "Epoch 01371: loss did not improve from -174.08386\n",
      "Epoch 1372/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.9396 - val_loss: -179.0201\n",
      "\n",
      "Epoch 01372: loss did not improve from -174.08386\n",
      "Epoch 1373/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.9316 - val_loss: -179.0860\n",
      "\n",
      "Epoch 01373: loss did not improve from -174.08386\n",
      "Epoch 1374/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.9441 - val_loss: -178.8962\n",
      "\n",
      "Epoch 01374: loss did not improve from -174.08386\n",
      "Epoch 1375/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.0445 - val_loss: -179.0147\n",
      "\n",
      "Epoch 01375: loss did not improve from -174.08386\n",
      "Epoch 1376/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.7892 - val_loss: -179.2537\n",
      "\n",
      "Epoch 01376: loss did not improve from -174.08386\n",
      "Epoch 1377/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.1954 - val_loss: -178.8448\n",
      "\n",
      "Epoch 01377: loss improved from -174.08386 to -174.19541, saving model to gendance.h5\n",
      "Epoch 1378/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.1360 - val_loss: -179.1650\n",
      "\n",
      "Epoch 01378: loss did not improve from -174.19541\n",
      "Epoch 1379/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.0212 - val_loss: -178.6885\n",
      "\n",
      "Epoch 01379: loss did not improve from -174.19541\n",
      "Epoch 1380/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.8779 - val_loss: -179.1267\n",
      "\n",
      "Epoch 01380: loss did not improve from -174.19541\n",
      "Epoch 1381/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.1330 - val_loss: -178.8885\n",
      "\n",
      "Epoch 01381: loss did not improve from -174.19541\n",
      "Epoch 1382/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.0075 - val_loss: -179.1036\n",
      "\n",
      "Epoch 01382: loss did not improve from -174.19541\n",
      "Epoch 1383/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.8365 - val_loss: -179.1460\n",
      "\n",
      "Epoch 01383: loss did not improve from -174.19541\n",
      "Epoch 1384/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.0082 - val_loss: -179.1550\n",
      "\n",
      "Epoch 01384: loss did not improve from -174.19541\n",
      "Epoch 1385/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.1617 - val_loss: -179.3272\n",
      "\n",
      "Epoch 01385: loss did not improve from -174.19541\n",
      "Epoch 1386/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.0384 - val_loss: -179.2114\n",
      "\n",
      "Epoch 01386: loss did not improve from -174.19541\n",
      "Epoch 1387/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.3171 - val_loss: -179.1428\n",
      "\n",
      "Epoch 01387: loss improved from -174.19541 to -174.31713, saving model to gendance.h5\n",
      "Epoch 1388/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.1630 - val_loss: -179.1780\n",
      "\n",
      "Epoch 01388: loss did not improve from -174.31713\n",
      "Epoch 1389/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.9733 - val_loss: -179.2434\n",
      "\n",
      "Epoch 01389: loss did not improve from -174.31713\n",
      "Epoch 1390/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.1516 - val_loss: -179.1403\n",
      "\n",
      "Epoch 01390: loss did not improve from -174.31713\n",
      "Epoch 1391/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.1523 - val_loss: -179.2649\n",
      "\n",
      "Epoch 01391: loss did not improve from -174.31713\n",
      "Epoch 1392/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.0511 - val_loss: -179.2563\n",
      "\n",
      "Epoch 01392: loss did not improve from -174.31713\n",
      "Epoch 1393/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.1153 - val_loss: -179.1126\n",
      "\n",
      "Epoch 01393: loss did not improve from -174.31713\n",
      "Epoch 1394/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.0149 - val_loss: -179.0953\n",
      "\n",
      "Epoch 01394: loss did not improve from -174.31713\n",
      "Epoch 1395/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.3528 - val_loss: -179.3218\n",
      "\n",
      "Epoch 01395: loss improved from -174.31713 to -174.35280, saving model to gendance.h5\n",
      "Epoch 1396/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.9938 - val_loss: -179.1950\n",
      "\n",
      "Epoch 01396: loss did not improve from -174.35280\n",
      "Epoch 1397/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.3879 - val_loss: -179.3685\n",
      "\n",
      "Epoch 01397: loss improved from -174.35280 to -174.38791, saving model to gendance.h5\n",
      "Epoch 1398/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.9620 - val_loss: -179.2887\n",
      "\n",
      "Epoch 01398: loss did not improve from -174.38791\n",
      "Epoch 1399/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.9014 - val_loss: -179.1742\n",
      "\n",
      "Epoch 01399: loss did not improve from -174.38791\n",
      "Epoch 1400/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.9605 - val_loss: -178.8264\n",
      "\n",
      "Epoch 01400: loss did not improve from -174.38791\n",
      "Epoch 1401/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -174.0211 - val_loss: -179.2479\n",
      "\n",
      "Epoch 01401: loss did not improve from -174.38791\n",
      "Epoch 1402/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.9164 - val_loss: -179.2978\n",
      "\n",
      "Epoch 01402: loss did not improve from -174.38791\n",
      "Epoch 1403/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.8673 - val_loss: -179.1646\n",
      "\n",
      "Epoch 01403: loss did not improve from -174.38791\n",
      "Epoch 1404/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.0714 - val_loss: -179.1591\n",
      "\n",
      "Epoch 01404: loss did not improve from -174.38791\n",
      "Epoch 1405/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.2892 - val_loss: -179.4008\n",
      "\n",
      "Epoch 01405: loss did not improve from -174.38791\n",
      "Epoch 1406/2000\n",
      "16017/16017 [==============================] - 1s 54us/step - loss: -174.1906 - val_loss: -179.4108\n",
      "\n",
      "Epoch 01406: loss did not improve from -174.38791\n",
      "Epoch 1407/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.2518 - val_loss: -179.0589\n",
      "\n",
      "Epoch 01407: loss did not improve from -174.38791\n",
      "Epoch 1408/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.0107 - val_loss: -179.4477\n",
      "\n",
      "Epoch 01408: loss did not improve from -174.38791\n",
      "Epoch 1409/2000\n",
      "16017/16017 [==============================] - 1s 55us/step - loss: -174.1704 - val_loss: -179.4007\n",
      "\n",
      "Epoch 01409: loss did not improve from -174.38791\n",
      "Epoch 1410/2000\n",
      "16017/16017 [==============================] - 1s 53us/step - loss: -174.1091 - val_loss: -179.3031\n",
      "\n",
      "Epoch 01410: loss did not improve from -174.38791\n",
      "Epoch 1411/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.1872 - val_loss: -179.4971\n",
      "\n",
      "Epoch 01411: loss did not improve from -174.38791\n",
      "Epoch 1412/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.1538 - val_loss: -179.3569\n",
      "\n",
      "Epoch 01412: loss did not improve from -174.38791\n",
      "Epoch 1413/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.9218 - val_loss: -179.1242\n",
      "\n",
      "Epoch 01413: loss did not improve from -174.38791\n",
      "Epoch 1414/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.3203 - val_loss: -179.3418\n",
      "\n",
      "Epoch 01414: loss did not improve from -174.38791\n",
      "Epoch 1415/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.3283 - val_loss: -179.1910\n",
      "\n",
      "Epoch 01415: loss did not improve from -174.38791\n",
      "Epoch 1416/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.0050 - val_loss: -179.2439\n",
      "\n",
      "Epoch 01416: loss did not improve from -174.38791\n",
      "Epoch 1417/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.0864 - val_loss: -179.0983\n",
      "\n",
      "Epoch 01417: loss did not improve from -174.38791\n",
      "Epoch 1418/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.0074 - val_loss: -179.5459\n",
      "\n",
      "Epoch 01418: loss did not improve from -174.38791\n",
      "Epoch 1419/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.1230 - val_loss: -179.0602\n",
      "\n",
      "Epoch 01419: loss did not improve from -174.38791\n",
      "Epoch 1420/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.1821 - val_loss: -179.3623\n",
      "\n",
      "Epoch 01420: loss did not improve from -174.38791\n",
      "Epoch 1421/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.2260 - val_loss: -179.7162\n",
      "\n",
      "Epoch 01421: loss did not improve from -174.38791\n",
      "Epoch 1422/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.1794 - val_loss: -179.5925\n",
      "\n",
      "Epoch 01422: loss did not improve from -174.38791\n",
      "Epoch 1423/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.3534 - val_loss: -179.4586\n",
      "\n",
      "Epoch 01423: loss did not improve from -174.38791\n",
      "Epoch 1424/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.1503 - val_loss: -179.1299\n",
      "\n",
      "Epoch 01424: loss did not improve from -174.38791\n",
      "Epoch 1425/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -173.8819 - val_loss: -179.2387\n",
      "\n",
      "Epoch 01425: loss did not improve from -174.38791\n",
      "Epoch 1426/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.0081 - val_loss: -179.5499\n",
      "\n",
      "Epoch 01426: loss did not improve from -174.38791\n",
      "Epoch 1427/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.2825 - val_loss: -179.3914\n",
      "\n",
      "Epoch 01427: loss did not improve from -174.38791\n",
      "Epoch 1428/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.2329 - val_loss: -179.5948\n",
      "\n",
      "Epoch 01428: loss did not improve from -174.38791\n",
      "Epoch 1429/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.1653 - val_loss: -179.5071\n",
      "\n",
      "Epoch 01429: loss did not improve from -174.38791\n",
      "Epoch 1430/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.1341 - val_loss: -179.5818\n",
      "\n",
      "Epoch 01430: loss did not improve from -174.38791\n",
      "Epoch 1431/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.5280 - val_loss: -179.5313\n",
      "\n",
      "Epoch 01431: loss improved from -174.38791 to -174.52803, saving model to gendance.h5\n",
      "Epoch 1432/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.2976 - val_loss: -179.5190\n",
      "\n",
      "Epoch 01432: loss did not improve from -174.52803\n",
      "Epoch 1433/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.2448 - val_loss: -179.3646\n",
      "\n",
      "Epoch 01433: loss did not improve from -174.52803\n",
      "Epoch 1434/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.1703 - val_loss: -179.3956\n",
      "\n",
      "Epoch 01434: loss did not improve from -174.52803\n",
      "Epoch 1435/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.2357 - val_loss: -179.4152\n",
      "\n",
      "Epoch 01435: loss did not improve from -174.52803\n",
      "Epoch 1436/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.1277 - val_loss: -179.4293\n",
      "\n",
      "Epoch 01436: loss did not improve from -174.52803\n",
      "Epoch 1437/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.3437 - val_loss: -179.3613\n",
      "\n",
      "Epoch 01437: loss did not improve from -174.52803\n",
      "Epoch 1438/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.3400 - val_loss: -179.5869\n",
      "\n",
      "Epoch 01438: loss did not improve from -174.52803\n",
      "Epoch 1439/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.3612 - val_loss: -179.5980\n",
      "\n",
      "Epoch 01439: loss did not improve from -174.52803\n",
      "Epoch 1440/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.3515 - val_loss: -179.3317\n",
      "\n",
      "Epoch 01440: loss did not improve from -174.52803\n",
      "Epoch 1441/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.1263 - val_loss: -179.5345\n",
      "\n",
      "Epoch 01441: loss did not improve from -174.52803\n",
      "Epoch 1442/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.4035 - val_loss: -179.7173\n",
      "\n",
      "Epoch 01442: loss did not improve from -174.52803\n",
      "Epoch 1443/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.3886 - val_loss: -179.6959\n",
      "\n",
      "Epoch 01443: loss did not improve from -174.52803\n",
      "Epoch 1444/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.2484 - val_loss: -179.4787\n",
      "\n",
      "Epoch 01444: loss did not improve from -174.52803\n",
      "Epoch 1445/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.4109 - val_loss: -179.6977\n",
      "\n",
      "Epoch 01445: loss did not improve from -174.52803\n",
      "Epoch 1446/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.2898 - val_loss: -179.6878\n",
      "\n",
      "Epoch 01446: loss did not improve from -174.52803\n",
      "Epoch 1447/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.2314 - val_loss: -179.0565\n",
      "\n",
      "Epoch 01447: loss did not improve from -174.52803\n",
      "Epoch 1448/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.2340 - val_loss: -179.4717\n",
      "\n",
      "Epoch 01448: loss did not improve from -174.52803\n",
      "Epoch 1449/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.5773 - val_loss: -179.4746\n",
      "\n",
      "Epoch 01449: loss improved from -174.52803 to -174.57730, saving model to gendance.h5\n",
      "Epoch 1450/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.5264 - val_loss: -179.3577\n",
      "\n",
      "Epoch 01450: loss did not improve from -174.57730\n",
      "Epoch 1451/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.5549 - val_loss: -179.4410\n",
      "\n",
      "Epoch 01451: loss did not improve from -174.57730\n",
      "Epoch 1452/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.2608 - val_loss: -179.7239\n",
      "\n",
      "Epoch 01452: loss did not improve from -174.57730\n",
      "Epoch 1453/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.2637 - val_loss: -179.1552\n",
      "\n",
      "Epoch 01453: loss did not improve from -174.57730\n",
      "Epoch 1454/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.2412 - val_loss: -179.4135\n",
      "\n",
      "Epoch 01454: loss did not improve from -174.57730\n",
      "Epoch 1455/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.5023 - val_loss: -179.7521\n",
      "\n",
      "Epoch 01455: loss did not improve from -174.57730\n",
      "Epoch 1456/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.4706 - val_loss: -179.5395\n",
      "\n",
      "Epoch 01456: loss did not improve from -174.57730\n",
      "Epoch 1457/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.3223 - val_loss: -178.9857\n",
      "\n",
      "Epoch 01457: loss did not improve from -174.57730\n",
      "Epoch 1458/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.3216 - val_loss: -179.3761\n",
      "\n",
      "Epoch 01458: loss did not improve from -174.57730\n",
      "Epoch 1459/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.3991 - val_loss: -179.2225\n",
      "\n",
      "Epoch 01459: loss did not improve from -174.57730\n",
      "Epoch 1460/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.4360 - val_loss: -179.4237\n",
      "\n",
      "Epoch 01460: loss did not improve from -174.57730\n",
      "Epoch 1461/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.5203 - val_loss: -179.5361\n",
      "\n",
      "Epoch 01461: loss did not improve from -174.57730\n",
      "Epoch 1462/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.4537 - val_loss: -179.3648\n",
      "\n",
      "Epoch 01462: loss did not improve from -174.57730\n",
      "Epoch 1463/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -174.4751 - val_loss: -179.5450\n",
      "\n",
      "Epoch 01463: loss did not improve from -174.57730\n",
      "Epoch 1464/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.5792 - val_loss: -179.8052\n",
      "\n",
      "Epoch 01464: loss improved from -174.57730 to -174.57922, saving model to gendance.h5\n",
      "Epoch 1465/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.3753 - val_loss: -179.5821\n",
      "\n",
      "Epoch 01465: loss did not improve from -174.57922\n",
      "Epoch 1466/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.0597 - val_loss: -179.3392\n",
      "\n",
      "Epoch 01466: loss did not improve from -174.57922\n",
      "Epoch 1467/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.2299 - val_loss: -179.6967\n",
      "\n",
      "Epoch 01467: loss did not improve from -174.57922\n",
      "Epoch 1468/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.4162 - val_loss: -179.4321\n",
      "\n",
      "Epoch 01468: loss did not improve from -174.57922\n",
      "Epoch 1469/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.4008 - val_loss: -179.4896\n",
      "\n",
      "Epoch 01469: loss did not improve from -174.57922\n",
      "Epoch 1470/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.5344 - val_loss: -179.3993\n",
      "\n",
      "Epoch 01470: loss did not improve from -174.57922\n",
      "Epoch 1471/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.6454 - val_loss: -179.5202\n",
      "\n",
      "Epoch 01471: loss improved from -174.57922 to -174.64543, saving model to gendance.h5\n",
      "Epoch 1472/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.5555 - val_loss: -179.7810\n",
      "\n",
      "Epoch 01472: loss did not improve from -174.64543\n",
      "Epoch 1473/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.5632 - val_loss: -179.4412\n",
      "\n",
      "Epoch 01473: loss did not improve from -174.64543\n",
      "Epoch 1474/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.2902 - val_loss: -179.5750\n",
      "\n",
      "Epoch 01474: loss did not improve from -174.64543\n",
      "Epoch 1475/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.6400 - val_loss: -179.6648\n",
      "\n",
      "Epoch 01475: loss did not improve from -174.64543\n",
      "Epoch 1476/2000\n",
      "16017/16017 [==============================] - 1s 53us/step - loss: -174.6162 - val_loss: -179.5523\n",
      "\n",
      "Epoch 01476: loss did not improve from -174.64543\n",
      "Epoch 1477/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.6034 - val_loss: -179.6694\n",
      "\n",
      "Epoch 01477: loss did not improve from -174.64543\n",
      "Epoch 1478/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.4817 - val_loss: -179.6100\n",
      "\n",
      "Epoch 01478: loss did not improve from -174.64543\n",
      "Epoch 1479/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.6811 - val_loss: -179.9543\n",
      "\n",
      "Epoch 01479: loss improved from -174.64543 to -174.68111, saving model to gendance.h5\n",
      "Epoch 1480/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.6963 - val_loss: -179.4733\n",
      "\n",
      "Epoch 01480: loss improved from -174.68111 to -174.69629, saving model to gendance.h5\n",
      "Epoch 1481/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.5502 - val_loss: -179.3584\n",
      "\n",
      "Epoch 01481: loss did not improve from -174.69629\n",
      "Epoch 1482/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.4116 - val_loss: -179.9333\n",
      "\n",
      "Epoch 01482: loss did not improve from -174.69629\n",
      "Epoch 1483/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.8329 - val_loss: -179.4985\n",
      "\n",
      "Epoch 01483: loss improved from -174.69629 to -174.83292, saving model to gendance.h5\n",
      "Epoch 1484/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.3284 - val_loss: -179.6609\n",
      "\n",
      "Epoch 01484: loss did not improve from -174.83292\n",
      "Epoch 1485/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.5793 - val_loss: -179.6274\n",
      "\n",
      "Epoch 01485: loss did not improve from -174.83292\n",
      "Epoch 1486/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.3234 - val_loss: -179.3959\n",
      "\n",
      "Epoch 01486: loss did not improve from -174.83292\n",
      "Epoch 1487/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.5545 - val_loss: -179.9147\n",
      "\n",
      "Epoch 01487: loss did not improve from -174.83292\n",
      "Epoch 1488/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.6736 - val_loss: -179.8825\n",
      "\n",
      "Epoch 01488: loss did not improve from -174.83292\n",
      "Epoch 1489/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.6951 - val_loss: -179.4665\n",
      "\n",
      "Epoch 01489: loss did not improve from -174.83292\n",
      "Epoch 1490/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.6090 - val_loss: -179.7146\n",
      "\n",
      "Epoch 01490: loss did not improve from -174.83292\n",
      "Epoch 1491/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.6146 - val_loss: -179.6838\n",
      "\n",
      "Epoch 01491: loss did not improve from -174.83292\n",
      "Epoch 1492/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.5696 - val_loss: -179.7288\n",
      "\n",
      "Epoch 01492: loss did not improve from -174.83292\n",
      "Epoch 1493/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.5002 - val_loss: -179.1861\n",
      "\n",
      "Epoch 01493: loss did not improve from -174.83292\n",
      "Epoch 1494/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.6721 - val_loss: -179.8021\n",
      "\n",
      "Epoch 01494: loss did not improve from -174.83292\n",
      "Epoch 1495/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.7045 - val_loss: -179.7761\n",
      "\n",
      "Epoch 01495: loss did not improve from -174.83292\n",
      "Epoch 1496/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.7578 - val_loss: -180.0986\n",
      "\n",
      "Epoch 01496: loss did not improve from -174.83292\n",
      "Epoch 1497/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.4658 - val_loss: -179.7276\n",
      "\n",
      "Epoch 01497: loss did not improve from -174.83292\n",
      "Epoch 1498/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.4974 - val_loss: -179.7312\n",
      "\n",
      "Epoch 01498: loss did not improve from -174.83292\n",
      "Epoch 1499/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.6333 - val_loss: -179.8246\n",
      "\n",
      "Epoch 01499: loss did not improve from -174.83292\n",
      "Epoch 1500/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.3475 - val_loss: -179.5172\n",
      "\n",
      "Epoch 01500: loss did not improve from -174.83292\n",
      "Epoch 1501/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.4438 - val_loss: -179.7554\n",
      "\n",
      "Epoch 01501: loss did not improve from -174.83292\n",
      "Epoch 1502/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.5995 - val_loss: -179.8372\n",
      "\n",
      "Epoch 01502: loss did not improve from -174.83292\n",
      "Epoch 1503/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.7218 - val_loss: -179.6935\n",
      "\n",
      "Epoch 01503: loss did not improve from -174.83292\n",
      "Epoch 1504/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.5090 - val_loss: -179.8064\n",
      "\n",
      "Epoch 01504: loss did not improve from -174.83292\n",
      "Epoch 1505/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.6540 - val_loss: -179.9529\n",
      "\n",
      "Epoch 01505: loss did not improve from -174.83292\n",
      "Epoch 1506/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.5046 - val_loss: -179.5149\n",
      "\n",
      "Epoch 01506: loss did not improve from -174.83292\n",
      "Epoch 1507/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.7077 - val_loss: -180.1047\n",
      "\n",
      "Epoch 01507: loss did not improve from -174.83292\n",
      "Epoch 1508/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.4513 - val_loss: -179.5818\n",
      "\n",
      "Epoch 01508: loss did not improve from -174.83292\n",
      "Epoch 1509/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.7136 - val_loss: -179.6089\n",
      "\n",
      "Epoch 01509: loss did not improve from -174.83292\n",
      "Epoch 1510/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.8741 - val_loss: -179.8195\n",
      "\n",
      "Epoch 01510: loss improved from -174.83292 to -174.87407, saving model to gendance.h5\n",
      "Epoch 1511/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.7846 - val_loss: -179.9206\n",
      "\n",
      "Epoch 01511: loss did not improve from -174.87407\n",
      "Epoch 1512/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.6701 - val_loss: -179.7354\n",
      "\n",
      "Epoch 01512: loss did not improve from -174.87407\n",
      "Epoch 1513/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.6435 - val_loss: -179.8254\n",
      "\n",
      "Epoch 01513: loss did not improve from -174.87407\n",
      "Epoch 1514/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.6175 - val_loss: -180.0176\n",
      "\n",
      "Epoch 01514: loss did not improve from -174.87407\n",
      "Epoch 1515/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.9193 - val_loss: -179.8215\n",
      "\n",
      "Epoch 01515: loss improved from -174.87407 to -174.91931, saving model to gendance.h5\n",
      "Epoch 1516/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.7436 - val_loss: -180.1033\n",
      "\n",
      "Epoch 01516: loss did not improve from -174.91931\n",
      "Epoch 1517/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.7934 - val_loss: -179.9340\n",
      "\n",
      "Epoch 01517: loss did not improve from -174.91931\n",
      "Epoch 1518/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.8140 - val_loss: -179.8286\n",
      "\n",
      "Epoch 01518: loss did not improve from -174.91931\n",
      "Epoch 1519/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.8012 - val_loss: -179.6031\n",
      "\n",
      "Epoch 01519: loss did not improve from -174.91931\n",
      "Epoch 1520/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.6040 - val_loss: -179.6593\n",
      "\n",
      "Epoch 01520: loss did not improve from -174.91931\n",
      "Epoch 1521/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.7276 - val_loss: -180.0617\n",
      "\n",
      "Epoch 01521: loss did not improve from -174.91931\n",
      "Epoch 1522/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.8149 - val_loss: -180.0937\n",
      "\n",
      "Epoch 01522: loss did not improve from -174.91931\n",
      "Epoch 1523/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.9380 - val_loss: -180.0203\n",
      "\n",
      "Epoch 01523: loss improved from -174.91931 to -174.93796, saving model to gendance.h5\n",
      "Epoch 1524/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.9508 - val_loss: -179.9199\n",
      "\n",
      "Epoch 01524: loss improved from -174.93796 to -174.95081, saving model to gendance.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1525/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.6736 - val_loss: -180.0433\n",
      "\n",
      "Epoch 01525: loss did not improve from -174.95081\n",
      "Epoch 1526/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.0465 - val_loss: -179.9164\n",
      "\n",
      "Epoch 01526: loss improved from -174.95081 to -175.04646, saving model to gendance.h5\n",
      "Epoch 1527/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.7353 - val_loss: -179.7388\n",
      "\n",
      "Epoch 01527: loss did not improve from -175.04646\n",
      "Epoch 1528/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.8734 - val_loss: -179.7483\n",
      "\n",
      "Epoch 01528: loss did not improve from -175.04646\n",
      "Epoch 1529/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.7314 - val_loss: -179.9425\n",
      "\n",
      "Epoch 01529: loss did not improve from -175.04646\n",
      "Epoch 1530/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.8141 - val_loss: -180.0406\n",
      "\n",
      "Epoch 01530: loss did not improve from -175.04646\n",
      "Epoch 1531/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.9122 - val_loss: -179.8651\n",
      "\n",
      "Epoch 01531: loss did not improve from -175.04646\n",
      "Epoch 1532/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.8234 - val_loss: -179.6980\n",
      "\n",
      "Epoch 01532: loss did not improve from -175.04646\n",
      "Epoch 1533/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.7844 - val_loss: -179.8808\n",
      "\n",
      "Epoch 01533: loss did not improve from -175.04646\n",
      "Epoch 1534/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.8301 - val_loss: -180.1118\n",
      "\n",
      "Epoch 01534: loss did not improve from -175.04646\n",
      "Epoch 1535/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.8373 - val_loss: -180.1475\n",
      "\n",
      "Epoch 01535: loss did not improve from -175.04646\n",
      "Epoch 1536/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.6643 - val_loss: -179.8949\n",
      "\n",
      "Epoch 01536: loss did not improve from -175.04646\n",
      "Epoch 1537/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.5704 - val_loss: -179.8483\n",
      "\n",
      "Epoch 01537: loss did not improve from -175.04646\n",
      "Epoch 1538/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.7046 - val_loss: -180.0344\n",
      "\n",
      "Epoch 01538: loss did not improve from -175.04646\n",
      "Epoch 1539/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.7739 - val_loss: -180.0538\n",
      "\n",
      "Epoch 01539: loss did not improve from -175.04646\n",
      "Epoch 1540/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.7198 - val_loss: -179.6383\n",
      "\n",
      "Epoch 01540: loss did not improve from -175.04646\n",
      "Epoch 1541/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.7641 - val_loss: -179.8644\n",
      "\n",
      "Epoch 01541: loss did not improve from -175.04646\n",
      "Epoch 1542/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.8786 - val_loss: -180.1058\n",
      "\n",
      "Epoch 01542: loss did not improve from -175.04646\n",
      "Epoch 1543/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.0453 - val_loss: -180.1436\n",
      "\n",
      "Epoch 01543: loss did not improve from -175.04646\n",
      "Epoch 1544/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -174.9372 - val_loss: -179.8833\n",
      "\n",
      "Epoch 01544: loss did not improve from -175.04646\n",
      "Epoch 1545/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.6580 - val_loss: -179.9639\n",
      "\n",
      "Epoch 01545: loss did not improve from -175.04646\n",
      "Epoch 1546/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.8293 - val_loss: -179.6532\n",
      "\n",
      "Epoch 01546: loss did not improve from -175.04646\n",
      "Epoch 1547/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -174.7111 - val_loss: -180.3677\n",
      "\n",
      "Epoch 01547: loss did not improve from -175.04646\n",
      "Epoch 1548/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.7243 - val_loss: -179.6259\n",
      "\n",
      "Epoch 01548: loss did not improve from -175.04646\n",
      "Epoch 1549/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.8209 - val_loss: -180.3368\n",
      "\n",
      "Epoch 01549: loss did not improve from -175.04646\n",
      "Epoch 1550/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.9300 - val_loss: -179.9326\n",
      "\n",
      "Epoch 01550: loss did not improve from -175.04646\n",
      "Epoch 1551/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.9765 - val_loss: -179.9793\n",
      "\n",
      "Epoch 01551: loss did not improve from -175.04646\n",
      "Epoch 1552/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.9659 - val_loss: -179.9985\n",
      "\n",
      "Epoch 01552: loss did not improve from -175.04646\n",
      "Epoch 1553/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.9899 - val_loss: -180.2993\n",
      "\n",
      "Epoch 01553: loss did not improve from -175.04646\n",
      "Epoch 1554/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.7655 - val_loss: -180.0132\n",
      "\n",
      "Epoch 01554: loss did not improve from -175.04646\n",
      "Epoch 1555/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.9613 - val_loss: -180.1575\n",
      "\n",
      "Epoch 01555: loss did not improve from -175.04646\n",
      "Epoch 1556/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.7968 - val_loss: -179.9805\n",
      "\n",
      "Epoch 01556: loss did not improve from -175.04646\n",
      "Epoch 1557/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.8270 - val_loss: -180.0560\n",
      "\n",
      "Epoch 01557: loss did not improve from -175.04646\n",
      "Epoch 1558/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.0337 - val_loss: -180.0191\n",
      "\n",
      "Epoch 01558: loss did not improve from -175.04646\n",
      "Epoch 1559/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.9281 - val_loss: -180.0673\n",
      "\n",
      "Epoch 01559: loss did not improve from -175.04646\n",
      "Epoch 1560/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.7987 - val_loss: -179.6938\n",
      "\n",
      "Epoch 01560: loss did not improve from -175.04646\n",
      "Epoch 1561/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.8249 - val_loss: -179.9505\n",
      "\n",
      "Epoch 01561: loss did not improve from -175.04646\n",
      "Epoch 1562/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.8084 - val_loss: -180.0716\n",
      "\n",
      "Epoch 01562: loss did not improve from -175.04646\n",
      "Epoch 1563/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.1395 - val_loss: -180.2257\n",
      "\n",
      "Epoch 01563: loss improved from -175.04646 to -175.13947, saving model to gendance.h5\n",
      "Epoch 1564/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.8585 - val_loss: -180.0749\n",
      "\n",
      "Epoch 01564: loss did not improve from -175.13947\n",
      "Epoch 1565/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.7583 - val_loss: -180.1473\n",
      "\n",
      "Epoch 01565: loss did not improve from -175.13947\n",
      "Epoch 1566/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.0366 - val_loss: -180.2797\n",
      "\n",
      "Epoch 01566: loss did not improve from -175.13947\n",
      "Epoch 1567/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.0325 - val_loss: -180.0486\n",
      "\n",
      "Epoch 01567: loss did not improve from -175.13947\n",
      "Epoch 1568/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.0809 - val_loss: -179.9253\n",
      "\n",
      "Epoch 01568: loss did not improve from -175.13947\n",
      "Epoch 1569/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.1160 - val_loss: -180.2139\n",
      "\n",
      "Epoch 01569: loss did not improve from -175.13947\n",
      "Epoch 1570/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.0122 - val_loss: -180.1038\n",
      "\n",
      "Epoch 01570: loss did not improve from -175.13947\n",
      "Epoch 1571/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.8043 - val_loss: -180.2941\n",
      "\n",
      "Epoch 01571: loss did not improve from -175.13947\n",
      "Epoch 1572/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.0773 - val_loss: -180.1152\n",
      "\n",
      "Epoch 01572: loss did not improve from -175.13947\n",
      "Epoch 1573/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -175.0298 - val_loss: -180.0916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01573: loss did not improve from -175.13947\n",
      "Epoch 1574/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.2415 - val_loss: -180.1800\n",
      "\n",
      "Epoch 01574: loss improved from -175.13947 to -175.24149, saving model to gendance.h5\n",
      "Epoch 1575/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.0955 - val_loss: -180.3284\n",
      "\n",
      "Epoch 01575: loss did not improve from -175.24149\n",
      "Epoch 1576/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.1303 - val_loss: -180.1461\n",
      "\n",
      "Epoch 01576: loss did not improve from -175.24149\n",
      "Epoch 1577/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -175.0546 - val_loss: -180.1017\n",
      "\n",
      "Epoch 01577: loss did not improve from -175.24149\n",
      "Epoch 1578/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.0059 - val_loss: -180.0316\n",
      "\n",
      "Epoch 01578: loss did not improve from -175.24149\n",
      "Epoch 1579/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -174.9733 - val_loss: -180.3320\n",
      "\n",
      "Epoch 01579: loss did not improve from -175.24149\n",
      "Epoch 1580/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -174.8189 - val_loss: -180.0840\n",
      "\n",
      "Epoch 01580: loss did not improve from -175.24149\n",
      "Epoch 1581/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.9645 - val_loss: -180.0888\n",
      "\n",
      "Epoch 01581: loss did not improve from -175.24149\n",
      "Epoch 1582/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.9903 - val_loss: -180.3366\n",
      "\n",
      "Epoch 01582: loss did not improve from -175.24149\n",
      "Epoch 1583/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.0532 - val_loss: -180.0841\n",
      "\n",
      "Epoch 01583: loss did not improve from -175.24149\n",
      "Epoch 1584/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.0935 - val_loss: -179.7079\n",
      "\n",
      "Epoch 01584: loss did not improve from -175.24149\n",
      "Epoch 1585/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.0589 - val_loss: -180.2944\n",
      "\n",
      "Epoch 01585: loss did not improve from -175.24149\n",
      "Epoch 1586/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.9744 - val_loss: -180.3301\n",
      "\n",
      "Epoch 01586: loss did not improve from -175.24149\n",
      "Epoch 1587/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.8166 - val_loss: -179.9520\n",
      "\n",
      "Epoch 01587: loss did not improve from -175.24149\n",
      "Epoch 1588/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.1496 - val_loss: -180.2643\n",
      "\n",
      "Epoch 01588: loss did not improve from -175.24149\n",
      "Epoch 1589/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.4955 - val_loss: -180.0646\n",
      "\n",
      "Epoch 01589: loss improved from -175.24149 to -175.49554, saving model to gendance.h5\n",
      "Epoch 1590/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.2672 - val_loss: -180.1708\n",
      "\n",
      "Epoch 01590: loss did not improve from -175.49554\n",
      "Epoch 1591/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.0442 - val_loss: -180.0137\n",
      "\n",
      "Epoch 01591: loss did not improve from -175.49554\n",
      "Epoch 1592/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.1941 - val_loss: -179.9550\n",
      "\n",
      "Epoch 01592: loss did not improve from -175.49554\n",
      "Epoch 1593/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.9925 - val_loss: -180.1426\n",
      "\n",
      "Epoch 01593: loss did not improve from -175.49554\n",
      "Epoch 1594/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.0824 - val_loss: -180.2937\n",
      "\n",
      "Epoch 01594: loss did not improve from -175.49554\n",
      "Epoch 1595/2000\n",
      "16017/16017 [==============================] - 1s 53us/step - loss: -175.1537 - val_loss: -180.1329\n",
      "\n",
      "Epoch 01595: loss did not improve from -175.49554\n",
      "Epoch 1596/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.2255 - val_loss: -180.4073\n",
      "\n",
      "Epoch 01596: loss did not improve from -175.49554\n",
      "Epoch 1597/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.0884 - val_loss: -180.5116\n",
      "\n",
      "Epoch 01597: loss did not improve from -175.49554\n",
      "Epoch 1598/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.3600 - val_loss: -180.2600\n",
      "\n",
      "Epoch 01598: loss did not improve from -175.49554\n",
      "Epoch 1599/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.9461 - val_loss: -180.3163\n",
      "\n",
      "Epoch 01599: loss did not improve from -175.49554\n",
      "Epoch 1600/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.1133 - val_loss: -180.1205\n",
      "\n",
      "Epoch 01600: loss did not improve from -175.49554\n",
      "Epoch 1601/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.2485 - val_loss: -180.3740\n",
      "\n",
      "Epoch 01601: loss did not improve from -175.49554\n",
      "Epoch 1602/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.0644 - val_loss: -180.0266\n",
      "\n",
      "Epoch 01602: loss did not improve from -175.49554\n",
      "Epoch 1603/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.0960 - val_loss: -180.0406\n",
      "\n",
      "Epoch 01603: loss did not improve from -175.49554\n",
      "Epoch 1604/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.4080 - val_loss: -180.2762\n",
      "\n",
      "Epoch 01604: loss did not improve from -175.49554\n",
      "Epoch 1605/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -175.1236 - val_loss: -180.2606\n",
      "\n",
      "Epoch 01605: loss did not improve from -175.49554\n",
      "Epoch 1606/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.2429 - val_loss: -180.1206\n",
      "\n",
      "Epoch 01606: loss did not improve from -175.49554\n",
      "Epoch 1607/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.1729 - val_loss: -180.0415\n",
      "\n",
      "Epoch 01607: loss did not improve from -175.49554\n",
      "Epoch 1608/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -174.9281 - val_loss: -180.2176\n",
      "\n",
      "Epoch 01608: loss did not improve from -175.49554\n",
      "Epoch 1609/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.0317 - val_loss: -180.1324\n",
      "\n",
      "Epoch 01609: loss did not improve from -175.49554\n",
      "Epoch 1610/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.0304 - val_loss: -180.1294\n",
      "\n",
      "Epoch 01610: loss did not improve from -175.49554\n",
      "Epoch 1611/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.2689 - val_loss: -180.3513\n",
      "\n",
      "Epoch 01611: loss did not improve from -175.49554\n",
      "Epoch 1612/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.3484 - val_loss: -180.2870\n",
      "\n",
      "Epoch 01612: loss did not improve from -175.49554\n",
      "Epoch 1613/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.2216 - val_loss: -180.3948\n",
      "\n",
      "Epoch 01613: loss did not improve from -175.49554\n",
      "Epoch 1614/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.3275 - val_loss: -179.9958\n",
      "\n",
      "Epoch 01614: loss did not improve from -175.49554\n",
      "Epoch 1615/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.3791 - val_loss: -180.3310\n",
      "\n",
      "Epoch 01615: loss did not improve from -175.49554\n",
      "Epoch 1616/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.0872 - val_loss: -180.3416\n",
      "\n",
      "Epoch 01616: loss did not improve from -175.49554\n",
      "Epoch 1617/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -175.2900 - val_loss: -180.2788\n",
      "\n",
      "Epoch 01617: loss did not improve from -175.49554\n",
      "Epoch 1618/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.0682 - val_loss: -180.1837\n",
      "\n",
      "Epoch 01618: loss did not improve from -175.49554\n",
      "Epoch 1619/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.0917 - val_loss: -180.0786\n",
      "\n",
      "Epoch 01619: loss did not improve from -175.49554\n",
      "Epoch 1620/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.2005 - val_loss: -180.2181\n",
      "\n",
      "Epoch 01620: loss did not improve from -175.49554\n",
      "Epoch 1621/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.3835 - val_loss: -180.4221\n",
      "\n",
      "Epoch 01621: loss did not improve from -175.49554\n",
      "Epoch 1622/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.1344 - val_loss: -180.2239\n",
      "\n",
      "Epoch 01622: loss did not improve from -175.49554\n",
      "Epoch 1623/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.0641 - val_loss: -180.0474\n",
      "\n",
      "Epoch 01623: loss did not improve from -175.49554\n",
      "Epoch 1624/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.2750 - val_loss: -180.4289\n",
      "\n",
      "Epoch 01624: loss did not improve from -175.49554\n",
      "Epoch 1625/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.3562 - val_loss: -180.5173\n",
      "\n",
      "Epoch 01625: loss did not improve from -175.49554\n",
      "Epoch 1626/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.0656 - val_loss: -180.0905\n",
      "\n",
      "Epoch 01626: loss did not improve from -175.49554\n",
      "Epoch 1627/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.0347 - val_loss: -180.4604\n",
      "\n",
      "Epoch 01627: loss did not improve from -175.49554\n",
      "Epoch 1628/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.2733 - val_loss: -180.2613\n",
      "\n",
      "Epoch 01628: loss did not improve from -175.49554\n",
      "Epoch 1629/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.4527 - val_loss: -180.5172\n",
      "\n",
      "Epoch 01629: loss did not improve from -175.49554\n",
      "Epoch 1630/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.2816 - val_loss: -180.2891\n",
      "\n",
      "Epoch 01630: loss did not improve from -175.49554\n",
      "Epoch 1631/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.1251 - val_loss: -180.1999\n",
      "\n",
      "Epoch 01631: loss did not improve from -175.49554\n",
      "Epoch 1632/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.1555 - val_loss: -180.2161\n",
      "\n",
      "Epoch 01632: loss did not improve from -175.49554\n",
      "Epoch 1633/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.4196 - val_loss: -180.3134\n",
      "\n",
      "Epoch 01633: loss did not improve from -175.49554\n",
      "Epoch 1634/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.2455 - val_loss: -180.4490\n",
      "\n",
      "Epoch 01634: loss did not improve from -175.49554\n",
      "Epoch 1635/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.1883 - val_loss: -180.4599\n",
      "\n",
      "Epoch 01635: loss did not improve from -175.49554\n",
      "Epoch 1636/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.2653 - val_loss: -180.3014\n",
      "\n",
      "Epoch 01636: loss did not improve from -175.49554\n",
      "Epoch 1637/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.1652 - val_loss: -180.3887\n",
      "\n",
      "Epoch 01637: loss did not improve from -175.49554\n",
      "Epoch 1638/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.2078 - val_loss: -180.4081\n",
      "\n",
      "Epoch 01638: loss did not improve from -175.49554\n",
      "Epoch 1639/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.5594 - val_loss: -180.7444\n",
      "\n",
      "Epoch 01639: loss improved from -175.49554 to -175.55937, saving model to gendance.h5\n",
      "Epoch 1640/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.1078 - val_loss: -180.3919\n",
      "\n",
      "Epoch 01640: loss did not improve from -175.55937\n",
      "Epoch 1641/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.5604 - val_loss: -180.3436\n",
      "\n",
      "Epoch 01641: loss improved from -175.55937 to -175.56037, saving model to gendance.h5\n",
      "Epoch 1642/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.2013 - val_loss: -180.1432\n",
      "\n",
      "Epoch 01642: loss did not improve from -175.56037\n",
      "Epoch 1643/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.2980 - val_loss: -180.6189\n",
      "\n",
      "Epoch 01643: loss did not improve from -175.56037\n",
      "Epoch 1644/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -175.1122 - val_loss: -180.2896\n",
      "\n",
      "Epoch 01644: loss did not improve from -175.56037\n",
      "Epoch 1645/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.3107 - val_loss: -180.4053\n",
      "\n",
      "Epoch 01645: loss did not improve from -175.56037\n",
      "Epoch 1646/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -175.5096 - val_loss: -180.8037\n",
      "\n",
      "Epoch 01646: loss did not improve from -175.56037\n",
      "Epoch 1647/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.5475 - val_loss: -180.1968\n",
      "\n",
      "Epoch 01647: loss did not improve from -175.56037\n",
      "Epoch 1648/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.4981 - val_loss: -180.6628\n",
      "\n",
      "Epoch 01648: loss did not improve from -175.56037\n",
      "Epoch 1649/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.3098 - val_loss: -180.3813\n",
      "\n",
      "Epoch 01649: loss did not improve from -175.56037\n",
      "Epoch 1650/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.3424 - val_loss: -180.5872\n",
      "\n",
      "Epoch 01650: loss did not improve from -175.56037\n",
      "Epoch 1651/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.2174 - val_loss: -180.4351\n",
      "\n",
      "Epoch 01651: loss did not improve from -175.56037\n",
      "Epoch 1652/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.0756 - val_loss: -180.3462\n",
      "\n",
      "Epoch 01652: loss did not improve from -175.56037\n",
      "Epoch 1653/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.5624 - val_loss: -180.6032\n",
      "\n",
      "Epoch 01653: loss improved from -175.56037 to -175.56238, saving model to gendance.h5\n",
      "Epoch 1654/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.2143 - val_loss: -180.5040\n",
      "\n",
      "Epoch 01654: loss did not improve from -175.56238\n",
      "Epoch 1655/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.3750 - val_loss: -180.6818\n",
      "\n",
      "Epoch 01655: loss did not improve from -175.56238\n",
      "Epoch 1656/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.3906 - val_loss: -180.5557\n",
      "\n",
      "Epoch 01656: loss did not improve from -175.56238\n",
      "Epoch 1657/2000\n",
      "16017/16017 [==============================] - 1s 54us/step - loss: -175.3070 - val_loss: -180.4864\n",
      "\n",
      "Epoch 01657: loss did not improve from -175.56238\n",
      "Epoch 1658/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.6100 - val_loss: -180.2898\n",
      "\n",
      "Epoch 01658: loss improved from -175.56238 to -175.61004, saving model to gendance.h5\n",
      "Epoch 1659/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.3301 - val_loss: -180.2996\n",
      "\n",
      "Epoch 01659: loss did not improve from -175.61004\n",
      "Epoch 1660/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.5852 - val_loss: -180.7819\n",
      "\n",
      "Epoch 01660: loss did not improve from -175.61004\n",
      "Epoch 1661/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.5040 - val_loss: -180.3427\n",
      "\n",
      "Epoch 01661: loss did not improve from -175.61004\n",
      "Epoch 1662/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.2752 - val_loss: -180.5236\n",
      "\n",
      "Epoch 01662: loss did not improve from -175.61004\n",
      "Epoch 1663/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.3758 - val_loss: -180.4747\n",
      "\n",
      "Epoch 01663: loss did not improve from -175.61004\n",
      "Epoch 1664/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.6484 - val_loss: -180.7652\n",
      "\n",
      "Epoch 01664: loss improved from -175.61004 to -175.64838, saving model to gendance.h5\n",
      "Epoch 1665/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.5769 - val_loss: -180.6494\n",
      "\n",
      "Epoch 01665: loss did not improve from -175.64838\n",
      "Epoch 1666/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.5940 - val_loss: -180.3697\n",
      "\n",
      "Epoch 01666: loss did not improve from -175.64838\n",
      "Epoch 1667/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -175.4310 - val_loss: -180.5721\n",
      "\n",
      "Epoch 01667: loss did not improve from -175.64838\n",
      "Epoch 1668/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.6069 - val_loss: -180.3951\n",
      "\n",
      "Epoch 01668: loss did not improve from -175.64838\n",
      "Epoch 1669/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.5901 - val_loss: -180.4103\n",
      "\n",
      "Epoch 01669: loss did not improve from -175.64838\n",
      "Epoch 1670/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.6262 - val_loss: -180.8803\n",
      "\n",
      "Epoch 01670: loss did not improve from -175.64838\n",
      "Epoch 1671/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.4702 - val_loss: -180.6239\n",
      "\n",
      "Epoch 01671: loss did not improve from -175.64838\n",
      "Epoch 1672/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.2720 - val_loss: -180.1059\n",
      "\n",
      "Epoch 01672: loss did not improve from -175.64838\n",
      "Epoch 1673/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.1926 - val_loss: -180.6179\n",
      "\n",
      "Epoch 01673: loss did not improve from -175.64838\n",
      "Epoch 1674/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.6088 - val_loss: -180.6730\n",
      "\n",
      "Epoch 01674: loss did not improve from -175.64838\n",
      "Epoch 1675/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.5343 - val_loss: -180.6622\n",
      "\n",
      "Epoch 01675: loss did not improve from -175.64838\n",
      "Epoch 1676/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.3680 - val_loss: -180.6403\n",
      "\n",
      "Epoch 01676: loss did not improve from -175.64838\n",
      "Epoch 1677/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.4023 - val_loss: -180.6693\n",
      "\n",
      "Epoch 01677: loss did not improve from -175.64838\n",
      "Epoch 1678/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.4420 - val_loss: -180.7134\n",
      "\n",
      "Epoch 01678: loss did not improve from -175.64838\n",
      "Epoch 1679/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.4104 - val_loss: -180.6156\n",
      "\n",
      "Epoch 01679: loss did not improve from -175.64838\n",
      "Epoch 1680/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.1663 - val_loss: -180.6652\n",
      "\n",
      "Epoch 01680: loss did not improve from -175.64838\n",
      "Epoch 1681/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.5483 - val_loss: -180.6200\n",
      "\n",
      "Epoch 01681: loss did not improve from -175.64838\n",
      "Epoch 1682/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.5063 - val_loss: -180.4850\n",
      "\n",
      "Epoch 01682: loss did not improve from -175.64838\n",
      "Epoch 1683/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.7201 - val_loss: -180.3694\n",
      "\n",
      "Epoch 01683: loss improved from -175.64838 to -175.72009, saving model to gendance.h5\n",
      "Epoch 1684/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.3139 - val_loss: -180.5320\n",
      "\n",
      "Epoch 01684: loss did not improve from -175.72009\n",
      "Epoch 1685/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.3610 - val_loss: -180.2228\n",
      "\n",
      "Epoch 01685: loss did not improve from -175.72009\n",
      "Epoch 1686/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.3272 - val_loss: -180.7041\n",
      "\n",
      "Epoch 01686: loss did not improve from -175.72009\n",
      "Epoch 1687/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.4173 - val_loss: -180.3738\n",
      "\n",
      "Epoch 01687: loss did not improve from -175.72009\n",
      "Epoch 1688/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.3806 - val_loss: -180.2469\n",
      "\n",
      "Epoch 01688: loss did not improve from -175.72009\n",
      "Epoch 1689/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.3857 - val_loss: -180.6651\n",
      "\n",
      "Epoch 01689: loss did not improve from -175.72009\n",
      "Epoch 1690/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.5428 - val_loss: -180.3915\n",
      "\n",
      "Epoch 01690: loss did not improve from -175.72009\n",
      "Epoch 1691/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.4104 - val_loss: -180.8378\n",
      "\n",
      "Epoch 01691: loss did not improve from -175.72009\n",
      "Epoch 1692/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.4596 - val_loss: -180.6291\n",
      "\n",
      "Epoch 01692: loss did not improve from -175.72009\n",
      "Epoch 1693/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.4487 - val_loss: -180.5220\n",
      "\n",
      "Epoch 01693: loss did not improve from -175.72009\n",
      "Epoch 1694/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.6012 - val_loss: -180.7008\n",
      "\n",
      "Epoch 01694: loss did not improve from -175.72009\n",
      "Epoch 1695/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.4360 - val_loss: -180.5020\n",
      "\n",
      "Epoch 01695: loss did not improve from -175.72009\n",
      "Epoch 1696/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.4586 - val_loss: -180.7946\n",
      "\n",
      "Epoch 01696: loss did not improve from -175.72009\n",
      "Epoch 1697/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -175.5171 - val_loss: -180.8927\n",
      "\n",
      "Epoch 01697: loss did not improve from -175.72009\n",
      "Epoch 1698/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.5596 - val_loss: -180.6930\n",
      "\n",
      "Epoch 01698: loss did not improve from -175.72009\n",
      "Epoch 1699/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.5199 - val_loss: -180.4766\n",
      "\n",
      "Epoch 01699: loss did not improve from -175.72009\n",
      "Epoch 1700/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.7433 - val_loss: -180.8440\n",
      "\n",
      "Epoch 01700: loss improved from -175.72009 to -175.74325, saving model to gendance.h5\n",
      "Epoch 1701/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.7784 - val_loss: -180.6365\n",
      "\n",
      "Epoch 01701: loss improved from -175.74325 to -175.77836, saving model to gendance.h5\n",
      "Epoch 1702/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.4774 - val_loss: -180.6959\n",
      "\n",
      "Epoch 01702: loss did not improve from -175.77836\n",
      "Epoch 1703/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.6774 - val_loss: -180.4854\n",
      "\n",
      "Epoch 01703: loss did not improve from -175.77836\n",
      "Epoch 1704/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.5936 - val_loss: -180.5269\n",
      "\n",
      "Epoch 01704: loss did not improve from -175.77836\n",
      "Epoch 1705/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.4832 - val_loss: -180.4962\n",
      "\n",
      "Epoch 01705: loss did not improve from -175.77836\n",
      "Epoch 1706/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.7163 - val_loss: -180.5805\n",
      "\n",
      "Epoch 01706: loss did not improve from -175.77836\n",
      "Epoch 1707/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.6821 - val_loss: -180.7557\n",
      "\n",
      "Epoch 01707: loss did not improve from -175.77836\n",
      "Epoch 1708/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.5159 - val_loss: -180.5273\n",
      "\n",
      "Epoch 01708: loss did not improve from -175.77836\n",
      "Epoch 1709/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.6474 - val_loss: -180.5858\n",
      "\n",
      "Epoch 01709: loss did not improve from -175.77836\n",
      "Epoch 1710/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -175.9226 - val_loss: -180.9259\n",
      "\n",
      "Epoch 01710: loss improved from -175.77836 to -175.92258, saving model to gendance.h5\n",
      "Epoch 1711/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.6639 - val_loss: -180.6652\n",
      "\n",
      "Epoch 01711: loss did not improve from -175.92258\n",
      "Epoch 1712/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -175.6699 - val_loss: -180.8753\n",
      "\n",
      "Epoch 01712: loss did not improve from -175.92258\n",
      "Epoch 1713/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.6421 - val_loss: -180.6216\n",
      "\n",
      "Epoch 01713: loss did not improve from -175.92258\n",
      "Epoch 1714/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.7354 - val_loss: -180.7951\n",
      "\n",
      "Epoch 01714: loss did not improve from -175.92258\n",
      "Epoch 1715/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.8111 - val_loss: -180.6787\n",
      "\n",
      "Epoch 01715: loss did not improve from -175.92258\n",
      "Epoch 1716/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.7522 - val_loss: -181.0462\n",
      "\n",
      "Epoch 01716: loss did not improve from -175.92258\n",
      "Epoch 1717/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.6443 - val_loss: -180.6905\n",
      "\n",
      "Epoch 01717: loss did not improve from -175.92258\n",
      "Epoch 1718/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.6990 - val_loss: -180.5826\n",
      "\n",
      "Epoch 01718: loss did not improve from -175.92258\n",
      "Epoch 1719/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.8717 - val_loss: -180.9985\n",
      "\n",
      "Epoch 01719: loss did not improve from -175.92258\n",
      "Epoch 1720/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.7590 - val_loss: -180.8444\n",
      "\n",
      "Epoch 01720: loss did not improve from -175.92258\n",
      "Epoch 1721/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.8109 - val_loss: -180.5656\n",
      "\n",
      "Epoch 01721: loss did not improve from -175.92258\n",
      "Epoch 1722/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.7324 - val_loss: -180.5977\n",
      "\n",
      "Epoch 01722: loss did not improve from -175.92258\n",
      "Epoch 1723/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.5380 - val_loss: -180.8975\n",
      "\n",
      "Epoch 01723: loss did not improve from -175.92258\n",
      "Epoch 1724/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.5978 - val_loss: -180.5397\n",
      "\n",
      "Epoch 01724: loss did not improve from -175.92258\n",
      "Epoch 1725/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.7968 - val_loss: -180.3915\n",
      "\n",
      "Epoch 01725: loss did not improve from -175.92258\n",
      "Epoch 1726/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.6890 - val_loss: -180.9556\n",
      "\n",
      "Epoch 01726: loss did not improve from -175.92258\n",
      "Epoch 1727/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.6879 - val_loss: -180.7232\n",
      "\n",
      "Epoch 01727: loss did not improve from -175.92258\n",
      "Epoch 1728/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.7670 - val_loss: -181.0106\n",
      "\n",
      "Epoch 01728: loss did not improve from -175.92258\n",
      "Epoch 1729/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.5378 - val_loss: -180.5328\n",
      "\n",
      "Epoch 01729: loss did not improve from -175.92258\n",
      "Epoch 1730/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.6915 - val_loss: -181.0829\n",
      "\n",
      "Epoch 01730: loss did not improve from -175.92258\n",
      "Epoch 1731/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.7692 - val_loss: -180.6116\n",
      "\n",
      "Epoch 01731: loss did not improve from -175.92258\n",
      "Epoch 1732/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -175.7992 - val_loss: -181.0631\n",
      "\n",
      "Epoch 01732: loss did not improve from -175.92258\n",
      "Epoch 1733/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.5774 - val_loss: -180.9656\n",
      "\n",
      "Epoch 01733: loss did not improve from -175.92258\n",
      "Epoch 1734/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -175.7851 - val_loss: -180.8699\n",
      "\n",
      "Epoch 01734: loss did not improve from -175.92258\n",
      "Epoch 1735/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -175.6974 - val_loss: -180.8294\n",
      "\n",
      "Epoch 01735: loss did not improve from -175.92258\n",
      "Epoch 1736/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.7625 - val_loss: -180.6694\n",
      "\n",
      "Epoch 01736: loss did not improve from -175.92258\n",
      "Epoch 1737/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.7197 - val_loss: -180.7114\n",
      "\n",
      "Epoch 01737: loss did not improve from -175.92258\n",
      "Epoch 1738/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.4858 - val_loss: -180.8498\n",
      "\n",
      "Epoch 01738: loss did not improve from -175.92258\n",
      "Epoch 1739/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.0568 - val_loss: -180.8560\n",
      "\n",
      "Epoch 01739: loss improved from -175.92258 to -176.05675, saving model to gendance.h5\n",
      "Epoch 1740/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.8416 - val_loss: -181.0624\n",
      "\n",
      "Epoch 01740: loss did not improve from -176.05675\n",
      "Epoch 1741/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.7584 - val_loss: -180.6284\n",
      "\n",
      "Epoch 01741: loss did not improve from -176.05675\n",
      "Epoch 1742/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.5557 - val_loss: -180.9480\n",
      "\n",
      "Epoch 01742: loss did not improve from -176.05675\n",
      "Epoch 1743/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.6069 - val_loss: -181.0349\n",
      "\n",
      "Epoch 01743: loss did not improve from -176.05675\n",
      "Epoch 1744/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.7906 - val_loss: -180.8126\n",
      "\n",
      "Epoch 01744: loss did not improve from -176.05675\n",
      "Epoch 1745/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -175.7066 - val_loss: -180.8083\n",
      "\n",
      "Epoch 01745: loss did not improve from -176.05675\n",
      "Epoch 1746/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.6732 - val_loss: -180.6299\n",
      "\n",
      "Epoch 01746: loss did not improve from -176.05675\n",
      "Epoch 1747/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.7625 - val_loss: -181.0110\n",
      "\n",
      "Epoch 01747: loss did not improve from -176.05675\n",
      "Epoch 1748/2000\n",
      "16017/16017 [==============================] - 1s 55us/step - loss: -175.6531 - val_loss: -180.5163\n",
      "\n",
      "Epoch 01748: loss did not improve from -176.05675\n",
      "Epoch 1749/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.7613 - val_loss: -180.6303\n",
      "\n",
      "Epoch 01749: loss did not improve from -176.05675\n",
      "Epoch 1750/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.8770 - val_loss: -180.7472\n",
      "\n",
      "Epoch 01750: loss did not improve from -176.05675\n",
      "Epoch 1751/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.9975 - val_loss: -180.8580\n",
      "\n",
      "Epoch 01751: loss did not improve from -176.05675\n",
      "Epoch 1752/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.8688 - val_loss: -181.1124\n",
      "\n",
      "Epoch 01752: loss did not improve from -176.05675\n",
      "Epoch 1753/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.9012 - val_loss: -180.9377\n",
      "\n",
      "Epoch 01753: loss did not improve from -176.05675\n",
      "Epoch 1754/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.8207 - val_loss: -180.9498\n",
      "\n",
      "Epoch 01754: loss did not improve from -176.05675\n",
      "Epoch 1755/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -175.8545 - val_loss: -180.8861\n",
      "\n",
      "Epoch 01755: loss did not improve from -176.05675\n",
      "Epoch 1756/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.7136 - val_loss: -180.8465\n",
      "\n",
      "Epoch 01756: loss did not improve from -176.05675\n",
      "Epoch 1757/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -175.8766 - val_loss: -180.8393\n",
      "\n",
      "Epoch 01757: loss did not improve from -176.05675\n",
      "Epoch 1758/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.8589 - val_loss: -180.8553\n",
      "\n",
      "Epoch 01758: loss did not improve from -176.05675\n",
      "Epoch 1759/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.9073 - val_loss: -180.8080\n",
      "\n",
      "Epoch 01759: loss did not improve from -176.05675\n",
      "Epoch 1760/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.6845 - val_loss: -180.9472\n",
      "\n",
      "Epoch 01760: loss did not improve from -176.05675\n",
      "Epoch 1761/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.9131 - val_loss: -181.0230\n",
      "\n",
      "Epoch 01761: loss did not improve from -176.05675\n",
      "Epoch 1762/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.0236 - val_loss: -180.7626\n",
      "\n",
      "Epoch 01762: loss did not improve from -176.05675\n",
      "Epoch 1763/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.9376 - val_loss: -180.9638\n",
      "\n",
      "Epoch 01763: loss did not improve from -176.05675\n",
      "Epoch 1764/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.0187 - val_loss: -181.1088\n",
      "\n",
      "Epoch 01764: loss did not improve from -176.05675\n",
      "Epoch 1765/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.9045 - val_loss: -181.0229\n",
      "\n",
      "Epoch 01765: loss did not improve from -176.05675\n",
      "Epoch 1766/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.8443 - val_loss: -180.7033\n",
      "\n",
      "Epoch 01766: loss did not improve from -176.05675\n",
      "Epoch 1767/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.7430 - val_loss: -180.8834\n",
      "\n",
      "Epoch 01767: loss did not improve from -176.05675\n",
      "Epoch 1768/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.8470 - val_loss: -180.9748\n",
      "\n",
      "Epoch 01768: loss did not improve from -176.05675\n",
      "Epoch 1769/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.8369 - val_loss: -180.8898\n",
      "\n",
      "Epoch 01769: loss did not improve from -176.05675\n",
      "Epoch 1770/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.7480 - val_loss: -180.9496\n",
      "\n",
      "Epoch 01770: loss did not improve from -176.05675\n",
      "Epoch 1771/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.1045 - val_loss: -181.0985\n",
      "\n",
      "Epoch 01771: loss improved from -176.05675 to -176.10446, saving model to gendance.h5\n",
      "Epoch 1772/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.9836 - val_loss: -181.1223\n",
      "\n",
      "Epoch 01772: loss did not improve from -176.10446\n",
      "Epoch 1773/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.0979 - val_loss: -181.1115\n",
      "\n",
      "Epoch 01773: loss did not improve from -176.10446\n",
      "Epoch 1774/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.0814 - val_loss: -180.9009\n",
      "\n",
      "Epoch 01774: loss did not improve from -176.10446\n",
      "Epoch 1775/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.8762 - val_loss: -180.9169\n",
      "\n",
      "Epoch 01775: loss did not improve from -176.10446\n",
      "Epoch 1776/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.9202 - val_loss: -181.0952\n",
      "\n",
      "Epoch 01776: loss did not improve from -176.10446\n",
      "Epoch 1777/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.9621 - val_loss: -181.0503\n",
      "\n",
      "Epoch 01777: loss did not improve from -176.10446\n",
      "Epoch 1778/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.9996 - val_loss: -181.0525\n",
      "\n",
      "Epoch 01778: loss did not improve from -176.10446\n",
      "Epoch 1779/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.8899 - val_loss: -180.9857\n",
      "\n",
      "Epoch 01779: loss did not improve from -176.10446\n",
      "Epoch 1780/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.0785 - val_loss: -181.2269\n",
      "\n",
      "Epoch 01780: loss did not improve from -176.10446\n",
      "Epoch 1781/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.9030 - val_loss: -180.8772\n",
      "\n",
      "Epoch 01781: loss did not improve from -176.10446\n",
      "Epoch 1782/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.8369 - val_loss: -181.0498\n",
      "\n",
      "Epoch 01782: loss did not improve from -176.10446\n",
      "Epoch 1783/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.8893 - val_loss: -180.8547\n",
      "\n",
      "Epoch 01783: loss did not improve from -176.10446\n",
      "Epoch 1784/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.9599 - val_loss: -181.0340\n",
      "\n",
      "Epoch 01784: loss did not improve from -176.10446\n",
      "Epoch 1785/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.9882 - val_loss: -181.0930\n",
      "\n",
      "Epoch 01785: loss did not improve from -176.10446\n",
      "Epoch 1786/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.9718 - val_loss: -181.1567\n",
      "\n",
      "Epoch 01786: loss did not improve from -176.10446\n",
      "Epoch 1787/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.7530 - val_loss: -180.5709\n",
      "\n",
      "Epoch 01787: loss did not improve from -176.10446\n",
      "Epoch 1788/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.9547 - val_loss: -181.1728\n",
      "\n",
      "Epoch 01788: loss did not improve from -176.10446\n",
      "Epoch 1789/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.9239 - val_loss: -180.8882\n",
      "\n",
      "Epoch 01789: loss did not improve from -176.10446\n",
      "Epoch 1790/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.9446 - val_loss: -181.0373\n",
      "\n",
      "Epoch 01790: loss did not improve from -176.10446\n",
      "Epoch 1791/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.9267 - val_loss: -180.9734\n",
      "\n",
      "Epoch 01791: loss did not improve from -176.10446\n",
      "Epoch 1792/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -175.8848 - val_loss: -181.0406\n",
      "\n",
      "Epoch 01792: loss did not improve from -176.10446\n",
      "Epoch 1793/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.0582 - val_loss: -181.3055\n",
      "\n",
      "Epoch 01793: loss did not improve from -176.10446\n",
      "Epoch 1794/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.2930 - val_loss: -181.3468\n",
      "\n",
      "Epoch 01794: loss improved from -176.10446 to -176.29299, saving model to gendance.h5\n",
      "Epoch 1795/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.9202 - val_loss: -180.9681\n",
      "\n",
      "Epoch 01795: loss did not improve from -176.29299\n",
      "Epoch 1796/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.0573 - val_loss: -181.1197\n",
      "\n",
      "Epoch 01796: loss did not improve from -176.29299\n",
      "Epoch 1797/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.8778 - val_loss: -180.7649\n",
      "\n",
      "Epoch 01797: loss did not improve from -176.29299\n",
      "Epoch 1798/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.8554 - val_loss: -180.8689\n",
      "\n",
      "Epoch 01798: loss did not improve from -176.29299\n",
      "Epoch 1799/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.9377 - val_loss: -181.1975\n",
      "\n",
      "Epoch 01799: loss did not improve from -176.29299\n",
      "Epoch 1800/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.0091 - val_loss: -181.1466\n",
      "\n",
      "Epoch 01800: loss did not improve from -176.29299\n",
      "Epoch 1801/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.9843 - val_loss: -181.0078\n",
      "\n",
      "Epoch 01801: loss did not improve from -176.29299\n",
      "Epoch 1802/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -176.1153 - val_loss: -180.9157\n",
      "\n",
      "Epoch 01802: loss did not improve from -176.29299\n",
      "Epoch 1803/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -175.9893 - val_loss: -180.8774\n",
      "\n",
      "Epoch 01803: loss did not improve from -176.29299\n",
      "Epoch 1804/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.9878 - val_loss: -181.0565\n",
      "\n",
      "Epoch 01804: loss did not improve from -176.29299\n",
      "Epoch 1805/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.8733 - val_loss: -180.8790\n",
      "\n",
      "Epoch 01805: loss did not improve from -176.29299\n",
      "Epoch 1806/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.2008 - val_loss: -181.3095\n",
      "\n",
      "Epoch 01806: loss did not improve from -176.29299\n",
      "Epoch 1807/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.1369 - val_loss: -180.9458\n",
      "\n",
      "Epoch 01807: loss did not improve from -176.29299\n",
      "Epoch 1808/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.0136 - val_loss: -181.1994\n",
      "\n",
      "Epoch 01808: loss did not improve from -176.29299\n",
      "Epoch 1809/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.9709 - val_loss: -181.0919\n",
      "\n",
      "Epoch 01809: loss did not improve from -176.29299\n",
      "Epoch 1810/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.1864 - val_loss: -180.9034\n",
      "\n",
      "Epoch 01810: loss did not improve from -176.29299\n",
      "Epoch 1811/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.6639 - val_loss: -181.1111\n",
      "\n",
      "Epoch 01811: loss did not improve from -176.29299\n",
      "Epoch 1812/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.9472 - val_loss: -181.0827\n",
      "\n",
      "Epoch 01812: loss did not improve from -176.29299\n",
      "Epoch 1813/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.1758 - val_loss: -181.3783\n",
      "\n",
      "Epoch 01813: loss did not improve from -176.29299\n",
      "Epoch 1814/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.1541 - val_loss: -181.3165\n",
      "\n",
      "Epoch 01814: loss did not improve from -176.29299\n",
      "Epoch 1815/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.2027 - val_loss: -181.1218\n",
      "\n",
      "Epoch 01815: loss did not improve from -176.29299\n",
      "Epoch 1816/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.1389 - val_loss: -180.7746\n",
      "\n",
      "Epoch 01816: loss did not improve from -176.29299\n",
      "Epoch 1817/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.9657 - val_loss: -181.1333\n",
      "\n",
      "Epoch 01817: loss did not improve from -176.29299\n",
      "Epoch 1818/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.0780 - val_loss: -181.0954\n",
      "\n",
      "Epoch 01818: loss did not improve from -176.29299\n",
      "Epoch 1819/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.1138 - val_loss: -181.2630\n",
      "\n",
      "Epoch 01819: loss did not improve from -176.29299\n",
      "Epoch 1820/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.0350 - val_loss: -181.0675\n",
      "\n",
      "Epoch 01820: loss did not improve from -176.29299\n",
      "Epoch 1821/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.7882 - val_loss: -181.3194\n",
      "\n",
      "Epoch 01821: loss did not improve from -176.29299\n",
      "Epoch 1822/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.1941 - val_loss: -181.4790\n",
      "\n",
      "Epoch 01822: loss did not improve from -176.29299\n",
      "Epoch 1823/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.9667 - val_loss: -180.9546\n",
      "\n",
      "Epoch 01823: loss did not improve from -176.29299\n",
      "Epoch 1824/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.8735 - val_loss: -180.8652\n",
      "\n",
      "Epoch 01824: loss did not improve from -176.29299\n",
      "Epoch 1825/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.0179 - val_loss: -181.2868\n",
      "\n",
      "Epoch 01825: loss did not improve from -176.29299\n",
      "Epoch 1826/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.1662 - val_loss: -181.0328\n",
      "\n",
      "Epoch 01826: loss did not improve from -176.29299\n",
      "Epoch 1827/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.9117 - val_loss: -181.0454\n",
      "\n",
      "Epoch 01827: loss did not improve from -176.29299\n",
      "Epoch 1828/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.1361 - val_loss: -181.2712\n",
      "\n",
      "Epoch 01828: loss did not improve from -176.29299\n",
      "Epoch 1829/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -176.3895 - val_loss: -181.3826\n",
      "\n",
      "Epoch 01829: loss improved from -176.29299 to -176.38946, saving model to gendance.h5\n",
      "Epoch 1830/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.3684 - val_loss: -181.1173\n",
      "\n",
      "Epoch 01830: loss did not improve from -176.38946\n",
      "Epoch 1831/2000\n",
      "16017/16017 [==============================] - 1s 56us/step - loss: -176.0278 - val_loss: -181.2753\n",
      "\n",
      "Epoch 01831: loss did not improve from -176.38946\n",
      "Epoch 1832/2000\n",
      "16017/16017 [==============================] - 1s 55us/step - loss: -175.9624 - val_loss: -181.2864\n",
      "\n",
      "Epoch 01832: loss did not improve from -176.38946\n",
      "Epoch 1833/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.1271 - val_loss: -181.0787\n",
      "\n",
      "Epoch 01833: loss did not improve from -176.38946\n",
      "Epoch 1834/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.0580 - val_loss: -181.1700\n",
      "\n",
      "Epoch 01834: loss did not improve from -176.38946\n",
      "Epoch 1835/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.2461 - val_loss: -181.3888\n",
      "\n",
      "Epoch 01835: loss did not improve from -176.38946\n",
      "Epoch 1836/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.2979 - val_loss: -181.3418\n",
      "\n",
      "Epoch 01836: loss did not improve from -176.38946\n",
      "Epoch 1837/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.0876 - val_loss: -181.1545\n",
      "\n",
      "Epoch 01837: loss did not improve from -176.38946\n",
      "Epoch 1838/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.3024 - val_loss: -181.2977\n",
      "\n",
      "Epoch 01838: loss did not improve from -176.38946\n",
      "Epoch 1839/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.0290 - val_loss: -181.2278\n",
      "\n",
      "Epoch 01839: loss did not improve from -176.38946\n",
      "Epoch 1840/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.0630 - val_loss: -181.0655\n",
      "\n",
      "Epoch 01840: loss did not improve from -176.38946\n",
      "Epoch 1841/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.0655 - val_loss: -181.1276\n",
      "\n",
      "Epoch 01841: loss did not improve from -176.38946\n",
      "Epoch 1842/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.1288 - val_loss: -181.0130\n",
      "\n",
      "Epoch 01842: loss did not improve from -176.38946\n",
      "Epoch 1843/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.0384 - val_loss: -181.1034\n",
      "\n",
      "Epoch 01843: loss did not improve from -176.38946\n",
      "Epoch 1844/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.9330 - val_loss: -180.8804\n",
      "\n",
      "Epoch 01844: loss did not improve from -176.38946\n",
      "Epoch 1845/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.9369 - val_loss: -181.2083\n",
      "\n",
      "Epoch 01845: loss did not improve from -176.38946\n",
      "Epoch 1846/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.9204 - val_loss: -181.1863\n",
      "\n",
      "Epoch 01846: loss did not improve from -176.38946\n",
      "Epoch 1847/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.2530 - val_loss: -181.5203\n",
      "\n",
      "Epoch 01847: loss did not improve from -176.38946\n",
      "Epoch 1848/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -176.1357 - val_loss: -181.2431\n",
      "\n",
      "Epoch 01848: loss did not improve from -176.38946\n",
      "Epoch 1849/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.2001 - val_loss: -181.0811\n",
      "\n",
      "Epoch 01849: loss did not improve from -176.38946\n",
      "Epoch 1850/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -176.2963 - val_loss: -181.3267\n",
      "\n",
      "Epoch 01850: loss did not improve from -176.38946\n",
      "Epoch 1851/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.0643 - val_loss: -181.2466\n",
      "\n",
      "Epoch 01851: loss did not improve from -176.38946\n",
      "Epoch 1852/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.2096 - val_loss: -181.2447\n",
      "\n",
      "Epoch 01852: loss did not improve from -176.38946\n",
      "Epoch 1853/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.1581 - val_loss: -181.0991\n",
      "\n",
      "Epoch 01853: loss did not improve from -176.38946\n",
      "Epoch 1854/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.4078 - val_loss: -181.4070\n",
      "\n",
      "Epoch 01854: loss improved from -176.38946 to -176.40776, saving model to gendance.h5\n",
      "Epoch 1855/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.2621 - val_loss: -180.9667\n",
      "\n",
      "Epoch 01855: loss did not improve from -176.40776\n",
      "Epoch 1856/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -176.3135 - val_loss: -181.0685\n",
      "\n",
      "Epoch 01856: loss did not improve from -176.40776\n",
      "Epoch 1857/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.1126 - val_loss: -181.1918\n",
      "\n",
      "Epoch 01857: loss did not improve from -176.40776\n",
      "Epoch 1858/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.1167 - val_loss: -181.3950\n",
      "\n",
      "Epoch 01858: loss did not improve from -176.40776\n",
      "Epoch 1859/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.0961 - val_loss: -181.0924\n",
      "\n",
      "Epoch 01859: loss did not improve from -176.40776\n",
      "Epoch 1860/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -176.1566 - val_loss: -181.4083\n",
      "\n",
      "Epoch 01860: loss did not improve from -176.40776\n",
      "Epoch 1861/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -176.1920 - val_loss: -181.2247\n",
      "\n",
      "Epoch 01861: loss did not improve from -176.40776\n",
      "Epoch 1862/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.1047 - val_loss: -181.1541\n",
      "\n",
      "Epoch 01862: loss did not improve from -176.40776\n",
      "Epoch 1863/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -176.2641 - val_loss: -181.3100\n",
      "\n",
      "Epoch 01863: loss did not improve from -176.40776\n",
      "Epoch 1864/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.2961 - val_loss: -181.2885\n",
      "\n",
      "Epoch 01864: loss did not improve from -176.40776\n",
      "Epoch 1865/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.2189 - val_loss: -180.8927\n",
      "\n",
      "Epoch 01865: loss did not improve from -176.40776\n",
      "Epoch 1866/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.5669 - val_loss: -181.1712\n",
      "\n",
      "Epoch 01866: loss improved from -176.40776 to -176.56695, saving model to gendance.h5\n",
      "Epoch 1867/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.1835 - val_loss: -181.4590\n",
      "\n",
      "Epoch 01867: loss did not improve from -176.56695\n",
      "Epoch 1868/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.2721 - val_loss: -181.3532\n",
      "\n",
      "Epoch 01868: loss did not improve from -176.56695\n",
      "Epoch 1869/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.1731 - val_loss: -181.4564\n",
      "\n",
      "Epoch 01869: loss did not improve from -176.56695\n",
      "Epoch 1870/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.2373 - val_loss: -181.3819\n",
      "\n",
      "Epoch 01870: loss did not improve from -176.56695\n",
      "Epoch 1871/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -175.9184 - val_loss: -180.8897\n",
      "\n",
      "Epoch 01871: loss did not improve from -176.56695\n",
      "Epoch 1872/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.1836 - val_loss: -181.3593\n",
      "\n",
      "Epoch 01872: loss did not improve from -176.56695\n",
      "Epoch 1873/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.4346 - val_loss: -181.4092\n",
      "\n",
      "Epoch 01873: loss did not improve from -176.56695\n",
      "Epoch 1874/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.4623 - val_loss: -181.3874\n",
      "\n",
      "Epoch 01874: loss did not improve from -176.56695\n",
      "Epoch 1875/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.3306 - val_loss: -181.3232\n",
      "\n",
      "Epoch 01875: loss did not improve from -176.56695\n",
      "Epoch 1876/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.2862 - val_loss: -181.1944\n",
      "\n",
      "Epoch 01876: loss did not improve from -176.56695\n",
      "Epoch 1877/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.2366 - val_loss: -181.0648\n",
      "\n",
      "Epoch 01877: loss did not improve from -176.56695\n",
      "Epoch 1878/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.3716 - val_loss: -181.1672\n",
      "\n",
      "Epoch 01878: loss did not improve from -176.56695\n",
      "Epoch 1879/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.2860 - val_loss: -181.2346\n",
      "\n",
      "Epoch 01879: loss did not improve from -176.56695\n",
      "Epoch 1880/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.3575 - val_loss: -181.1403\n",
      "\n",
      "Epoch 01880: loss did not improve from -176.56695\n",
      "Epoch 1881/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.1848 - val_loss: -181.3338\n",
      "\n",
      "Epoch 01881: loss did not improve from -176.56695\n",
      "Epoch 1882/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -176.2334 - val_loss: -181.1882\n",
      "\n",
      "Epoch 01882: loss did not improve from -176.56695\n",
      "Epoch 1883/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.1740 - val_loss: -181.2696\n",
      "\n",
      "Epoch 01883: loss did not improve from -176.56695\n",
      "Epoch 1884/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.4879 - val_loss: -181.3815\n",
      "\n",
      "Epoch 01884: loss did not improve from -176.56695\n",
      "Epoch 1885/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.4954 - val_loss: -181.3307\n",
      "\n",
      "Epoch 01885: loss did not improve from -176.56695\n",
      "Epoch 1886/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.2868 - val_loss: -181.5295\n",
      "\n",
      "Epoch 01886: loss did not improve from -176.56695\n",
      "Epoch 1887/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.2783 - val_loss: -181.3581\n",
      "\n",
      "Epoch 01887: loss did not improve from -176.56695\n",
      "Epoch 1888/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.4687 - val_loss: -181.3279\n",
      "\n",
      "Epoch 01888: loss did not improve from -176.56695\n",
      "Epoch 1889/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.4428 - val_loss: -181.6539\n",
      "\n",
      "Epoch 01889: loss did not improve from -176.56695\n",
      "Epoch 1890/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.3252 - val_loss: -181.5474\n",
      "\n",
      "Epoch 01890: loss did not improve from -176.56695\n",
      "Epoch 1891/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.4930 - val_loss: -181.3550\n",
      "\n",
      "Epoch 01891: loss did not improve from -176.56695\n",
      "Epoch 1892/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.4439 - val_loss: -181.4319\n",
      "\n",
      "Epoch 01892: loss did not improve from -176.56695\n",
      "Epoch 1893/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.2710 - val_loss: -181.5943\n",
      "\n",
      "Epoch 01893: loss did not improve from -176.56695\n",
      "Epoch 1894/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -176.2719 - val_loss: -181.5609\n",
      "\n",
      "Epoch 01894: loss did not improve from -176.56695\n",
      "Epoch 1895/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.4831 - val_loss: -181.5536\n",
      "\n",
      "Epoch 01895: loss did not improve from -176.56695\n",
      "Epoch 1896/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.3081 - val_loss: -181.4270\n",
      "\n",
      "Epoch 01896: loss did not improve from -176.56695\n",
      "Epoch 1897/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.5318 - val_loss: -181.3613\n",
      "\n",
      "Epoch 01897: loss did not improve from -176.56695\n",
      "Epoch 1898/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.4336 - val_loss: -181.4845\n",
      "\n",
      "Epoch 01898: loss did not improve from -176.56695\n",
      "Epoch 1899/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.6017 - val_loss: -181.4306\n",
      "\n",
      "Epoch 01899: loss improved from -176.56695 to -176.60166, saving model to gendance.h5\n",
      "Epoch 1900/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.3444 - val_loss: -181.7140\n",
      "\n",
      "Epoch 01900: loss did not improve from -176.60166\n",
      "Epoch 1901/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -176.3175 - val_loss: -181.1969\n",
      "\n",
      "Epoch 01901: loss did not improve from -176.60166\n",
      "Epoch 1902/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.2755 - val_loss: -181.4130\n",
      "\n",
      "Epoch 01902: loss did not improve from -176.60166\n",
      "Epoch 1903/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.4166 - val_loss: -181.5192\n",
      "\n",
      "Epoch 01903: loss did not improve from -176.60166\n",
      "Epoch 1904/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.4439 - val_loss: -181.3854\n",
      "\n",
      "Epoch 01904: loss did not improve from -176.60166\n",
      "Epoch 1905/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.4552 - val_loss: -181.2601\n",
      "\n",
      "Epoch 01905: loss did not improve from -176.60166\n",
      "Epoch 1906/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.4762 - val_loss: -181.4965\n",
      "\n",
      "Epoch 01906: loss did not improve from -176.60166\n",
      "Epoch 1907/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.4470 - val_loss: -181.4836\n",
      "\n",
      "Epoch 01907: loss did not improve from -176.60166\n",
      "Epoch 1908/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.4033 - val_loss: -181.3343\n",
      "\n",
      "Epoch 01908: loss did not improve from -176.60166\n",
      "Epoch 1909/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.5595 - val_loss: -181.5589\n",
      "\n",
      "Epoch 01909: loss did not improve from -176.60166\n",
      "Epoch 1910/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.4132 - val_loss: -181.6768\n",
      "\n",
      "Epoch 01910: loss did not improve from -176.60166\n",
      "Epoch 1911/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -176.5499 - val_loss: -181.4781\n",
      "\n",
      "Epoch 01911: loss did not improve from -176.60166\n",
      "Epoch 1912/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -176.1853 - val_loss: -181.5832\n",
      "\n",
      "Epoch 01912: loss did not improve from -176.60166\n",
      "Epoch 1913/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.5589 - val_loss: -181.3154\n",
      "\n",
      "Epoch 01913: loss did not improve from -176.60166\n",
      "Epoch 1914/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.2283 - val_loss: -181.0945\n",
      "\n",
      "Epoch 01914: loss did not improve from -176.60166\n",
      "Epoch 1915/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.5474 - val_loss: -181.6231\n",
      "\n",
      "Epoch 01915: loss did not improve from -176.60166\n",
      "Epoch 1916/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.4204 - val_loss: -181.5868\n",
      "\n",
      "Epoch 01916: loss did not improve from -176.60166\n",
      "Epoch 1917/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.7663 - val_loss: -181.6693\n",
      "\n",
      "Epoch 01917: loss improved from -176.60166 to -176.76629, saving model to gendance.h5\n",
      "Epoch 1918/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.4558 - val_loss: -181.4069\n",
      "\n",
      "Epoch 01918: loss did not improve from -176.76629\n",
      "Epoch 1919/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.3653 - val_loss: -181.5749\n",
      "\n",
      "Epoch 01919: loss did not improve from -176.76629\n",
      "Epoch 1920/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.5056 - val_loss: -181.1184\n",
      "\n",
      "Epoch 01920: loss did not improve from -176.76629\n",
      "Epoch 1921/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.4918 - val_loss: -181.7037\n",
      "\n",
      "Epoch 01921: loss did not improve from -176.76629\n",
      "Epoch 1922/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -176.3322 - val_loss: -181.4956\n",
      "\n",
      "Epoch 01922: loss did not improve from -176.76629\n",
      "Epoch 1923/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.6050 - val_loss: -181.4537\n",
      "\n",
      "Epoch 01923: loss did not improve from -176.76629\n",
      "Epoch 1924/2000\n",
      "16017/16017 [==============================] - 1s 53us/step - loss: -176.3204 - val_loss: -181.5631\n",
      "\n",
      "Epoch 01924: loss did not improve from -176.76629\n",
      "Epoch 1925/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.5333 - val_loss: -181.5794\n",
      "\n",
      "Epoch 01925: loss did not improve from -176.76629\n",
      "Epoch 1926/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.5850 - val_loss: -181.4807\n",
      "\n",
      "Epoch 01926: loss did not improve from -176.76629\n",
      "Epoch 1927/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.4637 - val_loss: -181.5418\n",
      "\n",
      "Epoch 01927: loss did not improve from -176.76629\n",
      "Epoch 1928/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.3679 - val_loss: -181.6148\n",
      "\n",
      "Epoch 01928: loss did not improve from -176.76629\n",
      "Epoch 1929/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.5551 - val_loss: -181.6739\n",
      "\n",
      "Epoch 01929: loss did not improve from -176.76629\n",
      "Epoch 1930/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.7044 - val_loss: -181.6162\n",
      "\n",
      "Epoch 01930: loss did not improve from -176.76629\n",
      "Epoch 1931/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.5322 - val_loss: -181.5050\n",
      "\n",
      "Epoch 01931: loss did not improve from -176.76629\n",
      "Epoch 1932/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.5651 - val_loss: -181.2374\n",
      "\n",
      "Epoch 01932: loss did not improve from -176.76629\n",
      "Epoch 1933/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.7613 - val_loss: -181.7481\n",
      "\n",
      "Epoch 01933: loss did not improve from -176.76629\n",
      "Epoch 1934/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.6018 - val_loss: -181.6865\n",
      "\n",
      "Epoch 01934: loss did not improve from -176.76629\n",
      "Epoch 1935/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.6579 - val_loss: -181.5099\n",
      "\n",
      "Epoch 01935: loss did not improve from -176.76629\n",
      "Epoch 1936/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.6013 - val_loss: -181.7720\n",
      "\n",
      "Epoch 01936: loss did not improve from -176.76629\n",
      "Epoch 1937/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.8439 - val_loss: -181.4878\n",
      "\n",
      "Epoch 01937: loss improved from -176.76629 to -176.84389, saving model to gendance.h5\n",
      "Epoch 1938/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.5426 - val_loss: -181.6850\n",
      "\n",
      "Epoch 01938: loss did not improve from -176.84389\n",
      "Epoch 1939/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -176.7330 - val_loss: -181.6945\n",
      "\n",
      "Epoch 01939: loss did not improve from -176.84389\n",
      "Epoch 1940/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.5089 - val_loss: -181.5768\n",
      "\n",
      "Epoch 01940: loss did not improve from -176.84389\n",
      "Epoch 1941/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.3172 - val_loss: -181.5868\n",
      "\n",
      "Epoch 01941: loss did not improve from -176.84389\n",
      "Epoch 1942/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.5116 - val_loss: -181.6077\n",
      "\n",
      "Epoch 01942: loss did not improve from -176.84389\n",
      "Epoch 1943/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.5961 - val_loss: -181.6766\n",
      "\n",
      "Epoch 01943: loss did not improve from -176.84389\n",
      "Epoch 1944/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.6349 - val_loss: -181.6989\n",
      "\n",
      "Epoch 01944: loss did not improve from -176.84389\n",
      "Epoch 1945/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.5191 - val_loss: -181.7311\n",
      "\n",
      "Epoch 01945: loss did not improve from -176.84389\n",
      "Epoch 1946/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.7677 - val_loss: -181.5675\n",
      "\n",
      "Epoch 01946: loss did not improve from -176.84389\n",
      "Epoch 1947/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.4458 - val_loss: -181.5748\n",
      "\n",
      "Epoch 01947: loss did not improve from -176.84389\n",
      "Epoch 1948/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.6340 - val_loss: -181.7145\n",
      "\n",
      "Epoch 01948: loss did not improve from -176.84389\n",
      "Epoch 1949/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.6924 - val_loss: -181.5541\n",
      "\n",
      "Epoch 01949: loss did not improve from -176.84389\n",
      "Epoch 1950/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.5247 - val_loss: -181.5831\n",
      "\n",
      "Epoch 01950: loss did not improve from -176.84389\n",
      "Epoch 1951/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.6997 - val_loss: -181.4985\n",
      "\n",
      "Epoch 01951: loss did not improve from -176.84389\n",
      "Epoch 1952/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -176.4021 - val_loss: -181.5591\n",
      "\n",
      "Epoch 01952: loss did not improve from -176.84389\n",
      "Epoch 1953/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.8151 - val_loss: -181.9051\n",
      "\n",
      "Epoch 01953: loss did not improve from -176.84389\n",
      "Epoch 1954/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.6006 - val_loss: -181.6271\n",
      "\n",
      "Epoch 01954: loss did not improve from -176.84389\n",
      "Epoch 1955/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.5525 - val_loss: -181.6435\n",
      "\n",
      "Epoch 01955: loss did not improve from -176.84389\n",
      "Epoch 1956/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.6775 - val_loss: -181.9633\n",
      "\n",
      "Epoch 01956: loss did not improve from -176.84389\n",
      "Epoch 1957/2000\n",
      "16017/16017 [==============================] - 1s 53us/step - loss: -176.4445 - val_loss: -181.3749\n",
      "\n",
      "Epoch 01957: loss did not improve from -176.84389\n",
      "Epoch 1958/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.6151 - val_loss: -181.5897\n",
      "\n",
      "Epoch 01958: loss did not improve from -176.84389\n",
      "Epoch 1959/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.6584 - val_loss: -181.7643\n",
      "\n",
      "Epoch 01959: loss did not improve from -176.84389\n",
      "Epoch 1960/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.6931 - val_loss: -181.7316\n",
      "\n",
      "Epoch 01960: loss did not improve from -176.84389\n",
      "Epoch 1961/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -176.4175 - val_loss: -181.6354\n",
      "\n",
      "Epoch 01961: loss did not improve from -176.84389\n",
      "Epoch 1962/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.6838 - val_loss: -181.6595\n",
      "\n",
      "Epoch 01962: loss did not improve from -176.84389\n",
      "Epoch 1963/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.4664 - val_loss: -181.4003\n",
      "\n",
      "Epoch 01963: loss did not improve from -176.84389\n",
      "Epoch 1964/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.6025 - val_loss: -181.6030\n",
      "\n",
      "Epoch 01964: loss did not improve from -176.84389\n",
      "Epoch 1965/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.6097 - val_loss: -181.6897\n",
      "\n",
      "Epoch 01965: loss did not improve from -176.84389\n",
      "Epoch 1966/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -176.6511 - val_loss: -181.5816\n",
      "\n",
      "Epoch 01966: loss did not improve from -176.84389\n",
      "Epoch 1967/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.7913 - val_loss: -181.6788\n",
      "\n",
      "Epoch 01967: loss did not improve from -176.84389\n",
      "Epoch 1968/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.6678 - val_loss: -181.7534\n",
      "\n",
      "Epoch 01968: loss did not improve from -176.84389\n",
      "Epoch 1969/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.8459 - val_loss: -181.7450\n",
      "\n",
      "Epoch 01969: loss improved from -176.84389 to -176.84591, saving model to gendance.h5\n",
      "Epoch 1970/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.3759 - val_loss: -181.7282\n",
      "\n",
      "Epoch 01970: loss did not improve from -176.84591\n",
      "Epoch 1971/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.8211 - val_loss: -181.4988\n",
      "\n",
      "Epoch 01971: loss did not improve from -176.84591\n",
      "Epoch 1972/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.7800 - val_loss: -181.8513\n",
      "\n",
      "Epoch 01972: loss did not improve from -176.84591\n",
      "Epoch 1973/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.6860 - val_loss: -181.6242\n",
      "\n",
      "Epoch 01973: loss did not improve from -176.84591\n",
      "Epoch 1974/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.6672 - val_loss: -181.7937\n",
      "\n",
      "Epoch 01974: loss did not improve from -176.84591\n",
      "Epoch 1975/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.7067 - val_loss: -181.8697\n",
      "\n",
      "Epoch 01975: loss did not improve from -176.84591\n",
      "Epoch 1976/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.6196 - val_loss: -181.8131\n",
      "\n",
      "Epoch 01976: loss did not improve from -176.84591\n",
      "Epoch 1977/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.6499 - val_loss: -181.6674\n",
      "\n",
      "Epoch 01977: loss did not improve from -176.84591\n",
      "Epoch 1978/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.6023 - val_loss: -181.7810\n",
      "\n",
      "Epoch 01978: loss did not improve from -176.84591\n",
      "Epoch 1979/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.6910 - val_loss: -181.8046\n",
      "\n",
      "Epoch 01979: loss did not improve from -176.84591\n",
      "Epoch 1980/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.6137 - val_loss: -181.2983\n",
      "\n",
      "Epoch 01980: loss did not improve from -176.84591\n",
      "Epoch 1981/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.7429 - val_loss: -181.8371\n",
      "\n",
      "Epoch 01981: loss did not improve from -176.84591\n",
      "Epoch 1982/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.7812 - val_loss: -181.4970\n",
      "\n",
      "Epoch 01982: loss did not improve from -176.84591\n",
      "Epoch 1983/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.5907 - val_loss: -181.7213\n",
      "\n",
      "Epoch 01983: loss did not improve from -176.84591\n",
      "Epoch 1984/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.8305 - val_loss: -181.8651\n",
      "\n",
      "Epoch 01984: loss did not improve from -176.84591\n",
      "Epoch 1985/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.4402 - val_loss: -181.5964\n",
      "\n",
      "Epoch 01985: loss did not improve from -176.84591\n",
      "Epoch 1986/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.4061 - val_loss: -181.5940\n",
      "\n",
      "Epoch 01986: loss did not improve from -176.84591\n",
      "Epoch 1987/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -176.6302 - val_loss: -181.7708\n",
      "\n",
      "Epoch 01987: loss did not improve from -176.84591\n",
      "Epoch 1988/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.8997 - val_loss: -181.9627\n",
      "\n",
      "Epoch 01988: loss improved from -176.84591 to -176.89966, saving model to gendance.h5\n",
      "Epoch 1989/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.7309 - val_loss: -181.4594\n",
      "\n",
      "Epoch 01989: loss did not improve from -176.89966\n",
      "Epoch 1990/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.5870 - val_loss: -181.8112\n",
      "\n",
      "Epoch 01990: loss did not improve from -176.89966\n",
      "Epoch 1991/2000\n",
      "16017/16017 [==============================] - 1s 51us/step - loss: -176.5549 - val_loss: -181.6697\n",
      "\n",
      "Epoch 01991: loss did not improve from -176.89966\n",
      "Epoch 1992/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.7019 - val_loss: -181.8501\n",
      "\n",
      "Epoch 01992: loss did not improve from -176.89966\n",
      "Epoch 1993/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.6946 - val_loss: -181.5489\n",
      "\n",
      "Epoch 01993: loss did not improve from -176.89966\n",
      "Epoch 1994/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.5166 - val_loss: -181.8396\n",
      "\n",
      "Epoch 01994: loss did not improve from -176.89966\n",
      "Epoch 1995/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.7292 - val_loss: -181.9019\n",
      "\n",
      "Epoch 01995: loss did not improve from -176.89966\n",
      "Epoch 1996/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.7072 - val_loss: -181.4566\n",
      "\n",
      "Epoch 01996: loss did not improve from -176.89966\n",
      "Epoch 1997/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.6707 - val_loss: -181.7491\n",
      "\n",
      "Epoch 01997: loss did not improve from -176.89966\n",
      "Epoch 1998/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.8982 - val_loss: -181.9404\n",
      "\n",
      "Epoch 01998: loss did not improve from -176.89966\n",
      "Epoch 1999/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.8694 - val_loss: -181.6236\n",
      "\n",
      "Epoch 01999: loss did not improve from -176.89966\n",
      "Epoch 2000/2000\n",
      "16017/16017 [==============================] - 1s 52us/step - loss: -176.8478 - val_loss: -181.8196\n",
      "\n",
      "Epoch 02000: loss did not improve from -176.89966\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc1cc8e09b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data[0:len(data)-1]\n",
    "Y = data[1:len(data)]\n",
    "checkpoint = keras.callbacks.ModelCheckpoint('gendance.h5', monitor='loss', verbose=1, save_best_only=True, mode='auto')\n",
    "callbacks_list = [checkpoint]\n",
    "model.fit(X,Y,batch_size=512, verbose=1, validation_split=0.20, epochs=2000, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 120, 208, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 120, 208, 128 1280        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 60, 104, 128) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 60, 104, 64)  73792       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 30, 52, 64)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 30, 52, 32)   18464       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 15, 26, 32)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 12480)        0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          1597568     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          16512       dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          16512       dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "z (Lambda)                      (None, 128)          0           dense_2[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,724,128\n",
      "Trainable params: 1,724,128\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "z_sampling (InputLayer)      (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 12480)             1609920   \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 15, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 15, 26, 128)       4224      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 15, 26, 32)        36896     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 30, 52, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 30, 52, 64)        18496     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 60, 104, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 60, 104, 128)      73856     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 120, 208, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 120, 208, 1)       1153      \n",
      "=================================================================\n",
      "Total params: 1,744,545\n",
      "Trainable params: 1,744,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(?, 120, 208, 1)\n"
     ]
    }
   ],
   "source": [
    "from model import decoder,vae\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.load_weights(\"vae_cnn.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"gendance.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "video = cv2.VideoWriter(\"out.mp4\", fourcc, 30.0, (208, 120))\n",
    "lv_in = data[0]\n",
    "for i in range(1000):\n",
    "    input = np.array(lv_in).reshape(1,128)\n",
    "    lv_out = model.predict(input)\n",
    "    shape = np.array(lv_out).shape[1]\n",
    "    lv_out = np.array(lv_out).reshape(shape)\n",
    "    lv_out = mdn.sample_from_output(lv_out,128,numComponents,temp=0.06)\n",
    "    lv_out = scaler.inverse_transform(lv_out)\n",
    "    img = decoder.predict(np.array(lv_out).reshape(1,128))\n",
    "    \n",
    "    img = np.array(img).reshape(120,208,1)\n",
    "    img = img * 255\n",
    "    img = np.array(img).astype(\"uint8\")\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_GRAY2RGB)\n",
    "    lv_in = lv_out\n",
    "    video.write(img)\n",
    "video.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
